Airbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases. This loader exposes the Gong connector as a document loader, allowing you to load various Gong objects as documents. First, you need to install the airbyte-source-gong python package. Check out the Airbyte documentation page for details about how to configure the reader. The JSON schema the config object should adhere to can be found on Github: https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-gong/source_gong/spec.yaml. The general shape looks like this: By default all fields are stored as metadata in the documents and the text is set to an empty string. Construct the text of the document by transforming the documents returned by the reader. Now you can load documents the usual way As load returns a list, it will block until all documents are loaded. To have better control over this process, you can also you the lazy_load method which returns an iterator instead: Keep in mind that by default the page content is empty and the metadata object contains all the information from the record. To process documents, create a class inheriting from the base loader and implement the _handle_records method yourself: Some streams allow incremental loading, this means the source keeps track of synced records and won't load them again. This is useful for sources that have a high volume of data and are updated frequently. To take advantage of this, store the last_state property of the loader and pass it in when creating the loader again. This will ensure that only new records are loaded. IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Callbacks Chat models Chat loaders Document loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcripts Etherscan Loader acreom Airbyte CDK Airbyte Gong Airbyte Hubspot Airbyte JSON Airbyte Salesforce Airbyte Shopify Airbyte Stripe Airbyte Typeform Airbyte Zendesk Support Airtable Alibaba Cloud MaxCompute Apify Dataset ArcGIS Arxiv AssemblyAI Audio Transcripts Async Chromium AsyncHtmlLoader AWS S3 Directory AWS S3 File AZLyrics Azure Blob Storage Container Azure Blob Storage File Azure Document Intelligence BibTeX BiliBili Blackboard Blockchain Brave Search Browserless ChatGPT Data College Confidential Concurrent Loader Confluence CoNLL-U Copy Paste CSV Cube Semantic Layer Datadog Logs Diffbot Discord Docugami Dropbox DuckDB Email Embaas EPub EverNote example_data Microsoft Excel Facebook Chat Fauna Figma Geopandas Git GitBook GitHub Google BigQuery Google Cloud Storage Directory Google Cloud Storage File Google Drive Grobid Gutenberg Hacker News Huawei OBS Directory Huawei OBS File HuggingFace dataset iFixit Images Image captions IMSDb Iugu Joplin Jupyter Notebook LarkSuite (FeiShu) Mastodon MediaWikiDump MergeDocLoader mhtml Microsoft OneDrive Microsoft PowerPoint Microsoft SharePoint Microsoft Word Modern Treasury News URL Notion DB 1/2 Notion DB 2/2 Nuclia Understanding API document loader Obsidian Open Document Format (ODT) Open City Data Org-mode Pandas DataFrame Amazon Textract Polars DataFrame Psychic PubMed PySpark DataFrame Loader ReadTheDocs Documentation Recursive URL Loader Reddit Roam Rockset RSS Feeds RST Sitemap Slack Snowflake Source Code Spreedly Stripe Subtitle Telegram Tencent COS Directory Tencent COS File TensorFlow Datasets 2Markdown TOML Trello TSV Twitter Unstructured File URL Weather WebBaseLoader WhatsApp Chat Wikipedia XML Xorbits Pandas DataFrame Loading documents from a YouTube url YouTube transcripts Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations Document loaders Airbyte Gong AirbyteGongLoader Document Installation Example Incremental loads Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsDocument loadersAirbyte GongOn this pageAirbyte GongAirbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.This loader exposes the Gong connector as a document loader, allowing you to load various Gong objects as documents.Installation‚ÄãFirst, you need to install the airbyte-source-gong python package.#!pip install airbyte-source-gongExample‚ÄãCheck out the Airbyte documentation page for details about how to configure the reader. The JSON schema the config object should adhere to can be found on Github: https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-gong/source_gong/spec.yaml.The general shape looks like this:{  "access_key": "<access key name>",  "access_key_secret": "<access key secret>",  "start_date": "<date from which to start retrieving records from in ISO format, e.g. 2020-10-20T00:00:00Z>",}By default all fields are stored as metadata in the documents and the text is set to an empty string. Construct the text of the document by transforming the documents returned by the reader.from langchain.document_loaders.airbyte import AirbyteGongLoaderconfig = {    # your gong configuration}loader = AirbyteGongLoader(config=config, stream_name="calls") # check the documentation linked above for a list of all streamsAPI Reference:AirbyteGongLoaderNow you can load documents the usual waydocs = loader.load()As load returns a list, it will block until all documents are loaded. To have better control over this process, you can also you the lazy_load method which returns an iterator instead:docs_iterator = loader.lazy_load()Keep in mind that by default the page content is empty and the metadata object contains all the information from the record. To process documents, create a class inheriting from the base loader and implement the _handle_records method yourself:from langchain.docstore.document import Documentdef handle_record(record, id):    return Document(page_content=record.data["title"], metadata=record.data)loader = AirbyteGongLoader(config=config, record_handler=handle_record, stream_name="calls")docs = loader.load()API Reference:DocumentIncremental loads‚ÄãSome streams allow incremental loading, this means the source keeps track of synced records and won't load them again. This is useful for sources that have a high volume of data and are updated frequently.To take advantage of this, store the last_state property of the loader and pass it in when creating the loader again. This will ensure that only new records are loaded.last_state = loader.last_state # store safelyincremental_loader = AirbyteGongLoader(config=config, stream_name="calls", state=last_state)new_docs = incremental_loader.load()PreviousAirbyte CDKNextAirbyte HubspotInstallationExampleIncremental loadsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsDocument loadersAirbyte GongOn this pageAirbyte GongAirbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.This loader exposes the Gong connector as a document loader, allowing you to load various Gong objects as documents.Installation‚ÄãFirst, you need to install the airbyte-source-gong python package.#!pip install airbyte-source-gongExample‚ÄãCheck out the Airbyte documentation page for details about how to configure the reader. The JSON schema the config object should adhere to can be found on Github: https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-gong/source_gong/spec.yaml.The general shape looks like this:{  "access_key": "<access key name>",  "access_key_secret": "<access key secret>",  "start_date": "<date from which to start retrieving records from in ISO format, e.g. 2020-10-20T00:00:00Z>",}By default all fields are stored as metadata in the documents and the text is set to an empty string. Construct the text of the document by transforming the documents returned by the reader.from langchain.document_loaders.airbyte import AirbyteGongLoaderconfig = {    # your gong configuration}loader = AirbyteGongLoader(config=config, stream_name="calls") # check the documentation linked above for a list of all streamsAPI Reference:AirbyteGongLoaderNow you can load documents the usual waydocs = loader.load()As load returns a list, it will block until all documents are loaded. To have better control over this process, you can also you the lazy_load method which returns an iterator instead:docs_iterator = loader.lazy_load()Keep in mind that by default the page content is empty and the metadata object contains all the information from the record. To process documents, create a class inheriting from the base loader and implement the _handle_records method yourself:from langchain.docstore.document import Documentdef handle_record(record, id):    return Document(page_content=record.data["title"], metadata=record.data)loader = AirbyteGongLoader(config=config, record_handler=handle_record, stream_name="calls")docs = loader.load()API Reference:DocumentIncremental loads‚ÄãSome streams allow incremental loading, this means the source keeps track of synced records and won't load them again. This is useful for sources that have a high volume of data and are updated frequently.To take advantage of this, store the last_state property of the loader and pass it in when creating the loader again. This will ensure that only new records are loaded.last_state = loader.last_state # store safelyincremental_loader = AirbyteGongLoader(config=config, stream_name="calls", state=last_state)new_docs = incremental_loader.load()PreviousAirbyte CDKNextAirbyte HubspotInstallationExampleIncremental loads IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsDocument loadersAirbyte GongOn this pageAirbyte GongAirbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.This loader exposes the Gong connector as a document loader, allowing you to load various Gong objects as documents.Installation‚ÄãFirst, you need to install the airbyte-source-gong python package.#!pip install airbyte-source-gongExample‚ÄãCheck out the Airbyte documentation page for details about how to configure the reader. The JSON schema the config object should adhere to can be found on Github: https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-gong/source_gong/spec.yaml.The general shape looks like this:{  "access_key": "<access key name>",  "access_key_secret": "<access key secret>",  "start_date": "<date from which to start retrieving records from in ISO format, e.g. 2020-10-20T00:00:00Z>",}By default all fields are stored as metadata in the documents and the text is set to an empty string. Construct the text of the document by transforming the documents returned by the reader.from langchain.document_loaders.airbyte import AirbyteGongLoaderconfig = {    # your gong configuration}loader = AirbyteGongLoader(config=config, stream_name="calls") # check the documentation linked above for a list of all streamsAPI Reference:AirbyteGongLoaderNow you can load documents the usual waydocs = loader.load()As load returns a list, it will block until all documents are loaded. To have better control over this process, you can also you the lazy_load method which returns an iterator instead:docs_iterator = loader.lazy_load()Keep in mind that by default the page content is empty and the metadata object contains all the information from the record. To process documents, create a class inheriting from the base loader and implement the _handle_records method yourself:from langchain.docstore.document import Documentdef handle_record(record, id):    return Document(page_content=record.data["title"], metadata=record.data)loader = AirbyteGongLoader(config=config, record_handler=handle_record, stream_name="calls")docs = loader.load()API Reference:DocumentIncremental loads‚ÄãSome streams allow incremental loading, this means the source keeps track of synced records and won't load them again. This is useful for sources that have a high volume of data and are updated frequently.To take advantage of this, store the last_state property of the loader and pass it in when creating the loader again. This will ensure that only new records are loaded.last_state = loader.last_state # store safelyincremental_loader = AirbyteGongLoader(config=config, stream_name="calls", state=last_state)new_docs = incremental_loader.load()PreviousAirbyte CDKNextAirbyte HubspotInstallationExampleIncremental loads IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders example_data Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsDocument loadersAirbyte GongOn this pageAirbyte GongAirbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.This loader exposes the Gong connector as a document loader, allowing you to load various Gong objects as documents.Installation‚ÄãFirst, you need to install the airbyte-source-gong python package.#!pip install airbyte-source-gongExample‚ÄãCheck out the Airbyte documentation page for details about how to configure the reader. The JSON schema the config object should adhere to can be found on Github: https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-gong/source_gong/spec.yaml.The general shape looks like this:{  "access_key": "<access key name>",  "access_key_secret": "<access key secret>",  "start_date": "<date from which to start retrieving records from in ISO format, e.g. 2020-10-20T00:00:00Z>",}By default all fields are stored as metadata in the documents and the text is set to an empty string. Construct the text of the document by transforming the documents returned by the reader.from langchain.document_loaders.airbyte import AirbyteGongLoaderconfig = {    # your gong configuration}loader = AirbyteGongLoader(config=config, stream_name="calls") # check the documentation linked above for a list of all streamsAPI Reference:AirbyteGongLoaderNow you can load documents the usual waydocs = loader.load()As load returns a list, it will block until all documents are loaded. To have better control over this process, you can also you the lazy_load method which returns an iterator instead:docs_iterator = loader.lazy_load()Keep in mind that by default the page content is empty and the metadata object contains all the information from the record. To process documents, create a class inheriting from the base loader and implement the _handle_records method yourself:from langchain.docstore.document import Documentdef handle_record(record, id):    return Document(page_content=record.data["title"], metadata=record.data)loader = AirbyteGongLoader(config=config, record_handler=handle_record, stream_name="calls")docs = loader.load()API Reference:DocumentIncremental loads‚ÄãSome streams allow incremental loading, this means the source keeps track of synced records and won't load them again. This is useful for sources that have a high volume of data and are updated frequently.To take advantage of this, store the last_state property of the loader and pass it in when creating the loader again. This will ensure that only new records are loaded.last_state = loader.last_state # store safelyincremental_loader = AirbyteGongLoader(config=config, stream_name="calls", state=last_state)new_docs = incremental_loader.load()PreviousAirbyte CDKNextAirbyte HubspotInstallationExampleIncremental loads IntegrationsDocument loadersAirbyte GongOn this pageAirbyte GongAirbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.This loader exposes the Gong connector as a document loader, allowing you to load various Gong objects as documents.Installation‚ÄãFirst, you need to install the airbyte-source-gong python package.#!pip install airbyte-source-gongExample‚ÄãCheck out the Airbyte documentation page for details about how to configure the reader. The JSON schema the config object should adhere to can be found on Github: https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-gong/source_gong/spec.yaml.The general shape looks like this:{  "access_key": "<access key name>",  "access_key_secret": "<access key secret>",  "start_date": "<date from which to start retrieving records from in ISO format, e.g. 2020-10-20T00:00:00Z>",}By default all fields are stored as metadata in the documents and the text is set to an empty string. Construct the text of the document by transforming the documents returned by the reader.from langchain.document_loaders.airbyte import AirbyteGongLoaderconfig = {    # your gong configuration}loader = AirbyteGongLoader(config=config, stream_name="calls") # check the documentation linked above for a list of all streamsAPI Reference:AirbyteGongLoaderNow you can load documents the usual waydocs = loader.load()As load returns a list, it will block until all documents are loaded. To have better control over this process, you can also you the lazy_load method which returns an iterator instead:docs_iterator = loader.lazy_load()Keep in mind that by default the page content is empty and the metadata object contains all the information from the record. To process documents, create a class inheriting from the base loader and implement the _handle_records method yourself:from langchain.docstore.document import Documentdef handle_record(record, id):    return Document(page_content=record.data["title"], metadata=record.data)loader = AirbyteGongLoader(config=config, record_handler=handle_record, stream_name="calls")docs = loader.load()API Reference:DocumentIncremental loads‚ÄãSome streams allow incremental loading, this means the source keeps track of synced records and won't load them again. This is useful for sources that have a high volume of data and are updated frequently.To take advantage of this, store the last_state property of the loader and pass it in when creating the loader again. This will ensure that only new records are loaded.last_state = loader.last_state # store safelyincremental_loader = AirbyteGongLoader(config=config, stream_name="calls", state=last_state)new_docs = incremental_loader.load()PreviousAirbyte CDKNextAirbyte Hubspot IntegrationsDocument loadersAirbyte GongOn this pageAirbyte GongAirbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.This loader exposes the Gong connector as a document loader, allowing you to load various Gong objects as documents.Installation‚ÄãFirst, you need to install the airbyte-source-gong python package.#!pip install airbyte-source-gongExample‚ÄãCheck out the Airbyte documentation page for details about how to configure the reader. The JSON schema the config object should adhere to can be found on Github: https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-gong/source_gong/spec.yaml.The general shape looks like this:{  "access_key": "<access key name>",  "access_key_secret": "<access key secret>",  "start_date": "<date from which to start retrieving records from in ISO format, e.g. 2020-10-20T00:00:00Z>",}By default all fields are stored as metadata in the documents and the text is set to an empty string. Construct the text of the document by transforming the documents returned by the reader.from langchain.document_loaders.airbyte import AirbyteGongLoaderconfig = {    # your gong configuration}loader = AirbyteGongLoader(config=config, stream_name="calls") # check the documentation linked above for a list of all streamsAPI Reference:AirbyteGongLoaderNow you can load documents the usual waydocs = loader.load()As load returns a list, it will block until all documents are loaded. To have better control over this process, you can also you the lazy_load method which returns an iterator instead:docs_iterator = loader.lazy_load()Keep in mind that by default the page content is empty and the metadata object contains all the information from the record. To process documents, create a class inheriting from the base loader and implement the _handle_records method yourself:from langchain.docstore.document import Documentdef handle_record(record, id):    return Document(page_content=record.data["title"], metadata=record.data)loader = AirbyteGongLoader(config=config, record_handler=handle_record, stream_name="calls")docs = loader.load()API Reference:DocumentIncremental loads‚ÄãSome streams allow incremental loading, this means the source keeps track of synced records and won't load them again. This is useful for sources that have a high volume of data and are updated frequently.To take advantage of this, store the last_state property of the loader and pass it in when creating the loader again. This will ensure that only new records are loaded.last_state = loader.last_state # store safelyincremental_loader = AirbyteGongLoader(config=config, stream_name="calls", state=last_state)new_docs = incremental_loader.load()PreviousAirbyte CDKNextAirbyte Hubspot On this page Airbyte GongAirbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.This loader exposes the Gong connector as a document loader, allowing you to load various Gong objects as documents.Installation‚ÄãFirst, you need to install the airbyte-source-gong python package.#!pip install airbyte-source-gongExample‚ÄãCheck out the Airbyte documentation page for details about how to configure the reader. The JSON schema the config object should adhere to can be found on Github: https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-gong/source_gong/spec.yaml.The general shape looks like this:{  "access_key": "<access key name>",  "access_key_secret": "<access key secret>",  "start_date": "<date from which to start retrieving records from in ISO format, e.g. 2020-10-20T00:00:00Z>",}By default all fields are stored as metadata in the documents and the text is set to an empty string. Construct the text of the document by transforming the documents returned by the reader.from langchain.document_loaders.airbyte import AirbyteGongLoaderconfig = {    # your gong configuration}loader = AirbyteGongLoader(config=config, stream_name="calls") # check the documentation linked above for a list of all streamsAPI Reference:AirbyteGongLoaderNow you can load documents the usual waydocs = loader.load()As load returns a list, it will block until all documents are loaded. To have better control over this process, you can also you the lazy_load method which returns an iterator instead:docs_iterator = loader.lazy_load()Keep in mind that by default the page content is empty and the metadata object contains all the information from the record. To process documents, create a class inheriting from the base loader and implement the _handle_records method yourself:from langchain.docstore.document import Documentdef handle_record(record, id):    return Document(page_content=record.data["title"], metadata=record.data)loader = AirbyteGongLoader(config=config, record_handler=handle_record, stream_name="calls")docs = loader.load()API Reference:DocumentIncremental loads‚ÄãSome streams allow incremental loading, this means the source keeps track of synced records and won't load them again. This is useful for sources that have a high volume of data and are updated frequently.To take advantage of this, store the last_state property of the loader and pass it in when creating the loader again. This will ensure that only new records are loaded.last_state = loader.last_state # store safelyincremental_loader = AirbyteGongLoader(config=config, stream_name="calls", state=last_state)new_docs = incremental_loader.load() #!pip install airbyte-source-gong #!pip install airbyte-source-gong  {  "access_key": "<access key name>",  "access_key_secret": "<access key secret>",  "start_date": "<date from which to start retrieving records from in ISO format, e.g. 2020-10-20T00:00:00Z>",} {  "access_key": "<access key name>",  "access_key_secret": "<access key secret>",  "start_date": "<date from which to start retrieving records from in ISO format, e.g. 2020-10-20T00:00:00Z>",}  from langchain.document_loaders.airbyte import AirbyteGongLoaderconfig = {    # your gong configuration}loader = AirbyteGongLoader(config=config, stream_name="calls") # check the documentation linked above for a list of all streams from langchain.document_loaders.airbyte import AirbyteGongLoaderconfig = {    # your gong configuration}loader = AirbyteGongLoader(config=config, stream_name="calls") # check the documentation linked above for a list of all streams  API Reference:AirbyteGongLoader docs = loader.load() docs = loader.load()  docs_iterator = loader.lazy_load() docs_iterator = loader.lazy_load()  from langchain.docstore.document import Documentdef handle_record(record, id):    return Document(page_content=record.data["title"], metadata=record.data)loader = AirbyteGongLoader(config=config, record_handler=handle_record, stream_name="calls")docs = loader.load() from langchain.docstore.document import Documentdef handle_record(record, id):    return Document(page_content=record.data["title"], metadata=record.data)loader = AirbyteGongLoader(config=config, record_handler=handle_record, stream_name="calls")docs = loader.load()  API Reference:Document last_state = loader.last_state # store safelyincremental_loader = AirbyteGongLoader(config=config, stream_name="calls", state=last_state)new_docs = incremental_loader.load() last_state = loader.last_state # store safelyincremental_loader = AirbyteGongLoader(config=config, stream_name="calls", state=last_state)new_docs = incremental_loader.load()  Previous Airbyte CDK Next Airbyte Hubspot InstallationExampleIncremental loads InstallationExampleIncremental loads CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Etherscan Loader (/docs/integrations/document_loaders/Etherscan) acreom (/docs/integrations/document_loaders/acreom) Airbyte CDK (/docs/integrations/document_loaders/airbyte_cdk) Airbyte Gong (/docs/integrations/document_loaders/airbyte_gong) Airbyte Hubspot (/docs/integrations/document_loaders/airbyte_hubspot) Airbyte JSON (/docs/integrations/document_loaders/airbyte_json) Airbyte Salesforce (/docs/integrations/document_loaders/airbyte_salesforce) Airbyte Shopify (/docs/integrations/document_loaders/airbyte_shopify) Airbyte Stripe (/docs/integrations/document_loaders/airbyte_stripe) Airbyte Typeform (/docs/integrations/document_loaders/airbyte_typeform) Airbyte Zendesk Support (/docs/integrations/document_loaders/airbyte_zendesk_support) Airtable (/docs/integrations/document_loaders/airtable) Alibaba Cloud MaxCompute (/docs/integrations/document_loaders/alibaba_cloud_maxcompute) Apify Dataset (/docs/integrations/document_loaders/apify_dataset) ArcGIS (/docs/integrations/document_loaders/arcgis) Arxiv (/docs/integrations/document_loaders/arxiv) AssemblyAI Audio Transcripts (/docs/integrations/document_loaders/assemblyai) Async Chromium (/docs/integrations/document_loaders/async_chromium) AsyncHtmlLoader (/docs/integrations/document_loaders/async_html) AWS S3 Directory (/docs/integrations/document_loaders/aws_s3_directory) AWS S3 File (/docs/integrations/document_loaders/aws_s3_file) AZLyrics (/docs/integrations/document_loaders/azlyrics) Azure Blob Storage Container (/docs/integrations/document_loaders/azure_blob_storage_container) Azure Blob Storage File (/docs/integrations/document_loaders/azure_blob_storage_file) Azure Document Intelligence (/docs/integrations/document_loaders/azure_document_intelligence) BibTeX (/docs/integrations/document_loaders/bibtex) BiliBili (/docs/integrations/document_loaders/bilibili) Blackboard (/docs/integrations/document_loaders/blackboard) Blockchain (/docs/integrations/document_loaders/blockchain) Brave Search (/docs/integrations/document_loaders/brave_search) Browserless (/docs/integrations/document_loaders/browserless) ChatGPT Data (/docs/integrations/document_loaders/chatgpt_loader) College Confidential (/docs/integrations/document_loaders/college_confidential) Concurrent Loader (/docs/integrations/document_loaders/concurrent) Confluence (/docs/integrations/document_loaders/confluence) CoNLL-U (/docs/integrations/document_loaders/conll-u) Copy Paste (/docs/integrations/document_loaders/copypaste) CSV (/docs/integrations/document_loaders/csv) Cube Semantic Layer (/docs/integrations/document_loaders/cube_semantic) Datadog Logs (/docs/integrations/document_loaders/datadog_logs) Diffbot (/docs/integrations/document_loaders/diffbot) Discord (/docs/integrations/document_loaders/discord) Docugami (/docs/integrations/document_loaders/docugami) Dropbox (/docs/integrations/document_loaders/dropbox) DuckDB (/docs/integrations/document_loaders/duckdb) Email (/docs/integrations/document_loaders/email) Embaas (/docs/integrations/document_loaders/embaas) EPub (/docs/integrations/document_loaders/epub) EverNote (/docs/integrations/document_loaders/evernote) example_data (/docs/integrations/document_loaders/example_data/notebook) Microsoft Excel (/docs/integrations/document_loaders/excel) Facebook Chat (/docs/integrations/document_loaders/facebook_chat) Fauna (/docs/integrations/document_loaders/fauna) Figma (/docs/integrations/document_loaders/figma) Geopandas (/docs/integrations/document_loaders/geopandas) Git (/docs/integrations/document_loaders/git) GitBook (/docs/integrations/document_loaders/gitbook) GitHub (/docs/integrations/document_loaders/github) Google BigQuery (/docs/integrations/document_loaders/google_bigquery) Google Cloud Storage Directory (/docs/integrations/document_loaders/google_cloud_storage_directory) Google Cloud Storage File (/docs/integrations/document_loaders/google_cloud_storage_file) Google Drive (/docs/integrations/document_loaders/google_drive) Grobid (/docs/integrations/document_loaders/grobid) Gutenberg (/docs/integrations/document_loaders/gutenberg) Hacker News (/docs/integrations/document_loaders/hacker_news) Huawei OBS Directory (/docs/integrations/document_loaders/huawei_obs_directory) Huawei OBS File (/docs/integrations/document_loaders/huawei_obs_file) HuggingFace dataset (/docs/integrations/document_loaders/hugging_face_dataset) iFixit (/docs/integrations/document_loaders/ifixit) Images (/docs/integrations/document_loaders/image) Image captions (/docs/integrations/document_loaders/image_captions) IMSDb (/docs/integrations/document_loaders/imsdb) Iugu (/docs/integrations/document_loaders/iugu) Joplin (/docs/integrations/document_loaders/joplin) Jupyter Notebook (/docs/integrations/document_loaders/jupyter_notebook) LarkSuite (FeiShu) (/docs/integrations/document_loaders/larksuite) Mastodon (/docs/integrations/document_loaders/mastodon) MediaWikiDump (/docs/integrations/document_loaders/mediawikidump) MergeDocLoader (/docs/integrations/document_loaders/merge_doc_loader) mhtml (/docs/integrations/document_loaders/mhtml) Microsoft OneDrive (/docs/integrations/document_loaders/microsoft_onedrive) Microsoft PowerPoint (/docs/integrations/document_loaders/microsoft_powerpoint) Microsoft SharePoint (/docs/integrations/document_loaders/microsoft_sharepoint) Microsoft Word (/docs/integrations/document_loaders/microsoft_word) Modern Treasury (/docs/integrations/document_loaders/modern_treasury) News URL (/docs/integrations/document_loaders/news) Notion DB 1/2 (/docs/integrations/document_loaders/notion) Notion DB 2/2 (/docs/integrations/document_loaders/notiondb) Nuclia Understanding API document loader (/docs/integrations/document_loaders/nuclia) Obsidian (/docs/integrations/document_loaders/obsidian) Open Document Format (ODT) (/docs/integrations/document_loaders/odt) Open City Data (/docs/integrations/document_loaders/open_city_data) Org-mode (/docs/integrations/document_loaders/org_mode) Pandas DataFrame (/docs/integrations/document_loaders/pandas_dataframe) Amazon Textract (/docs/integrations/document_loaders/pdf-amazonTextractPDFLoader) Polars DataFrame (/docs/integrations/document_loaders/polars_dataframe) Psychic (/docs/integrations/document_loaders/psychic) PubMed (/docs/integrations/document_loaders/pubmed) PySpark DataFrame Loader (/docs/integrations/document_loaders/pyspark_dataframe) ReadTheDocs Documentation (/docs/integrations/document_loaders/readthedocs_documentation) Recursive URL Loader (/docs/integrations/document_loaders/recursive_url_loader) Reddit (/docs/integrations/document_loaders/reddit) Roam (/docs/integrations/document_loaders/roam) Rockset (/docs/integrations/document_loaders/rockset) RSS Feeds (/docs/integrations/document_loaders/rss) RST (/docs/integrations/document_loaders/rst) Sitemap (/docs/integrations/document_loaders/sitemap) Slack (/docs/integrations/document_loaders/slack) Snowflake (/docs/integrations/document_loaders/snowflake) Source Code (/docs/integrations/document_loaders/source_code) Spreedly (/docs/integrations/document_loaders/spreedly) Stripe (/docs/integrations/document_loaders/stripe) Subtitle (/docs/integrations/document_loaders/subtitle) Telegram (/docs/integrations/document_loaders/telegram) Tencent COS Directory (/docs/integrations/document_loaders/tencent_cos_directory) Tencent COS File (/docs/integrations/document_loaders/tencent_cos_file) TensorFlow Datasets (/docs/integrations/document_loaders/tensorflow_datasets) 2Markdown (/docs/integrations/document_loaders/tomarkdown) TOML (/docs/integrations/document_loaders/toml) Trello (/docs/integrations/document_loaders/trello) TSV (/docs/integrations/document_loaders/tsv) Twitter (/docs/integrations/document_loaders/twitter) Unstructured File (/docs/integrations/document_loaders/unstructured_file) URL (/docs/integrations/document_loaders/url) Weather (/docs/integrations/document_loaders/weather) WebBaseLoader (/docs/integrations/document_loaders/web_base) WhatsApp Chat (/docs/integrations/document_loaders/whatsapp_chat) Wikipedia (/docs/integrations/document_loaders/wikipedia) XML (/docs/integrations/document_loaders/xml) Xorbits Pandas DataFrame (/docs/integrations/document_loaders/xorbits) Loading documents from a YouTube url (/docs/integrations/document_loaders/youtube_audio) YouTube transcripts (/docs/integrations/document_loaders/youtube_transcript) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Document loaders (/docs/integrations/document_loaders/) Airbyte (https://github.com/airbytehq/airbyte) ‚Äã (#installation) ‚Äã (#example) Airbyte documentation page (https://docs.airbyte.com/integrations/sources/gong/) https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-gong/source_gong/spec.yaml (https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-gong/source_gong/spec.yaml) AirbyteGongLoader (https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.airbyte.AirbyteGongLoader.html) Document (https://api.python.langchain.com/en/latest/schema/langchain.schema.document.Document.html) ‚Äã (#incremental-loads) PreviousAirbyte CDK (/docs/integrations/document_loaders/airbyte_cdk) NextAirbyte Hubspot (/docs/integrations/document_loaders/airbyte_hubspot) Installation (#installation) Example (#example) Incremental loads (#incremental-loads) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)