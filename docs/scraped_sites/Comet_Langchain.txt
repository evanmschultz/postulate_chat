In this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with Comet.   Example Project: Comet with LangChain  You can grab your Comet API Key here or click the link after initializing Comet You will need an OpenAI API Key and a SerpAPI API Key to run the following examples The CometCallbackManager also allows you to define and use Custom Evaluation Metrics to assess generated outputs from your model. Let's take a look at how this works.  In the snippet below, we will use the ROUGE metric to evaluate the quality of a generated summary of an input prompt.  IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz Activeloop Deep Lake AI21 Labs Aim AINetwork Airbyte Airtable Aleph Alpha Alibaba Cloud Opensearch Amazon API Gateway AnalyticDB Annoy Anyscale Apify ArangoDB Argilla Arthur Arxiv Atlas AwaDB AWS S3 Directory AZLyrics Azure Blob Storage Azure Cognitive Search Azure OpenAI BagelDB Banana Baseten Beam Bedrock BiliBili NIBittensor Blackboard Brave Search Cassandra CerebriumAI Chaindesk Chroma Clarifai ClearML ClickHouse CnosDB Cohere College Confidential Comet Confident AI Confluence C Transformers DashVector Databricks Datadog Tracing Datadog Logs DataForSEO DeepInfra DeepSparse Diffbot Dingo Discord DocArray Docugami DuckDB Elasticsearch Epsilla EverNote Facebook Chat Facebook Faiss Figma Fireworks Flyte ForefrontAI Git GitBook Golden Google BigQuery Google Cloud Storage Google Drive Google Search Google Serper Google Vertex AI MatchingEngine GooseAI GPT4All Graphsignal Grobid Gutenberg Hacker News Hazy Research Helicone Hologres Hugging Face iFixit IMSDb Infino Jina Konko LanceDB LangChain Decorators ‚ú® Llama.cpp Log10 Marqo MediaWikiDump Meilisearch Metal Microsoft OneDrive Microsoft PowerPoint Microsoft Word Milvus Minimax MLflow AI Gateway MLflow Modal ModelScope Modern Treasury Momento MongoDB Atlas Motherduck MyScale Neo4j NLPCloud Notion DB Obsidian OpenAI OpenLLM OpenSearch OpenWeatherMap Petals Postgres Embedding PGVector Pinecone PipelineAI Portkey Predibase Prediction Guard PromptLayer Psychic PubMed Qdrant Ray Serve Rebuff Reddit Redis Replicate Roam Rockset Runhouse RWKV-4 SageMaker Endpoint SageMaker Tracking ScaNN SearxNG Search API SerpAPI Shale Protocol SingleStoreDB scikit-learn Slack spaCy Spreedly StarRocks StochasticAI Stripe Supabase (Postgres) Nebula Tair Telegram TencentVectorDB TensorFlow Datasets Tigris 2Markdown Trello TruLens Twitter Typesense Unstructured USearch Vearch Vectara Vespa WandB Tracing Weights & Biases Weather Weaviate WhatsApp WhyLabs Wikipedia Wolfram Alpha Writer Xata Xorbits Inference (Xinference) Yeager.ai YouTube Zep Zilliz  Integrations Grouped by provider Comet CometCallbackHandler StdOutCallbackHandler OpenAI CometCallbackHandler StdOutCallbackHandler LLMChain OpenAI PromptTemplate initialize_agent load_tools CometCallbackHandler StdOutCallbackHandler OpenAI CometCallbackHandler StdOutCallbackHandler LLMChain OpenAI PromptTemplate Install Comet and Dependencies Initialize Comet and Set your Credentials Set OpenAI and SerpAPI credentials Scenario 1: Using just an LLM Scenario 2: Using an LLM in a Chain Scenario 3: Using An Agent with Tools Scenario 4: Using Custom Evaluation Metrics Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZillizIntegrationsGrouped by providerCometOn this pageCometIn this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with Comet.  Example Project: Comet with LangChainInstall Comet and Dependencies‚Äãimport sys{sys.executable} -m spacy download en_core_web_smInitialize Comet and Set your Credentials‚ÄãYou can grab your Comet API Key here or click the link after initializing Cometimport comet_mlcomet_ml.init(project_name="comet-example-langchain")Set OpenAI and SerpAPI credentials‚ÄãYou will need an OpenAI API Key and a SerpAPI API Key to run the following examplesimport osos.environ["OPENAI_API_KEY"] = "..."# os.environ["OPENAI_ORGANIZATION"] = "..."os.environ["SERPAPI_API_KEY"] = "..."Scenario 1: Using just an LLM‚Äãfrom datetime import datetimefrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["llm"],    visualizations=["dep"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)llm_result = llm.generate(["Tell me a joke", "Tell me a poem", "Tell me a fact"] * 3)print("LLM result", llm_result)comet_callback.flush_tracker(llm, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 2: Using an LLM in a Chain‚Äãfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatecomet_callback = CometCallbackHandler(    complexity_metrics=True,    project_name="comet-example-langchain",    stream_logs=True,    tags=["synopsis-chain"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)test_prompts = [{"title": "Documentary about Bigfoot in Paris"}]print(synopsis_chain.apply(test_prompts))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplateScenario 3: Using An Agent with Tools‚Äãfrom langchain.agents import initialize_agent, load_toolsfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["agent"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)tools = load_tools(["serpapi", "llm-math"], llm=llm, callbacks=callbacks)agent = initialize_agent(    tools,    llm,    agent="zero-shot-react-description",    callbacks=callbacks,    verbose=True,)agent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?")comet_callback.flush_tracker(agent, finish=True)API Reference:initialize_agentload_toolsCometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 4: Using Custom Evaluation Metrics‚ÄãThe CometCallbackManager also allows you to define and use Custom Evaluation Metrics to assess generated outputs from your model. Let's take a look at how this works. In the snippet below, we will use the ROUGE metric to evaluate the quality of a generated summary of an input prompt. %pip install rouge-scorefrom rouge_score import rouge_scorerfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplateclass Rouge:    def __init__(self, reference):        self.reference = reference        self.scorer = rouge_scorer.RougeScorer(["rougeLsum"], use_stemmer=True)    def compute_metric(self, generation, prompt_idx, gen_idx):        prediction = generation.text        results = self.scorer.score(target=self.reference, prediction=prediction)        return {            "rougeLsum_score": results["rougeLsum"].fmeasure,            "reference": self.reference,        }reference = """The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building.It was the first structure to reach a height of 300 metres.It is now taller than the Chrysler Building in New York City by 5.2 metres (17 ft)Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France ."""rouge_score = Rouge(reference=reference)template = """Given the following article, it is your job to write a summary.Article:{article}Summary: This is the summary for the above article:"""prompt_template = PromptTemplate(input_variables=["article"], template=template)comet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=False,    stream_logs=True,    tags=["custom_metrics"],    custom_metrics=rouge_score.compute_metric,)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)test_prompts = [    {        "article": """                 The tower is 324 metres (1,063 ft) tall, about the same height as                 an 81-storey building, and the tallest structure in Paris. Its base is square,                 measuring 125 metres (410 ft) on each side.                 During its construction, the Eiffel Tower surpassed the                 Washington Monument to become the tallest man-made structure in the world,                 a title it held for 41 years until the Chrysler Building                 in New York City was finished in 1930.                 It was the first structure to reach a height of 300 metres.                 Due to the addition of a broadcasting aerial at the top of the tower in 1957,                 it is now taller than the Chrysler Building by 5.2 metres (17 ft).                 Excluding transmitters, the Eiffel Tower is the second tallest                 free-standing structure in France after the Millau Viaduct.                 """    }]print(synopsis_chain.apply(test_prompts, callbacks=callbacks))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplatePreviousCollege ConfidentialNextConfident AIInstall Comet and DependenciesInitialize Comet and Set your CredentialsSet OpenAI and SerpAPI credentialsScenario 1: Using just an LLMScenario 2: Using an LLM in a ChainScenario 3: Using An Agent with ToolsScenario 4: Using Custom Evaluation MetricsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZillizIntegrationsGrouped by providerCometOn this pageCometIn this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with Comet.  Example Project: Comet with LangChainInstall Comet and Dependencies‚Äãimport sys{sys.executable} -m spacy download en_core_web_smInitialize Comet and Set your Credentials‚ÄãYou can grab your Comet API Key here or click the link after initializing Cometimport comet_mlcomet_ml.init(project_name="comet-example-langchain")Set OpenAI and SerpAPI credentials‚ÄãYou will need an OpenAI API Key and a SerpAPI API Key to run the following examplesimport osos.environ["OPENAI_API_KEY"] = "..."# os.environ["OPENAI_ORGANIZATION"] = "..."os.environ["SERPAPI_API_KEY"] = "..."Scenario 1: Using just an LLM‚Äãfrom datetime import datetimefrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["llm"],    visualizations=["dep"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)llm_result = llm.generate(["Tell me a joke", "Tell me a poem", "Tell me a fact"] * 3)print("LLM result", llm_result)comet_callback.flush_tracker(llm, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 2: Using an LLM in a Chain‚Äãfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatecomet_callback = CometCallbackHandler(    complexity_metrics=True,    project_name="comet-example-langchain",    stream_logs=True,    tags=["synopsis-chain"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)test_prompts = [{"title": "Documentary about Bigfoot in Paris"}]print(synopsis_chain.apply(test_prompts))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplateScenario 3: Using An Agent with Tools‚Äãfrom langchain.agents import initialize_agent, load_toolsfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["agent"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)tools = load_tools(["serpapi", "llm-math"], llm=llm, callbacks=callbacks)agent = initialize_agent(    tools,    llm,    agent="zero-shot-react-description",    callbacks=callbacks,    verbose=True,)agent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?")comet_callback.flush_tracker(agent, finish=True)API Reference:initialize_agentload_toolsCometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 4: Using Custom Evaluation Metrics‚ÄãThe CometCallbackManager also allows you to define and use Custom Evaluation Metrics to assess generated outputs from your model. Let's take a look at how this works. In the snippet below, we will use the ROUGE metric to evaluate the quality of a generated summary of an input prompt. %pip install rouge-scorefrom rouge_score import rouge_scorerfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplateclass Rouge:    def __init__(self, reference):        self.reference = reference        self.scorer = rouge_scorer.RougeScorer(["rougeLsum"], use_stemmer=True)    def compute_metric(self, generation, prompt_idx, gen_idx):        prediction = generation.text        results = self.scorer.score(target=self.reference, prediction=prediction)        return {            "rougeLsum_score": results["rougeLsum"].fmeasure,            "reference": self.reference,        }reference = """The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building.It was the first structure to reach a height of 300 metres.It is now taller than the Chrysler Building in New York City by 5.2 metres (17 ft)Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France ."""rouge_score = Rouge(reference=reference)template = """Given the following article, it is your job to write a summary.Article:{article}Summary: This is the summary for the above article:"""prompt_template = PromptTemplate(input_variables=["article"], template=template)comet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=False,    stream_logs=True,    tags=["custom_metrics"],    custom_metrics=rouge_score.compute_metric,)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)test_prompts = [    {        "article": """                 The tower is 324 metres (1,063 ft) tall, about the same height as                 an 81-storey building, and the tallest structure in Paris. Its base is square,                 measuring 125 metres (410 ft) on each side.                 During its construction, the Eiffel Tower surpassed the                 Washington Monument to become the tallest man-made structure in the world,                 a title it held for 41 years until the Chrysler Building                 in New York City was finished in 1930.                 It was the first structure to reach a height of 300 metres.                 Due to the addition of a broadcasting aerial at the top of the tower in 1957,                 it is now taller than the Chrysler Building by 5.2 metres (17 ft).                 Excluding transmitters, the Eiffel Tower is the second tallest                 free-standing structure in France after the Millau Viaduct.                 """    }]print(synopsis_chain.apply(test_prompts, callbacks=callbacks))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplatePreviousCollege ConfidentialNextConfident AIInstall Comet and DependenciesInitialize Comet and Set your CredentialsSet OpenAI and SerpAPI credentialsScenario 1: Using just an LLMScenario 2: Using an LLM in a ChainScenario 3: Using An Agent with ToolsScenario 4: Using Custom Evaluation Metrics IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZillizIntegrationsGrouped by providerCometOn this pageCometIn this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with Comet.  Example Project: Comet with LangChainInstall Comet and Dependencies‚Äãimport sys{sys.executable} -m spacy download en_core_web_smInitialize Comet and Set your Credentials‚ÄãYou can grab your Comet API Key here or click the link after initializing Cometimport comet_mlcomet_ml.init(project_name="comet-example-langchain")Set OpenAI and SerpAPI credentials‚ÄãYou will need an OpenAI API Key and a SerpAPI API Key to run the following examplesimport osos.environ["OPENAI_API_KEY"] = "..."# os.environ["OPENAI_ORGANIZATION"] = "..."os.environ["SERPAPI_API_KEY"] = "..."Scenario 1: Using just an LLM‚Äãfrom datetime import datetimefrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["llm"],    visualizations=["dep"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)llm_result = llm.generate(["Tell me a joke", "Tell me a poem", "Tell me a fact"] * 3)print("LLM result", llm_result)comet_callback.flush_tracker(llm, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 2: Using an LLM in a Chain‚Äãfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatecomet_callback = CometCallbackHandler(    complexity_metrics=True,    project_name="comet-example-langchain",    stream_logs=True,    tags=["synopsis-chain"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)test_prompts = [{"title": "Documentary about Bigfoot in Paris"}]print(synopsis_chain.apply(test_prompts))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplateScenario 3: Using An Agent with Tools‚Äãfrom langchain.agents import initialize_agent, load_toolsfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["agent"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)tools = load_tools(["serpapi", "llm-math"], llm=llm, callbacks=callbacks)agent = initialize_agent(    tools,    llm,    agent="zero-shot-react-description",    callbacks=callbacks,    verbose=True,)agent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?")comet_callback.flush_tracker(agent, finish=True)API Reference:initialize_agentload_toolsCometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 4: Using Custom Evaluation Metrics‚ÄãThe CometCallbackManager also allows you to define and use Custom Evaluation Metrics to assess generated outputs from your model. Let's take a look at how this works. In the snippet below, we will use the ROUGE metric to evaluate the quality of a generated summary of an input prompt. %pip install rouge-scorefrom rouge_score import rouge_scorerfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplateclass Rouge:    def __init__(self, reference):        self.reference = reference        self.scorer = rouge_scorer.RougeScorer(["rougeLsum"], use_stemmer=True)    def compute_metric(self, generation, prompt_idx, gen_idx):        prediction = generation.text        results = self.scorer.score(target=self.reference, prediction=prediction)        return {            "rougeLsum_score": results["rougeLsum"].fmeasure,            "reference": self.reference,        }reference = """The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building.It was the first structure to reach a height of 300 metres.It is now taller than the Chrysler Building in New York City by 5.2 metres (17 ft)Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France ."""rouge_score = Rouge(reference=reference)template = """Given the following article, it is your job to write a summary.Article:{article}Summary: This is the summary for the above article:"""prompt_template = PromptTemplate(input_variables=["article"], template=template)comet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=False,    stream_logs=True,    tags=["custom_metrics"],    custom_metrics=rouge_score.compute_metric,)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)test_prompts = [    {        "article": """                 The tower is 324 metres (1,063 ft) tall, about the same height as                 an 81-storey building, and the tallest structure in Paris. Its base is square,                 measuring 125 metres (410 ft) on each side.                 During its construction, the Eiffel Tower surpassed the                 Washington Monument to become the tallest man-made structure in the world,                 a title it held for 41 years until the Chrysler Building                 in New York City was finished in 1930.                 It was the first structure to reach a height of 300 metres.                 Due to the addition of a broadcasting aerial at the top of the tower in 1957,                 it is now taller than the Chrysler Building by 5.2 metres (17 ft).                 Excluding transmitters, the Eiffel Tower is the second tallest                 free-standing structure in France after the Millau Viaduct.                 """    }]print(synopsis_chain.apply(test_prompts, callbacks=callbacks))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplatePreviousCollege ConfidentialNextConfident AIInstall Comet and DependenciesInitialize Comet and Set your CredentialsSet OpenAI and SerpAPI credentialsScenario 1: Using just an LLMScenario 2: Using an LLM in a ChainScenario 3: Using An Agent with ToolsScenario 4: Using Custom Evaluation Metrics IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider Portkey Vectara IntegrationsGrouped by providerCometOn this pageCometIn this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with Comet.  Example Project: Comet with LangChainInstall Comet and Dependencies‚Äãimport sys{sys.executable} -m spacy download en_core_web_smInitialize Comet and Set your Credentials‚ÄãYou can grab your Comet API Key here or click the link after initializing Cometimport comet_mlcomet_ml.init(project_name="comet-example-langchain")Set OpenAI and SerpAPI credentials‚ÄãYou will need an OpenAI API Key and a SerpAPI API Key to run the following examplesimport osos.environ["OPENAI_API_KEY"] = "..."# os.environ["OPENAI_ORGANIZATION"] = "..."os.environ["SERPAPI_API_KEY"] = "..."Scenario 1: Using just an LLM‚Äãfrom datetime import datetimefrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["llm"],    visualizations=["dep"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)llm_result = llm.generate(["Tell me a joke", "Tell me a poem", "Tell me a fact"] * 3)print("LLM result", llm_result)comet_callback.flush_tracker(llm, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 2: Using an LLM in a Chain‚Äãfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatecomet_callback = CometCallbackHandler(    complexity_metrics=True,    project_name="comet-example-langchain",    stream_logs=True,    tags=["synopsis-chain"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)test_prompts = [{"title": "Documentary about Bigfoot in Paris"}]print(synopsis_chain.apply(test_prompts))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplateScenario 3: Using An Agent with Tools‚Äãfrom langchain.agents import initialize_agent, load_toolsfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["agent"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)tools = load_tools(["serpapi", "llm-math"], llm=llm, callbacks=callbacks)agent = initialize_agent(    tools,    llm,    agent="zero-shot-react-description",    callbacks=callbacks,    verbose=True,)agent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?")comet_callback.flush_tracker(agent, finish=True)API Reference:initialize_agentload_toolsCometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 4: Using Custom Evaluation Metrics‚ÄãThe CometCallbackManager also allows you to define and use Custom Evaluation Metrics to assess generated outputs from your model. Let's take a look at how this works. In the snippet below, we will use the ROUGE metric to evaluate the quality of a generated summary of an input prompt. %pip install rouge-scorefrom rouge_score import rouge_scorerfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplateclass Rouge:    def __init__(self, reference):        self.reference = reference        self.scorer = rouge_scorer.RougeScorer(["rougeLsum"], use_stemmer=True)    def compute_metric(self, generation, prompt_idx, gen_idx):        prediction = generation.text        results = self.scorer.score(target=self.reference, prediction=prediction)        return {            "rougeLsum_score": results["rougeLsum"].fmeasure,            "reference": self.reference,        }reference = """The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building.It was the first structure to reach a height of 300 metres.It is now taller than the Chrysler Building in New York City by 5.2 metres (17 ft)Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France ."""rouge_score = Rouge(reference=reference)template = """Given the following article, it is your job to write a summary.Article:{article}Summary: This is the summary for the above article:"""prompt_template = PromptTemplate(input_variables=["article"], template=template)comet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=False,    stream_logs=True,    tags=["custom_metrics"],    custom_metrics=rouge_score.compute_metric,)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)test_prompts = [    {        "article": """                 The tower is 324 metres (1,063 ft) tall, about the same height as                 an 81-storey building, and the tallest structure in Paris. Its base is square,                 measuring 125 metres (410 ft) on each side.                 During its construction, the Eiffel Tower surpassed the                 Washington Monument to become the tallest man-made structure in the world,                 a title it held for 41 years until the Chrysler Building                 in New York City was finished in 1930.                 It was the first structure to reach a height of 300 metres.                 Due to the addition of a broadcasting aerial at the top of the tower in 1957,                 it is now taller than the Chrysler Building by 5.2 metres (17 ft).                 Excluding transmitters, the Eiffel Tower is the second tallest                 free-standing structure in France after the Millau Viaduct.                 """    }]print(synopsis_chain.apply(test_prompts, callbacks=callbacks))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplatePreviousCollege ConfidentialNextConfident AIInstall Comet and DependenciesInitialize Comet and Set your CredentialsSet OpenAI and SerpAPI credentialsScenario 1: Using just an LLMScenario 2: Using an LLM in a ChainScenario 3: Using An Agent with ToolsScenario 4: Using Custom Evaluation Metrics IntegrationsGrouped by providerCometOn this pageCometIn this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with Comet.  Example Project: Comet with LangChainInstall Comet and Dependencies‚Äãimport sys{sys.executable} -m spacy download en_core_web_smInitialize Comet and Set your Credentials‚ÄãYou can grab your Comet API Key here or click the link after initializing Cometimport comet_mlcomet_ml.init(project_name="comet-example-langchain")Set OpenAI and SerpAPI credentials‚ÄãYou will need an OpenAI API Key and a SerpAPI API Key to run the following examplesimport osos.environ["OPENAI_API_KEY"] = "..."# os.environ["OPENAI_ORGANIZATION"] = "..."os.environ["SERPAPI_API_KEY"] = "..."Scenario 1: Using just an LLM‚Äãfrom datetime import datetimefrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["llm"],    visualizations=["dep"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)llm_result = llm.generate(["Tell me a joke", "Tell me a poem", "Tell me a fact"] * 3)print("LLM result", llm_result)comet_callback.flush_tracker(llm, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 2: Using an LLM in a Chain‚Äãfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatecomet_callback = CometCallbackHandler(    complexity_metrics=True,    project_name="comet-example-langchain",    stream_logs=True,    tags=["synopsis-chain"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)test_prompts = [{"title": "Documentary about Bigfoot in Paris"}]print(synopsis_chain.apply(test_prompts))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplateScenario 3: Using An Agent with Tools‚Äãfrom langchain.agents import initialize_agent, load_toolsfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["agent"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)tools = load_tools(["serpapi", "llm-math"], llm=llm, callbacks=callbacks)agent = initialize_agent(    tools,    llm,    agent="zero-shot-react-description",    callbacks=callbacks,    verbose=True,)agent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?")comet_callback.flush_tracker(agent, finish=True)API Reference:initialize_agentload_toolsCometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 4: Using Custom Evaluation Metrics‚ÄãThe CometCallbackManager also allows you to define and use Custom Evaluation Metrics to assess generated outputs from your model. Let's take a look at how this works. In the snippet below, we will use the ROUGE metric to evaluate the quality of a generated summary of an input prompt. %pip install rouge-scorefrom rouge_score import rouge_scorerfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplateclass Rouge:    def __init__(self, reference):        self.reference = reference        self.scorer = rouge_scorer.RougeScorer(["rougeLsum"], use_stemmer=True)    def compute_metric(self, generation, prompt_idx, gen_idx):        prediction = generation.text        results = self.scorer.score(target=self.reference, prediction=prediction)        return {            "rougeLsum_score": results["rougeLsum"].fmeasure,            "reference": self.reference,        }reference = """The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building.It was the first structure to reach a height of 300 metres.It is now taller than the Chrysler Building in New York City by 5.2 metres (17 ft)Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France ."""rouge_score = Rouge(reference=reference)template = """Given the following article, it is your job to write a summary.Article:{article}Summary: This is the summary for the above article:"""prompt_template = PromptTemplate(input_variables=["article"], template=template)comet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=False,    stream_logs=True,    tags=["custom_metrics"],    custom_metrics=rouge_score.compute_metric,)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)test_prompts = [    {        "article": """                 The tower is 324 metres (1,063 ft) tall, about the same height as                 an 81-storey building, and the tallest structure in Paris. Its base is square,                 measuring 125 metres (410 ft) on each side.                 During its construction, the Eiffel Tower surpassed the                 Washington Monument to become the tallest man-made structure in the world,                 a title it held for 41 years until the Chrysler Building                 in New York City was finished in 1930.                 It was the first structure to reach a height of 300 metres.                 Due to the addition of a broadcasting aerial at the top of the tower in 1957,                 it is now taller than the Chrysler Building by 5.2 metres (17 ft).                 Excluding transmitters, the Eiffel Tower is the second tallest                 free-standing structure in France after the Millau Viaduct.                 """    }]print(synopsis_chain.apply(test_prompts, callbacks=callbacks))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplatePreviousCollege ConfidentialNextConfident AIInstall Comet and DependenciesInitialize Comet and Set your CredentialsSet OpenAI and SerpAPI credentialsScenario 1: Using just an LLMScenario 2: Using an LLM in a ChainScenario 3: Using An Agent with ToolsScenario 4: Using Custom Evaluation Metrics IntegrationsGrouped by providerCometOn this pageCometIn this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with Comet.  Example Project: Comet with LangChainInstall Comet and Dependencies‚Äãimport sys{sys.executable} -m spacy download en_core_web_smInitialize Comet and Set your Credentials‚ÄãYou can grab your Comet API Key here or click the link after initializing Cometimport comet_mlcomet_ml.init(project_name="comet-example-langchain")Set OpenAI and SerpAPI credentials‚ÄãYou will need an OpenAI API Key and a SerpAPI API Key to run the following examplesimport osos.environ["OPENAI_API_KEY"] = "..."# os.environ["OPENAI_ORGANIZATION"] = "..."os.environ["SERPAPI_API_KEY"] = "..."Scenario 1: Using just an LLM‚Äãfrom datetime import datetimefrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["llm"],    visualizations=["dep"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)llm_result = llm.generate(["Tell me a joke", "Tell me a poem", "Tell me a fact"] * 3)print("LLM result", llm_result)comet_callback.flush_tracker(llm, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 2: Using an LLM in a Chain‚Äãfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatecomet_callback = CometCallbackHandler(    complexity_metrics=True,    project_name="comet-example-langchain",    stream_logs=True,    tags=["synopsis-chain"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)test_prompts = [{"title": "Documentary about Bigfoot in Paris"}]print(synopsis_chain.apply(test_prompts))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplateScenario 3: Using An Agent with Tools‚Äãfrom langchain.agents import initialize_agent, load_toolsfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["agent"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)tools = load_tools(["serpapi", "llm-math"], llm=llm, callbacks=callbacks)agent = initialize_agent(    tools,    llm,    agent="zero-shot-react-description",    callbacks=callbacks,    verbose=True,)agent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?")comet_callback.flush_tracker(agent, finish=True)API Reference:initialize_agentload_toolsCometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 4: Using Custom Evaluation Metrics‚ÄãThe CometCallbackManager also allows you to define and use Custom Evaluation Metrics to assess generated outputs from your model. Let's take a look at how this works. In the snippet below, we will use the ROUGE metric to evaluate the quality of a generated summary of an input prompt. %pip install rouge-scorefrom rouge_score import rouge_scorerfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplateclass Rouge:    def __init__(self, reference):        self.reference = reference        self.scorer = rouge_scorer.RougeScorer(["rougeLsum"], use_stemmer=True)    def compute_metric(self, generation, prompt_idx, gen_idx):        prediction = generation.text        results = self.scorer.score(target=self.reference, prediction=prediction)        return {            "rougeLsum_score": results["rougeLsum"].fmeasure,            "reference": self.reference,        }reference = """The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building.It was the first structure to reach a height of 300 metres.It is now taller than the Chrysler Building in New York City by 5.2 metres (17 ft)Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France ."""rouge_score = Rouge(reference=reference)template = """Given the following article, it is your job to write a summary.Article:{article}Summary: This is the summary for the above article:"""prompt_template = PromptTemplate(input_variables=["article"], template=template)comet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=False,    stream_logs=True,    tags=["custom_metrics"],    custom_metrics=rouge_score.compute_metric,)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)test_prompts = [    {        "article": """                 The tower is 324 metres (1,063 ft) tall, about the same height as                 an 81-storey building, and the tallest structure in Paris. Its base is square,                 measuring 125 metres (410 ft) on each side.                 During its construction, the Eiffel Tower surpassed the                 Washington Monument to become the tallest man-made structure in the world,                 a title it held for 41 years until the Chrysler Building                 in New York City was finished in 1930.                 It was the first structure to reach a height of 300 metres.                 Due to the addition of a broadcasting aerial at the top of the tower in 1957,                 it is now taller than the Chrysler Building by 5.2 metres (17 ft).                 Excluding transmitters, the Eiffel Tower is the second tallest                 free-standing structure in France after the Millau Viaduct.                 """    }]print(synopsis_chain.apply(test_prompts, callbacks=callbacks))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplatePreviousCollege ConfidentialNextConfident AI IntegrationsGrouped by providerCometOn this pageCometIn this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with Comet.  Example Project: Comet with LangChainInstall Comet and Dependencies‚Äãimport sys{sys.executable} -m spacy download en_core_web_smInitialize Comet and Set your Credentials‚ÄãYou can grab your Comet API Key here or click the link after initializing Cometimport comet_mlcomet_ml.init(project_name="comet-example-langchain")Set OpenAI and SerpAPI credentials‚ÄãYou will need an OpenAI API Key and a SerpAPI API Key to run the following examplesimport osos.environ["OPENAI_API_KEY"] = "..."# os.environ["OPENAI_ORGANIZATION"] = "..."os.environ["SERPAPI_API_KEY"] = "..."Scenario 1: Using just an LLM‚Äãfrom datetime import datetimefrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["llm"],    visualizations=["dep"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)llm_result = llm.generate(["Tell me a joke", "Tell me a poem", "Tell me a fact"] * 3)print("LLM result", llm_result)comet_callback.flush_tracker(llm, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 2: Using an LLM in a Chain‚Äãfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatecomet_callback = CometCallbackHandler(    complexity_metrics=True,    project_name="comet-example-langchain",    stream_logs=True,    tags=["synopsis-chain"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)test_prompts = [{"title": "Documentary about Bigfoot in Paris"}]print(synopsis_chain.apply(test_prompts))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplateScenario 3: Using An Agent with Tools‚Äãfrom langchain.agents import initialize_agent, load_toolsfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["agent"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)tools = load_tools(["serpapi", "llm-math"], llm=llm, callbacks=callbacks)agent = initialize_agent(    tools,    llm,    agent="zero-shot-react-description",    callbacks=callbacks,    verbose=True,)agent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?")comet_callback.flush_tracker(agent, finish=True)API Reference:initialize_agentload_toolsCometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 4: Using Custom Evaluation Metrics‚ÄãThe CometCallbackManager also allows you to define and use Custom Evaluation Metrics to assess generated outputs from your model. Let's take a look at how this works. In the snippet below, we will use the ROUGE metric to evaluate the quality of a generated summary of an input prompt. %pip install rouge-scorefrom rouge_score import rouge_scorerfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplateclass Rouge:    def __init__(self, reference):        self.reference = reference        self.scorer = rouge_scorer.RougeScorer(["rougeLsum"], use_stemmer=True)    def compute_metric(self, generation, prompt_idx, gen_idx):        prediction = generation.text        results = self.scorer.score(target=self.reference, prediction=prediction)        return {            "rougeLsum_score": results["rougeLsum"].fmeasure,            "reference": self.reference,        }reference = """The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building.It was the first structure to reach a height of 300 metres.It is now taller than the Chrysler Building in New York City by 5.2 metres (17 ft)Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France ."""rouge_score = Rouge(reference=reference)template = """Given the following article, it is your job to write a summary.Article:{article}Summary: This is the summary for the above article:"""prompt_template = PromptTemplate(input_variables=["article"], template=template)comet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=False,    stream_logs=True,    tags=["custom_metrics"],    custom_metrics=rouge_score.compute_metric,)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)test_prompts = [    {        "article": """                 The tower is 324 metres (1,063 ft) tall, about the same height as                 an 81-storey building, and the tallest structure in Paris. Its base is square,                 measuring 125 metres (410 ft) on each side.                 During its construction, the Eiffel Tower surpassed the                 Washington Monument to become the tallest man-made structure in the world,                 a title it held for 41 years until the Chrysler Building                 in New York City was finished in 1930.                 It was the first structure to reach a height of 300 metres.                 Due to the addition of a broadcasting aerial at the top of the tower in 1957,                 it is now taller than the Chrysler Building by 5.2 metres (17 ft).                 Excluding transmitters, the Eiffel Tower is the second tallest                 free-standing structure in France after the Millau Viaduct.                 """    }]print(synopsis_chain.apply(test_prompts, callbacks=callbacks))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplatePreviousCollege ConfidentialNextConfident AI On this page CometIn this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with Comet.  Example Project: Comet with LangChainInstall Comet and Dependencies‚Äãimport sys{sys.executable} -m spacy download en_core_web_smInitialize Comet and Set your Credentials‚ÄãYou can grab your Comet API Key here or click the link after initializing Cometimport comet_mlcomet_ml.init(project_name="comet-example-langchain")Set OpenAI and SerpAPI credentials‚ÄãYou will need an OpenAI API Key and a SerpAPI API Key to run the following examplesimport osos.environ["OPENAI_API_KEY"] = "..."# os.environ["OPENAI_ORGANIZATION"] = "..."os.environ["SERPAPI_API_KEY"] = "..."Scenario 1: Using just an LLM‚Äãfrom datetime import datetimefrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["llm"],    visualizations=["dep"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)llm_result = llm.generate(["Tell me a joke", "Tell me a poem", "Tell me a fact"] * 3)print("LLM result", llm_result)comet_callback.flush_tracker(llm, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 2: Using an LLM in a Chain‚Äãfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatecomet_callback = CometCallbackHandler(    complexity_metrics=True,    project_name="comet-example-langchain",    stream_logs=True,    tags=["synopsis-chain"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)test_prompts = [{"title": "Documentary about Bigfoot in Paris"}]print(synopsis_chain.apply(test_prompts))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplateScenario 3: Using An Agent with Tools‚Äãfrom langchain.agents import initialize_agent, load_toolsfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["agent"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)tools = load_tools(["serpapi", "llm-math"], llm=llm, callbacks=callbacks)agent = initialize_agent(    tools,    llm,    agent="zero-shot-react-description",    callbacks=callbacks,    verbose=True,)agent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?")comet_callback.flush_tracker(agent, finish=True)API Reference:initialize_agentload_toolsCometCallbackHandlerStdOutCallbackHandlerOpenAIScenario 4: Using Custom Evaluation Metrics‚ÄãThe CometCallbackManager also allows you to define and use Custom Evaluation Metrics to assess generated outputs from your model. Let's take a look at how this works. In the snippet below, we will use the ROUGE metric to evaluate the quality of a generated summary of an input prompt. %pip install rouge-scorefrom rouge_score import rouge_scorerfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplateclass Rouge:    def __init__(self, reference):        self.reference = reference        self.scorer = rouge_scorer.RougeScorer(["rougeLsum"], use_stemmer=True)    def compute_metric(self, generation, prompt_idx, gen_idx):        prediction = generation.text        results = self.scorer.score(target=self.reference, prediction=prediction)        return {            "rougeLsum_score": results["rougeLsum"].fmeasure,            "reference": self.reference,        }reference = """The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building.It was the first structure to reach a height of 300 metres.It is now taller than the Chrysler Building in New York City by 5.2 metres (17 ft)Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France ."""rouge_score = Rouge(reference=reference)template = """Given the following article, it is your job to write a summary.Article:{article}Summary: This is the summary for the above article:"""prompt_template = PromptTemplate(input_variables=["article"], template=template)comet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=False,    stream_logs=True,    tags=["custom_metrics"],    custom_metrics=rouge_score.compute_metric,)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)test_prompts = [    {        "article": """                 The tower is 324 metres (1,063 ft) tall, about the same height as                 an 81-storey building, and the tallest structure in Paris. Its base is square,                 measuring 125 metres (410 ft) on each side.                 During its construction, the Eiffel Tower surpassed the                 Washington Monument to become the tallest man-made structure in the world,                 a title it held for 41 years until the Chrysler Building                 in New York City was finished in 1930.                 It was the first structure to reach a height of 300 metres.                 Due to the addition of a broadcasting aerial at the top of the tower in 1957,                 it is now taller than the Chrysler Building by 5.2 metres (17 ft).                 Excluding transmitters, the Eiffel Tower is the second tallest                 free-standing structure in France after the Millau Viaduct.                 """    }]print(synopsis_chain.apply(test_prompts, callbacks=callbacks))comet_callback.flush_tracker(synopsis_chain, finish=True)API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplate import sys{sys.executable} -m spacy download en_core_web_sm import sys{sys.executable} -m spacy download en_core_web_sm  import comet_mlcomet_ml.init(project_name="comet-example-langchain") import comet_mlcomet_ml.init(project_name="comet-example-langchain")  import osos.environ["OPENAI_API_KEY"] = "..."# os.environ["OPENAI_ORGANIZATION"] = "..."os.environ["SERPAPI_API_KEY"] = "..." import osos.environ["OPENAI_API_KEY"] = "..."# os.environ["OPENAI_ORGANIZATION"] = "..."os.environ["SERPAPI_API_KEY"] = "..."  from datetime import datetimefrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["llm"],    visualizations=["dep"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)llm_result = llm.generate(["Tell me a joke", "Tell me a poem", "Tell me a fact"] * 3)print("LLM result", llm_result)comet_callback.flush_tracker(llm, finish=True) from datetime import datetimefrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["llm"],    visualizations=["dep"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks, verbose=True)llm_result = llm.generate(["Tell me a joke", "Tell me a poem", "Tell me a fact"] * 3)print("LLM result", llm_result)comet_callback.flush_tracker(llm, finish=True)  API Reference:CometCallbackHandlerStdOutCallbackHandlerOpenAI from langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatecomet_callback = CometCallbackHandler(    complexity_metrics=True,    project_name="comet-example-langchain",    stream_logs=True,    tags=["synopsis-chain"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)test_prompts = [{"title": "Documentary about Bigfoot in Paris"}]print(synopsis_chain.apply(test_prompts))comet_callback.flush_tracker(synopsis_chain, finish=True) from langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatecomet_callback = CometCallbackHandler(    complexity_metrics=True,    project_name="comet-example-langchain",    stream_logs=True,    tags=["synopsis-chain"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)test_prompts = [{"title": "Documentary about Bigfoot in Paris"}]print(synopsis_chain.apply(test_prompts))comet_callback.flush_tracker(synopsis_chain, finish=True)  API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplate from langchain.agents import initialize_agent, load_toolsfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["agent"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)tools = load_tools(["serpapi", "llm-math"], llm=llm, callbacks=callbacks)agent = initialize_agent(    tools,    llm,    agent="zero-shot-react-description",    callbacks=callbacks,    verbose=True,)agent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?")comet_callback.flush_tracker(agent, finish=True) from langchain.agents import initialize_agent, load_toolsfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.llms import OpenAIcomet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=True,    stream_logs=True,    tags=["agent"],)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9, callbacks=callbacks)tools = load_tools(["serpapi", "llm-math"], llm=llm, callbacks=callbacks)agent = initialize_agent(    tools,    llm,    agent="zero-shot-react-description",    callbacks=callbacks,    verbose=True,)agent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?")comet_callback.flush_tracker(agent, finish=True)  API Reference:initialize_agentload_toolsCometCallbackHandlerStdOutCallbackHandlerOpenAI %pip install rouge-score %pip install rouge-score  from rouge_score import rouge_scorerfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplateclass Rouge:    def __init__(self, reference):        self.reference = reference        self.scorer = rouge_scorer.RougeScorer(["rougeLsum"], use_stemmer=True)    def compute_metric(self, generation, prompt_idx, gen_idx):        prediction = generation.text        results = self.scorer.score(target=self.reference, prediction=prediction)        return {            "rougeLsum_score": results["rougeLsum"].fmeasure,            "reference": self.reference,        }reference = """The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building.It was the first structure to reach a height of 300 metres.It is now taller than the Chrysler Building in New York City by 5.2 metres (17 ft)Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France ."""rouge_score = Rouge(reference=reference)template = """Given the following article, it is your job to write a summary.Article:{article}Summary: This is the summary for the above article:"""prompt_template = PromptTemplate(input_variables=["article"], template=template)comet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=False,    stream_logs=True,    tags=["custom_metrics"],    custom_metrics=rouge_score.compute_metric,)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)test_prompts = [    {        "article": """                 The tower is 324 metres (1,063 ft) tall, about the same height as                 an 81-storey building, and the tallest structure in Paris. Its base is square,                 measuring 125 metres (410 ft) on each side.                 During its construction, the Eiffel Tower surpassed the                 Washington Monument to become the tallest man-made structure in the world,                 a title it held for 41 years until the Chrysler Building                 in New York City was finished in 1930.                 It was the first structure to reach a height of 300 metres.                 Due to the addition of a broadcasting aerial at the top of the tower in 1957,                 it is now taller than the Chrysler Building by 5.2 metres (17 ft).                 Excluding transmitters, the Eiffel Tower is the second tallest                 free-standing structure in France after the Millau Viaduct.                 """    }]print(synopsis_chain.apply(test_prompts, callbacks=callbacks))comet_callback.flush_tracker(synopsis_chain, finish=True) from rouge_score import rouge_scorerfrom langchain.callbacks import CometCallbackHandler, StdOutCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplateclass Rouge:    def __init__(self, reference):        self.reference = reference        self.scorer = rouge_scorer.RougeScorer(["rougeLsum"], use_stemmer=True)    def compute_metric(self, generation, prompt_idx, gen_idx):        prediction = generation.text        results = self.scorer.score(target=self.reference, prediction=prediction)        return {            "rougeLsum_score": results["rougeLsum"].fmeasure,            "reference": self.reference,        }reference = """The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building.It was the first structure to reach a height of 300 metres.It is now taller than the Chrysler Building in New York City by 5.2 metres (17 ft)Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France ."""rouge_score = Rouge(reference=reference)template = """Given the following article, it is your job to write a summary.Article:{article}Summary: This is the summary for the above article:"""prompt_template = PromptTemplate(input_variables=["article"], template=template)comet_callback = CometCallbackHandler(    project_name="comet-example-langchain",    complexity_metrics=False,    stream_logs=True,    tags=["custom_metrics"],    custom_metrics=rouge_score.compute_metric,)callbacks = [StdOutCallbackHandler(), comet_callback]llm = OpenAI(temperature=0.9)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)test_prompts = [    {        "article": """                 The tower is 324 metres (1,063 ft) tall, about the same height as                 an 81-storey building, and the tallest structure in Paris. Its base is square,                 measuring 125 metres (410 ft) on each side.                 During its construction, the Eiffel Tower surpassed the                 Washington Monument to become the tallest man-made structure in the world,                 a title it held for 41 years until the Chrysler Building                 in New York City was finished in 1930.                 It was the first structure to reach a height of 300 metres.                 Due to the addition of a broadcasting aerial at the top of the tower in 1957,                 it is now taller than the Chrysler Building by 5.2 metres (17 ft).                 Excluding transmitters, the Eiffel Tower is the second tallest                 free-standing structure in France after the Millau Viaduct.                 """    }]print(synopsis_chain.apply(test_prompts, callbacks=callbacks))comet_callback.flush_tracker(synopsis_chain, finish=True)  API Reference:CometCallbackHandlerStdOutCallbackHandlerLLMChainOpenAIPromptTemplate Previous College Confidential Next Confident AI Install Comet and DependenciesInitialize Comet and Set your CredentialsSet OpenAI and SerpAPI credentialsScenario 1: Using just an LLMScenario 2: Using an LLM in a ChainScenario 3: Using An Agent with ToolsScenario 4: Using Custom Evaluation Metrics Install Comet and DependenciesInitialize Comet and Set your CredentialsSet OpenAI and SerpAPI credentialsScenario 1: Using just an LLMScenario 2: Using an LLM in a ChainScenario 3: Using An Agent with ToolsScenario 4: Using Custom Evaluation Metrics CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/) Activeloop Deep Lake (/docs/integrations/providers/activeloop_deeplake) AI21 Labs (/docs/integrations/providers/ai21) Aim (/docs/integrations/providers/aim_tracking) AINetwork (/docs/integrations/providers/ainetwork) Airbyte (/docs/integrations/providers/airbyte) Airtable (/docs/integrations/providers/airtable) Aleph Alpha (/docs/integrations/providers/aleph_alpha) Alibaba Cloud Opensearch (/docs/integrations/providers/alibabacloud_opensearch) Amazon API Gateway (/docs/integrations/providers/amazon_api_gateway) AnalyticDB (/docs/integrations/providers/analyticdb) Annoy (/docs/integrations/providers/annoy) Anyscale (/docs/integrations/providers/anyscale) Apify (/docs/integrations/providers/apify) ArangoDB (/docs/integrations/providers/arangodb) Argilla (/docs/integrations/providers/argilla) Arthur (/docs/integrations/providers/arthur_tracking) Arxiv (/docs/integrations/providers/arxiv) Atlas (/docs/integrations/providers/atlas) AwaDB (/docs/integrations/providers/awadb) AWS S3 Directory (/docs/integrations/providers/aws_s3) AZLyrics (/docs/integrations/providers/azlyrics) Azure Blob Storage (/docs/integrations/providers/azure_blob_storage) Azure Cognitive Search (/docs/integrations/providers/azure_cognitive_search_) Azure OpenAI (/docs/integrations/providers/azure_openai) BagelDB (/docs/integrations/providers/bageldb) Banana (/docs/integrations/providers/bananadev) Baseten (/docs/integrations/providers/baseten) Beam (/docs/integrations/providers/beam) Bedrock (/docs/integrations/providers/bedrock) BiliBili (/docs/integrations/providers/bilibili) NIBittensor (/docs/integrations/providers/bittensor) Blackboard (/docs/integrations/providers/blackboard) Brave Search (/docs/integrations/providers/brave_search) Cassandra (/docs/integrations/providers/cassandra) CerebriumAI (/docs/integrations/providers/cerebriumai) Chaindesk (/docs/integrations/providers/chaindesk) Chroma (/docs/integrations/providers/chroma) Clarifai (/docs/integrations/providers/clarifai) ClearML (/docs/integrations/providers/clearml_tracking) ClickHouse (/docs/integrations/providers/clickhouse) CnosDB (/docs/integrations/providers/cnosdb) Cohere (/docs/integrations/providers/cohere) College Confidential (/docs/integrations/providers/college_confidential) Comet (/docs/integrations/providers/comet_tracking) Confident AI (/docs/integrations/providers/confident) Confluence (/docs/integrations/providers/confluence) C Transformers (/docs/integrations/providers/ctransformers) DashVector (/docs/integrations/providers/dashvector) Databricks (/docs/integrations/providers/databricks) Datadog Tracing (/docs/integrations/providers/datadog) Datadog Logs (/docs/integrations/providers/datadog_logs) DataForSEO (/docs/integrations/providers/dataforseo) DeepInfra (/docs/integrations/providers/deepinfra) DeepSparse (/docs/integrations/providers/deepsparse) Diffbot (/docs/integrations/providers/diffbot) Dingo (/docs/integrations/providers/dingo) Discord (/docs/integrations/providers/discord) DocArray (/docs/integrations/providers/docarray) Docugami (/docs/integrations/providers/docugami) DuckDB (/docs/integrations/providers/duckdb) Elasticsearch (/docs/integrations/providers/elasticsearch) Epsilla (/docs/integrations/providers/epsilla) EverNote (/docs/integrations/providers/evernote) Facebook Chat (/docs/integrations/providers/facebook_chat) Facebook Faiss (/docs/integrations/providers/facebook_faiss) Figma (/docs/integrations/providers/figma) Fireworks (/docs/integrations/providers/fireworks) Flyte (/docs/integrations/providers/flyte) ForefrontAI (/docs/integrations/providers/forefrontai) Git (/docs/integrations/providers/git) GitBook (/docs/integrations/providers/gitbook) Golden (/docs/integrations/providers/golden) Google BigQuery (/docs/integrations/providers/google_bigquery) Google Cloud Storage (/docs/integrations/providers/google_cloud_storage) Google Drive (/docs/integrations/providers/google_drive) Google Search (/docs/integrations/providers/google_search) Google Serper (/docs/integrations/providers/google_serper) Google Vertex AI MatchingEngine (/docs/integrations/providers/google_vertex_ai_matchingengine) GooseAI (/docs/integrations/providers/gooseai) GPT4All (/docs/integrations/providers/gpt4all) Graphsignal (/docs/integrations/providers/graphsignal) Grobid (/docs/integrations/providers/grobid) Gutenberg (/docs/integrations/providers/gutenberg) Hacker News (/docs/integrations/providers/hacker_news) Hazy Research (/docs/integrations/providers/hazy_research) Helicone (/docs/integrations/providers/helicone) Hologres (/docs/integrations/providers/hologres) Hugging Face (/docs/integrations/providers/huggingface) iFixit (/docs/integrations/providers/ifixit) IMSDb (/docs/integrations/providers/imsdb) Infino (/docs/integrations/providers/infino) Jina (/docs/integrations/providers/jina) Konko (/docs/integrations/providers/konko) LanceDB (/docs/integrations/providers/lancedb) LangChain Decorators ‚ú® (/docs/integrations/providers/langchain_decorators) Llama.cpp (/docs/integrations/providers/llamacpp) Log10 (/docs/integrations/providers/log10) Marqo (/docs/integrations/providers/marqo) MediaWikiDump (/docs/integrations/providers/mediawikidump) Meilisearch (/docs/integrations/providers/meilisearch) Metal (/docs/integrations/providers/metal) Microsoft OneDrive (/docs/integrations/providers/microsoft_onedrive) Microsoft PowerPoint (/docs/integrations/providers/microsoft_powerpoint) Microsoft Word (/docs/integrations/providers/microsoft_word) Milvus (/docs/integrations/providers/milvus) Minimax (/docs/integrations/providers/minimax) MLflow AI Gateway (/docs/integrations/providers/mlflow_ai_gateway) MLflow (/docs/integrations/providers/mlflow_tracking) Modal (/docs/integrations/providers/modal) ModelScope (/docs/integrations/providers/modelscope) Modern Treasury (/docs/integrations/providers/modern_treasury) Momento (/docs/integrations/providers/momento) MongoDB Atlas (/docs/integrations/providers/mongodb_atlas) Motherduck (/docs/integrations/providers/motherduck) MyScale (/docs/integrations/providers/myscale) Neo4j (/docs/integrations/providers/neo4j) NLPCloud (/docs/integrations/providers/nlpcloud) Notion DB (/docs/integrations/providers/notion) Obsidian (/docs/integrations/providers/obsidian) OpenAI (/docs/integrations/providers/openai) OpenLLM (/docs/integrations/providers/openllm) OpenSearch (/docs/integrations/providers/opensearch) OpenWeatherMap (/docs/integrations/providers/openweathermap) Petals (/docs/integrations/providers/petals) Postgres Embedding (/docs/integrations/providers/pg_embedding) PGVector (/docs/integrations/providers/pgvector) Pinecone (/docs/integrations/providers/pinecone) PipelineAI (/docs/integrations/providers/pipelineai) Portkey (/docs/integrations/providers/portkey/) Predibase (/docs/integrations/providers/predibase) Prediction Guard (/docs/integrations/providers/predictionguard) PromptLayer (/docs/integrations/providers/promptlayer) Psychic (/docs/integrations/providers/psychic) PubMed (/docs/integrations/providers/pubmed) Qdrant (/docs/integrations/providers/qdrant) Ray Serve (/docs/integrations/providers/ray_serve) Rebuff (/docs/integrations/providers/rebuff) Reddit (/docs/integrations/providers/reddit) Redis (/docs/integrations/providers/redis) Replicate (/docs/integrations/providers/replicate) Roam (/docs/integrations/providers/roam) Rockset (/docs/integrations/providers/rockset) Runhouse (/docs/integrations/providers/runhouse) RWKV-4 (/docs/integrations/providers/rwkv) SageMaker Endpoint (/docs/integrations/providers/sagemaker_endpoint) SageMaker Tracking (/docs/integrations/providers/sagemaker_tracking) ScaNN (/docs/integrations/providers/scann) SearxNG Search API (/docs/integrations/providers/searx) SerpAPI (/docs/integrations/providers/serpapi) Shale Protocol (/docs/integrations/providers/shaleprotocol) SingleStoreDB (/docs/integrations/providers/singlestoredb) scikit-learn (/docs/integrations/providers/sklearn) Slack (/docs/integrations/providers/slack) spaCy (/docs/integrations/providers/spacy) Spreedly (/docs/integrations/providers/spreedly) StarRocks (/docs/integrations/providers/starrocks) StochasticAI (/docs/integrations/providers/stochasticai) Stripe (/docs/integrations/providers/stripe) Supabase (Postgres) (/docs/integrations/providers/supabase) Nebula (/docs/integrations/providers/symblai_nebula) Tair (/docs/integrations/providers/tair) Telegram (/docs/integrations/providers/telegram) TencentVectorDB (/docs/integrations/providers/tencentvectordb) TensorFlow Datasets (/docs/integrations/providers/tensorflow_datasets) Tigris (/docs/integrations/providers/tigris) 2Markdown (/docs/integrations/providers/tomarkdown) Trello (/docs/integrations/providers/trello) TruLens (/docs/integrations/providers/trulens) Twitter (/docs/integrations/providers/twitter) Typesense (/docs/integrations/providers/typesense) Unstructured (/docs/integrations/providers/unstructured) USearch (/docs/integrations/providers/usearch) Vearch (/docs/integrations/providers/vearch) Vectara (/docs/integrations/providers/vectara/) Vespa (/docs/integrations/providers/vespa) WandB Tracing (/docs/integrations/providers/wandb_tracing) Weights & Biases (/docs/integrations/providers/wandb_tracking) Weather (/docs/integrations/providers/weather) Weaviate (/docs/integrations/providers/weaviate) WhatsApp (/docs/integrations/providers/whatsapp) WhyLabs (/docs/integrations/providers/whylabs_profiling) Wikipedia (/docs/integrations/providers/wikipedia) Wolfram Alpha (/docs/integrations/providers/wolfram_alpha) Writer (/docs/integrations/providers/writer) Xata (/docs/integrations/providers/xata) Xorbits Inference (Xinference) (/docs/integrations/providers/xinference) Yeager.ai (/docs/integrations/providers/yeagerai) YouTube (/docs/integrations/providers/youtube) Zep (/docs/integrations/providers/zep) Zilliz (/docs/integrations/providers/zilliz)  (/) Integrations (/docs/integrations) Grouped by provider (/docs/integrations/providers/) Comet (https://www.comet.com/site/?utm_source=langchain&utm_medium=referral&utm_campaign=comet_notebook)  (https://colab.research.google.com/github/hwchase17/langchain/blob/master/docs/ecosystem/comet_tracking.html) Comet with LangChain (https://www.comet.com/examples/comet-example-langchain/view/b5ZThK6OFdhKWVSP3fDfRtrNF/panels?utm_source=langchain&utm_medium=referral&utm_campaign=comet_notebook) ‚Äã (#install-comet-and-dependencies) ‚Äã (#initialize-comet-and-set-your-credentials) Comet API Key here (https://www.comet.com/signup?utm_source=langchain&utm_medium=referral&utm_campaign=comet_notebook) ‚Äã (#set-openai-and-serpapi-credentials) OpenAI API Key (https://platform.openai.com/account/api-keys) SerpAPI API Key (https://serpapi.com/dashboard) ‚Äã (#scenario-1-using-just-an-llm) CometCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.comet_ml_callback.CometCallbackHandler.html) StdOutCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.stdout.StdOutCallbackHandler.html) OpenAI (https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html) ‚Äã (#scenario-2-using-an-llm-in-a-chain) CometCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.comet_ml_callback.CometCallbackHandler.html) StdOutCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.stdout.StdOutCallbackHandler.html) LLMChain (https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html) OpenAI (https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html) PromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html) ‚Äã (#scenario-3-using-an-agent-with-tools) initialize_agent (https://api.python.langchain.com/en/latest/agents/langchain.agents.initialize.initialize_agent.html) load_tools (https://api.python.langchain.com/en/latest/agents/langchain.agents.load_tools.load_tools.html) CometCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.comet_ml_callback.CometCallbackHandler.html) StdOutCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.stdout.StdOutCallbackHandler.html) OpenAI (https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html) ‚Äã (#scenario-4-using-custom-evaluation-metrics) ROUGE (https://huggingface.co/spaces/evaluate-metric/rouge) CometCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.comet_ml_callback.CometCallbackHandler.html) StdOutCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.stdout.StdOutCallbackHandler.html) LLMChain (https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html) OpenAI (https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html) PromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html) PreviousCollege Confidential (/docs/integrations/providers/college_confidential) NextConfident AI (/docs/integrations/providers/confident) Install Comet and Dependencies (#install-comet-and-dependencies) Initialize Comet and Set your Credentials (#initialize-comet-and-set-your-credentials) Set OpenAI and SerpAPI credentials (#set-openai-and-serpapi-credentials) Scenario 1: Using just an LLM (#scenario-1-using-just-an-llm) Scenario 2: Using an LLM in a Chain (#scenario-2-using-an-llm-in-a-chain) Scenario 3: Using An Agent with Tools (#scenario-3-using-an-agent-with-tools) Scenario 4: Using Custom Evaluation Metrics (#scenario-4-using-custom-evaluation-metrics) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)