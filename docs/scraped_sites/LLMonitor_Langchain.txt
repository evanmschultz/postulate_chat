LLMonitor is an open-source observability platform that provides cost and usage analytics, user tracking, tracing and evaluation tools. Create an account on llmonitor.com, then copy your new app's tracking id. Once you have it, set it as an environment variable by running: If you'd prefer not to set an environment variable, you can pass the key directly when initializing the callback handler: Make sure to pass the callback handler to the run method so that all related chains and llm calls are correctly tracked. It is also recommended to pass agent_name in the metadata to be able to distinguish between agents in the dashboard. Example: Another example: For any question or issue with integration you can reach out to the LLMonitor team on Discord or via email. IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider CallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlit Argilla Confident Context Infino Label Studio LLMonitor PromptLayer Streamlit Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations Callbacks LLMonitor LLMonitorCallbackHandler OpenAI ChatOpenAI LLMonitorCallbackHandler ChatOpenAI SystemMessage HumanMessage OpenAIFunctionsAgent AgentExecutor tool LLMonitorCallbackHandler load_tools initialize_agent AgentType OpenAI LLMonitorCallbackHandler Setup Usage with LLM/Chat models Usage with chains and agents Support Discord Twitter Python JS/TS Homepage Blog Skip to main content🦜️🔗 LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsCallbacksLLMonitorOn this pageLLMonitorLLMonitor is an open-source observability platform that provides cost and usage analytics, user tracking, tracing and evaluation tools.Setup​Create an account on llmonitor.com, then copy your new app's tracking id.Once you have it, set it as an environment variable by running:export LLMONITOR_APP_ID="..."If you'd prefer not to set an environment variable, you can pass the key directly when initializing the callback handler:from langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler(app_id="...")API Reference:LLMonitorCallbackHandlerUsage with LLM/Chat models​from langchain.llms import OpenAIfrom langchain.chat_models import ChatOpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(    callbacks=[handler],)chat = ChatOpenAI(    callbacks=[handler],    metadata={"userId": "123"},  # you can assign user ids to models in the metadata)API Reference:OpenAIChatOpenAILLMonitorCallbackHandlerUsage with chains and agents​Make sure to pass the callback handler to the run method so that all related chains and llm calls are correctly tracked.It is also recommended to pass agent_name in the metadata to be able to distinguish between agents in the dashboard.Example:from langchain.chat_models import ChatOpenAIfrom langchain.schema import SystemMessage, HumanMessagefrom langchain.agents import OpenAIFunctionsAgent, AgentExecutor, toolfrom langchain.callbacks import LLMonitorCallbackHandlerllm = ChatOpenAI(temperature=0)handler = LLMonitorCallbackHandler()@tooldef get_word_length(word: str) -> int:    """Returns the length of a word."""    return len(word)tools = [get_word_length]prompt = OpenAIFunctionsAgent.create_prompt(    system_message=SystemMessage(        content="You are very powerful assistant, but bad at calculating lengths of words."    ))agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt, verbose=True)agent_executor = AgentExecutor(    agent=agent, tools=tools, verbose=True, metadata={"agent_name": "WordCount"}  # <- recommended, assign a custom name)agent_executor.run("how many letters in the word educa?", callbacks=[handler])API Reference:ChatOpenAISystemMessageHumanMessageOpenAIFunctionsAgentAgentExecutortoolLLMonitorCallbackHandlerAnother example:from langchain.agents import load_tools, initialize_agent, AgentTypefrom langchain.llms import OpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(temperature=0)tools = load_tools(["serpapi", "llm-math"], llm=llm)agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, metadata={ "agent_name": "GirlfriendAgeFinder" })  # <- recommended, assign a custom nameagent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?",    callbacks=[handler],)API Reference:load_toolsinitialize_agentAgentTypeOpenAILLMonitorCallbackHandlerSupport​For any question or issue with integration you can reach out to the LLMonitor team on Discord or via email.PreviousLabel StudioNextPromptLayerSetupUsage with LLM/Chat modelsUsage with chains and agentsSupportCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright © 2023 LangChain, Inc. Skip to main content 🦜️🔗 LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK 🦜️🔗 LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsCallbacksLLMonitorOn this pageLLMonitorLLMonitor is an open-source observability platform that provides cost and usage analytics, user tracking, tracing and evaluation tools.Setup​Create an account on llmonitor.com, then copy your new app's tracking id.Once you have it, set it as an environment variable by running:export LLMONITOR_APP_ID="..."If you'd prefer not to set an environment variable, you can pass the key directly when initializing the callback handler:from langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler(app_id="...")API Reference:LLMonitorCallbackHandlerUsage with LLM/Chat models​from langchain.llms import OpenAIfrom langchain.chat_models import ChatOpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(    callbacks=[handler],)chat = ChatOpenAI(    callbacks=[handler],    metadata={"userId": "123"},  # you can assign user ids to models in the metadata)API Reference:OpenAIChatOpenAILLMonitorCallbackHandlerUsage with chains and agents​Make sure to pass the callback handler to the run method so that all related chains and llm calls are correctly tracked.It is also recommended to pass agent_name in the metadata to be able to distinguish between agents in the dashboard.Example:from langchain.chat_models import ChatOpenAIfrom langchain.schema import SystemMessage, HumanMessagefrom langchain.agents import OpenAIFunctionsAgent, AgentExecutor, toolfrom langchain.callbacks import LLMonitorCallbackHandlerllm = ChatOpenAI(temperature=0)handler = LLMonitorCallbackHandler()@tooldef get_word_length(word: str) -> int:    """Returns the length of a word."""    return len(word)tools = [get_word_length]prompt = OpenAIFunctionsAgent.create_prompt(    system_message=SystemMessage(        content="You are very powerful assistant, but bad at calculating lengths of words."    ))agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt, verbose=True)agent_executor = AgentExecutor(    agent=agent, tools=tools, verbose=True, metadata={"agent_name": "WordCount"}  # <- recommended, assign a custom name)agent_executor.run("how many letters in the word educa?", callbacks=[handler])API Reference:ChatOpenAISystemMessageHumanMessageOpenAIFunctionsAgentAgentExecutortoolLLMonitorCallbackHandlerAnother example:from langchain.agents import load_tools, initialize_agent, AgentTypefrom langchain.llms import OpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(temperature=0)tools = load_tools(["serpapi", "llm-math"], llm=llm)agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, metadata={ "agent_name": "GirlfriendAgeFinder" })  # <- recommended, assign a custom nameagent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?",    callbacks=[handler],)API Reference:load_toolsinitialize_agentAgentTypeOpenAILLMonitorCallbackHandlerSupport​For any question or issue with integration you can reach out to the LLMonitor team on Discord or via email.PreviousLabel StudioNextPromptLayerSetupUsage with LLM/Chat modelsUsage with chains and agentsSupport IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsCallbacksLLMonitorOn this pageLLMonitorLLMonitor is an open-source observability platform that provides cost and usage analytics, user tracking, tracing and evaluation tools.Setup​Create an account on llmonitor.com, then copy your new app's tracking id.Once you have it, set it as an environment variable by running:export LLMONITOR_APP_ID="..."If you'd prefer not to set an environment variable, you can pass the key directly when initializing the callback handler:from langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler(app_id="...")API Reference:LLMonitorCallbackHandlerUsage with LLM/Chat models​from langchain.llms import OpenAIfrom langchain.chat_models import ChatOpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(    callbacks=[handler],)chat = ChatOpenAI(    callbacks=[handler],    metadata={"userId": "123"},  # you can assign user ids to models in the metadata)API Reference:OpenAIChatOpenAILLMonitorCallbackHandlerUsage with chains and agents​Make sure to pass the callback handler to the run method so that all related chains and llm calls are correctly tracked.It is also recommended to pass agent_name in the metadata to be able to distinguish between agents in the dashboard.Example:from langchain.chat_models import ChatOpenAIfrom langchain.schema import SystemMessage, HumanMessagefrom langchain.agents import OpenAIFunctionsAgent, AgentExecutor, toolfrom langchain.callbacks import LLMonitorCallbackHandlerllm = ChatOpenAI(temperature=0)handler = LLMonitorCallbackHandler()@tooldef get_word_length(word: str) -> int:    """Returns the length of a word."""    return len(word)tools = [get_word_length]prompt = OpenAIFunctionsAgent.create_prompt(    system_message=SystemMessage(        content="You are very powerful assistant, but bad at calculating lengths of words."    ))agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt, verbose=True)agent_executor = AgentExecutor(    agent=agent, tools=tools, verbose=True, metadata={"agent_name": "WordCount"}  # <- recommended, assign a custom name)agent_executor.run("how many letters in the word educa?", callbacks=[handler])API Reference:ChatOpenAISystemMessageHumanMessageOpenAIFunctionsAgentAgentExecutortoolLLMonitorCallbackHandlerAnother example:from langchain.agents import load_tools, initialize_agent, AgentTypefrom langchain.llms import OpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(temperature=0)tools = load_tools(["serpapi", "llm-math"], llm=llm)agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, metadata={ "agent_name": "GirlfriendAgeFinder" })  # <- recommended, assign a custom nameagent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?",    callbacks=[handler],)API Reference:load_toolsinitialize_agentAgentTypeOpenAILLMonitorCallbackHandlerSupport​For any question or issue with integration you can reach out to the LLMonitor team on Discord or via email.PreviousLabel StudioNextPromptLayerSetupUsage with LLM/Chat modelsUsage with chains and agentsSupport IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsCallbacksLLMonitorOn this pageLLMonitorLLMonitor is an open-source observability platform that provides cost and usage analytics, user tracking, tracing and evaluation tools.Setup​Create an account on llmonitor.com, then copy your new app's tracking id.Once you have it, set it as an environment variable by running:export LLMONITOR_APP_ID="..."If you'd prefer not to set an environment variable, you can pass the key directly when initializing the callback handler:from langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler(app_id="...")API Reference:LLMonitorCallbackHandlerUsage with LLM/Chat models​from langchain.llms import OpenAIfrom langchain.chat_models import ChatOpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(    callbacks=[handler],)chat = ChatOpenAI(    callbacks=[handler],    metadata={"userId": "123"},  # you can assign user ids to models in the metadata)API Reference:OpenAIChatOpenAILLMonitorCallbackHandlerUsage with chains and agents​Make sure to pass the callback handler to the run method so that all related chains and llm calls are correctly tracked.It is also recommended to pass agent_name in the metadata to be able to distinguish between agents in the dashboard.Example:from langchain.chat_models import ChatOpenAIfrom langchain.schema import SystemMessage, HumanMessagefrom langchain.agents import OpenAIFunctionsAgent, AgentExecutor, toolfrom langchain.callbacks import LLMonitorCallbackHandlerllm = ChatOpenAI(temperature=0)handler = LLMonitorCallbackHandler()@tooldef get_word_length(word: str) -> int:    """Returns the length of a word."""    return len(word)tools = [get_word_length]prompt = OpenAIFunctionsAgent.create_prompt(    system_message=SystemMessage(        content="You are very powerful assistant, but bad at calculating lengths of words."    ))agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt, verbose=True)agent_executor = AgentExecutor(    agent=agent, tools=tools, verbose=True, metadata={"agent_name": "WordCount"}  # <- recommended, assign a custom name)agent_executor.run("how many letters in the word educa?", callbacks=[handler])API Reference:ChatOpenAISystemMessageHumanMessageOpenAIFunctionsAgentAgentExecutortoolLLMonitorCallbackHandlerAnother example:from langchain.agents import load_tools, initialize_agent, AgentTypefrom langchain.llms import OpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(temperature=0)tools = load_tools(["serpapi", "llm-math"], llm=llm)agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, metadata={ "agent_name": "GirlfriendAgeFinder" })  # <- recommended, assign a custom nameagent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?",    callbacks=[handler],)API Reference:load_toolsinitialize_agentAgentTypeOpenAILLMonitorCallbackHandlerSupport​For any question or issue with integration you can reach out to the LLMonitor team on Discord or via email.PreviousLabel StudioNextPromptLayerSetupUsage with LLM/Chat modelsUsage with chains and agentsSupport IntegrationsCallbacksLLMonitorOn this pageLLMonitorLLMonitor is an open-source observability platform that provides cost and usage analytics, user tracking, tracing and evaluation tools.Setup​Create an account on llmonitor.com, then copy your new app's tracking id.Once you have it, set it as an environment variable by running:export LLMONITOR_APP_ID="..."If you'd prefer not to set an environment variable, you can pass the key directly when initializing the callback handler:from langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler(app_id="...")API Reference:LLMonitorCallbackHandlerUsage with LLM/Chat models​from langchain.llms import OpenAIfrom langchain.chat_models import ChatOpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(    callbacks=[handler],)chat = ChatOpenAI(    callbacks=[handler],    metadata={"userId": "123"},  # you can assign user ids to models in the metadata)API Reference:OpenAIChatOpenAILLMonitorCallbackHandlerUsage with chains and agents​Make sure to pass the callback handler to the run method so that all related chains and llm calls are correctly tracked.It is also recommended to pass agent_name in the metadata to be able to distinguish between agents in the dashboard.Example:from langchain.chat_models import ChatOpenAIfrom langchain.schema import SystemMessage, HumanMessagefrom langchain.agents import OpenAIFunctionsAgent, AgentExecutor, toolfrom langchain.callbacks import LLMonitorCallbackHandlerllm = ChatOpenAI(temperature=0)handler = LLMonitorCallbackHandler()@tooldef get_word_length(word: str) -> int:    """Returns the length of a word."""    return len(word)tools = [get_word_length]prompt = OpenAIFunctionsAgent.create_prompt(    system_message=SystemMessage(        content="You are very powerful assistant, but bad at calculating lengths of words."    ))agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt, verbose=True)agent_executor = AgentExecutor(    agent=agent, tools=tools, verbose=True, metadata={"agent_name": "WordCount"}  # <- recommended, assign a custom name)agent_executor.run("how many letters in the word educa?", callbacks=[handler])API Reference:ChatOpenAISystemMessageHumanMessageOpenAIFunctionsAgentAgentExecutortoolLLMonitorCallbackHandlerAnother example:from langchain.agents import load_tools, initialize_agent, AgentTypefrom langchain.llms import OpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(temperature=0)tools = load_tools(["serpapi", "llm-math"], llm=llm)agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, metadata={ "agent_name": "GirlfriendAgeFinder" })  # <- recommended, assign a custom nameagent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?",    callbacks=[handler],)API Reference:load_toolsinitialize_agentAgentTypeOpenAILLMonitorCallbackHandlerSupport​For any question or issue with integration you can reach out to the LLMonitor team on Discord or via email.PreviousLabel StudioNextPromptLayerSetupUsage with LLM/Chat modelsUsage with chains and agentsSupport IntegrationsCallbacksLLMonitorOn this pageLLMonitorLLMonitor is an open-source observability platform that provides cost and usage analytics, user tracking, tracing and evaluation tools.Setup​Create an account on llmonitor.com, then copy your new app's tracking id.Once you have it, set it as an environment variable by running:export LLMONITOR_APP_ID="..."If you'd prefer not to set an environment variable, you can pass the key directly when initializing the callback handler:from langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler(app_id="...")API Reference:LLMonitorCallbackHandlerUsage with LLM/Chat models​from langchain.llms import OpenAIfrom langchain.chat_models import ChatOpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(    callbacks=[handler],)chat = ChatOpenAI(    callbacks=[handler],    metadata={"userId": "123"},  # you can assign user ids to models in the metadata)API Reference:OpenAIChatOpenAILLMonitorCallbackHandlerUsage with chains and agents​Make sure to pass the callback handler to the run method so that all related chains and llm calls are correctly tracked.It is also recommended to pass agent_name in the metadata to be able to distinguish between agents in the dashboard.Example:from langchain.chat_models import ChatOpenAIfrom langchain.schema import SystemMessage, HumanMessagefrom langchain.agents import OpenAIFunctionsAgent, AgentExecutor, toolfrom langchain.callbacks import LLMonitorCallbackHandlerllm = ChatOpenAI(temperature=0)handler = LLMonitorCallbackHandler()@tooldef get_word_length(word: str) -> int:    """Returns the length of a word."""    return len(word)tools = [get_word_length]prompt = OpenAIFunctionsAgent.create_prompt(    system_message=SystemMessage(        content="You are very powerful assistant, but bad at calculating lengths of words."    ))agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt, verbose=True)agent_executor = AgentExecutor(    agent=agent, tools=tools, verbose=True, metadata={"agent_name": "WordCount"}  # <- recommended, assign a custom name)agent_executor.run("how many letters in the word educa?", callbacks=[handler])API Reference:ChatOpenAISystemMessageHumanMessageOpenAIFunctionsAgentAgentExecutortoolLLMonitorCallbackHandlerAnother example:from langchain.agents import load_tools, initialize_agent, AgentTypefrom langchain.llms import OpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(temperature=0)tools = load_tools(["serpapi", "llm-math"], llm=llm)agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, metadata={ "agent_name": "GirlfriendAgeFinder" })  # <- recommended, assign a custom nameagent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?",    callbacks=[handler],)API Reference:load_toolsinitialize_agentAgentTypeOpenAILLMonitorCallbackHandlerSupport​For any question or issue with integration you can reach out to the LLMonitor team on Discord or via email.PreviousLabel StudioNextPromptLayer IntegrationsCallbacksLLMonitorOn this pageLLMonitorLLMonitor is an open-source observability platform that provides cost and usage analytics, user tracking, tracing and evaluation tools.Setup​Create an account on llmonitor.com, then copy your new app's tracking id.Once you have it, set it as an environment variable by running:export LLMONITOR_APP_ID="..."If you'd prefer not to set an environment variable, you can pass the key directly when initializing the callback handler:from langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler(app_id="...")API Reference:LLMonitorCallbackHandlerUsage with LLM/Chat models​from langchain.llms import OpenAIfrom langchain.chat_models import ChatOpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(    callbacks=[handler],)chat = ChatOpenAI(    callbacks=[handler],    metadata={"userId": "123"},  # you can assign user ids to models in the metadata)API Reference:OpenAIChatOpenAILLMonitorCallbackHandlerUsage with chains and agents​Make sure to pass the callback handler to the run method so that all related chains and llm calls are correctly tracked.It is also recommended to pass agent_name in the metadata to be able to distinguish between agents in the dashboard.Example:from langchain.chat_models import ChatOpenAIfrom langchain.schema import SystemMessage, HumanMessagefrom langchain.agents import OpenAIFunctionsAgent, AgentExecutor, toolfrom langchain.callbacks import LLMonitorCallbackHandlerllm = ChatOpenAI(temperature=0)handler = LLMonitorCallbackHandler()@tooldef get_word_length(word: str) -> int:    """Returns the length of a word."""    return len(word)tools = [get_word_length]prompt = OpenAIFunctionsAgent.create_prompt(    system_message=SystemMessage(        content="You are very powerful assistant, but bad at calculating lengths of words."    ))agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt, verbose=True)agent_executor = AgentExecutor(    agent=agent, tools=tools, verbose=True, metadata={"agent_name": "WordCount"}  # <- recommended, assign a custom name)agent_executor.run("how many letters in the word educa?", callbacks=[handler])API Reference:ChatOpenAISystemMessageHumanMessageOpenAIFunctionsAgentAgentExecutortoolLLMonitorCallbackHandlerAnother example:from langchain.agents import load_tools, initialize_agent, AgentTypefrom langchain.llms import OpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(temperature=0)tools = load_tools(["serpapi", "llm-math"], llm=llm)agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, metadata={ "agent_name": "GirlfriendAgeFinder" })  # <- recommended, assign a custom nameagent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?",    callbacks=[handler],)API Reference:load_toolsinitialize_agentAgentTypeOpenAILLMonitorCallbackHandlerSupport​For any question or issue with integration you can reach out to the LLMonitor team on Discord or via email.PreviousLabel StudioNextPromptLayer On this page LLMonitorLLMonitor is an open-source observability platform that provides cost and usage analytics, user tracking, tracing and evaluation tools.Setup​Create an account on llmonitor.com, then copy your new app's tracking id.Once you have it, set it as an environment variable by running:export LLMONITOR_APP_ID="..."If you'd prefer not to set an environment variable, you can pass the key directly when initializing the callback handler:from langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler(app_id="...")API Reference:LLMonitorCallbackHandlerUsage with LLM/Chat models​from langchain.llms import OpenAIfrom langchain.chat_models import ChatOpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(    callbacks=[handler],)chat = ChatOpenAI(    callbacks=[handler],    metadata={"userId": "123"},  # you can assign user ids to models in the metadata)API Reference:OpenAIChatOpenAILLMonitorCallbackHandlerUsage with chains and agents​Make sure to pass the callback handler to the run method so that all related chains and llm calls are correctly tracked.It is also recommended to pass agent_name in the metadata to be able to distinguish between agents in the dashboard.Example:from langchain.chat_models import ChatOpenAIfrom langchain.schema import SystemMessage, HumanMessagefrom langchain.agents import OpenAIFunctionsAgent, AgentExecutor, toolfrom langchain.callbacks import LLMonitorCallbackHandlerllm = ChatOpenAI(temperature=0)handler = LLMonitorCallbackHandler()@tooldef get_word_length(word: str) -> int:    """Returns the length of a word."""    return len(word)tools = [get_word_length]prompt = OpenAIFunctionsAgent.create_prompt(    system_message=SystemMessage(        content="You are very powerful assistant, but bad at calculating lengths of words."    ))agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt, verbose=True)agent_executor = AgentExecutor(    agent=agent, tools=tools, verbose=True, metadata={"agent_name": "WordCount"}  # <- recommended, assign a custom name)agent_executor.run("how many letters in the word educa?", callbacks=[handler])API Reference:ChatOpenAISystemMessageHumanMessageOpenAIFunctionsAgentAgentExecutortoolLLMonitorCallbackHandlerAnother example:from langchain.agents import load_tools, initialize_agent, AgentTypefrom langchain.llms import OpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(temperature=0)tools = load_tools(["serpapi", "llm-math"], llm=llm)agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, metadata={ "agent_name": "GirlfriendAgeFinder" })  # <- recommended, assign a custom nameagent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?",    callbacks=[handler],)API Reference:load_toolsinitialize_agentAgentTypeOpenAILLMonitorCallbackHandlerSupport​For any question or issue with integration you can reach out to the LLMonitor team on Discord or via email. export LLMONITOR_APP_ID="..." export LLMONITOR_APP_ID="..."  from langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler(app_id="...") from langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler(app_id="...")  API Reference:LLMonitorCallbackHandler from langchain.llms import OpenAIfrom langchain.chat_models import ChatOpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(    callbacks=[handler],)chat = ChatOpenAI(    callbacks=[handler],    metadata={"userId": "123"},  # you can assign user ids to models in the metadata) from langchain.llms import OpenAIfrom langchain.chat_models import ChatOpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(    callbacks=[handler],)chat = ChatOpenAI(    callbacks=[handler],    metadata={"userId": "123"},  # you can assign user ids to models in the metadata)  API Reference:OpenAIChatOpenAILLMonitorCallbackHandler from langchain.chat_models import ChatOpenAIfrom langchain.schema import SystemMessage, HumanMessagefrom langchain.agents import OpenAIFunctionsAgent, AgentExecutor, toolfrom langchain.callbacks import LLMonitorCallbackHandlerllm = ChatOpenAI(temperature=0)handler = LLMonitorCallbackHandler()@tooldef get_word_length(word: str) -> int:    """Returns the length of a word."""    return len(word)tools = [get_word_length]prompt = OpenAIFunctionsAgent.create_prompt(    system_message=SystemMessage(        content="You are very powerful assistant, but bad at calculating lengths of words."    ))agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt, verbose=True)agent_executor = AgentExecutor(    agent=agent, tools=tools, verbose=True, metadata={"agent_name": "WordCount"}  # <- recommended, assign a custom name)agent_executor.run("how many letters in the word educa?", callbacks=[handler]) from langchain.chat_models import ChatOpenAIfrom langchain.schema import SystemMessage, HumanMessagefrom langchain.agents import OpenAIFunctionsAgent, AgentExecutor, toolfrom langchain.callbacks import LLMonitorCallbackHandlerllm = ChatOpenAI(temperature=0)handler = LLMonitorCallbackHandler()@tooldef get_word_length(word: str) -> int:    """Returns the length of a word."""    return len(word)tools = [get_word_length]prompt = OpenAIFunctionsAgent.create_prompt(    system_message=SystemMessage(        content="You are very powerful assistant, but bad at calculating lengths of words."    ))agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt, verbose=True)agent_executor = AgentExecutor(    agent=agent, tools=tools, verbose=True, metadata={"agent_name": "WordCount"}  # <- recommended, assign a custom name)agent_executor.run("how many letters in the word educa?", callbacks=[handler])  API Reference:ChatOpenAISystemMessageHumanMessageOpenAIFunctionsAgentAgentExecutortoolLLMonitorCallbackHandler from langchain.agents import load_tools, initialize_agent, AgentTypefrom langchain.llms import OpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(temperature=0)tools = load_tools(["serpapi", "llm-math"], llm=llm)agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, metadata={ "agent_name": "GirlfriendAgeFinder" })  # <- recommended, assign a custom nameagent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?",    callbacks=[handler],) from langchain.agents import load_tools, initialize_agent, AgentTypefrom langchain.llms import OpenAIfrom langchain.callbacks import LLMonitorCallbackHandlerhandler = LLMonitorCallbackHandler()llm = OpenAI(temperature=0)tools = load_tools(["serpapi", "llm-math"], llm=llm)agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, metadata={ "agent_name": "GirlfriendAgeFinder" })  # <- recommended, assign a custom nameagent.run(    "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?",    callbacks=[handler],)  API Reference:load_toolsinitialize_agentAgentTypeOpenAILLMonitorCallbackHandler Previous Label Studio Next PromptLayer SetupUsage with LLM/Chat modelsUsage with chains and agentsSupport SetupUsage with LLM/Chat modelsUsage with chains and agentsSupport CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright © 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright © 2023 LangChain, Inc. Copyright © 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) 🦜️🔗 LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Argilla (/docs/integrations/callbacks/argilla) Confident (/docs/integrations/callbacks/confident) Context (/docs/integrations/callbacks/context) Infino (/docs/integrations/callbacks/infino) Label Studio (/docs/integrations/callbacks/labelstudio) LLMonitor (/docs/integrations/callbacks/llmonitor) PromptLayer (/docs/integrations/callbacks/promptlayer) Streamlit (/docs/integrations/callbacks/streamlit) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) LLMonitor (https://llmonitor.com?utm_source=langchain&utm_medium=py&utm_campaign=docs) ​ (#setup) llmonitor.com (https://llmonitor.com?utm_source=langchain&utm_medium=py&utm_campaign=docs) LLMonitorCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.llmonitor_callback.LLMonitorCallbackHandler.html) ​ (#usage-with-llmchat-models) OpenAI (https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html) ChatOpenAI (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html) LLMonitorCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.llmonitor_callback.LLMonitorCallbackHandler.html) ​ (#usage-with-chains-and-agents) ChatOpenAI (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html) SystemMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.SystemMessage.html) HumanMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.HumanMessage.html) OpenAIFunctionsAgent (https://api.python.langchain.com/en/latest/agents/langchain.agents.openai_functions_agent.base.OpenAIFunctionsAgent.html) AgentExecutor (https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html) tool (https://api.python.langchain.com/en/latest/tools/langchain.tools.base.tool.html) LLMonitorCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.llmonitor_callback.LLMonitorCallbackHandler.html) load_tools (https://api.python.langchain.com/en/latest/agents/langchain.agents.load_tools.load_tools.html) initialize_agent (https://api.python.langchain.com/en/latest/agents/langchain.agents.initialize.initialize_agent.html) AgentType (https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_types.AgentType.html) OpenAI (https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html) LLMonitorCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.llmonitor_callback.LLMonitorCallbackHandler.html) ​ (#support) Discord (http://discord.com/invite/8PafSG58kK) email (mailto:vince@llmonitor.com) PreviousLabel Studio (/docs/integrations/callbacks/labelstudio) NextPromptLayer (/docs/integrations/callbacks/promptlayer) Setup (#setup) Usage with LLM/Chat models (#usage-with-llmchat-models) Usage with chains and agents (#usage-with-chains-and-agents) Support (#support) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)