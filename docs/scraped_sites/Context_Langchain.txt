Context provides user analytics for LLM powered products and features. With Context, you can start understanding your users and improving their experiences in less than 30 minutes. In this guide we will show you how to integrate with Context. To get your Context API token: To use the ContextCallbackHandler, import the handler from Langchain and instantiate it with your Context API token. Ensure you have installed the context-python package before using the handler. The Context callback handler can be used to directly record transcripts between users and AI assistants. The Context callback handler can also be used to record the inputs and outputs of chains. Note that intermediate steps of the chain are not recorded - only the starting inputs and final outputs. Note: Ensure that you pass the same context object to the chat model and the chain. Wrong: Correct: IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider CallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlit Argilla Confident Context Infino Label Studio LLMonitor PromptLayer Streamlit Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations Callbacks Context Go to the settings page within your Context account (https://with.context.ai/settings). Generate a new API Token. Store this token somewhere secure. ContextCallbackHandler ChatOpenAI SystemMessage HumanMessage ContextCallbackHandler ChatOpenAI PromptTemplate ChatPromptTemplate HumanMessagePromptTemplate ContextCallbackHandler Installation and SetupGetting API CredentialsSetup Context Getting API Credentials Setup Context UsageUsing the Context callback within a chat modelUsing the Context callback within Chains Using the Context callback within a chat model Using the Context callback within Chains Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsCallbacksContextOn this pageContextContext provides user analytics for LLM powered products and features.With Context, you can start understanding your users and improving their experiences in less than 30 minutes.In this guide we will show you how to integrate with Context.Installation and Setup‚Äã$ pip install context-python --upgradeGetting API Credentials‚ÄãTo get your Context API token:Go to the settings page within your Context account (https://with.context.ai/settings).Generate a new API Token.Store this token somewhere secure.Setup Context‚ÄãTo use the ContextCallbackHandler, import the handler from Langchain and instantiate it with your Context API token.Ensure you have installed the context-python package before using the handler.import osfrom langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]context_callback = ContextCallbackHandler(token)API Reference:ContextCallbackHandlerUsage‚ÄãUsing the Context callback within a chat model‚ÄãThe Context callback handler can be used to directly record transcripts between users and AI assistants.Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import (    SystemMessage,    HumanMessage,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]chat = ChatOpenAI(    headers={"user_id": "123"}, temperature=0, callbacks=[ContextCallbackHandler(token)])messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(content="I love programming."),]print(chat(messages))API Reference:ChatOpenAISystemMessageHumanMessageContextCallbackHandlerUsing the Context callback within Chains‚ÄãThe Context callback handler can also be used to record the inputs and outputs of chains. Note that intermediate steps of the chain are not recorded - only the starting inputs and final outputs.Note: Ensure that you pass the same context object to the chat model and the chain.Wrong:chat = ChatOpenAI(temperature=0.9, callbacks=[ContextCallbackHandler(token)])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[ContextCallbackHandler(token)])Correct:handler = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain import LLMChainfrom langchain.prompts import PromptTemplatefrom langchain.prompts.chat import (    ChatPromptTemplate,    HumanMessagePromptTemplate,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]human_message_prompt = HumanMessagePromptTemplate(    prompt=PromptTemplate(        template="What is a good name for a company that makes {product}?",        input_variables=["product"],    ))chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])callback = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])print(chain.run("colorful socks"))API Reference:ChatOpenAIPromptTemplateChatPromptTemplateHumanMessagePromptTemplateContextCallbackHandlerPreviousConfidentNextInfinoInstallation and SetupGetting API CredentialsSetup ContextUsageUsing the Context callback within a chat modelUsing the Context callback within ChainsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsCallbacksContextOn this pageContextContext provides user analytics for LLM powered products and features.With Context, you can start understanding your users and improving their experiences in less than 30 minutes.In this guide we will show you how to integrate with Context.Installation and Setup‚Äã$ pip install context-python --upgradeGetting API Credentials‚ÄãTo get your Context API token:Go to the settings page within your Context account (https://with.context.ai/settings).Generate a new API Token.Store this token somewhere secure.Setup Context‚ÄãTo use the ContextCallbackHandler, import the handler from Langchain and instantiate it with your Context API token.Ensure you have installed the context-python package before using the handler.import osfrom langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]context_callback = ContextCallbackHandler(token)API Reference:ContextCallbackHandlerUsage‚ÄãUsing the Context callback within a chat model‚ÄãThe Context callback handler can be used to directly record transcripts between users and AI assistants.Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import (    SystemMessage,    HumanMessage,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]chat = ChatOpenAI(    headers={"user_id": "123"}, temperature=0, callbacks=[ContextCallbackHandler(token)])messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(content="I love programming."),]print(chat(messages))API Reference:ChatOpenAISystemMessageHumanMessageContextCallbackHandlerUsing the Context callback within Chains‚ÄãThe Context callback handler can also be used to record the inputs and outputs of chains. Note that intermediate steps of the chain are not recorded - only the starting inputs and final outputs.Note: Ensure that you pass the same context object to the chat model and the chain.Wrong:chat = ChatOpenAI(temperature=0.9, callbacks=[ContextCallbackHandler(token)])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[ContextCallbackHandler(token)])Correct:handler = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain import LLMChainfrom langchain.prompts import PromptTemplatefrom langchain.prompts.chat import (    ChatPromptTemplate,    HumanMessagePromptTemplate,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]human_message_prompt = HumanMessagePromptTemplate(    prompt=PromptTemplate(        template="What is a good name for a company that makes {product}?",        input_variables=["product"],    ))chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])callback = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])print(chain.run("colorful socks"))API Reference:ChatOpenAIPromptTemplateChatPromptTemplateHumanMessagePromptTemplateContextCallbackHandlerPreviousConfidentNextInfinoInstallation and SetupGetting API CredentialsSetup ContextUsageUsing the Context callback within a chat modelUsing the Context callback within Chains IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsCallbacksContextOn this pageContextContext provides user analytics for LLM powered products and features.With Context, you can start understanding your users and improving their experiences in less than 30 minutes.In this guide we will show you how to integrate with Context.Installation and Setup‚Äã$ pip install context-python --upgradeGetting API Credentials‚ÄãTo get your Context API token:Go to the settings page within your Context account (https://with.context.ai/settings).Generate a new API Token.Store this token somewhere secure.Setup Context‚ÄãTo use the ContextCallbackHandler, import the handler from Langchain and instantiate it with your Context API token.Ensure you have installed the context-python package before using the handler.import osfrom langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]context_callback = ContextCallbackHandler(token)API Reference:ContextCallbackHandlerUsage‚ÄãUsing the Context callback within a chat model‚ÄãThe Context callback handler can be used to directly record transcripts between users and AI assistants.Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import (    SystemMessage,    HumanMessage,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]chat = ChatOpenAI(    headers={"user_id": "123"}, temperature=0, callbacks=[ContextCallbackHandler(token)])messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(content="I love programming."),]print(chat(messages))API Reference:ChatOpenAISystemMessageHumanMessageContextCallbackHandlerUsing the Context callback within Chains‚ÄãThe Context callback handler can also be used to record the inputs and outputs of chains. Note that intermediate steps of the chain are not recorded - only the starting inputs and final outputs.Note: Ensure that you pass the same context object to the chat model and the chain.Wrong:chat = ChatOpenAI(temperature=0.9, callbacks=[ContextCallbackHandler(token)])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[ContextCallbackHandler(token)])Correct:handler = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain import LLMChainfrom langchain.prompts import PromptTemplatefrom langchain.prompts.chat import (    ChatPromptTemplate,    HumanMessagePromptTemplate,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]human_message_prompt = HumanMessagePromptTemplate(    prompt=PromptTemplate(        template="What is a good name for a company that makes {product}?",        input_variables=["product"],    ))chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])callback = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])print(chain.run("colorful socks"))API Reference:ChatOpenAIPromptTemplateChatPromptTemplateHumanMessagePromptTemplateContextCallbackHandlerPreviousConfidentNextInfinoInstallation and SetupGetting API CredentialsSetup ContextUsageUsing the Context callback within a chat modelUsing the Context callback within Chains IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsCallbacksContextOn this pageContextContext provides user analytics for LLM powered products and features.With Context, you can start understanding your users and improving their experiences in less than 30 minutes.In this guide we will show you how to integrate with Context.Installation and Setup‚Äã$ pip install context-python --upgradeGetting API Credentials‚ÄãTo get your Context API token:Go to the settings page within your Context account (https://with.context.ai/settings).Generate a new API Token.Store this token somewhere secure.Setup Context‚ÄãTo use the ContextCallbackHandler, import the handler from Langchain and instantiate it with your Context API token.Ensure you have installed the context-python package before using the handler.import osfrom langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]context_callback = ContextCallbackHandler(token)API Reference:ContextCallbackHandlerUsage‚ÄãUsing the Context callback within a chat model‚ÄãThe Context callback handler can be used to directly record transcripts between users and AI assistants.Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import (    SystemMessage,    HumanMessage,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]chat = ChatOpenAI(    headers={"user_id": "123"}, temperature=0, callbacks=[ContextCallbackHandler(token)])messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(content="I love programming."),]print(chat(messages))API Reference:ChatOpenAISystemMessageHumanMessageContextCallbackHandlerUsing the Context callback within Chains‚ÄãThe Context callback handler can also be used to record the inputs and outputs of chains. Note that intermediate steps of the chain are not recorded - only the starting inputs and final outputs.Note: Ensure that you pass the same context object to the chat model and the chain.Wrong:chat = ChatOpenAI(temperature=0.9, callbacks=[ContextCallbackHandler(token)])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[ContextCallbackHandler(token)])Correct:handler = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain import LLMChainfrom langchain.prompts import PromptTemplatefrom langchain.prompts.chat import (    ChatPromptTemplate,    HumanMessagePromptTemplate,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]human_message_prompt = HumanMessagePromptTemplate(    prompt=PromptTemplate(        template="What is a good name for a company that makes {product}?",        input_variables=["product"],    ))chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])callback = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])print(chain.run("colorful socks"))API Reference:ChatOpenAIPromptTemplateChatPromptTemplateHumanMessagePromptTemplateContextCallbackHandlerPreviousConfidentNextInfinoInstallation and SetupGetting API CredentialsSetup ContextUsageUsing the Context callback within a chat modelUsing the Context callback within Chains IntegrationsCallbacksContextOn this pageContextContext provides user analytics for LLM powered products and features.With Context, you can start understanding your users and improving their experiences in less than 30 minutes.In this guide we will show you how to integrate with Context.Installation and Setup‚Äã$ pip install context-python --upgradeGetting API Credentials‚ÄãTo get your Context API token:Go to the settings page within your Context account (https://with.context.ai/settings).Generate a new API Token.Store this token somewhere secure.Setup Context‚ÄãTo use the ContextCallbackHandler, import the handler from Langchain and instantiate it with your Context API token.Ensure you have installed the context-python package before using the handler.import osfrom langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]context_callback = ContextCallbackHandler(token)API Reference:ContextCallbackHandlerUsage‚ÄãUsing the Context callback within a chat model‚ÄãThe Context callback handler can be used to directly record transcripts between users and AI assistants.Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import (    SystemMessage,    HumanMessage,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]chat = ChatOpenAI(    headers={"user_id": "123"}, temperature=0, callbacks=[ContextCallbackHandler(token)])messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(content="I love programming."),]print(chat(messages))API Reference:ChatOpenAISystemMessageHumanMessageContextCallbackHandlerUsing the Context callback within Chains‚ÄãThe Context callback handler can also be used to record the inputs and outputs of chains. Note that intermediate steps of the chain are not recorded - only the starting inputs and final outputs.Note: Ensure that you pass the same context object to the chat model and the chain.Wrong:chat = ChatOpenAI(temperature=0.9, callbacks=[ContextCallbackHandler(token)])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[ContextCallbackHandler(token)])Correct:handler = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain import LLMChainfrom langchain.prompts import PromptTemplatefrom langchain.prompts.chat import (    ChatPromptTemplate,    HumanMessagePromptTemplate,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]human_message_prompt = HumanMessagePromptTemplate(    prompt=PromptTemplate(        template="What is a good name for a company that makes {product}?",        input_variables=["product"],    ))chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])callback = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])print(chain.run("colorful socks"))API Reference:ChatOpenAIPromptTemplateChatPromptTemplateHumanMessagePromptTemplateContextCallbackHandlerPreviousConfidentNextInfinoInstallation and SetupGetting API CredentialsSetup ContextUsageUsing the Context callback within a chat modelUsing the Context callback within Chains IntegrationsCallbacksContextOn this pageContextContext provides user analytics for LLM powered products and features.With Context, you can start understanding your users and improving their experiences in less than 30 minutes.In this guide we will show you how to integrate with Context.Installation and Setup‚Äã$ pip install context-python --upgradeGetting API Credentials‚ÄãTo get your Context API token:Go to the settings page within your Context account (https://with.context.ai/settings).Generate a new API Token.Store this token somewhere secure.Setup Context‚ÄãTo use the ContextCallbackHandler, import the handler from Langchain and instantiate it with your Context API token.Ensure you have installed the context-python package before using the handler.import osfrom langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]context_callback = ContextCallbackHandler(token)API Reference:ContextCallbackHandlerUsage‚ÄãUsing the Context callback within a chat model‚ÄãThe Context callback handler can be used to directly record transcripts between users and AI assistants.Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import (    SystemMessage,    HumanMessage,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]chat = ChatOpenAI(    headers={"user_id": "123"}, temperature=0, callbacks=[ContextCallbackHandler(token)])messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(content="I love programming."),]print(chat(messages))API Reference:ChatOpenAISystemMessageHumanMessageContextCallbackHandlerUsing the Context callback within Chains‚ÄãThe Context callback handler can also be used to record the inputs and outputs of chains. Note that intermediate steps of the chain are not recorded - only the starting inputs and final outputs.Note: Ensure that you pass the same context object to the chat model and the chain.Wrong:chat = ChatOpenAI(temperature=0.9, callbacks=[ContextCallbackHandler(token)])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[ContextCallbackHandler(token)])Correct:handler = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain import LLMChainfrom langchain.prompts import PromptTemplatefrom langchain.prompts.chat import (    ChatPromptTemplate,    HumanMessagePromptTemplate,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]human_message_prompt = HumanMessagePromptTemplate(    prompt=PromptTemplate(        template="What is a good name for a company that makes {product}?",        input_variables=["product"],    ))chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])callback = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])print(chain.run("colorful socks"))API Reference:ChatOpenAIPromptTemplateChatPromptTemplateHumanMessagePromptTemplateContextCallbackHandlerPreviousConfidentNextInfino IntegrationsCallbacksContextOn this pageContextContext provides user analytics for LLM powered products and features.With Context, you can start understanding your users and improving their experiences in less than 30 minutes.In this guide we will show you how to integrate with Context.Installation and Setup‚Äã$ pip install context-python --upgradeGetting API Credentials‚ÄãTo get your Context API token:Go to the settings page within your Context account (https://with.context.ai/settings).Generate a new API Token.Store this token somewhere secure.Setup Context‚ÄãTo use the ContextCallbackHandler, import the handler from Langchain and instantiate it with your Context API token.Ensure you have installed the context-python package before using the handler.import osfrom langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]context_callback = ContextCallbackHandler(token)API Reference:ContextCallbackHandlerUsage‚ÄãUsing the Context callback within a chat model‚ÄãThe Context callback handler can be used to directly record transcripts between users and AI assistants.Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import (    SystemMessage,    HumanMessage,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]chat = ChatOpenAI(    headers={"user_id": "123"}, temperature=0, callbacks=[ContextCallbackHandler(token)])messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(content="I love programming."),]print(chat(messages))API Reference:ChatOpenAISystemMessageHumanMessageContextCallbackHandlerUsing the Context callback within Chains‚ÄãThe Context callback handler can also be used to record the inputs and outputs of chains. Note that intermediate steps of the chain are not recorded - only the starting inputs and final outputs.Note: Ensure that you pass the same context object to the chat model and the chain.Wrong:chat = ChatOpenAI(temperature=0.9, callbacks=[ContextCallbackHandler(token)])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[ContextCallbackHandler(token)])Correct:handler = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain import LLMChainfrom langchain.prompts import PromptTemplatefrom langchain.prompts.chat import (    ChatPromptTemplate,    HumanMessagePromptTemplate,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]human_message_prompt = HumanMessagePromptTemplate(    prompt=PromptTemplate(        template="What is a good name for a company that makes {product}?",        input_variables=["product"],    ))chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])callback = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])print(chain.run("colorful socks"))API Reference:ChatOpenAIPromptTemplateChatPromptTemplateHumanMessagePromptTemplateContextCallbackHandlerPreviousConfidentNextInfino On this page ContextContext provides user analytics for LLM powered products and features.With Context, you can start understanding your users and improving their experiences in less than 30 minutes.In this guide we will show you how to integrate with Context.Installation and Setup‚Äã$ pip install context-python --upgradeGetting API Credentials‚ÄãTo get your Context API token:Go to the settings page within your Context account (https://with.context.ai/settings).Generate a new API Token.Store this token somewhere secure.Setup Context‚ÄãTo use the ContextCallbackHandler, import the handler from Langchain and instantiate it with your Context API token.Ensure you have installed the context-python package before using the handler.import osfrom langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]context_callback = ContextCallbackHandler(token)API Reference:ContextCallbackHandlerUsage‚ÄãUsing the Context callback within a chat model‚ÄãThe Context callback handler can be used to directly record transcripts between users and AI assistants.Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import (    SystemMessage,    HumanMessage,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]chat = ChatOpenAI(    headers={"user_id": "123"}, temperature=0, callbacks=[ContextCallbackHandler(token)])messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(content="I love programming."),]print(chat(messages))API Reference:ChatOpenAISystemMessageHumanMessageContextCallbackHandlerUsing the Context callback within Chains‚ÄãThe Context callback handler can also be used to record the inputs and outputs of chains. Note that intermediate steps of the chain are not recorded - only the starting inputs and final outputs.Note: Ensure that you pass the same context object to the chat model and the chain.Wrong:chat = ChatOpenAI(temperature=0.9, callbacks=[ContextCallbackHandler(token)])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[ContextCallbackHandler(token)])Correct:handler = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain import LLMChainfrom langchain.prompts import PromptTemplatefrom langchain.prompts.chat import (    ChatPromptTemplate,    HumanMessagePromptTemplate,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]human_message_prompt = HumanMessagePromptTemplate(    prompt=PromptTemplate(        template="What is a good name for a company that makes {product}?",        input_variables=["product"],    ))chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])callback = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])print(chain.run("colorful socks"))API Reference:ChatOpenAIPromptTemplateChatPromptTemplateHumanMessagePromptTemplateContextCallbackHandler $ pip install context-python --upgrade $ pip install context-python --upgrade  import osfrom langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]context_callback = ContextCallbackHandler(token) import osfrom langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]context_callback = ContextCallbackHandler(token)  API Reference:ContextCallbackHandler import osfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import (    SystemMessage,    HumanMessage,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]chat = ChatOpenAI(    headers={"user_id": "123"}, temperature=0, callbacks=[ContextCallbackHandler(token)])messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(content="I love programming."),]print(chat(messages)) import osfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import (    SystemMessage,    HumanMessage,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]chat = ChatOpenAI(    headers={"user_id": "123"}, temperature=0, callbacks=[ContextCallbackHandler(token)])messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(content="I love programming."),]print(chat(messages))  API Reference:ChatOpenAISystemMessageHumanMessageContextCallbackHandler chat = ChatOpenAI(temperature=0.9, callbacks=[ContextCallbackHandler(token)])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[ContextCallbackHandler(token)]) chat = ChatOpenAI(temperature=0.9, callbacks=[ContextCallbackHandler(token)])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[ContextCallbackHandler(token)])  handler = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback]) handler = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])  import osfrom langchain.chat_models import ChatOpenAIfrom langchain import LLMChainfrom langchain.prompts import PromptTemplatefrom langchain.prompts.chat import (    ChatPromptTemplate,    HumanMessagePromptTemplate,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]human_message_prompt = HumanMessagePromptTemplate(    prompt=PromptTemplate(        template="What is a good name for a company that makes {product}?",        input_variables=["product"],    ))chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])callback = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])print(chain.run("colorful socks")) import osfrom langchain.chat_models import ChatOpenAIfrom langchain import LLMChainfrom langchain.prompts import PromptTemplatefrom langchain.prompts.chat import (    ChatPromptTemplate,    HumanMessagePromptTemplate,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]human_message_prompt = HumanMessagePromptTemplate(    prompt=PromptTemplate(        template="What is a good name for a company that makes {product}?",        input_variables=["product"],    ))chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])callback = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])print(chain.run("colorful socks"))  API Reference:ChatOpenAIPromptTemplateChatPromptTemplateHumanMessagePromptTemplateContextCallbackHandler Previous Confident Next Infino Installation and SetupGetting API CredentialsSetup ContextUsageUsing the Context callback within a chat modelUsing the Context callback within Chains Installation and SetupGetting API CredentialsSetup ContextUsageUsing the Context callback within a chat modelUsing the Context callback within Chains CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Argilla (/docs/integrations/callbacks/argilla) Confident (/docs/integrations/callbacks/confident) Context (/docs/integrations/callbacks/context) Infino (/docs/integrations/callbacks/infino) Label Studio (/docs/integrations/callbacks/labelstudio) LLMonitor (/docs/integrations/callbacks/llmonitor) PromptLayer (/docs/integrations/callbacks/promptlayer) Streamlit (/docs/integrations/callbacks/streamlit) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Context (https://context.ai/) ‚Äã (#installation-and-setup) ‚Äã (#getting-api-credentials) https://with.context.ai/settings (https://with.context.ai/settings) ‚Äã (#setup-context) ContextCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.context_callback.ContextCallbackHandler.html) ‚Äã (#usage) ‚Äã (#using-the-context-callback-within-a-chat-model) ‚Äã (#example) ChatOpenAI (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html) SystemMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.SystemMessage.html) HumanMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.HumanMessage.html) ContextCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.context_callback.ContextCallbackHandler.html) ‚Äã (#using-the-context-callback-within-chains) ‚Äã (#example-1) ChatOpenAI (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html) PromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html) ChatPromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.chat.ChatPromptTemplate.html) HumanMessagePromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.chat.HumanMessagePromptTemplate.html) ContextCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.context_callback.ContextCallbackHandler.html) PreviousConfident (/docs/integrations/callbacks/confident) NextInfino (/docs/integrations/callbacks/infino) Installation and Setup (#installation-and-setup) Getting API Credentials (#getting-api-credentials) Setup Context (#setup-context) Usage (#usage) Using the Context callback within a chat model (#using-the-context-callback-within-a-chat-model) Using the Context callback within Chains (#using-the-context-callback-within-chains) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)