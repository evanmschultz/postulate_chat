Nuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing. The Nuclia Understanding API supports the processing of unstructured data, including text, web pages, documents, and audio/video contents. It extracts all texts wherever it is (using speech-to-text or OCR when needed), it identifies entities, it aslo extracts metadata, embedded files (like images in a PDF), and web links. It also provides a summary of the content. To use the Nuclia Understanding API, you need to have a Nuclia account. You can create one for free at https://nuclia.cloud, and then create a NUA key. You can push files to the Nuclia Understanding API using the push action. As the processing is done asynchronously, the results might be returned in a different order than the files were pushed. That is why you need to provide an id to match the results with the corresponding file. You can now call the pull action in a loop until you get the JSON-formatted result. You can also do it in one step in async mode, you only need to do a push, and it will wait until the results are pulled: Nuclia returns the following information: Note:   Generated files (thumbnail, extracted embedded files, etc.) are provided as a token. You can download them with the /processing/download endpoint.   Also at any level, if an attribute exceeds a certain size, it will be put in a downloadable file and will be replaced in the document by a file pointer. This will consist of {"file": {"uri": "JWT_TOKEN"}}. The rule is that if the size of the message is greater than 1000000 characters, the biggest parts will be moved to downloadable files. First, the compression process will target vectors. If that is not enough, it will target large field metadata, and finally it will target extracted text. IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language ActionsVector storesGrouped by provider Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits ToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language Actions Alpha Vantage Apify ArXiv AWS Lambda Shell (bash) Bing Search Brave Search ChatGPT Plugins Dall-E Image Generator DataForSeo DuckDuckGo Search Eden AI File System Golden Query Google Drive Google Places Google Search Google Serper Gradio GraphQL HuggingFace Hub Tools Human as a tool IFTTT WebHooks Lemon Agent Metaphor Search Nuclia Understanding OpenWeatherMap PubMed Requests SceneXplain Search Tools SearxNG Search SerpAPI Twilio Wikipedia Wolfram Alpha Yahoo Finance News YouTube Zapier Natural Language Actions Vector stores Grouped by provider  Integrations Tools Nuclia Understanding NucliaUnderstandingAPI file metadata extracted text nested text (like text in an embedded image) a summary (only when enable_ml is set to True) paragraphs and sentences splitting (defined by the position of their first and last characters, plus start time and end time for a video or audio file) named entities: people, dates, places, organizations, etc. (only when enable_ml is set to True) links a thumbnail embedded files the vector representations of the text (only when enable_ml is set to True) Retrieved information Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language ActionsVector storesGrouped by providerIntegrationsToolsNuclia UnderstandingOn this pageNuclia UnderstandingNuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.The Nuclia Understanding API supports the processing of unstructured data, including text, web pages, documents, and audio/video contents. It extracts all texts wherever it is (using speech-to-text or OCR when needed), it identifies entities, it aslo extracts metadata, embedded files (like images in a PDF), and web links. It also provides a summary of the content.To use the Nuclia Understanding API, you need to have a Nuclia account. You can create one for free at https://nuclia.cloud, and then create a NUA key.#!pip install --upgrade protobuf#!pip install nucliadb-protosimport osos.environ["NUCLIA_ZONE"] = "<YOUR_ZONE>"  # e.g. europe-1os.environ["NUCLIA_NUA_KEY"] = "<YOUR_API_KEY>"from langchain.tools.nuclia import NucliaUnderstandingAPInua = NucliaUnderstandingAPI(enable_ml=False)API Reference:NucliaUnderstandingAPIYou can push files to the Nuclia Understanding API using the push action. As the processing is done asynchronously, the results might be returned in a different order than the files were pushed. That is why you need to provide an id to match the results with the corresponding file.nua.run({"action": "push", "id": "1", "path": "./report.docx"})nua.run({"action": "push", "id": "2", "path": "./interview.mp4"})You can now call the pull action in a loop until you get the JSON-formatted result.import timepending = Truedata = Nonewhile pending:    time.sleep(15)    data = nua.run({"action": "pull", "id": "1", "path": None})    if data:        print(data)        pending = False    else:        print("waiting...")You can also do it in one step in async mode, you only need to do a push, and it will wait until the results are pulled:import asyncioasync def process():    data = await nua.arun(        {"action": "push", "id": "1", "path": "./talk.mp4", "text": None}    )    print(data)asyncio.run(process())Retrieved information‚ÄãNuclia returns the following information:file metadataextracted textnested text (like text in an embedded image)a summary (only when enable_ml is set to True)paragraphs and sentences splitting (defined by the position of their first and last characters, plus start time and end time for a video or audio file)named entities: people, dates, places, organizations, etc. (only when enable_ml is set to True)linksa thumbnailembedded filesthe vector representations of the text (only when enable_ml is set to True)Note:  Generated files (thumbnail, extracted embedded files, etc.) are provided as a token. You can download them with the /processing/download endpoint.  Also at any level, if an attribute exceeds a certain size, it will be put in a downloadable file and will be replaced in the document by a file pointer. This will consist of {"file": {"uri": "JWT_TOKEN"}}. The rule is that if the size of the message is greater than 1000000 characters, the biggest parts will be moved to downloadable files. First, the compression process will target vectors. If that is not enough, it will target large field metadata, and finally it will target extracted text.PreviousMetaphor SearchNextOpenWeatherMapRetrieved informationCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language ActionsVector storesGrouped by providerIntegrationsToolsNuclia UnderstandingOn this pageNuclia UnderstandingNuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.The Nuclia Understanding API supports the processing of unstructured data, including text, web pages, documents, and audio/video contents. It extracts all texts wherever it is (using speech-to-text or OCR when needed), it identifies entities, it aslo extracts metadata, embedded files (like images in a PDF), and web links. It also provides a summary of the content.To use the Nuclia Understanding API, you need to have a Nuclia account. You can create one for free at https://nuclia.cloud, and then create a NUA key.#!pip install --upgrade protobuf#!pip install nucliadb-protosimport osos.environ["NUCLIA_ZONE"] = "<YOUR_ZONE>"  # e.g. europe-1os.environ["NUCLIA_NUA_KEY"] = "<YOUR_API_KEY>"from langchain.tools.nuclia import NucliaUnderstandingAPInua = NucliaUnderstandingAPI(enable_ml=False)API Reference:NucliaUnderstandingAPIYou can push files to the Nuclia Understanding API using the push action. As the processing is done asynchronously, the results might be returned in a different order than the files were pushed. That is why you need to provide an id to match the results with the corresponding file.nua.run({"action": "push", "id": "1", "path": "./report.docx"})nua.run({"action": "push", "id": "2", "path": "./interview.mp4"})You can now call the pull action in a loop until you get the JSON-formatted result.import timepending = Truedata = Nonewhile pending:    time.sleep(15)    data = nua.run({"action": "pull", "id": "1", "path": None})    if data:        print(data)        pending = False    else:        print("waiting...")You can also do it in one step in async mode, you only need to do a push, and it will wait until the results are pulled:import asyncioasync def process():    data = await nua.arun(        {"action": "push", "id": "1", "path": "./talk.mp4", "text": None}    )    print(data)asyncio.run(process())Retrieved information‚ÄãNuclia returns the following information:file metadataextracted textnested text (like text in an embedded image)a summary (only when enable_ml is set to True)paragraphs and sentences splitting (defined by the position of their first and last characters, plus start time and end time for a video or audio file)named entities: people, dates, places, organizations, etc. (only when enable_ml is set to True)linksa thumbnailembedded filesthe vector representations of the text (only when enable_ml is set to True)Note:  Generated files (thumbnail, extracted embedded files, etc.) are provided as a token. You can download them with the /processing/download endpoint.  Also at any level, if an attribute exceeds a certain size, it will be put in a downloadable file and will be replaced in the document by a file pointer. This will consist of {"file": {"uri": "JWT_TOKEN"}}. The rule is that if the size of the message is greater than 1000000 characters, the biggest parts will be moved to downloadable files. First, the compression process will target vectors. If that is not enough, it will target large field metadata, and finally it will target extracted text.PreviousMetaphor SearchNextOpenWeatherMapRetrieved information IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language ActionsVector storesGrouped by providerIntegrationsToolsNuclia UnderstandingOn this pageNuclia UnderstandingNuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.The Nuclia Understanding API supports the processing of unstructured data, including text, web pages, documents, and audio/video contents. It extracts all texts wherever it is (using speech-to-text or OCR when needed), it identifies entities, it aslo extracts metadata, embedded files (like images in a PDF), and web links. It also provides a summary of the content.To use the Nuclia Understanding API, you need to have a Nuclia account. You can create one for free at https://nuclia.cloud, and then create a NUA key.#!pip install --upgrade protobuf#!pip install nucliadb-protosimport osos.environ["NUCLIA_ZONE"] = "<YOUR_ZONE>"  # e.g. europe-1os.environ["NUCLIA_NUA_KEY"] = "<YOUR_API_KEY>"from langchain.tools.nuclia import NucliaUnderstandingAPInua = NucliaUnderstandingAPI(enable_ml=False)API Reference:NucliaUnderstandingAPIYou can push files to the Nuclia Understanding API using the push action. As the processing is done asynchronously, the results might be returned in a different order than the files were pushed. That is why you need to provide an id to match the results with the corresponding file.nua.run({"action": "push", "id": "1", "path": "./report.docx"})nua.run({"action": "push", "id": "2", "path": "./interview.mp4"})You can now call the pull action in a loop until you get the JSON-formatted result.import timepending = Truedata = Nonewhile pending:    time.sleep(15)    data = nua.run({"action": "pull", "id": "1", "path": None})    if data:        print(data)        pending = False    else:        print("waiting...")You can also do it in one step in async mode, you only need to do a push, and it will wait until the results are pulled:import asyncioasync def process():    data = await nua.arun(        {"action": "push", "id": "1", "path": "./talk.mp4", "text": None}    )    print(data)asyncio.run(process())Retrieved information‚ÄãNuclia returns the following information:file metadataextracted textnested text (like text in an embedded image)a summary (only when enable_ml is set to True)paragraphs and sentences splitting (defined by the position of their first and last characters, plus start time and end time for a video or audio file)named entities: people, dates, places, organizations, etc. (only when enable_ml is set to True)linksa thumbnailembedded filesthe vector representations of the text (only when enable_ml is set to True)Note:  Generated files (thumbnail, extracted embedded files, etc.) are provided as a token. You can download them with the /processing/download endpoint.  Also at any level, if an attribute exceeds a certain size, it will be put in a downloadable file and will be replaced in the document by a file pointer. This will consist of {"file": {"uri": "JWT_TOKEN"}}. The rule is that if the size of the message is greater than 1000000 characters, the biggest parts will be moved to downloadable files. First, the compression process will target vectors. If that is not enough, it will target large field metadata, and finally it will target extracted text.PreviousMetaphor SearchNextOpenWeatherMapRetrieved information IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language ActionsVector storesGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language ActionsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsToolsNuclia UnderstandingOn this pageNuclia UnderstandingNuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.The Nuclia Understanding API supports the processing of unstructured data, including text, web pages, documents, and audio/video contents. It extracts all texts wherever it is (using speech-to-text or OCR when needed), it identifies entities, it aslo extracts metadata, embedded files (like images in a PDF), and web links. It also provides a summary of the content.To use the Nuclia Understanding API, you need to have a Nuclia account. You can create one for free at https://nuclia.cloud, and then create a NUA key.#!pip install --upgrade protobuf#!pip install nucliadb-protosimport osos.environ["NUCLIA_ZONE"] = "<YOUR_ZONE>"  # e.g. europe-1os.environ["NUCLIA_NUA_KEY"] = "<YOUR_API_KEY>"from langchain.tools.nuclia import NucliaUnderstandingAPInua = NucliaUnderstandingAPI(enable_ml=False)API Reference:NucliaUnderstandingAPIYou can push files to the Nuclia Understanding API using the push action. As the processing is done asynchronously, the results might be returned in a different order than the files were pushed. That is why you need to provide an id to match the results with the corresponding file.nua.run({"action": "push", "id": "1", "path": "./report.docx"})nua.run({"action": "push", "id": "2", "path": "./interview.mp4"})You can now call the pull action in a loop until you get the JSON-formatted result.import timepending = Truedata = Nonewhile pending:    time.sleep(15)    data = nua.run({"action": "pull", "id": "1", "path": None})    if data:        print(data)        pending = False    else:        print("waiting...")You can also do it in one step in async mode, you only need to do a push, and it will wait until the results are pulled:import asyncioasync def process():    data = await nua.arun(        {"action": "push", "id": "1", "path": "./talk.mp4", "text": None}    )    print(data)asyncio.run(process())Retrieved information‚ÄãNuclia returns the following information:file metadataextracted textnested text (like text in an embedded image)a summary (only when enable_ml is set to True)paragraphs and sentences splitting (defined by the position of their first and last characters, plus start time and end time for a video or audio file)named entities: people, dates, places, organizations, etc. (only when enable_ml is set to True)linksa thumbnailembedded filesthe vector representations of the text (only when enable_ml is set to True)Note:  Generated files (thumbnail, extracted embedded files, etc.) are provided as a token. You can download them with the /processing/download endpoint.  Also at any level, if an attribute exceeds a certain size, it will be put in a downloadable file and will be replaced in the document by a file pointer. This will consist of {"file": {"uri": "JWT_TOKEN"}}. The rule is that if the size of the message is greater than 1000000 characters, the biggest parts will be moved to downloadable files. First, the compression process will target vectors. If that is not enough, it will target large field metadata, and finally it will target extracted text.PreviousMetaphor SearchNextOpenWeatherMapRetrieved information IntegrationsToolsNuclia UnderstandingOn this pageNuclia UnderstandingNuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.The Nuclia Understanding API supports the processing of unstructured data, including text, web pages, documents, and audio/video contents. It extracts all texts wherever it is (using speech-to-text or OCR when needed), it identifies entities, it aslo extracts metadata, embedded files (like images in a PDF), and web links. It also provides a summary of the content.To use the Nuclia Understanding API, you need to have a Nuclia account. You can create one for free at https://nuclia.cloud, and then create a NUA key.#!pip install --upgrade protobuf#!pip install nucliadb-protosimport osos.environ["NUCLIA_ZONE"] = "<YOUR_ZONE>"  # e.g. europe-1os.environ["NUCLIA_NUA_KEY"] = "<YOUR_API_KEY>"from langchain.tools.nuclia import NucliaUnderstandingAPInua = NucliaUnderstandingAPI(enable_ml=False)API Reference:NucliaUnderstandingAPIYou can push files to the Nuclia Understanding API using the push action. As the processing is done asynchronously, the results might be returned in a different order than the files were pushed. That is why you need to provide an id to match the results with the corresponding file.nua.run({"action": "push", "id": "1", "path": "./report.docx"})nua.run({"action": "push", "id": "2", "path": "./interview.mp4"})You can now call the pull action in a loop until you get the JSON-formatted result.import timepending = Truedata = Nonewhile pending:    time.sleep(15)    data = nua.run({"action": "pull", "id": "1", "path": None})    if data:        print(data)        pending = False    else:        print("waiting...")You can also do it in one step in async mode, you only need to do a push, and it will wait until the results are pulled:import asyncioasync def process():    data = await nua.arun(        {"action": "push", "id": "1", "path": "./talk.mp4", "text": None}    )    print(data)asyncio.run(process())Retrieved information‚ÄãNuclia returns the following information:file metadataextracted textnested text (like text in an embedded image)a summary (only when enable_ml is set to True)paragraphs and sentences splitting (defined by the position of their first and last characters, plus start time and end time for a video or audio file)named entities: people, dates, places, organizations, etc. (only when enable_ml is set to True)linksa thumbnailembedded filesthe vector representations of the text (only when enable_ml is set to True)Note:  Generated files (thumbnail, extracted embedded files, etc.) are provided as a token. You can download them with the /processing/download endpoint.  Also at any level, if an attribute exceeds a certain size, it will be put in a downloadable file and will be replaced in the document by a file pointer. This will consist of {"file": {"uri": "JWT_TOKEN"}}. The rule is that if the size of the message is greater than 1000000 characters, the biggest parts will be moved to downloadable files. First, the compression process will target vectors. If that is not enough, it will target large field metadata, and finally it will target extracted text.PreviousMetaphor SearchNextOpenWeatherMapRetrieved information IntegrationsToolsNuclia UnderstandingOn this pageNuclia UnderstandingNuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.The Nuclia Understanding API supports the processing of unstructured data, including text, web pages, documents, and audio/video contents. It extracts all texts wherever it is (using speech-to-text or OCR when needed), it identifies entities, it aslo extracts metadata, embedded files (like images in a PDF), and web links. It also provides a summary of the content.To use the Nuclia Understanding API, you need to have a Nuclia account. You can create one for free at https://nuclia.cloud, and then create a NUA key.#!pip install --upgrade protobuf#!pip install nucliadb-protosimport osos.environ["NUCLIA_ZONE"] = "<YOUR_ZONE>"  # e.g. europe-1os.environ["NUCLIA_NUA_KEY"] = "<YOUR_API_KEY>"from langchain.tools.nuclia import NucliaUnderstandingAPInua = NucliaUnderstandingAPI(enable_ml=False)API Reference:NucliaUnderstandingAPIYou can push files to the Nuclia Understanding API using the push action. As the processing is done asynchronously, the results might be returned in a different order than the files were pushed. That is why you need to provide an id to match the results with the corresponding file.nua.run({"action": "push", "id": "1", "path": "./report.docx"})nua.run({"action": "push", "id": "2", "path": "./interview.mp4"})You can now call the pull action in a loop until you get the JSON-formatted result.import timepending = Truedata = Nonewhile pending:    time.sleep(15)    data = nua.run({"action": "pull", "id": "1", "path": None})    if data:        print(data)        pending = False    else:        print("waiting...")You can also do it in one step in async mode, you only need to do a push, and it will wait until the results are pulled:import asyncioasync def process():    data = await nua.arun(        {"action": "push", "id": "1", "path": "./talk.mp4", "text": None}    )    print(data)asyncio.run(process())Retrieved information‚ÄãNuclia returns the following information:file metadataextracted textnested text (like text in an embedded image)a summary (only when enable_ml is set to True)paragraphs and sentences splitting (defined by the position of their first and last characters, plus start time and end time for a video or audio file)named entities: people, dates, places, organizations, etc. (only when enable_ml is set to True)linksa thumbnailembedded filesthe vector representations of the text (only when enable_ml is set to True)Note:  Generated files (thumbnail, extracted embedded files, etc.) are provided as a token. You can download them with the /processing/download endpoint.  Also at any level, if an attribute exceeds a certain size, it will be put in a downloadable file and will be replaced in the document by a file pointer. This will consist of {"file": {"uri": "JWT_TOKEN"}}. The rule is that if the size of the message is greater than 1000000 characters, the biggest parts will be moved to downloadable files. First, the compression process will target vectors. If that is not enough, it will target large field metadata, and finally it will target extracted text.PreviousMetaphor SearchNextOpenWeatherMap IntegrationsToolsNuclia UnderstandingOn this pageNuclia UnderstandingNuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.The Nuclia Understanding API supports the processing of unstructured data, including text, web pages, documents, and audio/video contents. It extracts all texts wherever it is (using speech-to-text or OCR when needed), it identifies entities, it aslo extracts metadata, embedded files (like images in a PDF), and web links. It also provides a summary of the content.To use the Nuclia Understanding API, you need to have a Nuclia account. You can create one for free at https://nuclia.cloud, and then create a NUA key.#!pip install --upgrade protobuf#!pip install nucliadb-protosimport osos.environ["NUCLIA_ZONE"] = "<YOUR_ZONE>"  # e.g. europe-1os.environ["NUCLIA_NUA_KEY"] = "<YOUR_API_KEY>"from langchain.tools.nuclia import NucliaUnderstandingAPInua = NucliaUnderstandingAPI(enable_ml=False)API Reference:NucliaUnderstandingAPIYou can push files to the Nuclia Understanding API using the push action. As the processing is done asynchronously, the results might be returned in a different order than the files were pushed. That is why you need to provide an id to match the results with the corresponding file.nua.run({"action": "push", "id": "1", "path": "./report.docx"})nua.run({"action": "push", "id": "2", "path": "./interview.mp4"})You can now call the pull action in a loop until you get the JSON-formatted result.import timepending = Truedata = Nonewhile pending:    time.sleep(15)    data = nua.run({"action": "pull", "id": "1", "path": None})    if data:        print(data)        pending = False    else:        print("waiting...")You can also do it in one step in async mode, you only need to do a push, and it will wait until the results are pulled:import asyncioasync def process():    data = await nua.arun(        {"action": "push", "id": "1", "path": "./talk.mp4", "text": None}    )    print(data)asyncio.run(process())Retrieved information‚ÄãNuclia returns the following information:file metadataextracted textnested text (like text in an embedded image)a summary (only when enable_ml is set to True)paragraphs and sentences splitting (defined by the position of their first and last characters, plus start time and end time for a video or audio file)named entities: people, dates, places, organizations, etc. (only when enable_ml is set to True)linksa thumbnailembedded filesthe vector representations of the text (only when enable_ml is set to True)Note:  Generated files (thumbnail, extracted embedded files, etc.) are provided as a token. You can download them with the /processing/download endpoint.  Also at any level, if an attribute exceeds a certain size, it will be put in a downloadable file and will be replaced in the document by a file pointer. This will consist of {"file": {"uri": "JWT_TOKEN"}}. The rule is that if the size of the message is greater than 1000000 characters, the biggest parts will be moved to downloadable files. First, the compression process will target vectors. If that is not enough, it will target large field metadata, and finally it will target extracted text.PreviousMetaphor SearchNextOpenWeatherMap On this page Nuclia UnderstandingNuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.The Nuclia Understanding API supports the processing of unstructured data, including text, web pages, documents, and audio/video contents. It extracts all texts wherever it is (using speech-to-text or OCR when needed), it identifies entities, it aslo extracts metadata, embedded files (like images in a PDF), and web links. It also provides a summary of the content.To use the Nuclia Understanding API, you need to have a Nuclia account. You can create one for free at https://nuclia.cloud, and then create a NUA key.#!pip install --upgrade protobuf#!pip install nucliadb-protosimport osos.environ["NUCLIA_ZONE"] = "<YOUR_ZONE>"  # e.g. europe-1os.environ["NUCLIA_NUA_KEY"] = "<YOUR_API_KEY>"from langchain.tools.nuclia import NucliaUnderstandingAPInua = NucliaUnderstandingAPI(enable_ml=False)API Reference:NucliaUnderstandingAPIYou can push files to the Nuclia Understanding API using the push action. As the processing is done asynchronously, the results might be returned in a different order than the files were pushed. That is why you need to provide an id to match the results with the corresponding file.nua.run({"action": "push", "id": "1", "path": "./report.docx"})nua.run({"action": "push", "id": "2", "path": "./interview.mp4"})You can now call the pull action in a loop until you get the JSON-formatted result.import timepending = Truedata = Nonewhile pending:    time.sleep(15)    data = nua.run({"action": "pull", "id": "1", "path": None})    if data:        print(data)        pending = False    else:        print("waiting...")You can also do it in one step in async mode, you only need to do a push, and it will wait until the results are pulled:import asyncioasync def process():    data = await nua.arun(        {"action": "push", "id": "1", "path": "./talk.mp4", "text": None}    )    print(data)asyncio.run(process())Retrieved information‚ÄãNuclia returns the following information:file metadataextracted textnested text (like text in an embedded image)a summary (only when enable_ml is set to True)paragraphs and sentences splitting (defined by the position of their first and last characters, plus start time and end time for a video or audio file)named entities: people, dates, places, organizations, etc. (only when enable_ml is set to True)linksa thumbnailembedded filesthe vector representations of the text (only when enable_ml is set to True)Note:  Generated files (thumbnail, extracted embedded files, etc.) are provided as a token. You can download them with the /processing/download endpoint.  Also at any level, if an attribute exceeds a certain size, it will be put in a downloadable file and will be replaced in the document by a file pointer. This will consist of {"file": {"uri": "JWT_TOKEN"}}. The rule is that if the size of the message is greater than 1000000 characters, the biggest parts will be moved to downloadable files. First, the compression process will target vectors. If that is not enough, it will target large field metadata, and finally it will target extracted text. #!pip install --upgrade protobuf#!pip install nucliadb-protos #!pip install --upgrade protobuf#!pip install nucliadb-protos  import osos.environ["NUCLIA_ZONE"] = "<YOUR_ZONE>"  # e.g. europe-1os.environ["NUCLIA_NUA_KEY"] = "<YOUR_API_KEY>" import osos.environ["NUCLIA_ZONE"] = "<YOUR_ZONE>"  # e.g. europe-1os.environ["NUCLIA_NUA_KEY"] = "<YOUR_API_KEY>"  from langchain.tools.nuclia import NucliaUnderstandingAPInua = NucliaUnderstandingAPI(enable_ml=False) from langchain.tools.nuclia import NucliaUnderstandingAPInua = NucliaUnderstandingAPI(enable_ml=False)  API Reference:NucliaUnderstandingAPI nua.run({"action": "push", "id": "1", "path": "./report.docx"})nua.run({"action": "push", "id": "2", "path": "./interview.mp4"}) nua.run({"action": "push", "id": "1", "path": "./report.docx"})nua.run({"action": "push", "id": "2", "path": "./interview.mp4"})  import timepending = Truedata = Nonewhile pending:    time.sleep(15)    data = nua.run({"action": "pull", "id": "1", "path": None})    if data:        print(data)        pending = False    else:        print("waiting...") import timepending = Truedata = Nonewhile pending:    time.sleep(15)    data = nua.run({"action": "pull", "id": "1", "path": None})    if data:        print(data)        pending = False    else:        print("waiting...")  import asyncioasync def process():    data = await nua.arun(        {"action": "push", "id": "1", "path": "./talk.mp4", "text": None}    )    print(data)asyncio.run(process()) import asyncioasync def process():    data = await nua.arun(        {"action": "push", "id": "1", "path": "./talk.mp4", "text": None}    )    print(data)asyncio.run(process())  Previous Metaphor Search Next OpenWeatherMap Retrieved information Retrieved information CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Alpha Vantage (/docs/integrations/tools/alpha_vantage) Apify (/docs/integrations/tools/apify) ArXiv (/docs/integrations/tools/arxiv) AWS Lambda (/docs/integrations/tools/awslambda) Shell (bash) (/docs/integrations/tools/bash) Bing Search (/docs/integrations/tools/bing_search) Brave Search (/docs/integrations/tools/brave_search) ChatGPT Plugins (/docs/integrations/tools/chatgpt_plugins) Dall-E Image Generator (/docs/integrations/tools/dalle_image_generator) DataForSeo (/docs/integrations/tools/dataforseo) DuckDuckGo Search (/docs/integrations/tools/ddg) Eden AI (/docs/integrations/tools/edenai_tools) File System (/docs/integrations/tools/filesystem) Golden Query (/docs/integrations/tools/golden_query) Google Drive (/docs/integrations/tools/google_drive) Google Places (/docs/integrations/tools/google_places) Google Search (/docs/integrations/tools/google_search) Google Serper (/docs/integrations/tools/google_serper) Gradio (/docs/integrations/tools/gradio_tools) GraphQL (/docs/integrations/tools/graphql) HuggingFace Hub Tools (/docs/integrations/tools/huggingface_tools) Human as a tool (/docs/integrations/tools/human_tools) IFTTT WebHooks (/docs/integrations/tools/ifttt) Lemon Agent (/docs/integrations/tools/lemonai) Metaphor Search (/docs/integrations/tools/metaphor_search) Nuclia Understanding (/docs/integrations/tools/nuclia) OpenWeatherMap (/docs/integrations/tools/openweathermap) PubMed (/docs/integrations/tools/pubmed) Requests (/docs/integrations/tools/requests) SceneXplain (/docs/integrations/tools/sceneXplain) Search Tools (/docs/integrations/tools/search_tools) SearxNG Search (/docs/integrations/tools/searx_search) SerpAPI (/docs/integrations/tools/serpapi) Twilio (/docs/integrations/tools/twilio) Wikipedia (/docs/integrations/tools/wikipedia) Wolfram Alpha (/docs/integrations/tools/wolfram_alpha) Yahoo Finance News (/docs/integrations/tools/yahoo_finance_news) YouTube (/docs/integrations/tools/youtube) Zapier Natural Language Actions (/docs/integrations/tools/zapier) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Tools (/docs/integrations/tools/) Nuclia (https://nuclia.com) https://nuclia.cloud (https://nuclia.cloud) create a NUA key (https://docs.nuclia.dev/docs/docs/using/understanding/intro) NucliaUnderstandingAPI (https://api.python.langchain.com/en/latest/tools/langchain.tools.nuclia.tool.NucliaUnderstandingAPI.html) ‚Äã (#retrieved-information) /processing/download endpoint (https://docs.nuclia.dev/docs/api#operation/Download_binary_file_processing_download_get) PreviousMetaphor Search (/docs/integrations/tools/metaphor_search) NextOpenWeatherMap (/docs/integrations/tools/openweathermap) Retrieved information (#retrieved-information) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)