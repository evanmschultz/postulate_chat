CTranslate2 is a C++ and Python library for efficient inference with Transformer models. The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to accelerate and reduce the memory usage of Transformer models on CPU and GPU. Full list of features and supported models is included in the project's repository. To start, please check out the official quickstart guide. To use, you should have ctranslate2 python package installed. To use a Hugging Face model with CTranslate2, it has to be first converted to CTranslate2 format using the ct2-transformers-converter command. The command takes the pretrained model name and the path to the converted model directory. IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Callbacks Chat models Chat loaders Document loaders Document transformers LLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference) AI21 Aleph Alpha Amazon API Gateway Anyscale Azure ML Azure OpenAI Banana Baseten Beam Bedrock Bittensor CerebriumAI ChatGLM Clarifai Cohere C Transformers CTranslate2 Databricks DeepInfra DeepSparse Eden AI Fireworks ForefrontAI Google Vertex AI PaLM GooseAI GPT4All Hugging Face Hub Hugging Face Local Pipelines Huggingface TextGen Inference JSONFormer KoboldAI API Llama.cpp LLM Caching integrations Manifest Minimax Modal MosaicML NLP Cloud OctoAI Ollama OpaquePrompts OpenAI OpenLLM OpenLM Petals PipelineAI Predibase Prediction Guard PromptLayer OpenAI RELLM Replicate Runhouse SageMakerEndpoint StochasticAI Nebula (Symbl.ai) TextGen Titan Takeoff Tongyi Qwen vLLM Writer Xorbits Inference (Xinference) Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations LLMs CTranslate2 CTranslate2 Single call Multiple calls: Integrate the model in an LLMChain Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsLLMsCTranslate2On this pageCTranslate2CTranslate2 is a C++ and Python library for efficient inference with Transformer models.The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to accelerate and reduce the memory usage of Transformer models on CPU and GPU.Full list of features and supported models is included in the project's repository. To start, please check out the official quickstart guide.To use, you should have ctranslate2 python package installed.#!pip install ctranslate2To use a Hugging Face model with CTranslate2, it has to be first converted to CTranslate2 format using the ct2-transformers-converter command. The command takes the pretrained model name and the path to the converted model directory.# converstion can take several minutesct2-transformers-converter --model meta-llama/Llama-2-7b-hf --quantization bfloat16 --output_dir ./llama-2-7b-ct2 --force    Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.81it/s]from langchain.llms import CTranslate2llm = CTranslate2(    # output_dir from above:    model_path="./llama-2-7b-ct2",    tokenizer_name="meta-llama/Llama-2-7b-hf",    device="cuda",    # device_index can be either single int or list or ints,    # indicating the ids of GPUs to use for inference:    device_index=[0,1],     compute_type="bfloat16")API Reference:CTranslate2Single call‚Äãprint(    llm(        "He presented me with plausible evidence for the existence of unicorns: ",        max_length=256,        sampling_topk=50,        sampling_temperature=0.2,        repetition_penalty=2,        cache_static_prompt=False,    ))    He presented me with plausible evidence for the existence of unicorns: 1) they are mentioned in ancient texts; and, more importantly to him (and not so much as a matter that would convince most people), he had seen one.    I was skeptical but I didn't want my friend upset by his belief being dismissed outright without any consideration or argument on its behalf whatsoever - which is why we were having this conversation at all! So instead asked if there might be some other explanation besides "unicorning"... maybe it could have been an ostrich? Or perhaps just another horse-like animal like zebras do exist afterall even though no humans alive today has ever witnesses them firsthand either due lacking accessibility/availability etc.. But then again those animals aren‚Äô t exactly known around here anyway‚Ä¶‚Äù And thus began our discussion about whether these creatures actually existed anywhere else outside Earth itself where only few scientists ventured before us nowadays because technology allows exploration beyond borders once thought impossible centuries ago when travel meant walking everywhere yourself until reaching destination point A->B via footsteps alone unless someone helped guide along way through woods full darkness nighttime hoursMultiple calls:‚Äãprint(    llm.generate(        ["The list of top romantic songs:\n1.", "The list of top rap songs:\n1."],        max_length=128    ))    generations=[[Generation(text='The list of top romantic songs:\n1. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n2. ‚ÄúCan‚Äôt Help Falling in Love‚Äù by Elvis Presley\n3. ‚ÄúUnchained Melody‚Äù by The Righteous Brothers\n4. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n5. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n6. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n7. ‚ÄúI Will Always Love You‚Äù by The Beatles\n8. ‚ÄúI Will Always Love You‚Äù by The Rol', generation_info=None)], [Generation(text='The list of top rap songs:\n1. ‚ÄúGod‚Äôs Plan‚Äù by Drake\n2. ‚ÄúRockstar‚Äù by Post Malone\n3. ‚ÄúBad and Boujee‚Äù by Migos\n4. ‚ÄúHumble‚Äù by Kendrick Lamar\n5. ‚ÄúBodak Yellow‚Äù by Cardi B\n6. ‚ÄúI‚Äôm the One‚Äù by DJ Khaled\n7. ‚ÄúMotorsport‚Äù by Migos\n8. ‚ÄúNo Limit‚Äù by G-Eazy\n9. ‚ÄúBounce Back‚Äù by Big Sean\n10. ‚Äú', generation_info=None)]] llm_output=None run=[RunInfo(run_id=UUID('628e0491-a310-4d12-81db-6f2c5309d5c2')), RunInfo(run_id=UUID('f88fdbcd-c1f6-4f13-b575-810b80ecbaaf'))]Integrate the model in an LLMChain‚Äãfrom langchain import PromptTemplate, LLMChaintemplate = """{question}Let's think step by step. """prompt = PromptTemplate(template=template, input_variables=["question"])llm_chain = LLMChain(prompt=prompt, llm=llm)question = "Who was the US president in the year the first Pokemon game was released?"print(llm_chain.run(question))    Who was the US president in the year the first Pokemon game was released?        Let's think step by step. 1996 was the year the first Pokemon game was released.        \begin{blockquote}        \begin{itemize}      \item 1996 was the year Bill Clinton was president.      \item 1996 was the year the first Pokemon game was released.      \item 1996 was the year the first Pokemon game was released.        \end{itemize}    \end{blockquote}        I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.    PreviousC TransformersNextDatabricksSingle callMultiple calls:Integrate the model in an LLMChainCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsLLMsCTranslate2On this pageCTranslate2CTranslate2 is a C++ and Python library for efficient inference with Transformer models.The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to accelerate and reduce the memory usage of Transformer models on CPU and GPU.Full list of features and supported models is included in the project's repository. To start, please check out the official quickstart guide.To use, you should have ctranslate2 python package installed.#!pip install ctranslate2To use a Hugging Face model with CTranslate2, it has to be first converted to CTranslate2 format using the ct2-transformers-converter command. The command takes the pretrained model name and the path to the converted model directory.# converstion can take several minutesct2-transformers-converter --model meta-llama/Llama-2-7b-hf --quantization bfloat16 --output_dir ./llama-2-7b-ct2 --force    Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.81it/s]from langchain.llms import CTranslate2llm = CTranslate2(    # output_dir from above:    model_path="./llama-2-7b-ct2",    tokenizer_name="meta-llama/Llama-2-7b-hf",    device="cuda",    # device_index can be either single int or list or ints,    # indicating the ids of GPUs to use for inference:    device_index=[0,1],     compute_type="bfloat16")API Reference:CTranslate2Single call‚Äãprint(    llm(        "He presented me with plausible evidence for the existence of unicorns: ",        max_length=256,        sampling_topk=50,        sampling_temperature=0.2,        repetition_penalty=2,        cache_static_prompt=False,    ))    He presented me with plausible evidence for the existence of unicorns: 1) they are mentioned in ancient texts; and, more importantly to him (and not so much as a matter that would convince most people), he had seen one.    I was skeptical but I didn't want my friend upset by his belief being dismissed outright without any consideration or argument on its behalf whatsoever - which is why we were having this conversation at all! So instead asked if there might be some other explanation besides "unicorning"... maybe it could have been an ostrich? Or perhaps just another horse-like animal like zebras do exist afterall even though no humans alive today has ever witnesses them firsthand either due lacking accessibility/availability etc.. But then again those animals aren‚Äô t exactly known around here anyway‚Ä¶‚Äù And thus began our discussion about whether these creatures actually existed anywhere else outside Earth itself where only few scientists ventured before us nowadays because technology allows exploration beyond borders once thought impossible centuries ago when travel meant walking everywhere yourself until reaching destination point A->B via footsteps alone unless someone helped guide along way through woods full darkness nighttime hoursMultiple calls:‚Äãprint(    llm.generate(        ["The list of top romantic songs:\n1.", "The list of top rap songs:\n1."],        max_length=128    ))    generations=[[Generation(text='The list of top romantic songs:\n1. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n2. ‚ÄúCan‚Äôt Help Falling in Love‚Äù by Elvis Presley\n3. ‚ÄúUnchained Melody‚Äù by The Righteous Brothers\n4. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n5. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n6. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n7. ‚ÄúI Will Always Love You‚Äù by The Beatles\n8. ‚ÄúI Will Always Love You‚Äù by The Rol', generation_info=None)], [Generation(text='The list of top rap songs:\n1. ‚ÄúGod‚Äôs Plan‚Äù by Drake\n2. ‚ÄúRockstar‚Äù by Post Malone\n3. ‚ÄúBad and Boujee‚Äù by Migos\n4. ‚ÄúHumble‚Äù by Kendrick Lamar\n5. ‚ÄúBodak Yellow‚Äù by Cardi B\n6. ‚ÄúI‚Äôm the One‚Äù by DJ Khaled\n7. ‚ÄúMotorsport‚Äù by Migos\n8. ‚ÄúNo Limit‚Äù by G-Eazy\n9. ‚ÄúBounce Back‚Äù by Big Sean\n10. ‚Äú', generation_info=None)]] llm_output=None run=[RunInfo(run_id=UUID('628e0491-a310-4d12-81db-6f2c5309d5c2')), RunInfo(run_id=UUID('f88fdbcd-c1f6-4f13-b575-810b80ecbaaf'))]Integrate the model in an LLMChain‚Äãfrom langchain import PromptTemplate, LLMChaintemplate = """{question}Let's think step by step. """prompt = PromptTemplate(template=template, input_variables=["question"])llm_chain = LLMChain(prompt=prompt, llm=llm)question = "Who was the US president in the year the first Pokemon game was released?"print(llm_chain.run(question))    Who was the US president in the year the first Pokemon game was released?        Let's think step by step. 1996 was the year the first Pokemon game was released.        \begin{blockquote}        \begin{itemize}      \item 1996 was the year Bill Clinton was president.      \item 1996 was the year the first Pokemon game was released.      \item 1996 was the year the first Pokemon game was released.        \end{itemize}    \end{blockquote}        I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.    PreviousC TransformersNextDatabricksSingle callMultiple calls:Integrate the model in an LLMChain IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsLLMsCTranslate2On this pageCTranslate2CTranslate2 is a C++ and Python library for efficient inference with Transformer models.The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to accelerate and reduce the memory usage of Transformer models on CPU and GPU.Full list of features and supported models is included in the project's repository. To start, please check out the official quickstart guide.To use, you should have ctranslate2 python package installed.#!pip install ctranslate2To use a Hugging Face model with CTranslate2, it has to be first converted to CTranslate2 format using the ct2-transformers-converter command. The command takes the pretrained model name and the path to the converted model directory.# converstion can take several minutesct2-transformers-converter --model meta-llama/Llama-2-7b-hf --quantization bfloat16 --output_dir ./llama-2-7b-ct2 --force    Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.81it/s]from langchain.llms import CTranslate2llm = CTranslate2(    # output_dir from above:    model_path="./llama-2-7b-ct2",    tokenizer_name="meta-llama/Llama-2-7b-hf",    device="cuda",    # device_index can be either single int or list or ints,    # indicating the ids of GPUs to use for inference:    device_index=[0,1],     compute_type="bfloat16")API Reference:CTranslate2Single call‚Äãprint(    llm(        "He presented me with plausible evidence for the existence of unicorns: ",        max_length=256,        sampling_topk=50,        sampling_temperature=0.2,        repetition_penalty=2,        cache_static_prompt=False,    ))    He presented me with plausible evidence for the existence of unicorns: 1) they are mentioned in ancient texts; and, more importantly to him (and not so much as a matter that would convince most people), he had seen one.    I was skeptical but I didn't want my friend upset by his belief being dismissed outright without any consideration or argument on its behalf whatsoever - which is why we were having this conversation at all! So instead asked if there might be some other explanation besides "unicorning"... maybe it could have been an ostrich? Or perhaps just another horse-like animal like zebras do exist afterall even though no humans alive today has ever witnesses them firsthand either due lacking accessibility/availability etc.. But then again those animals aren‚Äô t exactly known around here anyway‚Ä¶‚Äù And thus began our discussion about whether these creatures actually existed anywhere else outside Earth itself where only few scientists ventured before us nowadays because technology allows exploration beyond borders once thought impossible centuries ago when travel meant walking everywhere yourself until reaching destination point A->B via footsteps alone unless someone helped guide along way through woods full darkness nighttime hoursMultiple calls:‚Äãprint(    llm.generate(        ["The list of top romantic songs:\n1.", "The list of top rap songs:\n1."],        max_length=128    ))    generations=[[Generation(text='The list of top romantic songs:\n1. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n2. ‚ÄúCan‚Äôt Help Falling in Love‚Äù by Elvis Presley\n3. ‚ÄúUnchained Melody‚Äù by The Righteous Brothers\n4. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n5. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n6. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n7. ‚ÄúI Will Always Love You‚Äù by The Beatles\n8. ‚ÄúI Will Always Love You‚Äù by The Rol', generation_info=None)], [Generation(text='The list of top rap songs:\n1. ‚ÄúGod‚Äôs Plan‚Äù by Drake\n2. ‚ÄúRockstar‚Äù by Post Malone\n3. ‚ÄúBad and Boujee‚Äù by Migos\n4. ‚ÄúHumble‚Äù by Kendrick Lamar\n5. ‚ÄúBodak Yellow‚Äù by Cardi B\n6. ‚ÄúI‚Äôm the One‚Äù by DJ Khaled\n7. ‚ÄúMotorsport‚Äù by Migos\n8. ‚ÄúNo Limit‚Äù by G-Eazy\n9. ‚ÄúBounce Back‚Äù by Big Sean\n10. ‚Äú', generation_info=None)]] llm_output=None run=[RunInfo(run_id=UUID('628e0491-a310-4d12-81db-6f2c5309d5c2')), RunInfo(run_id=UUID('f88fdbcd-c1f6-4f13-b575-810b80ecbaaf'))]Integrate the model in an LLMChain‚Äãfrom langchain import PromptTemplate, LLMChaintemplate = """{question}Let's think step by step. """prompt = PromptTemplate(template=template, input_variables=["question"])llm_chain = LLMChain(prompt=prompt, llm=llm)question = "Who was the US president in the year the first Pokemon game was released?"print(llm_chain.run(question))    Who was the US president in the year the first Pokemon game was released?        Let's think step by step. 1996 was the year the first Pokemon game was released.        \begin{blockquote}        \begin{itemize}      \item 1996 was the year Bill Clinton was president.      \item 1996 was the year the first Pokemon game was released.      \item 1996 was the year the first Pokemon game was released.        \end{itemize}    \end{blockquote}        I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.    PreviousC TransformersNextDatabricksSingle callMultiple calls:Integrate the model in an LLMChain IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsLLMsCTranslate2On this pageCTranslate2CTranslate2 is a C++ and Python library for efficient inference with Transformer models.The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to accelerate and reduce the memory usage of Transformer models on CPU and GPU.Full list of features and supported models is included in the project's repository. To start, please check out the official quickstart guide.To use, you should have ctranslate2 python package installed.#!pip install ctranslate2To use a Hugging Face model with CTranslate2, it has to be first converted to CTranslate2 format using the ct2-transformers-converter command. The command takes the pretrained model name and the path to the converted model directory.# converstion can take several minutesct2-transformers-converter --model meta-llama/Llama-2-7b-hf --quantization bfloat16 --output_dir ./llama-2-7b-ct2 --force    Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.81it/s]from langchain.llms import CTranslate2llm = CTranslate2(    # output_dir from above:    model_path="./llama-2-7b-ct2",    tokenizer_name="meta-llama/Llama-2-7b-hf",    device="cuda",    # device_index can be either single int or list or ints,    # indicating the ids of GPUs to use for inference:    device_index=[0,1],     compute_type="bfloat16")API Reference:CTranslate2Single call‚Äãprint(    llm(        "He presented me with plausible evidence for the existence of unicorns: ",        max_length=256,        sampling_topk=50,        sampling_temperature=0.2,        repetition_penalty=2,        cache_static_prompt=False,    ))    He presented me with plausible evidence for the existence of unicorns: 1) they are mentioned in ancient texts; and, more importantly to him (and not so much as a matter that would convince most people), he had seen one.    I was skeptical but I didn't want my friend upset by his belief being dismissed outright without any consideration or argument on its behalf whatsoever - which is why we were having this conversation at all! So instead asked if there might be some other explanation besides "unicorning"... maybe it could have been an ostrich? Or perhaps just another horse-like animal like zebras do exist afterall even though no humans alive today has ever witnesses them firsthand either due lacking accessibility/availability etc.. But then again those animals aren‚Äô t exactly known around here anyway‚Ä¶‚Äù And thus began our discussion about whether these creatures actually existed anywhere else outside Earth itself where only few scientists ventured before us nowadays because technology allows exploration beyond borders once thought impossible centuries ago when travel meant walking everywhere yourself until reaching destination point A->B via footsteps alone unless someone helped guide along way through woods full darkness nighttime hoursMultiple calls:‚Äãprint(    llm.generate(        ["The list of top romantic songs:\n1.", "The list of top rap songs:\n1."],        max_length=128    ))    generations=[[Generation(text='The list of top romantic songs:\n1. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n2. ‚ÄúCan‚Äôt Help Falling in Love‚Äù by Elvis Presley\n3. ‚ÄúUnchained Melody‚Äù by The Righteous Brothers\n4. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n5. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n6. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n7. ‚ÄúI Will Always Love You‚Äù by The Beatles\n8. ‚ÄúI Will Always Love You‚Äù by The Rol', generation_info=None)], [Generation(text='The list of top rap songs:\n1. ‚ÄúGod‚Äôs Plan‚Äù by Drake\n2. ‚ÄúRockstar‚Äù by Post Malone\n3. ‚ÄúBad and Boujee‚Äù by Migos\n4. ‚ÄúHumble‚Äù by Kendrick Lamar\n5. ‚ÄúBodak Yellow‚Äù by Cardi B\n6. ‚ÄúI‚Äôm the One‚Äù by DJ Khaled\n7. ‚ÄúMotorsport‚Äù by Migos\n8. ‚ÄúNo Limit‚Äù by G-Eazy\n9. ‚ÄúBounce Back‚Äù by Big Sean\n10. ‚Äú', generation_info=None)]] llm_output=None run=[RunInfo(run_id=UUID('628e0491-a310-4d12-81db-6f2c5309d5c2')), RunInfo(run_id=UUID('f88fdbcd-c1f6-4f13-b575-810b80ecbaaf'))]Integrate the model in an LLMChain‚Äãfrom langchain import PromptTemplate, LLMChaintemplate = """{question}Let's think step by step. """prompt = PromptTemplate(template=template, input_variables=["question"])llm_chain = LLMChain(prompt=prompt, llm=llm)question = "Who was the US president in the year the first Pokemon game was released?"print(llm_chain.run(question))    Who was the US president in the year the first Pokemon game was released?        Let's think step by step. 1996 was the year the first Pokemon game was released.        \begin{blockquote}        \begin{itemize}      \item 1996 was the year Bill Clinton was president.      \item 1996 was the year the first Pokemon game was released.      \item 1996 was the year the first Pokemon game was released.        \end{itemize}    \end{blockquote}        I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.    PreviousC TransformersNextDatabricksSingle callMultiple calls:Integrate the model in an LLMChain IntegrationsLLMsCTranslate2On this pageCTranslate2CTranslate2 is a C++ and Python library for efficient inference with Transformer models.The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to accelerate and reduce the memory usage of Transformer models on CPU and GPU.Full list of features and supported models is included in the project's repository. To start, please check out the official quickstart guide.To use, you should have ctranslate2 python package installed.#!pip install ctranslate2To use a Hugging Face model with CTranslate2, it has to be first converted to CTranslate2 format using the ct2-transformers-converter command. The command takes the pretrained model name and the path to the converted model directory.# converstion can take several minutesct2-transformers-converter --model meta-llama/Llama-2-7b-hf --quantization bfloat16 --output_dir ./llama-2-7b-ct2 --force    Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.81it/s]from langchain.llms import CTranslate2llm = CTranslate2(    # output_dir from above:    model_path="./llama-2-7b-ct2",    tokenizer_name="meta-llama/Llama-2-7b-hf",    device="cuda",    # device_index can be either single int or list or ints,    # indicating the ids of GPUs to use for inference:    device_index=[0,1],     compute_type="bfloat16")API Reference:CTranslate2Single call‚Äãprint(    llm(        "He presented me with plausible evidence for the existence of unicorns: ",        max_length=256,        sampling_topk=50,        sampling_temperature=0.2,        repetition_penalty=2,        cache_static_prompt=False,    ))    He presented me with plausible evidence for the existence of unicorns: 1) they are mentioned in ancient texts; and, more importantly to him (and not so much as a matter that would convince most people), he had seen one.    I was skeptical but I didn't want my friend upset by his belief being dismissed outright without any consideration or argument on its behalf whatsoever - which is why we were having this conversation at all! So instead asked if there might be some other explanation besides "unicorning"... maybe it could have been an ostrich? Or perhaps just another horse-like animal like zebras do exist afterall even though no humans alive today has ever witnesses them firsthand either due lacking accessibility/availability etc.. But then again those animals aren‚Äô t exactly known around here anyway‚Ä¶‚Äù And thus began our discussion about whether these creatures actually existed anywhere else outside Earth itself where only few scientists ventured before us nowadays because technology allows exploration beyond borders once thought impossible centuries ago when travel meant walking everywhere yourself until reaching destination point A->B via footsteps alone unless someone helped guide along way through woods full darkness nighttime hoursMultiple calls:‚Äãprint(    llm.generate(        ["The list of top romantic songs:\n1.", "The list of top rap songs:\n1."],        max_length=128    ))    generations=[[Generation(text='The list of top romantic songs:\n1. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n2. ‚ÄúCan‚Äôt Help Falling in Love‚Äù by Elvis Presley\n3. ‚ÄúUnchained Melody‚Äù by The Righteous Brothers\n4. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n5. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n6. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n7. ‚ÄúI Will Always Love You‚Äù by The Beatles\n8. ‚ÄúI Will Always Love You‚Äù by The Rol', generation_info=None)], [Generation(text='The list of top rap songs:\n1. ‚ÄúGod‚Äôs Plan‚Äù by Drake\n2. ‚ÄúRockstar‚Äù by Post Malone\n3. ‚ÄúBad and Boujee‚Äù by Migos\n4. ‚ÄúHumble‚Äù by Kendrick Lamar\n5. ‚ÄúBodak Yellow‚Äù by Cardi B\n6. ‚ÄúI‚Äôm the One‚Äù by DJ Khaled\n7. ‚ÄúMotorsport‚Äù by Migos\n8. ‚ÄúNo Limit‚Äù by G-Eazy\n9. ‚ÄúBounce Back‚Äù by Big Sean\n10. ‚Äú', generation_info=None)]] llm_output=None run=[RunInfo(run_id=UUID('628e0491-a310-4d12-81db-6f2c5309d5c2')), RunInfo(run_id=UUID('f88fdbcd-c1f6-4f13-b575-810b80ecbaaf'))]Integrate the model in an LLMChain‚Äãfrom langchain import PromptTemplate, LLMChaintemplate = """{question}Let's think step by step. """prompt = PromptTemplate(template=template, input_variables=["question"])llm_chain = LLMChain(prompt=prompt, llm=llm)question = "Who was the US president in the year the first Pokemon game was released?"print(llm_chain.run(question))    Who was the US president in the year the first Pokemon game was released?        Let's think step by step. 1996 was the year the first Pokemon game was released.        \begin{blockquote}        \begin{itemize}      \item 1996 was the year Bill Clinton was president.      \item 1996 was the year the first Pokemon game was released.      \item 1996 was the year the first Pokemon game was released.        \end{itemize}    \end{blockquote}        I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.    PreviousC TransformersNextDatabricksSingle callMultiple calls:Integrate the model in an LLMChain IntegrationsLLMsCTranslate2On this pageCTranslate2CTranslate2 is a C++ and Python library for efficient inference with Transformer models.The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to accelerate and reduce the memory usage of Transformer models on CPU and GPU.Full list of features and supported models is included in the project's repository. To start, please check out the official quickstart guide.To use, you should have ctranslate2 python package installed.#!pip install ctranslate2To use a Hugging Face model with CTranslate2, it has to be first converted to CTranslate2 format using the ct2-transformers-converter command. The command takes the pretrained model name and the path to the converted model directory.# converstion can take several minutesct2-transformers-converter --model meta-llama/Llama-2-7b-hf --quantization bfloat16 --output_dir ./llama-2-7b-ct2 --force    Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.81it/s]from langchain.llms import CTranslate2llm = CTranslate2(    # output_dir from above:    model_path="./llama-2-7b-ct2",    tokenizer_name="meta-llama/Llama-2-7b-hf",    device="cuda",    # device_index can be either single int or list or ints,    # indicating the ids of GPUs to use for inference:    device_index=[0,1],     compute_type="bfloat16")API Reference:CTranslate2Single call‚Äãprint(    llm(        "He presented me with plausible evidence for the existence of unicorns: ",        max_length=256,        sampling_topk=50,        sampling_temperature=0.2,        repetition_penalty=2,        cache_static_prompt=False,    ))    He presented me with plausible evidence for the existence of unicorns: 1) they are mentioned in ancient texts; and, more importantly to him (and not so much as a matter that would convince most people), he had seen one.    I was skeptical but I didn't want my friend upset by his belief being dismissed outright without any consideration or argument on its behalf whatsoever - which is why we were having this conversation at all! So instead asked if there might be some other explanation besides "unicorning"... maybe it could have been an ostrich? Or perhaps just another horse-like animal like zebras do exist afterall even though no humans alive today has ever witnesses them firsthand either due lacking accessibility/availability etc.. But then again those animals aren‚Äô t exactly known around here anyway‚Ä¶‚Äù And thus began our discussion about whether these creatures actually existed anywhere else outside Earth itself where only few scientists ventured before us nowadays because technology allows exploration beyond borders once thought impossible centuries ago when travel meant walking everywhere yourself until reaching destination point A->B via footsteps alone unless someone helped guide along way through woods full darkness nighttime hoursMultiple calls:‚Äãprint(    llm.generate(        ["The list of top romantic songs:\n1.", "The list of top rap songs:\n1."],        max_length=128    ))    generations=[[Generation(text='The list of top romantic songs:\n1. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n2. ‚ÄúCan‚Äôt Help Falling in Love‚Äù by Elvis Presley\n3. ‚ÄúUnchained Melody‚Äù by The Righteous Brothers\n4. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n5. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n6. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n7. ‚ÄúI Will Always Love You‚Äù by The Beatles\n8. ‚ÄúI Will Always Love You‚Äù by The Rol', generation_info=None)], [Generation(text='The list of top rap songs:\n1. ‚ÄúGod‚Äôs Plan‚Äù by Drake\n2. ‚ÄúRockstar‚Äù by Post Malone\n3. ‚ÄúBad and Boujee‚Äù by Migos\n4. ‚ÄúHumble‚Äù by Kendrick Lamar\n5. ‚ÄúBodak Yellow‚Äù by Cardi B\n6. ‚ÄúI‚Äôm the One‚Äù by DJ Khaled\n7. ‚ÄúMotorsport‚Äù by Migos\n8. ‚ÄúNo Limit‚Äù by G-Eazy\n9. ‚ÄúBounce Back‚Äù by Big Sean\n10. ‚Äú', generation_info=None)]] llm_output=None run=[RunInfo(run_id=UUID('628e0491-a310-4d12-81db-6f2c5309d5c2')), RunInfo(run_id=UUID('f88fdbcd-c1f6-4f13-b575-810b80ecbaaf'))]Integrate the model in an LLMChain‚Äãfrom langchain import PromptTemplate, LLMChaintemplate = """{question}Let's think step by step. """prompt = PromptTemplate(template=template, input_variables=["question"])llm_chain = LLMChain(prompt=prompt, llm=llm)question = "Who was the US president in the year the first Pokemon game was released?"print(llm_chain.run(question))    Who was the US president in the year the first Pokemon game was released?        Let's think step by step. 1996 was the year the first Pokemon game was released.        \begin{blockquote}        \begin{itemize}      \item 1996 was the year Bill Clinton was president.      \item 1996 was the year the first Pokemon game was released.      \item 1996 was the year the first Pokemon game was released.        \end{itemize}    \end{blockquote}        I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.    PreviousC TransformersNextDatabricks IntegrationsLLMsCTranslate2On this pageCTranslate2CTranslate2 is a C++ and Python library for efficient inference with Transformer models.The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to accelerate and reduce the memory usage of Transformer models on CPU and GPU.Full list of features and supported models is included in the project's repository. To start, please check out the official quickstart guide.To use, you should have ctranslate2 python package installed.#!pip install ctranslate2To use a Hugging Face model with CTranslate2, it has to be first converted to CTranslate2 format using the ct2-transformers-converter command. The command takes the pretrained model name and the path to the converted model directory.# converstion can take several minutesct2-transformers-converter --model meta-llama/Llama-2-7b-hf --quantization bfloat16 --output_dir ./llama-2-7b-ct2 --force    Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.81it/s]from langchain.llms import CTranslate2llm = CTranslate2(    # output_dir from above:    model_path="./llama-2-7b-ct2",    tokenizer_name="meta-llama/Llama-2-7b-hf",    device="cuda",    # device_index can be either single int or list or ints,    # indicating the ids of GPUs to use for inference:    device_index=[0,1],     compute_type="bfloat16")API Reference:CTranslate2Single call‚Äãprint(    llm(        "He presented me with plausible evidence for the existence of unicorns: ",        max_length=256,        sampling_topk=50,        sampling_temperature=0.2,        repetition_penalty=2,        cache_static_prompt=False,    ))    He presented me with plausible evidence for the existence of unicorns: 1) they are mentioned in ancient texts; and, more importantly to him (and not so much as a matter that would convince most people), he had seen one.    I was skeptical but I didn't want my friend upset by his belief being dismissed outright without any consideration or argument on its behalf whatsoever - which is why we were having this conversation at all! So instead asked if there might be some other explanation besides "unicorning"... maybe it could have been an ostrich? Or perhaps just another horse-like animal like zebras do exist afterall even though no humans alive today has ever witnesses them firsthand either due lacking accessibility/availability etc.. But then again those animals aren‚Äô t exactly known around here anyway‚Ä¶‚Äù And thus began our discussion about whether these creatures actually existed anywhere else outside Earth itself where only few scientists ventured before us nowadays because technology allows exploration beyond borders once thought impossible centuries ago when travel meant walking everywhere yourself until reaching destination point A->B via footsteps alone unless someone helped guide along way through woods full darkness nighttime hoursMultiple calls:‚Äãprint(    llm.generate(        ["The list of top romantic songs:\n1.", "The list of top rap songs:\n1."],        max_length=128    ))    generations=[[Generation(text='The list of top romantic songs:\n1. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n2. ‚ÄúCan‚Äôt Help Falling in Love‚Äù by Elvis Presley\n3. ‚ÄúUnchained Melody‚Äù by The Righteous Brothers\n4. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n5. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n6. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n7. ‚ÄúI Will Always Love You‚Äù by The Beatles\n8. ‚ÄúI Will Always Love You‚Äù by The Rol', generation_info=None)], [Generation(text='The list of top rap songs:\n1. ‚ÄúGod‚Äôs Plan‚Äù by Drake\n2. ‚ÄúRockstar‚Äù by Post Malone\n3. ‚ÄúBad and Boujee‚Äù by Migos\n4. ‚ÄúHumble‚Äù by Kendrick Lamar\n5. ‚ÄúBodak Yellow‚Äù by Cardi B\n6. ‚ÄúI‚Äôm the One‚Äù by DJ Khaled\n7. ‚ÄúMotorsport‚Äù by Migos\n8. ‚ÄúNo Limit‚Äù by G-Eazy\n9. ‚ÄúBounce Back‚Äù by Big Sean\n10. ‚Äú', generation_info=None)]] llm_output=None run=[RunInfo(run_id=UUID('628e0491-a310-4d12-81db-6f2c5309d5c2')), RunInfo(run_id=UUID('f88fdbcd-c1f6-4f13-b575-810b80ecbaaf'))]Integrate the model in an LLMChain‚Äãfrom langchain import PromptTemplate, LLMChaintemplate = """{question}Let's think step by step. """prompt = PromptTemplate(template=template, input_variables=["question"])llm_chain = LLMChain(prompt=prompt, llm=llm)question = "Who was the US president in the year the first Pokemon game was released?"print(llm_chain.run(question))    Who was the US president in the year the first Pokemon game was released?        Let's think step by step. 1996 was the year the first Pokemon game was released.        \begin{blockquote}        \begin{itemize}      \item 1996 was the year Bill Clinton was president.      \item 1996 was the year the first Pokemon game was released.      \item 1996 was the year the first Pokemon game was released.        \end{itemize}    \end{blockquote}        I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.    PreviousC TransformersNextDatabricks On this page CTranslate2CTranslate2 is a C++ and Python library for efficient inference with Transformer models.The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to accelerate and reduce the memory usage of Transformer models on CPU and GPU.Full list of features and supported models is included in the project's repository. To start, please check out the official quickstart guide.To use, you should have ctranslate2 python package installed.#!pip install ctranslate2To use a Hugging Face model with CTranslate2, it has to be first converted to CTranslate2 format using the ct2-transformers-converter command. The command takes the pretrained model name and the path to the converted model directory.# converstion can take several minutesct2-transformers-converter --model meta-llama/Llama-2-7b-hf --quantization bfloat16 --output_dir ./llama-2-7b-ct2 --force    Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.81it/s]from langchain.llms import CTranslate2llm = CTranslate2(    # output_dir from above:    model_path="./llama-2-7b-ct2",    tokenizer_name="meta-llama/Llama-2-7b-hf",    device="cuda",    # device_index can be either single int or list or ints,    # indicating the ids of GPUs to use for inference:    device_index=[0,1],     compute_type="bfloat16")API Reference:CTranslate2Single call‚Äãprint(    llm(        "He presented me with plausible evidence for the existence of unicorns: ",        max_length=256,        sampling_topk=50,        sampling_temperature=0.2,        repetition_penalty=2,        cache_static_prompt=False,    ))    He presented me with plausible evidence for the existence of unicorns: 1) they are mentioned in ancient texts; and, more importantly to him (and not so much as a matter that would convince most people), he had seen one.    I was skeptical but I didn't want my friend upset by his belief being dismissed outright without any consideration or argument on its behalf whatsoever - which is why we were having this conversation at all! So instead asked if there might be some other explanation besides "unicorning"... maybe it could have been an ostrich? Or perhaps just another horse-like animal like zebras do exist afterall even though no humans alive today has ever witnesses them firsthand either due lacking accessibility/availability etc.. But then again those animals aren‚Äô t exactly known around here anyway‚Ä¶‚Äù And thus began our discussion about whether these creatures actually existed anywhere else outside Earth itself where only few scientists ventured before us nowadays because technology allows exploration beyond borders once thought impossible centuries ago when travel meant walking everywhere yourself until reaching destination point A->B via footsteps alone unless someone helped guide along way through woods full darkness nighttime hoursMultiple calls:‚Äãprint(    llm.generate(        ["The list of top romantic songs:\n1.", "The list of top rap songs:\n1."],        max_length=128    ))    generations=[[Generation(text='The list of top romantic songs:\n1. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n2. ‚ÄúCan‚Äôt Help Falling in Love‚Äù by Elvis Presley\n3. ‚ÄúUnchained Melody‚Äù by The Righteous Brothers\n4. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n5. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n6. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n7. ‚ÄúI Will Always Love You‚Äù by The Beatles\n8. ‚ÄúI Will Always Love You‚Äù by The Rol', generation_info=None)], [Generation(text='The list of top rap songs:\n1. ‚ÄúGod‚Äôs Plan‚Äù by Drake\n2. ‚ÄúRockstar‚Äù by Post Malone\n3. ‚ÄúBad and Boujee‚Äù by Migos\n4. ‚ÄúHumble‚Äù by Kendrick Lamar\n5. ‚ÄúBodak Yellow‚Äù by Cardi B\n6. ‚ÄúI‚Äôm the One‚Äù by DJ Khaled\n7. ‚ÄúMotorsport‚Äù by Migos\n8. ‚ÄúNo Limit‚Äù by G-Eazy\n9. ‚ÄúBounce Back‚Äù by Big Sean\n10. ‚Äú', generation_info=None)]] llm_output=None run=[RunInfo(run_id=UUID('628e0491-a310-4d12-81db-6f2c5309d5c2')), RunInfo(run_id=UUID('f88fdbcd-c1f6-4f13-b575-810b80ecbaaf'))]Integrate the model in an LLMChain‚Äãfrom langchain import PromptTemplate, LLMChaintemplate = """{question}Let's think step by step. """prompt = PromptTemplate(template=template, input_variables=["question"])llm_chain = LLMChain(prompt=prompt, llm=llm)question = "Who was the US president in the year the first Pokemon game was released?"print(llm_chain.run(question))    Who was the US president in the year the first Pokemon game was released?        Let's think step by step. 1996 was the year the first Pokemon game was released.        \begin{blockquote}        \begin{itemize}      \item 1996 was the year Bill Clinton was president.      \item 1996 was the year the first Pokemon game was released.      \item 1996 was the year the first Pokemon game was released.        \end{itemize}    \end{blockquote}        I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.     #!pip install ctranslate2 #!pip install ctranslate2  # converstion can take several minutesct2-transformers-converter --model meta-llama/Llama-2-7b-hf --quantization bfloat16 --output_dir ./llama-2-7b-ct2 --force # converstion can take several minutesct2-transformers-converter --model meta-llama/Llama-2-7b-hf --quantization bfloat16 --output_dir ./llama-2-7b-ct2 --force      Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.81it/s]     Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.81it/s]     Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.81it/s]  from langchain.llms import CTranslate2llm = CTranslate2(    # output_dir from above:    model_path="./llama-2-7b-ct2",    tokenizer_name="meta-llama/Llama-2-7b-hf",    device="cuda",    # device_index can be either single int or list or ints,    # indicating the ids of GPUs to use for inference:    device_index=[0,1],     compute_type="bfloat16") from langchain.llms import CTranslate2llm = CTranslate2(    # output_dir from above:    model_path="./llama-2-7b-ct2",    tokenizer_name="meta-llama/Llama-2-7b-hf",    device="cuda",    # device_index can be either single int or list or ints,    # indicating the ids of GPUs to use for inference:    device_index=[0,1],     compute_type="bfloat16")  API Reference:CTranslate2 print(    llm(        "He presented me with plausible evidence for the existence of unicorns: ",        max_length=256,        sampling_topk=50,        sampling_temperature=0.2,        repetition_penalty=2,        cache_static_prompt=False,    )) print(    llm(        "He presented me with plausible evidence for the existence of unicorns: ",        max_length=256,        sampling_topk=50,        sampling_temperature=0.2,        repetition_penalty=2,        cache_static_prompt=False,    ))      He presented me with plausible evidence for the existence of unicorns: 1) they are mentioned in ancient texts; and, more importantly to him (and not so much as a matter that would convince most people), he had seen one.    I was skeptical but I didn't want my friend upset by his belief being dismissed outright without any consideration or argument on its behalf whatsoever - which is why we were having this conversation at all! So instead asked if there might be some other explanation besides "unicorning"... maybe it could have been an ostrich? Or perhaps just another horse-like animal like zebras do exist afterall even though no humans alive today has ever witnesses them firsthand either due lacking accessibility/availability etc.. But then again those animals aren‚Äô t exactly known around here anyway‚Ä¶‚Äù And thus began our discussion about whether these creatures actually existed anywhere else outside Earth itself where only few scientists ventured before us nowadays because technology allows exploration beyond borders once thought impossible centuries ago when travel meant walking everywhere yourself until reaching destination point A->B via footsteps alone unless someone helped guide along way through woods full darkness nighttime hours     He presented me with plausible evidence for the existence of unicorns: 1) they are mentioned in ancient texts; and, more importantly to him (and not so much as a matter that would convince most people), he had seen one.    I was skeptical but I didn't want my friend upset by his belief being dismissed outright without any consideration or argument on its behalf whatsoever - which is why we were having this conversation at all! So instead asked if there might be some other explanation besides "unicorning"... maybe it could have been an ostrich? Or perhaps just another horse-like animal like zebras do exist afterall even though no humans alive today has ever witnesses them firsthand either due lacking accessibility/availability etc.. But then again those animals aren‚Äô t exactly known around here anyway‚Ä¶‚Äù And thus began our discussion about whether these creatures actually existed anywhere else outside Earth itself where only few scientists ventured before us nowadays because technology allows exploration beyond borders once thought impossible centuries ago when travel meant walking everywhere yourself until reaching destination point A->B via footsteps alone unless someone helped guide along way through woods full darkness nighttime hours     He presented me with plausible evidence for the existence of unicorns: 1) they are mentioned in ancient texts; and, more importantly to him (and not so much as a matter that would convince most people), he had seen one.    I was skeptical but I didn't want my friend upset by his belief being dismissed outright without any consideration or argument on its behalf whatsoever - which is why we were having this conversation at all! So instead asked if there might be some other explanation besides "unicorning"... maybe it could have been an ostrich? Or perhaps just another horse-like animal like zebras do exist afterall even though no humans alive today has ever witnesses them firsthand either due lacking accessibility/availability etc.. But then again those animals aren‚Äô t exactly known around here anyway‚Ä¶‚Äù And thus began our discussion about whether these creatures actually existed anywhere else outside Earth itself where only few scientists ventured before us nowadays because technology allows exploration beyond borders once thought impossible centuries ago when travel meant walking everywhere yourself until reaching destination point A->B via footsteps alone unless someone helped guide along way through woods full darkness nighttime hours  print(    llm.generate(        ["The list of top romantic songs:\n1.", "The list of top rap songs:\n1."],        max_length=128    )) print(    llm.generate(        ["The list of top romantic songs:\n1.", "The list of top rap songs:\n1."],        max_length=128    ))      generations=[[Generation(text='The list of top romantic songs:\n1. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n2. ‚ÄúCan‚Äôt Help Falling in Love‚Äù by Elvis Presley\n3. ‚ÄúUnchained Melody‚Äù by The Righteous Brothers\n4. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n5. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n6. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n7. ‚ÄúI Will Always Love You‚Äù by The Beatles\n8. ‚ÄúI Will Always Love You‚Äù by The Rol', generation_info=None)], [Generation(text='The list of top rap songs:\n1. ‚ÄúGod‚Äôs Plan‚Äù by Drake\n2. ‚ÄúRockstar‚Äù by Post Malone\n3. ‚ÄúBad and Boujee‚Äù by Migos\n4. ‚ÄúHumble‚Äù by Kendrick Lamar\n5. ‚ÄúBodak Yellow‚Äù by Cardi B\n6. ‚ÄúI‚Äôm the One‚Äù by DJ Khaled\n7. ‚ÄúMotorsport‚Äù by Migos\n8. ‚ÄúNo Limit‚Äù by G-Eazy\n9. ‚ÄúBounce Back‚Äù by Big Sean\n10. ‚Äú', generation_info=None)]] llm_output=None run=[RunInfo(run_id=UUID('628e0491-a310-4d12-81db-6f2c5309d5c2')), RunInfo(run_id=UUID('f88fdbcd-c1f6-4f13-b575-810b80ecbaaf'))]     generations=[[Generation(text='The list of top romantic songs:\n1. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n2. ‚ÄúCan‚Äôt Help Falling in Love‚Äù by Elvis Presley\n3. ‚ÄúUnchained Melody‚Äù by The Righteous Brothers\n4. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n5. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n6. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n7. ‚ÄúI Will Always Love You‚Äù by The Beatles\n8. ‚ÄúI Will Always Love You‚Äù by The Rol', generation_info=None)], [Generation(text='The list of top rap songs:\n1. ‚ÄúGod‚Äôs Plan‚Äù by Drake\n2. ‚ÄúRockstar‚Äù by Post Malone\n3. ‚ÄúBad and Boujee‚Äù by Migos\n4. ‚ÄúHumble‚Äù by Kendrick Lamar\n5. ‚ÄúBodak Yellow‚Äù by Cardi B\n6. ‚ÄúI‚Äôm the One‚Äù by DJ Khaled\n7. ‚ÄúMotorsport‚Äù by Migos\n8. ‚ÄúNo Limit‚Äù by G-Eazy\n9. ‚ÄúBounce Back‚Äù by Big Sean\n10. ‚Äú', generation_info=None)]] llm_output=None run=[RunInfo(run_id=UUID('628e0491-a310-4d12-81db-6f2c5309d5c2')), RunInfo(run_id=UUID('f88fdbcd-c1f6-4f13-b575-810b80ecbaaf'))]     generations=[[Generation(text='The list of top romantic songs:\n1. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n2. ‚ÄúCan‚Äôt Help Falling in Love‚Äù by Elvis Presley\n3. ‚ÄúUnchained Melody‚Äù by The Righteous Brothers\n4. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n5. ‚ÄúI Will Always Love You‚Äù by Whitney Houston\n6. ‚ÄúI Will Always Love You‚Äù by Dolly Parton\n7. ‚ÄúI Will Always Love You‚Äù by The Beatles\n8. ‚ÄúI Will Always Love You‚Äù by The Rol', generation_info=None)], [Generation(text='The list of top rap songs:\n1. ‚ÄúGod‚Äôs Plan‚Äù by Drake\n2. ‚ÄúRockstar‚Äù by Post Malone\n3. ‚ÄúBad and Boujee‚Äù by Migos\n4. ‚ÄúHumble‚Äù by Kendrick Lamar\n5. ‚ÄúBodak Yellow‚Äù by Cardi B\n6. ‚ÄúI‚Äôm the One‚Äù by DJ Khaled\n7. ‚ÄúMotorsport‚Äù by Migos\n8. ‚ÄúNo Limit‚Äù by G-Eazy\n9. ‚ÄúBounce Back‚Äù by Big Sean\n10. ‚Äú', generation_info=None)]] llm_output=None run=[RunInfo(run_id=UUID('628e0491-a310-4d12-81db-6f2c5309d5c2')), RunInfo(run_id=UUID('f88fdbcd-c1f6-4f13-b575-810b80ecbaaf'))]  from langchain import PromptTemplate, LLMChaintemplate = """{question}Let's think step by step. """prompt = PromptTemplate(template=template, input_variables=["question"])llm_chain = LLMChain(prompt=prompt, llm=llm)question = "Who was the US president in the year the first Pokemon game was released?"print(llm_chain.run(question)) from langchain import PromptTemplate, LLMChaintemplate = """{question}Let's think step by step. """prompt = PromptTemplate(template=template, input_variables=["question"])llm_chain = LLMChain(prompt=prompt, llm=llm)question = "Who was the US president in the year the first Pokemon game was released?"print(llm_chain.run(question))      Who was the US president in the year the first Pokemon game was released?        Let's think step by step. 1996 was the year the first Pokemon game was released.        \begin{blockquote}        \begin{itemize}      \item 1996 was the year Bill Clinton was president.      \item 1996 was the year the first Pokemon game was released.      \item 1996 was the year the first Pokemon game was released.        \end{itemize}    \end{blockquote}        I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.         Who was the US president in the year the first Pokemon game was released?        Let's think step by step. 1996 was the year the first Pokemon game was released.        \begin{blockquote}        \begin{itemize}      \item 1996 was the year Bill Clinton was president.      \item 1996 was the year the first Pokemon game was released.      \item 1996 was the year the first Pokemon game was released.        \end{itemize}    \end{blockquote}        I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.         Who was the US president in the year the first Pokemon game was released?        Let's think step by step. 1996 was the year the first Pokemon game was released.        \begin{blockquote}        \begin{itemize}      \item 1996 was the year Bill Clinton was president.      \item 1996 was the year the first Pokemon game was released.      \item 1996 was the year the first Pokemon game was released.        \end{itemize}    \end{blockquote}        I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.        Comment: @JoeZ. I'm not sure if this is a valid question, but I'm sure it's a fun one.      Previous C Transformers Next Databricks Single callMultiple calls:Integrate the model in an LLMChain Single callMultiple calls:Integrate the model in an LLMChain CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) AI21 (/docs/integrations/llms/ai21) Aleph Alpha (/docs/integrations/llms/aleph_alpha) Amazon API Gateway (/docs/integrations/llms/amazon_api_gateway) Anyscale (/docs/integrations/llms/anyscale) Azure ML (/docs/integrations/llms/azure_ml) Azure OpenAI (/docs/integrations/llms/azure_openai) Banana (/docs/integrations/llms/banana) Baseten (/docs/integrations/llms/baseten) Beam (/docs/integrations/llms/beam) Bedrock (/docs/integrations/llms/bedrock) Bittensor (/docs/integrations/llms/bittensor) CerebriumAI (/docs/integrations/llms/cerebriumai) ChatGLM (/docs/integrations/llms/chatglm) Clarifai (/docs/integrations/llms/clarifai) Cohere (/docs/integrations/llms/cohere) C Transformers (/docs/integrations/llms/ctransformers) CTranslate2 (/docs/integrations/llms/ctranslate2) Databricks (/docs/integrations/llms/databricks) DeepInfra (/docs/integrations/llms/deepinfra) DeepSparse (/docs/integrations/llms/deepsparse) Eden AI (/docs/integrations/llms/edenai) Fireworks (/docs/integrations/llms/fireworks) ForefrontAI (/docs/integrations/llms/forefrontai) Google Vertex AI PaLM (/docs/integrations/llms/google_vertex_ai_palm) GooseAI (/docs/integrations/llms/gooseai) GPT4All (/docs/integrations/llms/gpt4all) Hugging Face Hub (/docs/integrations/llms/huggingface_hub) Hugging Face Local Pipelines (/docs/integrations/llms/huggingface_pipelines) Huggingface TextGen Inference (/docs/integrations/llms/huggingface_textgen_inference) JSONFormer (/docs/integrations/llms/jsonformer_experimental) KoboldAI API (/docs/integrations/llms/koboldai) Llama.cpp (/docs/integrations/llms/llamacpp) LLM Caching integrations (/docs/integrations/llms/llm_caching) Manifest (/docs/integrations/llms/manifest) Minimax (/docs/integrations/llms/minimax) Modal (/docs/integrations/llms/modal) MosaicML (/docs/integrations/llms/mosaicml) NLP Cloud (/docs/integrations/llms/nlpcloud) OctoAI (/docs/integrations/llms/octoai) Ollama (/docs/integrations/llms/ollama) OpaquePrompts (/docs/integrations/llms/opaqueprompts) OpenAI (/docs/integrations/llms/openai) OpenLLM (/docs/integrations/llms/openllm) OpenLM (/docs/integrations/llms/openlm) Petals (/docs/integrations/llms/petals) PipelineAI (/docs/integrations/llms/pipelineai) Predibase (/docs/integrations/llms/predibase) Prediction Guard (/docs/integrations/llms/predictionguard) PromptLayer OpenAI (/docs/integrations/llms/promptlayer_openai) RELLM (/docs/integrations/llms/rellm_experimental) Replicate (/docs/integrations/llms/replicate) Runhouse (/docs/integrations/llms/runhouse) SageMakerEndpoint (/docs/integrations/llms/sagemaker) StochasticAI (/docs/integrations/llms/stochasticai) Nebula (Symbl.ai) (/docs/integrations/llms/symblai_nebula) TextGen (/docs/integrations/llms/textgen) Titan Takeoff (/docs/integrations/llms/titan_takeoff) Tongyi Qwen (/docs/integrations/llms/tongyi) vLLM (/docs/integrations/llms/vllm) Writer (/docs/integrations/llms/writer) Xorbits Inference (Xinference) (/docs/integrations/llms/xinference) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) LLMs (/docs/integrations/llms/) project's repository (https://opennmt.net/CTranslate2/guides/transformers.html) quickstart guide (https://opennmt.net/CTranslate2/quickstart.html) CTranslate2 (https://api.python.langchain.com/en/latest/llms/langchain.llms.ctranslate2.CTranslate2.html) ‚Äã (#single-call) ‚Äã (#multiple-calls) ‚Äã (#integrate-the-model-in-an-llmchain) PreviousC Transformers (/docs/integrations/llms/ctransformers) NextDatabricks (/docs/integrations/llms/databricks) Single call (#single-call) Multiple calls: (#multiple-calls) Integrate the model in an LLMChain (#integrate-the-model-in-an-llmchain) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)