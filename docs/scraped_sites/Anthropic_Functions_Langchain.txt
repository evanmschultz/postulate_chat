This notebook shows how to use an experimental wrapper around Anthropic that gives it the same API as OpenAI Functions. You can initialize this wrapper the same way you'd initialize ChatAnthropic You can now pass in functions in a similar way You can now use this for extraction. You can now use this for tagging IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Callbacks Chat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAI Anthropic Anthropic Functions Anyscale Azure AzureML Chat Online Endpoint Bedrock Chat ERNIE-Bot Chat Google Cloud Platform Vertex AI PaLM JinaChat Konko üöÖ LiteLLM Llama API Ollama OpenAI PromptLayer ChatOpenAI Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations Chat models Anthropic Functions HumanMessage create_extraction_chain create_tagging_chain Initialize Model Passing in functions Using for extraction Using for tagging Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsChat modelsAnthropic FunctionsOn this pageAnthropic FunctionsThis notebook shows how to use an experimental wrapper around Anthropic that gives it the same API as OpenAI Functions.from langchain_experimental.llms.anthropic_functions import AnthropicFunctions    /Users/harrisonchase/.pyenv/versions/3.9.1/envs/langchain/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.      warnings.warn(Initialize Model‚ÄãYou can initialize this wrapper the same way you'd initialize ChatAnthropicmodel = AnthropicFunctions(model='claude-2')Passing in functions‚ÄãYou can now pass in functions in a similar wayfunctions=[    {      "name": "get_current_weather",      "description": "Get the current weather in a given location",      "parameters": {        "type": "object",        "properties": {          "location": {            "type": "string",            "description": "The city and state, e.g. San Francisco, CA"          },          "unit": {            "type": "string",            "enum": ["celsius", "fahrenheit"]          }        },        "required": ["location"]      }    }  ]from langchain.schema import HumanMessageAPI Reference:HumanMessageresponse = model.predict_messages(    [HumanMessage(content="whats the weater in boston?")],     functions=functions)response    AIMessage(content=' ', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{"location": "Boston, MA", "unit": "fahrenheit"}'}}, example=False)Using for extraction‚ÄãYou can now use this for extraction.from langchain.chains import create_extraction_chainschema = {    "properties": {        "name": {"type": "string"},        "height": {"type": "integer"},        "hair_color": {"type": "string"},    },    "required": ["name", "height"],}inp = """Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.        """API Reference:create_extraction_chainchain = create_extraction_chain(schema, model)chain.run(inp)    [{'name': 'Alex', 'height': '5', 'hair_color': 'blonde'},     {'name': 'Claudia', 'height': '6', 'hair_color': 'brunette'}]Using for tagging‚ÄãYou can now use this for taggingfrom langchain.chains import create_tagging_chainAPI Reference:create_tagging_chainschema = {    "properties": {        "sentiment": {"type": "string"},        "aggressiveness": {"type": "integer"},        "language": {"type": "string"},    }}chain = create_tagging_chain(schema, model)chain.run("this is really cool")    {'sentiment': 'positive', 'aggressiveness': '0', 'language': 'english'}PreviousAnthropicNextAnyscaleInitialize ModelPassing in functionsUsing for extractionUsing for taggingCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsChat modelsAnthropic FunctionsOn this pageAnthropic FunctionsThis notebook shows how to use an experimental wrapper around Anthropic that gives it the same API as OpenAI Functions.from langchain_experimental.llms.anthropic_functions import AnthropicFunctions    /Users/harrisonchase/.pyenv/versions/3.9.1/envs/langchain/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.      warnings.warn(Initialize Model‚ÄãYou can initialize this wrapper the same way you'd initialize ChatAnthropicmodel = AnthropicFunctions(model='claude-2')Passing in functions‚ÄãYou can now pass in functions in a similar wayfunctions=[    {      "name": "get_current_weather",      "description": "Get the current weather in a given location",      "parameters": {        "type": "object",        "properties": {          "location": {            "type": "string",            "description": "The city and state, e.g. San Francisco, CA"          },          "unit": {            "type": "string",            "enum": ["celsius", "fahrenheit"]          }        },        "required": ["location"]      }    }  ]from langchain.schema import HumanMessageAPI Reference:HumanMessageresponse = model.predict_messages(    [HumanMessage(content="whats the weater in boston?")],     functions=functions)response    AIMessage(content=' ', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{"location": "Boston, MA", "unit": "fahrenheit"}'}}, example=False)Using for extraction‚ÄãYou can now use this for extraction.from langchain.chains import create_extraction_chainschema = {    "properties": {        "name": {"type": "string"},        "height": {"type": "integer"},        "hair_color": {"type": "string"},    },    "required": ["name", "height"],}inp = """Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.        """API Reference:create_extraction_chainchain = create_extraction_chain(schema, model)chain.run(inp)    [{'name': 'Alex', 'height': '5', 'hair_color': 'blonde'},     {'name': 'Claudia', 'height': '6', 'hair_color': 'brunette'}]Using for tagging‚ÄãYou can now use this for taggingfrom langchain.chains import create_tagging_chainAPI Reference:create_tagging_chainschema = {    "properties": {        "sentiment": {"type": "string"},        "aggressiveness": {"type": "integer"},        "language": {"type": "string"},    }}chain = create_tagging_chain(schema, model)chain.run("this is really cool")    {'sentiment': 'positive', 'aggressiveness': '0', 'language': 'english'}PreviousAnthropicNextAnyscaleInitialize ModelPassing in functionsUsing for extractionUsing for tagging IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsChat modelsAnthropic FunctionsOn this pageAnthropic FunctionsThis notebook shows how to use an experimental wrapper around Anthropic that gives it the same API as OpenAI Functions.from langchain_experimental.llms.anthropic_functions import AnthropicFunctions    /Users/harrisonchase/.pyenv/versions/3.9.1/envs/langchain/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.      warnings.warn(Initialize Model‚ÄãYou can initialize this wrapper the same way you'd initialize ChatAnthropicmodel = AnthropicFunctions(model='claude-2')Passing in functions‚ÄãYou can now pass in functions in a similar wayfunctions=[    {      "name": "get_current_weather",      "description": "Get the current weather in a given location",      "parameters": {        "type": "object",        "properties": {          "location": {            "type": "string",            "description": "The city and state, e.g. San Francisco, CA"          },          "unit": {            "type": "string",            "enum": ["celsius", "fahrenheit"]          }        },        "required": ["location"]      }    }  ]from langchain.schema import HumanMessageAPI Reference:HumanMessageresponse = model.predict_messages(    [HumanMessage(content="whats the weater in boston?")],     functions=functions)response    AIMessage(content=' ', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{"location": "Boston, MA", "unit": "fahrenheit"}'}}, example=False)Using for extraction‚ÄãYou can now use this for extraction.from langchain.chains import create_extraction_chainschema = {    "properties": {        "name": {"type": "string"},        "height": {"type": "integer"},        "hair_color": {"type": "string"},    },    "required": ["name", "height"],}inp = """Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.        """API Reference:create_extraction_chainchain = create_extraction_chain(schema, model)chain.run(inp)    [{'name': 'Alex', 'height': '5', 'hair_color': 'blonde'},     {'name': 'Claudia', 'height': '6', 'hair_color': 'brunette'}]Using for tagging‚ÄãYou can now use this for taggingfrom langchain.chains import create_tagging_chainAPI Reference:create_tagging_chainschema = {    "properties": {        "sentiment": {"type": "string"},        "aggressiveness": {"type": "integer"},        "language": {"type": "string"},    }}chain = create_tagging_chain(schema, model)chain.run("this is really cool")    {'sentiment': 'positive', 'aggressiveness': '0', 'language': 'english'}PreviousAnthropicNextAnyscaleInitialize ModelPassing in functionsUsing for extractionUsing for tagging IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsChat modelsAnthropic FunctionsOn this pageAnthropic FunctionsThis notebook shows how to use an experimental wrapper around Anthropic that gives it the same API as OpenAI Functions.from langchain_experimental.llms.anthropic_functions import AnthropicFunctions    /Users/harrisonchase/.pyenv/versions/3.9.1/envs/langchain/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.      warnings.warn(Initialize Model‚ÄãYou can initialize this wrapper the same way you'd initialize ChatAnthropicmodel = AnthropicFunctions(model='claude-2')Passing in functions‚ÄãYou can now pass in functions in a similar wayfunctions=[    {      "name": "get_current_weather",      "description": "Get the current weather in a given location",      "parameters": {        "type": "object",        "properties": {          "location": {            "type": "string",            "description": "The city and state, e.g. San Francisco, CA"          },          "unit": {            "type": "string",            "enum": ["celsius", "fahrenheit"]          }        },        "required": ["location"]      }    }  ]from langchain.schema import HumanMessageAPI Reference:HumanMessageresponse = model.predict_messages(    [HumanMessage(content="whats the weater in boston?")],     functions=functions)response    AIMessage(content=' ', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{"location": "Boston, MA", "unit": "fahrenheit"}'}}, example=False)Using for extraction‚ÄãYou can now use this for extraction.from langchain.chains import create_extraction_chainschema = {    "properties": {        "name": {"type": "string"},        "height": {"type": "integer"},        "hair_color": {"type": "string"},    },    "required": ["name", "height"],}inp = """Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.        """API Reference:create_extraction_chainchain = create_extraction_chain(schema, model)chain.run(inp)    [{'name': 'Alex', 'height': '5', 'hair_color': 'blonde'},     {'name': 'Claudia', 'height': '6', 'hair_color': 'brunette'}]Using for tagging‚ÄãYou can now use this for taggingfrom langchain.chains import create_tagging_chainAPI Reference:create_tagging_chainschema = {    "properties": {        "sentiment": {"type": "string"},        "aggressiveness": {"type": "integer"},        "language": {"type": "string"},    }}chain = create_tagging_chain(schema, model)chain.run("this is really cool")    {'sentiment': 'positive', 'aggressiveness': '0', 'language': 'english'}PreviousAnthropicNextAnyscaleInitialize ModelPassing in functionsUsing for extractionUsing for tagging IntegrationsChat modelsAnthropic FunctionsOn this pageAnthropic FunctionsThis notebook shows how to use an experimental wrapper around Anthropic that gives it the same API as OpenAI Functions.from langchain_experimental.llms.anthropic_functions import AnthropicFunctions    /Users/harrisonchase/.pyenv/versions/3.9.1/envs/langchain/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.      warnings.warn(Initialize Model‚ÄãYou can initialize this wrapper the same way you'd initialize ChatAnthropicmodel = AnthropicFunctions(model='claude-2')Passing in functions‚ÄãYou can now pass in functions in a similar wayfunctions=[    {      "name": "get_current_weather",      "description": "Get the current weather in a given location",      "parameters": {        "type": "object",        "properties": {          "location": {            "type": "string",            "description": "The city and state, e.g. San Francisco, CA"          },          "unit": {            "type": "string",            "enum": ["celsius", "fahrenheit"]          }        },        "required": ["location"]      }    }  ]from langchain.schema import HumanMessageAPI Reference:HumanMessageresponse = model.predict_messages(    [HumanMessage(content="whats the weater in boston?")],     functions=functions)response    AIMessage(content=' ', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{"location": "Boston, MA", "unit": "fahrenheit"}'}}, example=False)Using for extraction‚ÄãYou can now use this for extraction.from langchain.chains import create_extraction_chainschema = {    "properties": {        "name": {"type": "string"},        "height": {"type": "integer"},        "hair_color": {"type": "string"},    },    "required": ["name", "height"],}inp = """Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.        """API Reference:create_extraction_chainchain = create_extraction_chain(schema, model)chain.run(inp)    [{'name': 'Alex', 'height': '5', 'hair_color': 'blonde'},     {'name': 'Claudia', 'height': '6', 'hair_color': 'brunette'}]Using for tagging‚ÄãYou can now use this for taggingfrom langchain.chains import create_tagging_chainAPI Reference:create_tagging_chainschema = {    "properties": {        "sentiment": {"type": "string"},        "aggressiveness": {"type": "integer"},        "language": {"type": "string"},    }}chain = create_tagging_chain(schema, model)chain.run("this is really cool")    {'sentiment': 'positive', 'aggressiveness': '0', 'language': 'english'}PreviousAnthropicNextAnyscaleInitialize ModelPassing in functionsUsing for extractionUsing for tagging IntegrationsChat modelsAnthropic FunctionsOn this pageAnthropic FunctionsThis notebook shows how to use an experimental wrapper around Anthropic that gives it the same API as OpenAI Functions.from langchain_experimental.llms.anthropic_functions import AnthropicFunctions    /Users/harrisonchase/.pyenv/versions/3.9.1/envs/langchain/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.      warnings.warn(Initialize Model‚ÄãYou can initialize this wrapper the same way you'd initialize ChatAnthropicmodel = AnthropicFunctions(model='claude-2')Passing in functions‚ÄãYou can now pass in functions in a similar wayfunctions=[    {      "name": "get_current_weather",      "description": "Get the current weather in a given location",      "parameters": {        "type": "object",        "properties": {          "location": {            "type": "string",            "description": "The city and state, e.g. San Francisco, CA"          },          "unit": {            "type": "string",            "enum": ["celsius", "fahrenheit"]          }        },        "required": ["location"]      }    }  ]from langchain.schema import HumanMessageAPI Reference:HumanMessageresponse = model.predict_messages(    [HumanMessage(content="whats the weater in boston?")],     functions=functions)response    AIMessage(content=' ', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{"location": "Boston, MA", "unit": "fahrenheit"}'}}, example=False)Using for extraction‚ÄãYou can now use this for extraction.from langchain.chains import create_extraction_chainschema = {    "properties": {        "name": {"type": "string"},        "height": {"type": "integer"},        "hair_color": {"type": "string"},    },    "required": ["name", "height"],}inp = """Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.        """API Reference:create_extraction_chainchain = create_extraction_chain(schema, model)chain.run(inp)    [{'name': 'Alex', 'height': '5', 'hair_color': 'blonde'},     {'name': 'Claudia', 'height': '6', 'hair_color': 'brunette'}]Using for tagging‚ÄãYou can now use this for taggingfrom langchain.chains import create_tagging_chainAPI Reference:create_tagging_chainschema = {    "properties": {        "sentiment": {"type": "string"},        "aggressiveness": {"type": "integer"},        "language": {"type": "string"},    }}chain = create_tagging_chain(schema, model)chain.run("this is really cool")    {'sentiment': 'positive', 'aggressiveness': '0', 'language': 'english'}PreviousAnthropicNextAnyscale IntegrationsChat modelsAnthropic FunctionsOn this pageAnthropic FunctionsThis notebook shows how to use an experimental wrapper around Anthropic that gives it the same API as OpenAI Functions.from langchain_experimental.llms.anthropic_functions import AnthropicFunctions    /Users/harrisonchase/.pyenv/versions/3.9.1/envs/langchain/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.      warnings.warn(Initialize Model‚ÄãYou can initialize this wrapper the same way you'd initialize ChatAnthropicmodel = AnthropicFunctions(model='claude-2')Passing in functions‚ÄãYou can now pass in functions in a similar wayfunctions=[    {      "name": "get_current_weather",      "description": "Get the current weather in a given location",      "parameters": {        "type": "object",        "properties": {          "location": {            "type": "string",            "description": "The city and state, e.g. San Francisco, CA"          },          "unit": {            "type": "string",            "enum": ["celsius", "fahrenheit"]          }        },        "required": ["location"]      }    }  ]from langchain.schema import HumanMessageAPI Reference:HumanMessageresponse = model.predict_messages(    [HumanMessage(content="whats the weater in boston?")],     functions=functions)response    AIMessage(content=' ', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{"location": "Boston, MA", "unit": "fahrenheit"}'}}, example=False)Using for extraction‚ÄãYou can now use this for extraction.from langchain.chains import create_extraction_chainschema = {    "properties": {        "name": {"type": "string"},        "height": {"type": "integer"},        "hair_color": {"type": "string"},    },    "required": ["name", "height"],}inp = """Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.        """API Reference:create_extraction_chainchain = create_extraction_chain(schema, model)chain.run(inp)    [{'name': 'Alex', 'height': '5', 'hair_color': 'blonde'},     {'name': 'Claudia', 'height': '6', 'hair_color': 'brunette'}]Using for tagging‚ÄãYou can now use this for taggingfrom langchain.chains import create_tagging_chainAPI Reference:create_tagging_chainschema = {    "properties": {        "sentiment": {"type": "string"},        "aggressiveness": {"type": "integer"},        "language": {"type": "string"},    }}chain = create_tagging_chain(schema, model)chain.run("this is really cool")    {'sentiment': 'positive', 'aggressiveness': '0', 'language': 'english'}PreviousAnthropicNextAnyscale On this page Anthropic FunctionsThis notebook shows how to use an experimental wrapper around Anthropic that gives it the same API as OpenAI Functions.from langchain_experimental.llms.anthropic_functions import AnthropicFunctions    /Users/harrisonchase/.pyenv/versions/3.9.1/envs/langchain/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.      warnings.warn(Initialize Model‚ÄãYou can initialize this wrapper the same way you'd initialize ChatAnthropicmodel = AnthropicFunctions(model='claude-2')Passing in functions‚ÄãYou can now pass in functions in a similar wayfunctions=[    {      "name": "get_current_weather",      "description": "Get the current weather in a given location",      "parameters": {        "type": "object",        "properties": {          "location": {            "type": "string",            "description": "The city and state, e.g. San Francisco, CA"          },          "unit": {            "type": "string",            "enum": ["celsius", "fahrenheit"]          }        },        "required": ["location"]      }    }  ]from langchain.schema import HumanMessageAPI Reference:HumanMessageresponse = model.predict_messages(    [HumanMessage(content="whats the weater in boston?")],     functions=functions)response    AIMessage(content=' ', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{"location": "Boston, MA", "unit": "fahrenheit"}'}}, example=False)Using for extraction‚ÄãYou can now use this for extraction.from langchain.chains import create_extraction_chainschema = {    "properties": {        "name": {"type": "string"},        "height": {"type": "integer"},        "hair_color": {"type": "string"},    },    "required": ["name", "height"],}inp = """Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.        """API Reference:create_extraction_chainchain = create_extraction_chain(schema, model)chain.run(inp)    [{'name': 'Alex', 'height': '5', 'hair_color': 'blonde'},     {'name': 'Claudia', 'height': '6', 'hair_color': 'brunette'}]Using for tagging‚ÄãYou can now use this for taggingfrom langchain.chains import create_tagging_chainAPI Reference:create_tagging_chainschema = {    "properties": {        "sentiment": {"type": "string"},        "aggressiveness": {"type": "integer"},        "language": {"type": "string"},    }}chain = create_tagging_chain(schema, model)chain.run("this is really cool")    {'sentiment': 'positive', 'aggressiveness': '0', 'language': 'english'} from langchain_experimental.llms.anthropic_functions import AnthropicFunctions from langchain_experimental.llms.anthropic_functions import AnthropicFunctions      /Users/harrisonchase/.pyenv/versions/3.9.1/envs/langchain/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.      warnings.warn(     /Users/harrisonchase/.pyenv/versions/3.9.1/envs/langchain/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.      warnings.warn(     /Users/harrisonchase/.pyenv/versions/3.9.1/envs/langchain/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.      warnings.warn(  model = AnthropicFunctions(model='claude-2') model = AnthropicFunctions(model='claude-2')  functions=[    {      "name": "get_current_weather",      "description": "Get the current weather in a given location",      "parameters": {        "type": "object",        "properties": {          "location": {            "type": "string",            "description": "The city and state, e.g. San Francisco, CA"          },          "unit": {            "type": "string",            "enum": ["celsius", "fahrenheit"]          }        },        "required": ["location"]      }    }  ] functions=[    {      "name": "get_current_weather",      "description": "Get the current weather in a given location",      "parameters": {        "type": "object",        "properties": {          "location": {            "type": "string",            "description": "The city and state, e.g. San Francisco, CA"          },          "unit": {            "type": "string",            "enum": ["celsius", "fahrenheit"]          }        },        "required": ["location"]      }    }  ]  from langchain.schema import HumanMessage from langchain.schema import HumanMessage  API Reference:HumanMessage response = model.predict_messages(    [HumanMessage(content="whats the weater in boston?")],     functions=functions) response = model.predict_messages(    [HumanMessage(content="whats the weater in boston?")],     functions=functions)  response response      AIMessage(content=' ', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{"location": "Boston, MA", "unit": "fahrenheit"}'}}, example=False)     AIMessage(content=' ', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{"location": "Boston, MA", "unit": "fahrenheit"}'}}, example=False)     AIMessage(content=' ', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{"location": "Boston, MA", "unit": "fahrenheit"}'}}, example=False)  from langchain.chains import create_extraction_chainschema = {    "properties": {        "name": {"type": "string"},        "height": {"type": "integer"},        "hair_color": {"type": "string"},    },    "required": ["name", "height"],}inp = """Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.        """ from langchain.chains import create_extraction_chainschema = {    "properties": {        "name": {"type": "string"},        "height": {"type": "integer"},        "hair_color": {"type": "string"},    },    "required": ["name", "height"],}inp = """Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.        """  API Reference:create_extraction_chain chain = create_extraction_chain(schema, model) chain = create_extraction_chain(schema, model)  chain.run(inp) chain.run(inp)      [{'name': 'Alex', 'height': '5', 'hair_color': 'blonde'},     {'name': 'Claudia', 'height': '6', 'hair_color': 'brunette'}]     [{'name': 'Alex', 'height': '5', 'hair_color': 'blonde'},     {'name': 'Claudia', 'height': '6', 'hair_color': 'brunette'}]     [{'name': 'Alex', 'height': '5', 'hair_color': 'blonde'},     {'name': 'Claudia', 'height': '6', 'hair_color': 'brunette'}]  from langchain.chains import create_tagging_chain from langchain.chains import create_tagging_chain  API Reference:create_tagging_chain schema = {    "properties": {        "sentiment": {"type": "string"},        "aggressiveness": {"type": "integer"},        "language": {"type": "string"},    }} schema = {    "properties": {        "sentiment": {"type": "string"},        "aggressiveness": {"type": "integer"},        "language": {"type": "string"},    }}  chain = create_tagging_chain(schema, model) chain = create_tagging_chain(schema, model)  chain.run("this is really cool") chain.run("this is really cool")      {'sentiment': 'positive', 'aggressiveness': '0', 'language': 'english'}     {'sentiment': 'positive', 'aggressiveness': '0', 'language': 'english'}     {'sentiment': 'positive', 'aggressiveness': '0', 'language': 'english'}  Previous Anthropic Next Anyscale Initialize ModelPassing in functionsUsing for extractionUsing for tagging Initialize ModelPassing in functionsUsing for extractionUsing for tagging CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Anthropic (/docs/integrations/chat/anthropic) Anthropic Functions (/docs/integrations/chat/anthropic_functions) Anyscale (/docs/integrations/chat/anyscale) Azure (/docs/integrations/chat/azure_chat_openai) AzureML Chat Online Endpoint (/docs/integrations/chat/azureml_chat_endpoint) Bedrock Chat (/docs/integrations/chat/bedrock) ERNIE-Bot Chat (/docs/integrations/chat/ernie) Google Cloud Platform Vertex AI PaLM (/docs/integrations/chat/google_vertex_ai_palm) JinaChat (/docs/integrations/chat/jinachat) Konko (/docs/integrations/chat/konko) üöÖ LiteLLM (/docs/integrations/chat/litellm) Llama API (/docs/integrations/chat/llama_api) Ollama (/docs/integrations/chat/ollama) OpenAI (/docs/integrations/chat/openai) PromptLayer ChatOpenAI (/docs/integrations/chat/promptlayer_chatopenai) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Chat models (/docs/integrations/chat/) ‚Äã (#initialize-model) ‚Äã (#passing-in-functions) HumanMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.HumanMessage.html) ‚Äã (#using-for-extraction) create_extraction_chain (https://api.python.langchain.com/en/latest/chains/langchain.chains.openai_functions.extraction.create_extraction_chain.html) ‚Äã (#using-for-tagging) create_tagging_chain (https://api.python.langchain.com/en/latest/chains/langchain.chains.openai_functions.tagging.create_tagging_chain.html) PreviousAnthropic (/docs/integrations/chat/anthropic) NextAnyscale (/docs/integrations/chat/anyscale) Initialize Model (#initialize-model) Passing in functions (#passing-in-functions) Using for extraction (#using-for-extraction) Using for tagging (#using-for-tagging) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)