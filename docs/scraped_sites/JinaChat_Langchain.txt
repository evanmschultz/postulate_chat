This notebook covers how to get started with JinaChat chat models. You can make use of templating by using a MessagePromptTemplate. You can build a ChatPromptTemplate from one or more MessagePromptTemplates. You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, which you can convert to a string or Message object, depending on whether you want to use the formatted value as input to an llm or chat model. For convenience, there is a from_template method exposed on the template. If you were to use this template, this is what it would look like: IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Callbacks Chat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAI Anthropic Anthropic Functions Anyscale Azure AzureML Chat Online Endpoint Bedrock Chat ERNIE-Bot Chat Google Cloud Platform Vertex AI PaLM JinaChat Konko üöÖ LiteLLM Llama API Ollama OpenAI PromptLayer ChatOpenAI Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations Chat models JinaChat JinaChat ChatPromptTemplate SystemMessagePromptTemplate AIMessagePromptTemplate HumanMessagePromptTemplate AIMessage HumanMessage SystemMessage Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsChat modelsJinaChatJinaChatThis notebook covers how to get started with JinaChat chat models.from langchain.chat_models import JinaChatfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)from langchain.schema import AIMessage, HumanMessage, SystemMessageAPI Reference:JinaChatChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateAIMessageHumanMessageSystemMessagechat = JinaChat(temperature=0)messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(        content="Translate this sentence from English to French. I love programming."    ),]chat(messages)    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)You can make use of templating by using a MessagePromptTemplate. You can build a ChatPromptTemplate from one or more MessagePromptTemplates. You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, which you can convert to a string or Message object, depending on whether you want to use the formatted value as input to an llm or chat model.For convenience, there is a from_template method exposed on the template. If you were to use this template, this is what it would look like:template = (    "You are a helpful assistant that translates {input_language} to {output_language}.")system_message_prompt = SystemMessagePromptTemplate.from_template(template)human_template = "{text}"human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)chat_prompt = ChatPromptTemplate.from_messages(    [system_message_prompt, human_message_prompt])# get a chat completion from the formatted messageschat(    chat_prompt.format_prompt(        input_language="English", output_language="French", text="I love programming."    ).to_messages())    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)PreviousGoogle Cloud Platform Vertex AI PaLMNextKonkoCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsChat modelsJinaChatJinaChatThis notebook covers how to get started with JinaChat chat models.from langchain.chat_models import JinaChatfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)from langchain.schema import AIMessage, HumanMessage, SystemMessageAPI Reference:JinaChatChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateAIMessageHumanMessageSystemMessagechat = JinaChat(temperature=0)messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(        content="Translate this sentence from English to French. I love programming."    ),]chat(messages)    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)You can make use of templating by using a MessagePromptTemplate. You can build a ChatPromptTemplate from one or more MessagePromptTemplates. You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, which you can convert to a string or Message object, depending on whether you want to use the formatted value as input to an llm or chat model.For convenience, there is a from_template method exposed on the template. If you were to use this template, this is what it would look like:template = (    "You are a helpful assistant that translates {input_language} to {output_language}.")system_message_prompt = SystemMessagePromptTemplate.from_template(template)human_template = "{text}"human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)chat_prompt = ChatPromptTemplate.from_messages(    [system_message_prompt, human_message_prompt])# get a chat completion from the formatted messageschat(    chat_prompt.format_prompt(        input_language="English", output_language="French", text="I love programming."    ).to_messages())    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)PreviousGoogle Cloud Platform Vertex AI PaLMNextKonko IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsChat modelsJinaChatJinaChatThis notebook covers how to get started with JinaChat chat models.from langchain.chat_models import JinaChatfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)from langchain.schema import AIMessage, HumanMessage, SystemMessageAPI Reference:JinaChatChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateAIMessageHumanMessageSystemMessagechat = JinaChat(temperature=0)messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(        content="Translate this sentence from English to French. I love programming."    ),]chat(messages)    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)You can make use of templating by using a MessagePromptTemplate. You can build a ChatPromptTemplate from one or more MessagePromptTemplates. You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, which you can convert to a string or Message object, depending on whether you want to use the formatted value as input to an llm or chat model.For convenience, there is a from_template method exposed on the template. If you were to use this template, this is what it would look like:template = (    "You are a helpful assistant that translates {input_language} to {output_language}.")system_message_prompt = SystemMessagePromptTemplate.from_template(template)human_template = "{text}"human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)chat_prompt = ChatPromptTemplate.from_messages(    [system_message_prompt, human_message_prompt])# get a chat completion from the formatted messageschat(    chat_prompt.format_prompt(        input_language="English", output_language="French", text="I love programming."    ).to_messages())    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)PreviousGoogle Cloud Platform Vertex AI PaLMNextKonko IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsChat modelsJinaChatJinaChatThis notebook covers how to get started with JinaChat chat models.from langchain.chat_models import JinaChatfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)from langchain.schema import AIMessage, HumanMessage, SystemMessageAPI Reference:JinaChatChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateAIMessageHumanMessageSystemMessagechat = JinaChat(temperature=0)messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(        content="Translate this sentence from English to French. I love programming."    ),]chat(messages)    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)You can make use of templating by using a MessagePromptTemplate. You can build a ChatPromptTemplate from one or more MessagePromptTemplates. You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, which you can convert to a string or Message object, depending on whether you want to use the formatted value as input to an llm or chat model.For convenience, there is a from_template method exposed on the template. If you were to use this template, this is what it would look like:template = (    "You are a helpful assistant that translates {input_language} to {output_language}.")system_message_prompt = SystemMessagePromptTemplate.from_template(template)human_template = "{text}"human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)chat_prompt = ChatPromptTemplate.from_messages(    [system_message_prompt, human_message_prompt])# get a chat completion from the formatted messageschat(    chat_prompt.format_prompt(        input_language="English", output_language="French", text="I love programming."    ).to_messages())    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)PreviousGoogle Cloud Platform Vertex AI PaLMNextKonko IntegrationsChat modelsJinaChatJinaChatThis notebook covers how to get started with JinaChat chat models.from langchain.chat_models import JinaChatfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)from langchain.schema import AIMessage, HumanMessage, SystemMessageAPI Reference:JinaChatChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateAIMessageHumanMessageSystemMessagechat = JinaChat(temperature=0)messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(        content="Translate this sentence from English to French. I love programming."    ),]chat(messages)    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)You can make use of templating by using a MessagePromptTemplate. You can build a ChatPromptTemplate from one or more MessagePromptTemplates. You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, which you can convert to a string or Message object, depending on whether you want to use the formatted value as input to an llm or chat model.For convenience, there is a from_template method exposed on the template. If you were to use this template, this is what it would look like:template = (    "You are a helpful assistant that translates {input_language} to {output_language}.")system_message_prompt = SystemMessagePromptTemplate.from_template(template)human_template = "{text}"human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)chat_prompt = ChatPromptTemplate.from_messages(    [system_message_prompt, human_message_prompt])# get a chat completion from the formatted messageschat(    chat_prompt.format_prompt(        input_language="English", output_language="French", text="I love programming."    ).to_messages())    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)PreviousGoogle Cloud Platform Vertex AI PaLMNextKonko IntegrationsChat modelsJinaChatJinaChatThis notebook covers how to get started with JinaChat chat models.from langchain.chat_models import JinaChatfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)from langchain.schema import AIMessage, HumanMessage, SystemMessageAPI Reference:JinaChatChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateAIMessageHumanMessageSystemMessagechat = JinaChat(temperature=0)messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(        content="Translate this sentence from English to French. I love programming."    ),]chat(messages)    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)You can make use of templating by using a MessagePromptTemplate. You can build a ChatPromptTemplate from one or more MessagePromptTemplates. You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, which you can convert to a string or Message object, depending on whether you want to use the formatted value as input to an llm or chat model.For convenience, there is a from_template method exposed on the template. If you were to use this template, this is what it would look like:template = (    "You are a helpful assistant that translates {input_language} to {output_language}.")system_message_prompt = SystemMessagePromptTemplate.from_template(template)human_template = "{text}"human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)chat_prompt = ChatPromptTemplate.from_messages(    [system_message_prompt, human_message_prompt])# get a chat completion from the formatted messageschat(    chat_prompt.format_prompt(        input_language="English", output_language="French", text="I love programming."    ).to_messages())    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)PreviousGoogle Cloud Platform Vertex AI PaLMNextKonko IntegrationsChat modelsJinaChatJinaChatThis notebook covers how to get started with JinaChat chat models.from langchain.chat_models import JinaChatfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)from langchain.schema import AIMessage, HumanMessage, SystemMessageAPI Reference:JinaChatChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateAIMessageHumanMessageSystemMessagechat = JinaChat(temperature=0)messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(        content="Translate this sentence from English to French. I love programming."    ),]chat(messages)    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)You can make use of templating by using a MessagePromptTemplate. You can build a ChatPromptTemplate from one or more MessagePromptTemplates. You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, which you can convert to a string or Message object, depending on whether you want to use the formatted value as input to an llm or chat model.For convenience, there is a from_template method exposed on the template. If you were to use this template, this is what it would look like:template = (    "You are a helpful assistant that translates {input_language} to {output_language}.")system_message_prompt = SystemMessagePromptTemplate.from_template(template)human_template = "{text}"human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)chat_prompt = ChatPromptTemplate.from_messages(    [system_message_prompt, human_message_prompt])# get a chat completion from the formatted messageschat(    chat_prompt.format_prompt(        input_language="English", output_language="French", text="I love programming."    ).to_messages())    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)PreviousGoogle Cloud Platform Vertex AI PaLMNextKonko JinaChatThis notebook covers how to get started with JinaChat chat models.from langchain.chat_models import JinaChatfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)from langchain.schema import AIMessage, HumanMessage, SystemMessageAPI Reference:JinaChatChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateAIMessageHumanMessageSystemMessagechat = JinaChat(temperature=0)messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(        content="Translate this sentence from English to French. I love programming."    ),]chat(messages)    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)You can make use of templating by using a MessagePromptTemplate. You can build a ChatPromptTemplate from one or more MessagePromptTemplates. You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, which you can convert to a string or Message object, depending on whether you want to use the formatted value as input to an llm or chat model.For convenience, there is a from_template method exposed on the template. If you were to use this template, this is what it would look like:template = (    "You are a helpful assistant that translates {input_language} to {output_language}.")system_message_prompt = SystemMessagePromptTemplate.from_template(template)human_template = "{text}"human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)chat_prompt = ChatPromptTemplate.from_messages(    [system_message_prompt, human_message_prompt])# get a chat completion from the formatted messageschat(    chat_prompt.format_prompt(        input_language="English", output_language="French", text="I love programming."    ).to_messages())    AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False) from langchain.chat_models import JinaChatfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)from langchain.schema import AIMessage, HumanMessage, SystemMessage from langchain.chat_models import JinaChatfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)from langchain.schema import AIMessage, HumanMessage, SystemMessage  API Reference:JinaChatChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateAIMessageHumanMessageSystemMessage chat = JinaChat(temperature=0) chat = JinaChat(temperature=0)  messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(        content="Translate this sentence from English to French. I love programming."    ),]chat(messages) messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(        content="Translate this sentence from English to French. I love programming."    ),]chat(messages)      AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)     AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)     AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)  template = (    "You are a helpful assistant that translates {input_language} to {output_language}.")system_message_prompt = SystemMessagePromptTemplate.from_template(template)human_template = "{text}"human_message_prompt = HumanMessagePromptTemplate.from_template(human_template) template = (    "You are a helpful assistant that translates {input_language} to {output_language}.")system_message_prompt = SystemMessagePromptTemplate.from_template(template)human_template = "{text}"human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)  chat_prompt = ChatPromptTemplate.from_messages(    [system_message_prompt, human_message_prompt])# get a chat completion from the formatted messageschat(    chat_prompt.format_prompt(        input_language="English", output_language="French", text="I love programming."    ).to_messages()) chat_prompt = ChatPromptTemplate.from_messages(    [system_message_prompt, human_message_prompt])# get a chat completion from the formatted messageschat(    chat_prompt.format_prompt(        input_language="English", output_language="French", text="I love programming."    ).to_messages())      AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)     AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)     AIMessage(content="J'aime programmer.", additional_kwargs={}, example=False)  Previous Google Cloud Platform Vertex AI PaLM Next Konko CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Anthropic (/docs/integrations/chat/anthropic) Anthropic Functions (/docs/integrations/chat/anthropic_functions) Anyscale (/docs/integrations/chat/anyscale) Azure (/docs/integrations/chat/azure_chat_openai) AzureML Chat Online Endpoint (/docs/integrations/chat/azureml_chat_endpoint) Bedrock Chat (/docs/integrations/chat/bedrock) ERNIE-Bot Chat (/docs/integrations/chat/ernie) Google Cloud Platform Vertex AI PaLM (/docs/integrations/chat/google_vertex_ai_palm) JinaChat (/docs/integrations/chat/jinachat) Konko (/docs/integrations/chat/konko) üöÖ LiteLLM (/docs/integrations/chat/litellm) Llama API (/docs/integrations/chat/llama_api) Ollama (/docs/integrations/chat/ollama) OpenAI (/docs/integrations/chat/openai) PromptLayer ChatOpenAI (/docs/integrations/chat/promptlayer_chatopenai) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Chat models (/docs/integrations/chat/) JinaChat (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.jinachat.JinaChat.html) ChatPromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.chat.ChatPromptTemplate.html) SystemMessagePromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.chat.SystemMessagePromptTemplate.html) AIMessagePromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.chat.AIMessagePromptTemplate.html) HumanMessagePromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.chat.HumanMessagePromptTemplate.html) AIMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.AIMessage.html) HumanMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.HumanMessage.html) SystemMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.SystemMessage.html) PreviousGoogle Cloud Platform Vertex AI PaLM (/docs/integrations/chat/google_vertex_ai_palm) NextKonko (/docs/integrations/chat/konko) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)