There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers ðŸ¦¾ Specifically, gradio-tools is a Python library for converting Gradio apps into tools that can be leveraged by a large language model (LLM)-based agent to complete its task. For example, an LLM could use a Gradio tool to transcribe a voice recording it finds online and then summarize it for you. Or it could use a different Gradio tool to apply OCR to a document on your Google Drive and then answer questions about it. It's very easy to create you own tool if you want to use a space that's not one of the pre-built tools. Please see this section of the gradio-tools documentation for information on how to do that. All contributions are welcome! IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language ActionsVector storesGrouped by provider Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits ToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language Actions Alpha Vantage Apify ArXiv AWS Lambda Shell (bash) Bing Search Brave Search ChatGPT Plugins Dall-E Image Generator DataForSeo DuckDuckGo Search Eden AI File System Golden Query Google Drive Google Places Google Search Google Serper Gradio GraphQL HuggingFace Hub Tools Human as a tool IFTTT WebHooks Lemon Agent Metaphor Search Nuclia Understanding OpenWeatherMap PubMed Requests SceneXplain Search Tools SearxNG Search SerpAPI Twilio Wikipedia Wolfram Alpha Yahoo Finance News YouTube Zapier Natural Language Actions Vector stores Grouped by provider  Integrations Tools Gradio initialize_agent OpenAI ConversationBufferMemory Using a tool Using within an agent Discord Twitter Python JS/TS Homepage Blog Skip to main contentðŸ¦œï¸ðŸ”— LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language ActionsVector storesGrouped by providerIntegrationsToolsGradioOn this pageGradioThere are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers ðŸ¦¾Specifically, gradio-tools is a Python library for converting Gradio apps into tools that can be leveraged by a large language model (LLM)-based agent to complete its task. For example, an LLM could use a Gradio tool to transcribe a voice recording it finds online and then summarize it for you. Or it could use a different Gradio tool to apply OCR to a document on your Google Drive and then answer questions about it.It's very easy to create you own tool if you want to use a space that's not one of the pre-built tools. Please see this section of the gradio-tools documentation for information on how to do that. All contributions are welcome!# !pip install gradio_toolsUsing a toolâ€‹from gradio_tools.tools import StableDiffusionToollocal_file_path = StableDiffusionTool().langchain.run(    "Please create a photo of a dog riding a skateboard")local_file_path    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”        Job Status: Status.STARTING eta: None    '/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/b61c1dd9-47e2-46f1-a47c-20d27640993d/tmp4ap48vnm.jpg'from PIL import Imageim = Image.open(local_file_path)display(im)Using within an agentâ€‹from langchain.agents import initialize_agentfrom langchain.llms import OpenAIfrom gradio_tools.tools import (    StableDiffusionTool,    ImageCaptioningTool,    StableDiffusionPromptGeneratorTool,    TextToVideoTool,)from langchain.memory import ConversationBufferMemoryllm = OpenAI(temperature=0)memory = ConversationBufferMemory(memory_key="chat_history")tools = [    StableDiffusionTool().langchain,    ImageCaptioningTool().langchain,    StableDiffusionPromptGeneratorTool().langchain,    TextToVideoTool().langchain,]agent = initialize_agent(    tools, llm, memory=memory, agent="conversational-react-description", verbose=True)output = agent.run(    input=(        "Please create a photo of a dog riding a skateboard "        "but improve my prompt prior to using an image generator."        "Please caption the generated image and create a video for it using the improved prompt."    ))API Reference:initialize_agentOpenAIConversationBufferMemory    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”    Loaded as API: https://taesiri-blip-2.hf.space âœ”    Loaded as API: https://microsoft-promptist.hf.space âœ”    Loaded as API: https://damo-vilab-modelscope-text-to-video-synthesis.hf.space âœ”            > Entering new AgentExecutor chain...        Thought: Do I need to use a tool? Yes    Action: StableDiffusionPromptGenerator    Action Input: A dog riding a skateboard    Job Status: Status.STARTING eta: None        Observation: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Thought: Do I need to use a tool? Yes    Action: StableDiffusion    Action Input: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Job Status: Status.STARTING eta: None        Job Status: Status.PROCESSING eta: None        Observation: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Thought: Do I need to use a tool? Yes    Action: ImageCaptioner    Action Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Job Status: Status.STARTING eta: None        Observation: a painting of a dog sitting on a skateboard    Thought: Do I need to use a tool? Yes    Action: TextToVideo    Action Input: a painting of a dog sitting on a skateboard    Job Status: Status.STARTING eta: None    Due to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 73.89824726581574    Due to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 42.49370198879602        Job Status: Status.IN_QUEUE eta: 21.314297944849187        Observation: /var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4    Thought: Do I need to use a tool? No    AI: Here is a video of a painting of a dog sitting on a skateboard.        > Finished chain.PreviousGoogle SerperNextGraphQLUsing a toolUsing within an agentCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc. Skip to main content ðŸ¦œï¸ðŸ”— LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ðŸ¦œï¸ðŸ”— LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language ActionsVector storesGrouped by providerIntegrationsToolsGradioOn this pageGradioThere are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers ðŸ¦¾Specifically, gradio-tools is a Python library for converting Gradio apps into tools that can be leveraged by a large language model (LLM)-based agent to complete its task. For example, an LLM could use a Gradio tool to transcribe a voice recording it finds online and then summarize it for you. Or it could use a different Gradio tool to apply OCR to a document on your Google Drive and then answer questions about it.It's very easy to create you own tool if you want to use a space that's not one of the pre-built tools. Please see this section of the gradio-tools documentation for information on how to do that. All contributions are welcome!# !pip install gradio_toolsUsing a toolâ€‹from gradio_tools.tools import StableDiffusionToollocal_file_path = StableDiffusionTool().langchain.run(    "Please create a photo of a dog riding a skateboard")local_file_path    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”        Job Status: Status.STARTING eta: None    '/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/b61c1dd9-47e2-46f1-a47c-20d27640993d/tmp4ap48vnm.jpg'from PIL import Imageim = Image.open(local_file_path)display(im)Using within an agentâ€‹from langchain.agents import initialize_agentfrom langchain.llms import OpenAIfrom gradio_tools.tools import (    StableDiffusionTool,    ImageCaptioningTool,    StableDiffusionPromptGeneratorTool,    TextToVideoTool,)from langchain.memory import ConversationBufferMemoryllm = OpenAI(temperature=0)memory = ConversationBufferMemory(memory_key="chat_history")tools = [    StableDiffusionTool().langchain,    ImageCaptioningTool().langchain,    StableDiffusionPromptGeneratorTool().langchain,    TextToVideoTool().langchain,]agent = initialize_agent(    tools, llm, memory=memory, agent="conversational-react-description", verbose=True)output = agent.run(    input=(        "Please create a photo of a dog riding a skateboard "        "but improve my prompt prior to using an image generator."        "Please caption the generated image and create a video for it using the improved prompt."    ))API Reference:initialize_agentOpenAIConversationBufferMemory    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”    Loaded as API: https://taesiri-blip-2.hf.space âœ”    Loaded as API: https://microsoft-promptist.hf.space âœ”    Loaded as API: https://damo-vilab-modelscope-text-to-video-synthesis.hf.space âœ”            > Entering new AgentExecutor chain...        Thought: Do I need to use a tool? Yes    Action: StableDiffusionPromptGenerator    Action Input: A dog riding a skateboard    Job Status: Status.STARTING eta: None        Observation: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Thought: Do I need to use a tool? Yes    Action: StableDiffusion    Action Input: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Job Status: Status.STARTING eta: None        Job Status: Status.PROCESSING eta: None        Observation: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Thought: Do I need to use a tool? Yes    Action: ImageCaptioner    Action Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Job Status: Status.STARTING eta: None        Observation: a painting of a dog sitting on a skateboard    Thought: Do I need to use a tool? Yes    Action: TextToVideo    Action Input: a painting of a dog sitting on a skateboard    Job Status: Status.STARTING eta: None    Due to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 73.89824726581574    Due to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 42.49370198879602        Job Status: Status.IN_QUEUE eta: 21.314297944849187        Observation: /var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4    Thought: Do I need to use a tool? No    AI: Here is a video of a painting of a dog sitting on a skateboard.        > Finished chain.PreviousGoogle SerperNextGraphQLUsing a toolUsing within an agent IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language ActionsVector storesGrouped by providerIntegrationsToolsGradioOn this pageGradioThere are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers ðŸ¦¾Specifically, gradio-tools is a Python library for converting Gradio apps into tools that can be leveraged by a large language model (LLM)-based agent to complete its task. For example, an LLM could use a Gradio tool to transcribe a voice recording it finds online and then summarize it for you. Or it could use a different Gradio tool to apply OCR to a document on your Google Drive and then answer questions about it.It's very easy to create you own tool if you want to use a space that's not one of the pre-built tools. Please see this section of the gradio-tools documentation for information on how to do that. All contributions are welcome!# !pip install gradio_toolsUsing a toolâ€‹from gradio_tools.tools import StableDiffusionToollocal_file_path = StableDiffusionTool().langchain.run(    "Please create a photo of a dog riding a skateboard")local_file_path    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”        Job Status: Status.STARTING eta: None    '/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/b61c1dd9-47e2-46f1-a47c-20d27640993d/tmp4ap48vnm.jpg'from PIL import Imageim = Image.open(local_file_path)display(im)Using within an agentâ€‹from langchain.agents import initialize_agentfrom langchain.llms import OpenAIfrom gradio_tools.tools import (    StableDiffusionTool,    ImageCaptioningTool,    StableDiffusionPromptGeneratorTool,    TextToVideoTool,)from langchain.memory import ConversationBufferMemoryllm = OpenAI(temperature=0)memory = ConversationBufferMemory(memory_key="chat_history")tools = [    StableDiffusionTool().langchain,    ImageCaptioningTool().langchain,    StableDiffusionPromptGeneratorTool().langchain,    TextToVideoTool().langchain,]agent = initialize_agent(    tools, llm, memory=memory, agent="conversational-react-description", verbose=True)output = agent.run(    input=(        "Please create a photo of a dog riding a skateboard "        "but improve my prompt prior to using an image generator."        "Please caption the generated image and create a video for it using the improved prompt."    ))API Reference:initialize_agentOpenAIConversationBufferMemory    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”    Loaded as API: https://taesiri-blip-2.hf.space âœ”    Loaded as API: https://microsoft-promptist.hf.space âœ”    Loaded as API: https://damo-vilab-modelscope-text-to-video-synthesis.hf.space âœ”            > Entering new AgentExecutor chain...        Thought: Do I need to use a tool? Yes    Action: StableDiffusionPromptGenerator    Action Input: A dog riding a skateboard    Job Status: Status.STARTING eta: None        Observation: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Thought: Do I need to use a tool? Yes    Action: StableDiffusion    Action Input: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Job Status: Status.STARTING eta: None        Job Status: Status.PROCESSING eta: None        Observation: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Thought: Do I need to use a tool? Yes    Action: ImageCaptioner    Action Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Job Status: Status.STARTING eta: None        Observation: a painting of a dog sitting on a skateboard    Thought: Do I need to use a tool? Yes    Action: TextToVideo    Action Input: a painting of a dog sitting on a skateboard    Job Status: Status.STARTING eta: None    Due to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 73.89824726581574    Due to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 42.49370198879602        Job Status: Status.IN_QUEUE eta: 21.314297944849187        Observation: /var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4    Thought: Do I need to use a tool? No    AI: Here is a video of a painting of a dog sitting on a skateboard.        > Finished chain.PreviousGoogle SerperNextGraphQLUsing a toolUsing within an agent IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language ActionsVector storesGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsAlpha VantageApifyArXivAWS LambdaShell (bash)Bing SearchBrave SearchChatGPT PluginsDall-E Image GeneratorDataForSeoDuckDuckGo SearchEden AIFile SystemGolden QueryGoogle DriveGoogle PlacesGoogle SearchGoogle SerperGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksLemon AgentMetaphor SearchNuclia UnderstandingOpenWeatherMapPubMedRequestsSceneXplainSearch ToolsSearxNG SearchSerpAPITwilioWikipediaWolfram AlphaYahoo Finance NewsYouTubeZapier Natural Language ActionsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsToolsGradioOn this pageGradioThere are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers ðŸ¦¾Specifically, gradio-tools is a Python library for converting Gradio apps into tools that can be leveraged by a large language model (LLM)-based agent to complete its task. For example, an LLM could use a Gradio tool to transcribe a voice recording it finds online and then summarize it for you. Or it could use a different Gradio tool to apply OCR to a document on your Google Drive and then answer questions about it.It's very easy to create you own tool if you want to use a space that's not one of the pre-built tools. Please see this section of the gradio-tools documentation for information on how to do that. All contributions are welcome!# !pip install gradio_toolsUsing a toolâ€‹from gradio_tools.tools import StableDiffusionToollocal_file_path = StableDiffusionTool().langchain.run(    "Please create a photo of a dog riding a skateboard")local_file_path    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”        Job Status: Status.STARTING eta: None    '/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/b61c1dd9-47e2-46f1-a47c-20d27640993d/tmp4ap48vnm.jpg'from PIL import Imageim = Image.open(local_file_path)display(im)Using within an agentâ€‹from langchain.agents import initialize_agentfrom langchain.llms import OpenAIfrom gradio_tools.tools import (    StableDiffusionTool,    ImageCaptioningTool,    StableDiffusionPromptGeneratorTool,    TextToVideoTool,)from langchain.memory import ConversationBufferMemoryllm = OpenAI(temperature=0)memory = ConversationBufferMemory(memory_key="chat_history")tools = [    StableDiffusionTool().langchain,    ImageCaptioningTool().langchain,    StableDiffusionPromptGeneratorTool().langchain,    TextToVideoTool().langchain,]agent = initialize_agent(    tools, llm, memory=memory, agent="conversational-react-description", verbose=True)output = agent.run(    input=(        "Please create a photo of a dog riding a skateboard "        "but improve my prompt prior to using an image generator."        "Please caption the generated image and create a video for it using the improved prompt."    ))API Reference:initialize_agentOpenAIConversationBufferMemory    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”    Loaded as API: https://taesiri-blip-2.hf.space âœ”    Loaded as API: https://microsoft-promptist.hf.space âœ”    Loaded as API: https://damo-vilab-modelscope-text-to-video-synthesis.hf.space âœ”            > Entering new AgentExecutor chain...        Thought: Do I need to use a tool? Yes    Action: StableDiffusionPromptGenerator    Action Input: A dog riding a skateboard    Job Status: Status.STARTING eta: None        Observation: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Thought: Do I need to use a tool? Yes    Action: StableDiffusion    Action Input: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Job Status: Status.STARTING eta: None        Job Status: Status.PROCESSING eta: None        Observation: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Thought: Do I need to use a tool? Yes    Action: ImageCaptioner    Action Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Job Status: Status.STARTING eta: None        Observation: a painting of a dog sitting on a skateboard    Thought: Do I need to use a tool? Yes    Action: TextToVideo    Action Input: a painting of a dog sitting on a skateboard    Job Status: Status.STARTING eta: None    Due to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 73.89824726581574    Due to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 42.49370198879602        Job Status: Status.IN_QUEUE eta: 21.314297944849187        Observation: /var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4    Thought: Do I need to use a tool? No    AI: Here is a video of a painting of a dog sitting on a skateboard.        > Finished chain.PreviousGoogle SerperNextGraphQLUsing a toolUsing within an agent IntegrationsToolsGradioOn this pageGradioThere are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers ðŸ¦¾Specifically, gradio-tools is a Python library for converting Gradio apps into tools that can be leveraged by a large language model (LLM)-based agent to complete its task. For example, an LLM could use a Gradio tool to transcribe a voice recording it finds online and then summarize it for you. Or it could use a different Gradio tool to apply OCR to a document on your Google Drive and then answer questions about it.It's very easy to create you own tool if you want to use a space that's not one of the pre-built tools. Please see this section of the gradio-tools documentation for information on how to do that. All contributions are welcome!# !pip install gradio_toolsUsing a toolâ€‹from gradio_tools.tools import StableDiffusionToollocal_file_path = StableDiffusionTool().langchain.run(    "Please create a photo of a dog riding a skateboard")local_file_path    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”        Job Status: Status.STARTING eta: None    '/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/b61c1dd9-47e2-46f1-a47c-20d27640993d/tmp4ap48vnm.jpg'from PIL import Imageim = Image.open(local_file_path)display(im)Using within an agentâ€‹from langchain.agents import initialize_agentfrom langchain.llms import OpenAIfrom gradio_tools.tools import (    StableDiffusionTool,    ImageCaptioningTool,    StableDiffusionPromptGeneratorTool,    TextToVideoTool,)from langchain.memory import ConversationBufferMemoryllm = OpenAI(temperature=0)memory = ConversationBufferMemory(memory_key="chat_history")tools = [    StableDiffusionTool().langchain,    ImageCaptioningTool().langchain,    StableDiffusionPromptGeneratorTool().langchain,    TextToVideoTool().langchain,]agent = initialize_agent(    tools, llm, memory=memory, agent="conversational-react-description", verbose=True)output = agent.run(    input=(        "Please create a photo of a dog riding a skateboard "        "but improve my prompt prior to using an image generator."        "Please caption the generated image and create a video for it using the improved prompt."    ))API Reference:initialize_agentOpenAIConversationBufferMemory    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”    Loaded as API: https://taesiri-blip-2.hf.space âœ”    Loaded as API: https://microsoft-promptist.hf.space âœ”    Loaded as API: https://damo-vilab-modelscope-text-to-video-synthesis.hf.space âœ”            > Entering new AgentExecutor chain...        Thought: Do I need to use a tool? Yes    Action: StableDiffusionPromptGenerator    Action Input: A dog riding a skateboard    Job Status: Status.STARTING eta: None        Observation: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Thought: Do I need to use a tool? Yes    Action: StableDiffusion    Action Input: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Job Status: Status.STARTING eta: None        Job Status: Status.PROCESSING eta: None        Observation: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Thought: Do I need to use a tool? Yes    Action: ImageCaptioner    Action Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Job Status: Status.STARTING eta: None        Observation: a painting of a dog sitting on a skateboard    Thought: Do I need to use a tool? Yes    Action: TextToVideo    Action Input: a painting of a dog sitting on a skateboard    Job Status: Status.STARTING eta: None    Due to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 73.89824726581574    Due to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 42.49370198879602        Job Status: Status.IN_QUEUE eta: 21.314297944849187        Observation: /var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4    Thought: Do I need to use a tool? No    AI: Here is a video of a painting of a dog sitting on a skateboard.        > Finished chain.PreviousGoogle SerperNextGraphQLUsing a toolUsing within an agent IntegrationsToolsGradioOn this pageGradioThere are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers ðŸ¦¾Specifically, gradio-tools is a Python library for converting Gradio apps into tools that can be leveraged by a large language model (LLM)-based agent to complete its task. For example, an LLM could use a Gradio tool to transcribe a voice recording it finds online and then summarize it for you. Or it could use a different Gradio tool to apply OCR to a document on your Google Drive and then answer questions about it.It's very easy to create you own tool if you want to use a space that's not one of the pre-built tools. Please see this section of the gradio-tools documentation for information on how to do that. All contributions are welcome!# !pip install gradio_toolsUsing a toolâ€‹from gradio_tools.tools import StableDiffusionToollocal_file_path = StableDiffusionTool().langchain.run(    "Please create a photo of a dog riding a skateboard")local_file_path    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”        Job Status: Status.STARTING eta: None    '/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/b61c1dd9-47e2-46f1-a47c-20d27640993d/tmp4ap48vnm.jpg'from PIL import Imageim = Image.open(local_file_path)display(im)Using within an agentâ€‹from langchain.agents import initialize_agentfrom langchain.llms import OpenAIfrom gradio_tools.tools import (    StableDiffusionTool,    ImageCaptioningTool,    StableDiffusionPromptGeneratorTool,    TextToVideoTool,)from langchain.memory import ConversationBufferMemoryllm = OpenAI(temperature=0)memory = ConversationBufferMemory(memory_key="chat_history")tools = [    StableDiffusionTool().langchain,    ImageCaptioningTool().langchain,    StableDiffusionPromptGeneratorTool().langchain,    TextToVideoTool().langchain,]agent = initialize_agent(    tools, llm, memory=memory, agent="conversational-react-description", verbose=True)output = agent.run(    input=(        "Please create a photo of a dog riding a skateboard "        "but improve my prompt prior to using an image generator."        "Please caption the generated image and create a video for it using the improved prompt."    ))API Reference:initialize_agentOpenAIConversationBufferMemory    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”    Loaded as API: https://taesiri-blip-2.hf.space âœ”    Loaded as API: https://microsoft-promptist.hf.space âœ”    Loaded as API: https://damo-vilab-modelscope-text-to-video-synthesis.hf.space âœ”            > Entering new AgentExecutor chain...        Thought: Do I need to use a tool? Yes    Action: StableDiffusionPromptGenerator    Action Input: A dog riding a skateboard    Job Status: Status.STARTING eta: None        Observation: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Thought: Do I need to use a tool? Yes    Action: StableDiffusion    Action Input: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Job Status: Status.STARTING eta: None        Job Status: Status.PROCESSING eta: None        Observation: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Thought: Do I need to use a tool? Yes    Action: ImageCaptioner    Action Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Job Status: Status.STARTING eta: None        Observation: a painting of a dog sitting on a skateboard    Thought: Do I need to use a tool? Yes    Action: TextToVideo    Action Input: a painting of a dog sitting on a skateboard    Job Status: Status.STARTING eta: None    Due to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 73.89824726581574    Due to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 42.49370198879602        Job Status: Status.IN_QUEUE eta: 21.314297944849187        Observation: /var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4    Thought: Do I need to use a tool? No    AI: Here is a video of a painting of a dog sitting on a skateboard.        > Finished chain.PreviousGoogle SerperNextGraphQL IntegrationsToolsGradioOn this pageGradioThere are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers ðŸ¦¾Specifically, gradio-tools is a Python library for converting Gradio apps into tools that can be leveraged by a large language model (LLM)-based agent to complete its task. For example, an LLM could use a Gradio tool to transcribe a voice recording it finds online and then summarize it for you. Or it could use a different Gradio tool to apply OCR to a document on your Google Drive and then answer questions about it.It's very easy to create you own tool if you want to use a space that's not one of the pre-built tools. Please see this section of the gradio-tools documentation for information on how to do that. All contributions are welcome!# !pip install gradio_toolsUsing a toolâ€‹from gradio_tools.tools import StableDiffusionToollocal_file_path = StableDiffusionTool().langchain.run(    "Please create a photo of a dog riding a skateboard")local_file_path    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”        Job Status: Status.STARTING eta: None    '/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/b61c1dd9-47e2-46f1-a47c-20d27640993d/tmp4ap48vnm.jpg'from PIL import Imageim = Image.open(local_file_path)display(im)Using within an agentâ€‹from langchain.agents import initialize_agentfrom langchain.llms import OpenAIfrom gradio_tools.tools import (    StableDiffusionTool,    ImageCaptioningTool,    StableDiffusionPromptGeneratorTool,    TextToVideoTool,)from langchain.memory import ConversationBufferMemoryllm = OpenAI(temperature=0)memory = ConversationBufferMemory(memory_key="chat_history")tools = [    StableDiffusionTool().langchain,    ImageCaptioningTool().langchain,    StableDiffusionPromptGeneratorTool().langchain,    TextToVideoTool().langchain,]agent = initialize_agent(    tools, llm, memory=memory, agent="conversational-react-description", verbose=True)output = agent.run(    input=(        "Please create a photo of a dog riding a skateboard "        "but improve my prompt prior to using an image generator."        "Please caption the generated image and create a video for it using the improved prompt."    ))API Reference:initialize_agentOpenAIConversationBufferMemory    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”    Loaded as API: https://taesiri-blip-2.hf.space âœ”    Loaded as API: https://microsoft-promptist.hf.space âœ”    Loaded as API: https://damo-vilab-modelscope-text-to-video-synthesis.hf.space âœ”            > Entering new AgentExecutor chain...        Thought: Do I need to use a tool? Yes    Action: StableDiffusionPromptGenerator    Action Input: A dog riding a skateboard    Job Status: Status.STARTING eta: None        Observation: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Thought: Do I need to use a tool? Yes    Action: StableDiffusion    Action Input: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Job Status: Status.STARTING eta: None        Job Status: Status.PROCESSING eta: None        Observation: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Thought: Do I need to use a tool? Yes    Action: ImageCaptioner    Action Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Job Status: Status.STARTING eta: None        Observation: a painting of a dog sitting on a skateboard    Thought: Do I need to use a tool? Yes    Action: TextToVideo    Action Input: a painting of a dog sitting on a skateboard    Job Status: Status.STARTING eta: None    Due to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 73.89824726581574    Due to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 42.49370198879602        Job Status: Status.IN_QUEUE eta: 21.314297944849187        Observation: /var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4    Thought: Do I need to use a tool? No    AI: Here is a video of a painting of a dog sitting on a skateboard.        > Finished chain.PreviousGoogle SerperNextGraphQL On this page GradioThere are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers ðŸ¦¾Specifically, gradio-tools is a Python library for converting Gradio apps into tools that can be leveraged by a large language model (LLM)-based agent to complete its task. For example, an LLM could use a Gradio tool to transcribe a voice recording it finds online and then summarize it for you. Or it could use a different Gradio tool to apply OCR to a document on your Google Drive and then answer questions about it.It's very easy to create you own tool if you want to use a space that's not one of the pre-built tools. Please see this section of the gradio-tools documentation for information on how to do that. All contributions are welcome!# !pip install gradio_toolsUsing a toolâ€‹from gradio_tools.tools import StableDiffusionToollocal_file_path = StableDiffusionTool().langchain.run(    "Please create a photo of a dog riding a skateboard")local_file_path    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”        Job Status: Status.STARTING eta: None    '/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/b61c1dd9-47e2-46f1-a47c-20d27640993d/tmp4ap48vnm.jpg'from PIL import Imageim = Image.open(local_file_path)display(im)Using within an agentâ€‹from langchain.agents import initialize_agentfrom langchain.llms import OpenAIfrom gradio_tools.tools import (    StableDiffusionTool,    ImageCaptioningTool,    StableDiffusionPromptGeneratorTool,    TextToVideoTool,)from langchain.memory import ConversationBufferMemoryllm = OpenAI(temperature=0)memory = ConversationBufferMemory(memory_key="chat_history")tools = [    StableDiffusionTool().langchain,    ImageCaptioningTool().langchain,    StableDiffusionPromptGeneratorTool().langchain,    TextToVideoTool().langchain,]agent = initialize_agent(    tools, llm, memory=memory, agent="conversational-react-description", verbose=True)output = agent.run(    input=(        "Please create a photo of a dog riding a skateboard "        "but improve my prompt prior to using an image generator."        "Please caption the generated image and create a video for it using the improved prompt."    ))API Reference:initialize_agentOpenAIConversationBufferMemory    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”    Loaded as API: https://taesiri-blip-2.hf.space âœ”    Loaded as API: https://microsoft-promptist.hf.space âœ”    Loaded as API: https://damo-vilab-modelscope-text-to-video-synthesis.hf.space âœ”            > Entering new AgentExecutor chain...        Thought: Do I need to use a tool? Yes    Action: StableDiffusionPromptGenerator    Action Input: A dog riding a skateboard    Job Status: Status.STARTING eta: None        Observation: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Thought: Do I need to use a tool? Yes    Action: StableDiffusion    Action Input: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Job Status: Status.STARTING eta: None        Job Status: Status.PROCESSING eta: None        Observation: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Thought: Do I need to use a tool? Yes    Action: ImageCaptioner    Action Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Job Status: Status.STARTING eta: None        Observation: a painting of a dog sitting on a skateboard    Thought: Do I need to use a tool? Yes    Action: TextToVideo    Action Input: a painting of a dog sitting on a skateboard    Job Status: Status.STARTING eta: None    Due to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 73.89824726581574    Due to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 42.49370198879602        Job Status: Status.IN_QUEUE eta: 21.314297944849187        Observation: /var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4    Thought: Do I need to use a tool? No    AI: Here is a video of a painting of a dog sitting on a skateboard.        > Finished chain. # !pip install gradio_tools # !pip install gradio_tools  from gradio_tools.tools import StableDiffusionTool from gradio_tools.tools import StableDiffusionTool  local_file_path = StableDiffusionTool().langchain.run(    "Please create a photo of a dog riding a skateboard")local_file_path local_file_path = StableDiffusionTool().langchain.run(    "Please create a photo of a dog riding a skateboard")local_file_path      Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”        Job Status: Status.STARTING eta: None    '/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/b61c1dd9-47e2-46f1-a47c-20d27640993d/tmp4ap48vnm.jpg'     Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”        Job Status: Status.STARTING eta: None    '/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/b61c1dd9-47e2-46f1-a47c-20d27640993d/tmp4ap48vnm.jpg'     Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”        Job Status: Status.STARTING eta: None    '/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/b61c1dd9-47e2-46f1-a47c-20d27640993d/tmp4ap48vnm.jpg'  from PIL import Image from PIL import Image  im = Image.open(local_file_path) im = Image.open(local_file_path)  display(im) display(im)  from langchain.agents import initialize_agentfrom langchain.llms import OpenAIfrom gradio_tools.tools import (    StableDiffusionTool,    ImageCaptioningTool,    StableDiffusionPromptGeneratorTool,    TextToVideoTool,)from langchain.memory import ConversationBufferMemoryllm = OpenAI(temperature=0)memory = ConversationBufferMemory(memory_key="chat_history")tools = [    StableDiffusionTool().langchain,    ImageCaptioningTool().langchain,    StableDiffusionPromptGeneratorTool().langchain,    TextToVideoTool().langchain,]agent = initialize_agent(    tools, llm, memory=memory, agent="conversational-react-description", verbose=True)output = agent.run(    input=(        "Please create a photo of a dog riding a skateboard "        "but improve my prompt prior to using an image generator."        "Please caption the generated image and create a video for it using the improved prompt."    )) from langchain.agents import initialize_agentfrom langchain.llms import OpenAIfrom gradio_tools.tools import (    StableDiffusionTool,    ImageCaptioningTool,    StableDiffusionPromptGeneratorTool,    TextToVideoTool,)from langchain.memory import ConversationBufferMemoryllm = OpenAI(temperature=0)memory = ConversationBufferMemory(memory_key="chat_history")tools = [    StableDiffusionTool().langchain,    ImageCaptioningTool().langchain,    StableDiffusionPromptGeneratorTool().langchain,    TextToVideoTool().langchain,]agent = initialize_agent(    tools, llm, memory=memory, agent="conversational-react-description", verbose=True)output = agent.run(    input=(        "Please create a photo of a dog riding a skateboard "        "but improve my prompt prior to using an image generator."        "Please caption the generated image and create a video for it using the improved prompt."    ))  API Reference:initialize_agentOpenAIConversationBufferMemory     Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”    Loaded as API: https://taesiri-blip-2.hf.space âœ”    Loaded as API: https://microsoft-promptist.hf.space âœ”    Loaded as API: https://damo-vilab-modelscope-text-to-video-synthesis.hf.space âœ”            > Entering new AgentExecutor chain...        Thought: Do I need to use a tool? Yes    Action: StableDiffusionPromptGenerator    Action Input: A dog riding a skateboard    Job Status: Status.STARTING eta: None        Observation: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Thought: Do I need to use a tool? Yes    Action: StableDiffusion    Action Input: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Job Status: Status.STARTING eta: None        Job Status: Status.PROCESSING eta: None        Observation: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Thought: Do I need to use a tool? Yes    Action: ImageCaptioner    Action Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Job Status: Status.STARTING eta: None        Observation: a painting of a dog sitting on a skateboard    Thought: Do I need to use a tool? Yes    Action: TextToVideo    Action Input: a painting of a dog sitting on a skateboard    Job Status: Status.STARTING eta: None    Due to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 73.89824726581574    Due to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 42.49370198879602        Job Status: Status.IN_QUEUE eta: 21.314297944849187        Observation: /var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4    Thought: Do I need to use a tool? No    AI: Here is a video of a painting of a dog sitting on a skateboard.        > Finished chain.     Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”    Loaded as API: https://taesiri-blip-2.hf.space âœ”    Loaded as API: https://microsoft-promptist.hf.space âœ”    Loaded as API: https://damo-vilab-modelscope-text-to-video-synthesis.hf.space âœ”            > Entering new AgentExecutor chain...        Thought: Do I need to use a tool? Yes    Action: StableDiffusionPromptGenerator    Action Input: A dog riding a skateboard    Job Status: Status.STARTING eta: None        Observation: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Thought: Do I need to use a tool? Yes    Action: StableDiffusion    Action Input: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Job Status: Status.STARTING eta: None        Job Status: Status.PROCESSING eta: None        Observation: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Thought: Do I need to use a tool? Yes    Action: ImageCaptioner    Action Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Job Status: Status.STARTING eta: None        Observation: a painting of a dog sitting on a skateboard    Thought: Do I need to use a tool? Yes    Action: TextToVideo    Action Input: a painting of a dog sitting on a skateboard    Job Status: Status.STARTING eta: None    Due to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 73.89824726581574    Due to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 42.49370198879602        Job Status: Status.IN_QUEUE eta: 21.314297944849187        Observation: /var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4    Thought: Do I need to use a tool? No    AI: Here is a video of a painting of a dog sitting on a skateboard.        > Finished chain.     Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ”    Loaded as API: https://taesiri-blip-2.hf.space âœ”    Loaded as API: https://microsoft-promptist.hf.space âœ”    Loaded as API: https://damo-vilab-modelscope-text-to-video-synthesis.hf.space âœ”            > Entering new AgentExecutor chain...        Thought: Do I need to use a tool? Yes    Action: StableDiffusionPromptGenerator    Action Input: A dog riding a skateboard    Job Status: Status.STARTING eta: None        Observation: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Thought: Do I need to use a tool? Yes    Action: StableDiffusion    Action Input: A dog riding a skateboard, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha    Job Status: Status.STARTING eta: None        Job Status: Status.PROCESSING eta: None        Observation: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Thought: Do I need to use a tool? Yes    Action: ImageCaptioner    Action Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg    Job Status: Status.STARTING eta: None        Observation: a painting of a dog sitting on a skateboard    Thought: Do I need to use a tool? Yes    Action: TextToVideo    Action Input: a painting of a dog sitting on a skateboard    Job Status: Status.STARTING eta: None    Due to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 73.89824726581574    Due to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)        Job Status: Status.IN_QUEUE eta: 42.49370198879602        Job Status: Status.IN_QUEUE eta: 21.314297944849187        Observation: /var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4    Thought: Do I need to use a tool? No    AI: Here is a video of a painting of a dog sitting on a skateboard.        > Finished chain.  Previous Google Serper Next GraphQL Using a toolUsing within an agent Using a toolUsing within an agent CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright Â© 2023 LangChain, Inc. Copyright Â© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ðŸ¦œï¸ðŸ”— LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Alpha Vantage (/docs/integrations/tools/alpha_vantage) Apify (/docs/integrations/tools/apify) ArXiv (/docs/integrations/tools/arxiv) AWS Lambda (/docs/integrations/tools/awslambda) Shell (bash) (/docs/integrations/tools/bash) Bing Search (/docs/integrations/tools/bing_search) Brave Search (/docs/integrations/tools/brave_search) ChatGPT Plugins (/docs/integrations/tools/chatgpt_plugins) Dall-E Image Generator (/docs/integrations/tools/dalle_image_generator) DataForSeo (/docs/integrations/tools/dataforseo) DuckDuckGo Search (/docs/integrations/tools/ddg) Eden AI (/docs/integrations/tools/edenai_tools) File System (/docs/integrations/tools/filesystem) Golden Query (/docs/integrations/tools/golden_query) Google Drive (/docs/integrations/tools/google_drive) Google Places (/docs/integrations/tools/google_places) Google Search (/docs/integrations/tools/google_search) Google Serper (/docs/integrations/tools/google_serper) Gradio (/docs/integrations/tools/gradio_tools) GraphQL (/docs/integrations/tools/graphql) HuggingFace Hub Tools (/docs/integrations/tools/huggingface_tools) Human as a tool (/docs/integrations/tools/human_tools) IFTTT WebHooks (/docs/integrations/tools/ifttt) Lemon Agent (/docs/integrations/tools/lemonai) Metaphor Search (/docs/integrations/tools/metaphor_search) Nuclia Understanding (/docs/integrations/tools/nuclia) OpenWeatherMap (/docs/integrations/tools/openweathermap) PubMed (/docs/integrations/tools/pubmed) Requests (/docs/integrations/tools/requests) SceneXplain (/docs/integrations/tools/sceneXplain) Search Tools (/docs/integrations/tools/search_tools) SearxNG Search (/docs/integrations/tools/searx_search) SerpAPI (/docs/integrations/tools/serpapi) Twilio (/docs/integrations/tools/twilio) Wikipedia (/docs/integrations/tools/wikipedia) Wolfram Alpha (/docs/integrations/tools/wolfram_alpha) Yahoo Finance News (/docs/integrations/tools/yahoo_finance_news) YouTube (/docs/integrations/tools/youtube) Zapier Natural Language Actions (/docs/integrations/tools/zapier) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Tools (/docs/integrations/tools/) â€‹ (#using-a-tool) â€‹ (#using-within-an-agent) initialize_agent (https://api.python.langchain.com/en/latest/agents/langchain.agents.initialize.initialize_agent.html) OpenAI (https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html) ConversationBufferMemory (https://api.python.langchain.com/en/latest/memory/langchain.memory.buffer.ConversationBufferMemory.html) PreviousGoogle Serper (/docs/integrations/tools/google_serper) NextGraphQL (/docs/integrations/tools/graphql) Using a tool (#using-a-tool) Using within an agent (#using-within-an-agent) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)