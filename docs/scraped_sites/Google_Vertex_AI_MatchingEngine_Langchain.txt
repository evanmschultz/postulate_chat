This notebook shows how to use functionality related to the GCP Vertex AI MatchingEngine vector database. Vertex AI Matching Engine provides the industry's leading high-scale low latency vector database. These vector databases are commonly referred to as vector similarity-matching or an approximate nearest neighbor (ANN) service. Note: This module expects an endpoint and deployed index already created as the creation time takes close to one hour. To see how to create an index refer to the section Create Index and deploy it to an Endpoint IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by provider Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZilliz Activeloop Deep Lake Alibaba Cloud OpenSearch AnalyticDB Annoy Atlas AwaDB Azure Cognitive Search BagelDB Cassandra Chroma ClickHouse DashVector Dingo DocArray HnswSearch DocArray InMemorySearch Elasticsearch Epsilla Faiss Hologres LanceDB Marqo Google Vertex AI MatchingEngine Meilisearch Milvus MongoDB Atlas MyScale Neo4j Vector Index NucliaDB OpenSearch Postgres Embedding PGVector Pinecone Qdrant Redis Rockset ScaNN SingleStoreDB scikit-learn sqlite-vss StarRocks Supabase (Postgres) Tair Tencent Cloud VectorDB Tigris Typesense USearch vearch Vectara Weaviate Xata Zep Zilliz Grouped by provider  Integrations Vector stores Google Vertex AI MatchingEngine MatchingEngine Create VectorStore from texts Create Index and deploy it to an EndpointImports, Constants and ConfigsUsing Tensorflow Universal Sentence Encoder as an EmbedderInserting a test embeddingCreating IndexCreating EndpointDeploy Index Imports, Constants and Configs Using Tensorflow Universal Sentence Encoder as an Embedder Inserting a test embedding Creating Index Creating Endpoint Deploy Index Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by providerIntegrationsVector storesGoogle Vertex AI MatchingEngineOn this pageGoogle Vertex AI MatchingEngineThis notebook shows how to use functionality related to the GCP Vertex AI MatchingEngine vector database.Vertex AI Matching Engine provides the industry's leading high-scale low latency vector database. These vector databases are commonly referred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.Note: This module expects an endpoint and deployed index already created as the creation time takes close to one hour. To see how to create an index refer to the section Create Index and deploy it to an EndpointCreate VectorStore from texts‚Äãfrom langchain.vectorstores import MatchingEngineAPI Reference:MatchingEnginetexts = [    "The cat sat on",    "the mat.",    "I like to",    "eat pizza for",    "dinner.",    "The sun sets",    "in the west.",]vector_store = MatchingEngine.from_components(    texts=texts,    project_id="<my_project_id>",    region="<my_region>",    gcs_bucket_uri="<my_gcs_bucket>",    index_id="<my_matching_engine_index_id>",    endpoint_id="<my_matching_engine_endpoint_id>",)vector_store.add_texts(texts=texts)vector_store.similarity_search("lunch", k=2)Create Index and deploy it to an Endpoint‚ÄãImports, Constants and Configs‚Äã# Installing dependencies.pip install tensorflow \            google-cloud-aiplatform \            tensorflow-hub \            tensorflow-textimport osimport jsonfrom google.cloud import aiplatformimport tensorflow_hub as hubimport tensorflow_textPROJECT_ID = "<my_project_id>"REGION = "<my_region>"VPC_NETWORK = "<my_vpc_network_name>"PEERING_RANGE_NAME = "ann-langchain-me-range"  # Name for creating the VPC peering.BUCKET_URI = "gs://<bucket_uri>"# The number of dimensions for the tensorflow universal sentence encoder.# If other embedder is used, the dimensions would probably need to change.DIMENSIONS = 512DISPLAY_NAME = "index-test-name"EMBEDDING_DIR = f"{BUCKET_URI}/banana"DEPLOYED_INDEX_ID = "endpoint-test-name"PROJECT_NUMBER = !gcloud projects list --filter="PROJECT_ID:'{PROJECT_ID}'" --format='value(PROJECT_NUMBER)'PROJECT_NUMBER = PROJECT_NUMBER[0]VPC_NETWORK_FULL = f"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}"# Change this if you need the VPC to be created.CREATE_VPC = False# Set the project id gcloud config set project {PROJECT_ID}# Remove the if condition to run the encapsulated codeif CREATE_VPC:    # Create a VPC network gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}    # Add necessary firewall rules gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9 gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389 gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22    # Reserve IP range gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description="peering range"    # Set up peering with service networking    # Your account must have the "Compute Network Admin" role to run the following. gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}# Creating bucket. gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URIUsing Tensorflow Universal Sentence Encoder as an Embedder‚Äã# Load the Universal Sentence Encoder modulemodule_url = "https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"model = hub.load(module_url)# Generate embeddings for each wordembeddings = model(["banana"])Inserting a test embedding‚Äãinitial_config = {    "id": "banana_id",    "embedding": [float(x) for x in list(embeddings.numpy()[0])],}with open("data.json", "w") as f:    json.dump(initial_config, f)gsutil cp data.json {EMBEDDING_DIR}/file.jsonaiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)Creating Index‚Äãmy_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(    display_name=DISPLAY_NAME,    contents_delta_uri=EMBEDDING_DIR,    dimensions=DIMENSIONS,    approximate_neighbors_count=150,    distance_measure_type="DOT_PRODUCT_DISTANCE",)Creating Endpoint‚Äãmy_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(    display_name=f"{DISPLAY_NAME}-endpoint",    network=VPC_NETWORK_FULL,)Deploy Index‚Äãmy_index_endpoint = my_index_endpoint.deploy_index(    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)my_index_endpoint.deployed_indexesPreviousMarqoNextMeilisearchCreate VectorStore from textsCreate Index and deploy it to an EndpointImports, Constants and ConfigsUsing Tensorflow Universal Sentence Encoder as an EmbedderInserting a test embeddingCreating IndexCreating EndpointDeploy IndexCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by providerIntegrationsVector storesGoogle Vertex AI MatchingEngineOn this pageGoogle Vertex AI MatchingEngineThis notebook shows how to use functionality related to the GCP Vertex AI MatchingEngine vector database.Vertex AI Matching Engine provides the industry's leading high-scale low latency vector database. These vector databases are commonly referred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.Note: This module expects an endpoint and deployed index already created as the creation time takes close to one hour. To see how to create an index refer to the section Create Index and deploy it to an EndpointCreate VectorStore from texts‚Äãfrom langchain.vectorstores import MatchingEngineAPI Reference:MatchingEnginetexts = [    "The cat sat on",    "the mat.",    "I like to",    "eat pizza for",    "dinner.",    "The sun sets",    "in the west.",]vector_store = MatchingEngine.from_components(    texts=texts,    project_id="<my_project_id>",    region="<my_region>",    gcs_bucket_uri="<my_gcs_bucket>",    index_id="<my_matching_engine_index_id>",    endpoint_id="<my_matching_engine_endpoint_id>",)vector_store.add_texts(texts=texts)vector_store.similarity_search("lunch", k=2)Create Index and deploy it to an Endpoint‚ÄãImports, Constants and Configs‚Äã# Installing dependencies.pip install tensorflow \            google-cloud-aiplatform \            tensorflow-hub \            tensorflow-textimport osimport jsonfrom google.cloud import aiplatformimport tensorflow_hub as hubimport tensorflow_textPROJECT_ID = "<my_project_id>"REGION = "<my_region>"VPC_NETWORK = "<my_vpc_network_name>"PEERING_RANGE_NAME = "ann-langchain-me-range"  # Name for creating the VPC peering.BUCKET_URI = "gs://<bucket_uri>"# The number of dimensions for the tensorflow universal sentence encoder.# If other embedder is used, the dimensions would probably need to change.DIMENSIONS = 512DISPLAY_NAME = "index-test-name"EMBEDDING_DIR = f"{BUCKET_URI}/banana"DEPLOYED_INDEX_ID = "endpoint-test-name"PROJECT_NUMBER = !gcloud projects list --filter="PROJECT_ID:'{PROJECT_ID}'" --format='value(PROJECT_NUMBER)'PROJECT_NUMBER = PROJECT_NUMBER[0]VPC_NETWORK_FULL = f"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}"# Change this if you need the VPC to be created.CREATE_VPC = False# Set the project id gcloud config set project {PROJECT_ID}# Remove the if condition to run the encapsulated codeif CREATE_VPC:    # Create a VPC network gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}    # Add necessary firewall rules gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9 gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389 gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22    # Reserve IP range gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description="peering range"    # Set up peering with service networking    # Your account must have the "Compute Network Admin" role to run the following. gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}# Creating bucket. gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URIUsing Tensorflow Universal Sentence Encoder as an Embedder‚Äã# Load the Universal Sentence Encoder modulemodule_url = "https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"model = hub.load(module_url)# Generate embeddings for each wordembeddings = model(["banana"])Inserting a test embedding‚Äãinitial_config = {    "id": "banana_id",    "embedding": [float(x) for x in list(embeddings.numpy()[0])],}with open("data.json", "w") as f:    json.dump(initial_config, f)gsutil cp data.json {EMBEDDING_DIR}/file.jsonaiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)Creating Index‚Äãmy_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(    display_name=DISPLAY_NAME,    contents_delta_uri=EMBEDDING_DIR,    dimensions=DIMENSIONS,    approximate_neighbors_count=150,    distance_measure_type="DOT_PRODUCT_DISTANCE",)Creating Endpoint‚Äãmy_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(    display_name=f"{DISPLAY_NAME}-endpoint",    network=VPC_NETWORK_FULL,)Deploy Index‚Äãmy_index_endpoint = my_index_endpoint.deploy_index(    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)my_index_endpoint.deployed_indexesPreviousMarqoNextMeilisearchCreate VectorStore from textsCreate Index and deploy it to an EndpointImports, Constants and ConfigsUsing Tensorflow Universal Sentence Encoder as an EmbedderInserting a test embeddingCreating IndexCreating EndpointDeploy Index IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by providerIntegrationsVector storesGoogle Vertex AI MatchingEngineOn this pageGoogle Vertex AI MatchingEngineThis notebook shows how to use functionality related to the GCP Vertex AI MatchingEngine vector database.Vertex AI Matching Engine provides the industry's leading high-scale low latency vector database. These vector databases are commonly referred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.Note: This module expects an endpoint and deployed index already created as the creation time takes close to one hour. To see how to create an index refer to the section Create Index and deploy it to an EndpointCreate VectorStore from texts‚Äãfrom langchain.vectorstores import MatchingEngineAPI Reference:MatchingEnginetexts = [    "The cat sat on",    "the mat.",    "I like to",    "eat pizza for",    "dinner.",    "The sun sets",    "in the west.",]vector_store = MatchingEngine.from_components(    texts=texts,    project_id="<my_project_id>",    region="<my_region>",    gcs_bucket_uri="<my_gcs_bucket>",    index_id="<my_matching_engine_index_id>",    endpoint_id="<my_matching_engine_endpoint_id>",)vector_store.add_texts(texts=texts)vector_store.similarity_search("lunch", k=2)Create Index and deploy it to an Endpoint‚ÄãImports, Constants and Configs‚Äã# Installing dependencies.pip install tensorflow \            google-cloud-aiplatform \            tensorflow-hub \            tensorflow-textimport osimport jsonfrom google.cloud import aiplatformimport tensorflow_hub as hubimport tensorflow_textPROJECT_ID = "<my_project_id>"REGION = "<my_region>"VPC_NETWORK = "<my_vpc_network_name>"PEERING_RANGE_NAME = "ann-langchain-me-range"  # Name for creating the VPC peering.BUCKET_URI = "gs://<bucket_uri>"# The number of dimensions for the tensorflow universal sentence encoder.# If other embedder is used, the dimensions would probably need to change.DIMENSIONS = 512DISPLAY_NAME = "index-test-name"EMBEDDING_DIR = f"{BUCKET_URI}/banana"DEPLOYED_INDEX_ID = "endpoint-test-name"PROJECT_NUMBER = !gcloud projects list --filter="PROJECT_ID:'{PROJECT_ID}'" --format='value(PROJECT_NUMBER)'PROJECT_NUMBER = PROJECT_NUMBER[0]VPC_NETWORK_FULL = f"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}"# Change this if you need the VPC to be created.CREATE_VPC = False# Set the project id gcloud config set project {PROJECT_ID}# Remove the if condition to run the encapsulated codeif CREATE_VPC:    # Create a VPC network gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}    # Add necessary firewall rules gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9 gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389 gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22    # Reserve IP range gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description="peering range"    # Set up peering with service networking    # Your account must have the "Compute Network Admin" role to run the following. gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}# Creating bucket. gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URIUsing Tensorflow Universal Sentence Encoder as an Embedder‚Äã# Load the Universal Sentence Encoder modulemodule_url = "https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"model = hub.load(module_url)# Generate embeddings for each wordembeddings = model(["banana"])Inserting a test embedding‚Äãinitial_config = {    "id": "banana_id",    "embedding": [float(x) for x in list(embeddings.numpy()[0])],}with open("data.json", "w") as f:    json.dump(initial_config, f)gsutil cp data.json {EMBEDDING_DIR}/file.jsonaiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)Creating Index‚Äãmy_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(    display_name=DISPLAY_NAME,    contents_delta_uri=EMBEDDING_DIR,    dimensions=DIMENSIONS,    approximate_neighbors_count=150,    distance_measure_type="DOT_PRODUCT_DISTANCE",)Creating Endpoint‚Äãmy_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(    display_name=f"{DISPLAY_NAME}-endpoint",    network=VPC_NETWORK_FULL,)Deploy Index‚Äãmy_index_endpoint = my_index_endpoint.deploy_index(    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)my_index_endpoint.deployed_indexesPreviousMarqoNextMeilisearchCreate VectorStore from textsCreate Index and deploy it to an EndpointImports, Constants and ConfigsUsing Tensorflow Universal Sentence Encoder as an EmbedderInserting a test embeddingCreating IndexCreating EndpointDeploy Index IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsVector storesGoogle Vertex AI MatchingEngineOn this pageGoogle Vertex AI MatchingEngineThis notebook shows how to use functionality related to the GCP Vertex AI MatchingEngine vector database.Vertex AI Matching Engine provides the industry's leading high-scale low latency vector database. These vector databases are commonly referred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.Note: This module expects an endpoint and deployed index already created as the creation time takes close to one hour. To see how to create an index refer to the section Create Index and deploy it to an EndpointCreate VectorStore from texts‚Äãfrom langchain.vectorstores import MatchingEngineAPI Reference:MatchingEnginetexts = [    "The cat sat on",    "the mat.",    "I like to",    "eat pizza for",    "dinner.",    "The sun sets",    "in the west.",]vector_store = MatchingEngine.from_components(    texts=texts,    project_id="<my_project_id>",    region="<my_region>",    gcs_bucket_uri="<my_gcs_bucket>",    index_id="<my_matching_engine_index_id>",    endpoint_id="<my_matching_engine_endpoint_id>",)vector_store.add_texts(texts=texts)vector_store.similarity_search("lunch", k=2)Create Index and deploy it to an Endpoint‚ÄãImports, Constants and Configs‚Äã# Installing dependencies.pip install tensorflow \            google-cloud-aiplatform \            tensorflow-hub \            tensorflow-textimport osimport jsonfrom google.cloud import aiplatformimport tensorflow_hub as hubimport tensorflow_textPROJECT_ID = "<my_project_id>"REGION = "<my_region>"VPC_NETWORK = "<my_vpc_network_name>"PEERING_RANGE_NAME = "ann-langchain-me-range"  # Name for creating the VPC peering.BUCKET_URI = "gs://<bucket_uri>"# The number of dimensions for the tensorflow universal sentence encoder.# If other embedder is used, the dimensions would probably need to change.DIMENSIONS = 512DISPLAY_NAME = "index-test-name"EMBEDDING_DIR = f"{BUCKET_URI}/banana"DEPLOYED_INDEX_ID = "endpoint-test-name"PROJECT_NUMBER = !gcloud projects list --filter="PROJECT_ID:'{PROJECT_ID}'" --format='value(PROJECT_NUMBER)'PROJECT_NUMBER = PROJECT_NUMBER[0]VPC_NETWORK_FULL = f"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}"# Change this if you need the VPC to be created.CREATE_VPC = False# Set the project id gcloud config set project {PROJECT_ID}# Remove the if condition to run the encapsulated codeif CREATE_VPC:    # Create a VPC network gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}    # Add necessary firewall rules gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9 gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389 gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22    # Reserve IP range gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description="peering range"    # Set up peering with service networking    # Your account must have the "Compute Network Admin" role to run the following. gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}# Creating bucket. gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URIUsing Tensorflow Universal Sentence Encoder as an Embedder‚Äã# Load the Universal Sentence Encoder modulemodule_url = "https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"model = hub.load(module_url)# Generate embeddings for each wordembeddings = model(["banana"])Inserting a test embedding‚Äãinitial_config = {    "id": "banana_id",    "embedding": [float(x) for x in list(embeddings.numpy()[0])],}with open("data.json", "w") as f:    json.dump(initial_config, f)gsutil cp data.json {EMBEDDING_DIR}/file.jsonaiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)Creating Index‚Äãmy_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(    display_name=DISPLAY_NAME,    contents_delta_uri=EMBEDDING_DIR,    dimensions=DIMENSIONS,    approximate_neighbors_count=150,    distance_measure_type="DOT_PRODUCT_DISTANCE",)Creating Endpoint‚Äãmy_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(    display_name=f"{DISPLAY_NAME}-endpoint",    network=VPC_NETWORK_FULL,)Deploy Index‚Äãmy_index_endpoint = my_index_endpoint.deploy_index(    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)my_index_endpoint.deployed_indexesPreviousMarqoNextMeilisearchCreate VectorStore from textsCreate Index and deploy it to an EndpointImports, Constants and ConfigsUsing Tensorflow Universal Sentence Encoder as an EmbedderInserting a test embeddingCreating IndexCreating EndpointDeploy Index IntegrationsVector storesGoogle Vertex AI MatchingEngineOn this pageGoogle Vertex AI MatchingEngineThis notebook shows how to use functionality related to the GCP Vertex AI MatchingEngine vector database.Vertex AI Matching Engine provides the industry's leading high-scale low latency vector database. These vector databases are commonly referred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.Note: This module expects an endpoint and deployed index already created as the creation time takes close to one hour. To see how to create an index refer to the section Create Index and deploy it to an EndpointCreate VectorStore from texts‚Äãfrom langchain.vectorstores import MatchingEngineAPI Reference:MatchingEnginetexts = [    "The cat sat on",    "the mat.",    "I like to",    "eat pizza for",    "dinner.",    "The sun sets",    "in the west.",]vector_store = MatchingEngine.from_components(    texts=texts,    project_id="<my_project_id>",    region="<my_region>",    gcs_bucket_uri="<my_gcs_bucket>",    index_id="<my_matching_engine_index_id>",    endpoint_id="<my_matching_engine_endpoint_id>",)vector_store.add_texts(texts=texts)vector_store.similarity_search("lunch", k=2)Create Index and deploy it to an Endpoint‚ÄãImports, Constants and Configs‚Äã# Installing dependencies.pip install tensorflow \            google-cloud-aiplatform \            tensorflow-hub \            tensorflow-textimport osimport jsonfrom google.cloud import aiplatformimport tensorflow_hub as hubimport tensorflow_textPROJECT_ID = "<my_project_id>"REGION = "<my_region>"VPC_NETWORK = "<my_vpc_network_name>"PEERING_RANGE_NAME = "ann-langchain-me-range"  # Name for creating the VPC peering.BUCKET_URI = "gs://<bucket_uri>"# The number of dimensions for the tensorflow universal sentence encoder.# If other embedder is used, the dimensions would probably need to change.DIMENSIONS = 512DISPLAY_NAME = "index-test-name"EMBEDDING_DIR = f"{BUCKET_URI}/banana"DEPLOYED_INDEX_ID = "endpoint-test-name"PROJECT_NUMBER = !gcloud projects list --filter="PROJECT_ID:'{PROJECT_ID}'" --format='value(PROJECT_NUMBER)'PROJECT_NUMBER = PROJECT_NUMBER[0]VPC_NETWORK_FULL = f"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}"# Change this if you need the VPC to be created.CREATE_VPC = False# Set the project id gcloud config set project {PROJECT_ID}# Remove the if condition to run the encapsulated codeif CREATE_VPC:    # Create a VPC network gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}    # Add necessary firewall rules gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9 gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389 gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22    # Reserve IP range gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description="peering range"    # Set up peering with service networking    # Your account must have the "Compute Network Admin" role to run the following. gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}# Creating bucket. gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URIUsing Tensorflow Universal Sentence Encoder as an Embedder‚Äã# Load the Universal Sentence Encoder modulemodule_url = "https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"model = hub.load(module_url)# Generate embeddings for each wordembeddings = model(["banana"])Inserting a test embedding‚Äãinitial_config = {    "id": "banana_id",    "embedding": [float(x) for x in list(embeddings.numpy()[0])],}with open("data.json", "w") as f:    json.dump(initial_config, f)gsutil cp data.json {EMBEDDING_DIR}/file.jsonaiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)Creating Index‚Äãmy_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(    display_name=DISPLAY_NAME,    contents_delta_uri=EMBEDDING_DIR,    dimensions=DIMENSIONS,    approximate_neighbors_count=150,    distance_measure_type="DOT_PRODUCT_DISTANCE",)Creating Endpoint‚Äãmy_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(    display_name=f"{DISPLAY_NAME}-endpoint",    network=VPC_NETWORK_FULL,)Deploy Index‚Äãmy_index_endpoint = my_index_endpoint.deploy_index(    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)my_index_endpoint.deployed_indexesPreviousMarqoNextMeilisearchCreate VectorStore from textsCreate Index and deploy it to an EndpointImports, Constants and ConfigsUsing Tensorflow Universal Sentence Encoder as an EmbedderInserting a test embeddingCreating IndexCreating EndpointDeploy Index IntegrationsVector storesGoogle Vertex AI MatchingEngineOn this pageGoogle Vertex AI MatchingEngineThis notebook shows how to use functionality related to the GCP Vertex AI MatchingEngine vector database.Vertex AI Matching Engine provides the industry's leading high-scale low latency vector database. These vector databases are commonly referred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.Note: This module expects an endpoint and deployed index already created as the creation time takes close to one hour. To see how to create an index refer to the section Create Index and deploy it to an EndpointCreate VectorStore from texts‚Äãfrom langchain.vectorstores import MatchingEngineAPI Reference:MatchingEnginetexts = [    "The cat sat on",    "the mat.",    "I like to",    "eat pizza for",    "dinner.",    "The sun sets",    "in the west.",]vector_store = MatchingEngine.from_components(    texts=texts,    project_id="<my_project_id>",    region="<my_region>",    gcs_bucket_uri="<my_gcs_bucket>",    index_id="<my_matching_engine_index_id>",    endpoint_id="<my_matching_engine_endpoint_id>",)vector_store.add_texts(texts=texts)vector_store.similarity_search("lunch", k=2)Create Index and deploy it to an Endpoint‚ÄãImports, Constants and Configs‚Äã# Installing dependencies.pip install tensorflow \            google-cloud-aiplatform \            tensorflow-hub \            tensorflow-textimport osimport jsonfrom google.cloud import aiplatformimport tensorflow_hub as hubimport tensorflow_textPROJECT_ID = "<my_project_id>"REGION = "<my_region>"VPC_NETWORK = "<my_vpc_network_name>"PEERING_RANGE_NAME = "ann-langchain-me-range"  # Name for creating the VPC peering.BUCKET_URI = "gs://<bucket_uri>"# The number of dimensions for the tensorflow universal sentence encoder.# If other embedder is used, the dimensions would probably need to change.DIMENSIONS = 512DISPLAY_NAME = "index-test-name"EMBEDDING_DIR = f"{BUCKET_URI}/banana"DEPLOYED_INDEX_ID = "endpoint-test-name"PROJECT_NUMBER = !gcloud projects list --filter="PROJECT_ID:'{PROJECT_ID}'" --format='value(PROJECT_NUMBER)'PROJECT_NUMBER = PROJECT_NUMBER[0]VPC_NETWORK_FULL = f"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}"# Change this if you need the VPC to be created.CREATE_VPC = False# Set the project id gcloud config set project {PROJECT_ID}# Remove the if condition to run the encapsulated codeif CREATE_VPC:    # Create a VPC network gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}    # Add necessary firewall rules gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9 gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389 gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22    # Reserve IP range gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description="peering range"    # Set up peering with service networking    # Your account must have the "Compute Network Admin" role to run the following. gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}# Creating bucket. gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URIUsing Tensorflow Universal Sentence Encoder as an Embedder‚Äã# Load the Universal Sentence Encoder modulemodule_url = "https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"model = hub.load(module_url)# Generate embeddings for each wordembeddings = model(["banana"])Inserting a test embedding‚Äãinitial_config = {    "id": "banana_id",    "embedding": [float(x) for x in list(embeddings.numpy()[0])],}with open("data.json", "w") as f:    json.dump(initial_config, f)gsutil cp data.json {EMBEDDING_DIR}/file.jsonaiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)Creating Index‚Äãmy_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(    display_name=DISPLAY_NAME,    contents_delta_uri=EMBEDDING_DIR,    dimensions=DIMENSIONS,    approximate_neighbors_count=150,    distance_measure_type="DOT_PRODUCT_DISTANCE",)Creating Endpoint‚Äãmy_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(    display_name=f"{DISPLAY_NAME}-endpoint",    network=VPC_NETWORK_FULL,)Deploy Index‚Äãmy_index_endpoint = my_index_endpoint.deploy_index(    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)my_index_endpoint.deployed_indexesPreviousMarqoNextMeilisearch IntegrationsVector storesGoogle Vertex AI MatchingEngineOn this pageGoogle Vertex AI MatchingEngineThis notebook shows how to use functionality related to the GCP Vertex AI MatchingEngine vector database.Vertex AI Matching Engine provides the industry's leading high-scale low latency vector database. These vector databases are commonly referred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.Note: This module expects an endpoint and deployed index already created as the creation time takes close to one hour. To see how to create an index refer to the section Create Index and deploy it to an EndpointCreate VectorStore from texts‚Äãfrom langchain.vectorstores import MatchingEngineAPI Reference:MatchingEnginetexts = [    "The cat sat on",    "the mat.",    "I like to",    "eat pizza for",    "dinner.",    "The sun sets",    "in the west.",]vector_store = MatchingEngine.from_components(    texts=texts,    project_id="<my_project_id>",    region="<my_region>",    gcs_bucket_uri="<my_gcs_bucket>",    index_id="<my_matching_engine_index_id>",    endpoint_id="<my_matching_engine_endpoint_id>",)vector_store.add_texts(texts=texts)vector_store.similarity_search("lunch", k=2)Create Index and deploy it to an Endpoint‚ÄãImports, Constants and Configs‚Äã# Installing dependencies.pip install tensorflow \            google-cloud-aiplatform \            tensorflow-hub \            tensorflow-textimport osimport jsonfrom google.cloud import aiplatformimport tensorflow_hub as hubimport tensorflow_textPROJECT_ID = "<my_project_id>"REGION = "<my_region>"VPC_NETWORK = "<my_vpc_network_name>"PEERING_RANGE_NAME = "ann-langchain-me-range"  # Name for creating the VPC peering.BUCKET_URI = "gs://<bucket_uri>"# The number of dimensions for the tensorflow universal sentence encoder.# If other embedder is used, the dimensions would probably need to change.DIMENSIONS = 512DISPLAY_NAME = "index-test-name"EMBEDDING_DIR = f"{BUCKET_URI}/banana"DEPLOYED_INDEX_ID = "endpoint-test-name"PROJECT_NUMBER = !gcloud projects list --filter="PROJECT_ID:'{PROJECT_ID}'" --format='value(PROJECT_NUMBER)'PROJECT_NUMBER = PROJECT_NUMBER[0]VPC_NETWORK_FULL = f"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}"# Change this if you need the VPC to be created.CREATE_VPC = False# Set the project id gcloud config set project {PROJECT_ID}# Remove the if condition to run the encapsulated codeif CREATE_VPC:    # Create a VPC network gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}    # Add necessary firewall rules gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9 gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389 gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22    # Reserve IP range gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description="peering range"    # Set up peering with service networking    # Your account must have the "Compute Network Admin" role to run the following. gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}# Creating bucket. gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URIUsing Tensorflow Universal Sentence Encoder as an Embedder‚Äã# Load the Universal Sentence Encoder modulemodule_url = "https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"model = hub.load(module_url)# Generate embeddings for each wordembeddings = model(["banana"])Inserting a test embedding‚Äãinitial_config = {    "id": "banana_id",    "embedding": [float(x) for x in list(embeddings.numpy()[0])],}with open("data.json", "w") as f:    json.dump(initial_config, f)gsutil cp data.json {EMBEDDING_DIR}/file.jsonaiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)Creating Index‚Äãmy_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(    display_name=DISPLAY_NAME,    contents_delta_uri=EMBEDDING_DIR,    dimensions=DIMENSIONS,    approximate_neighbors_count=150,    distance_measure_type="DOT_PRODUCT_DISTANCE",)Creating Endpoint‚Äãmy_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(    display_name=f"{DISPLAY_NAME}-endpoint",    network=VPC_NETWORK_FULL,)Deploy Index‚Äãmy_index_endpoint = my_index_endpoint.deploy_index(    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)my_index_endpoint.deployed_indexesPreviousMarqoNextMeilisearch On this page Google Vertex AI MatchingEngineThis notebook shows how to use functionality related to the GCP Vertex AI MatchingEngine vector database.Vertex AI Matching Engine provides the industry's leading high-scale low latency vector database. These vector databases are commonly referred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.Note: This module expects an endpoint and deployed index already created as the creation time takes close to one hour. To see how to create an index refer to the section Create Index and deploy it to an EndpointCreate VectorStore from texts‚Äãfrom langchain.vectorstores import MatchingEngineAPI Reference:MatchingEnginetexts = [    "The cat sat on",    "the mat.",    "I like to",    "eat pizza for",    "dinner.",    "The sun sets",    "in the west.",]vector_store = MatchingEngine.from_components(    texts=texts,    project_id="<my_project_id>",    region="<my_region>",    gcs_bucket_uri="<my_gcs_bucket>",    index_id="<my_matching_engine_index_id>",    endpoint_id="<my_matching_engine_endpoint_id>",)vector_store.add_texts(texts=texts)vector_store.similarity_search("lunch", k=2)Create Index and deploy it to an Endpoint‚ÄãImports, Constants and Configs‚Äã# Installing dependencies.pip install tensorflow \            google-cloud-aiplatform \            tensorflow-hub \            tensorflow-textimport osimport jsonfrom google.cloud import aiplatformimport tensorflow_hub as hubimport tensorflow_textPROJECT_ID = "<my_project_id>"REGION = "<my_region>"VPC_NETWORK = "<my_vpc_network_name>"PEERING_RANGE_NAME = "ann-langchain-me-range"  # Name for creating the VPC peering.BUCKET_URI = "gs://<bucket_uri>"# The number of dimensions for the tensorflow universal sentence encoder.# If other embedder is used, the dimensions would probably need to change.DIMENSIONS = 512DISPLAY_NAME = "index-test-name"EMBEDDING_DIR = f"{BUCKET_URI}/banana"DEPLOYED_INDEX_ID = "endpoint-test-name"PROJECT_NUMBER = !gcloud projects list --filter="PROJECT_ID:'{PROJECT_ID}'" --format='value(PROJECT_NUMBER)'PROJECT_NUMBER = PROJECT_NUMBER[0]VPC_NETWORK_FULL = f"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}"# Change this if you need the VPC to be created.CREATE_VPC = False# Set the project id gcloud config set project {PROJECT_ID}# Remove the if condition to run the encapsulated codeif CREATE_VPC:    # Create a VPC network gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}    # Add necessary firewall rules gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9 gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389 gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22    # Reserve IP range gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description="peering range"    # Set up peering with service networking    # Your account must have the "Compute Network Admin" role to run the following. gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}# Creating bucket. gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URIUsing Tensorflow Universal Sentence Encoder as an Embedder‚Äã# Load the Universal Sentence Encoder modulemodule_url = "https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"model = hub.load(module_url)# Generate embeddings for each wordembeddings = model(["banana"])Inserting a test embedding‚Äãinitial_config = {    "id": "banana_id",    "embedding": [float(x) for x in list(embeddings.numpy()[0])],}with open("data.json", "w") as f:    json.dump(initial_config, f)gsutil cp data.json {EMBEDDING_DIR}/file.jsonaiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)Creating Index‚Äãmy_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(    display_name=DISPLAY_NAME,    contents_delta_uri=EMBEDDING_DIR,    dimensions=DIMENSIONS,    approximate_neighbors_count=150,    distance_measure_type="DOT_PRODUCT_DISTANCE",)Creating Endpoint‚Äãmy_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(    display_name=f"{DISPLAY_NAME}-endpoint",    network=VPC_NETWORK_FULL,)Deploy Index‚Äãmy_index_endpoint = my_index_endpoint.deploy_index(    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)my_index_endpoint.deployed_indexes from langchain.vectorstores import MatchingEngine from langchain.vectorstores import MatchingEngine  API Reference:MatchingEngine texts = [    "The cat sat on",    "the mat.",    "I like to",    "eat pizza for",    "dinner.",    "The sun sets",    "in the west.",]vector_store = MatchingEngine.from_components(    texts=texts,    project_id="<my_project_id>",    region="<my_region>",    gcs_bucket_uri="<my_gcs_bucket>",    index_id="<my_matching_engine_index_id>",    endpoint_id="<my_matching_engine_endpoint_id>",)vector_store.add_texts(texts=texts)vector_store.similarity_search("lunch", k=2) texts = [    "The cat sat on",    "the mat.",    "I like to",    "eat pizza for",    "dinner.",    "The sun sets",    "in the west.",]vector_store = MatchingEngine.from_components(    texts=texts,    project_id="<my_project_id>",    region="<my_region>",    gcs_bucket_uri="<my_gcs_bucket>",    index_id="<my_matching_engine_index_id>",    endpoint_id="<my_matching_engine_endpoint_id>",)vector_store.add_texts(texts=texts)vector_store.similarity_search("lunch", k=2)  # Installing dependencies.pip install tensorflow \            google-cloud-aiplatform \            tensorflow-hub \            tensorflow-text # Installing dependencies.pip install tensorflow \            google-cloud-aiplatform \            tensorflow-hub \            tensorflow-text  import osimport jsonfrom google.cloud import aiplatformimport tensorflow_hub as hubimport tensorflow_text import osimport jsonfrom google.cloud import aiplatformimport tensorflow_hub as hubimport tensorflow_text  PROJECT_ID = "<my_project_id>"REGION = "<my_region>"VPC_NETWORK = "<my_vpc_network_name>"PEERING_RANGE_NAME = "ann-langchain-me-range"  # Name for creating the VPC peering.BUCKET_URI = "gs://<bucket_uri>"# The number of dimensions for the tensorflow universal sentence encoder.# If other embedder is used, the dimensions would probably need to change.DIMENSIONS = 512DISPLAY_NAME = "index-test-name"EMBEDDING_DIR = f"{BUCKET_URI}/banana"DEPLOYED_INDEX_ID = "endpoint-test-name"PROJECT_NUMBER = !gcloud projects list --filter="PROJECT_ID:'{PROJECT_ID}'" --format='value(PROJECT_NUMBER)'PROJECT_NUMBER = PROJECT_NUMBER[0]VPC_NETWORK_FULL = f"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}"# Change this if you need the VPC to be created.CREATE_VPC = False PROJECT_ID = "<my_project_id>"REGION = "<my_region>"VPC_NETWORK = "<my_vpc_network_name>"PEERING_RANGE_NAME = "ann-langchain-me-range"  # Name for creating the VPC peering.BUCKET_URI = "gs://<bucket_uri>"# The number of dimensions for the tensorflow universal sentence encoder.# If other embedder is used, the dimensions would probably need to change.DIMENSIONS = 512DISPLAY_NAME = "index-test-name"EMBEDDING_DIR = f"{BUCKET_URI}/banana"DEPLOYED_INDEX_ID = "endpoint-test-name"PROJECT_NUMBER = !gcloud projects list --filter="PROJECT_ID:'{PROJECT_ID}'" --format='value(PROJECT_NUMBER)'PROJECT_NUMBER = PROJECT_NUMBER[0]VPC_NETWORK_FULL = f"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}"# Change this if you need the VPC to be created.CREATE_VPC = False  # Set the project id gcloud config set project {PROJECT_ID} # Set the project id gcloud config set project {PROJECT_ID}  # Remove the if condition to run the encapsulated codeif CREATE_VPC:    # Create a VPC network gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}    # Add necessary firewall rules gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9 gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389 gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22    # Reserve IP range gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description="peering range"    # Set up peering with service networking    # Your account must have the "Compute Network Admin" role to run the following. gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID} # Remove the if condition to run the encapsulated codeif CREATE_VPC:    # Create a VPC network gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}    # Add necessary firewall rules gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9 gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389 gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22    # Reserve IP range gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description="peering range"    # Set up peering with service networking    # Your account must have the "Compute Network Admin" role to run the following. gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}  # Creating bucket. gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI # Creating bucket. gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI  # Load the Universal Sentence Encoder modulemodule_url = "https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"model = hub.load(module_url) # Load the Universal Sentence Encoder modulemodule_url = "https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"model = hub.load(module_url)  # Generate embeddings for each wordembeddings = model(["banana"]) # Generate embeddings for each wordembeddings = model(["banana"])  initial_config = {    "id": "banana_id",    "embedding": [float(x) for x in list(embeddings.numpy()[0])],}with open("data.json", "w") as f:    json.dump(initial_config, f)gsutil cp data.json {EMBEDDING_DIR}/file.json initial_config = {    "id": "banana_id",    "embedding": [float(x) for x in list(embeddings.numpy()[0])],}with open("data.json", "w") as f:    json.dump(initial_config, f)gsutil cp data.json {EMBEDDING_DIR}/file.json  aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI) aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)  my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(    display_name=DISPLAY_NAME,    contents_delta_uri=EMBEDDING_DIR,    dimensions=DIMENSIONS,    approximate_neighbors_count=150,    distance_measure_type="DOT_PRODUCT_DISTANCE",) my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(    display_name=DISPLAY_NAME,    contents_delta_uri=EMBEDDING_DIR,    dimensions=DIMENSIONS,    approximate_neighbors_count=150,    distance_measure_type="DOT_PRODUCT_DISTANCE",)  my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(    display_name=f"{DISPLAY_NAME}-endpoint",    network=VPC_NETWORK_FULL,) my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(    display_name=f"{DISPLAY_NAME}-endpoint",    network=VPC_NETWORK_FULL,)  my_index_endpoint = my_index_endpoint.deploy_index(    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)my_index_endpoint.deployed_indexes my_index_endpoint = my_index_endpoint.deploy_index(    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)my_index_endpoint.deployed_indexes  Previous Marqo Next Meilisearch Create VectorStore from textsCreate Index and deploy it to an EndpointImports, Constants and ConfigsUsing Tensorflow Universal Sentence Encoder as an EmbedderInserting a test embeddingCreating IndexCreating EndpointDeploy Index Create VectorStore from textsCreate Index and deploy it to an EndpointImports, Constants and ConfigsUsing Tensorflow Universal Sentence Encoder as an EmbedderInserting a test embeddingCreating IndexCreating EndpointDeploy Index CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Activeloop Deep Lake (/docs/integrations/vectorstores/activeloop_deeplake) Alibaba Cloud OpenSearch (/docs/integrations/vectorstores/alibabacloud_opensearch) AnalyticDB (/docs/integrations/vectorstores/analyticdb) Annoy (/docs/integrations/vectorstores/annoy) Atlas (/docs/integrations/vectorstores/atlas) AwaDB (/docs/integrations/vectorstores/awadb) Azure Cognitive Search (/docs/integrations/vectorstores/azuresearch) BagelDB (/docs/integrations/vectorstores/bageldb) Cassandra (/docs/integrations/vectorstores/cassandra) Chroma (/docs/integrations/vectorstores/chroma) ClickHouse (/docs/integrations/vectorstores/clickhouse) DashVector (/docs/integrations/vectorstores/dashvector) Dingo (/docs/integrations/vectorstores/dingo) DocArray HnswSearch (/docs/integrations/vectorstores/docarray_hnsw) DocArray InMemorySearch (/docs/integrations/vectorstores/docarray_in_memory) Elasticsearch (/docs/integrations/vectorstores/elasticsearch) Epsilla (/docs/integrations/vectorstores/epsilla) Faiss (/docs/integrations/vectorstores/faiss) Hologres (/docs/integrations/vectorstores/hologres) LanceDB (/docs/integrations/vectorstores/lancedb) Marqo (/docs/integrations/vectorstores/marqo) Google Vertex AI MatchingEngine (/docs/integrations/vectorstores/matchingengine) Meilisearch (/docs/integrations/vectorstores/meilisearch) Milvus (/docs/integrations/vectorstores/milvus) MongoDB Atlas (/docs/integrations/vectorstores/mongodb_atlas) MyScale (/docs/integrations/vectorstores/myscale) Neo4j Vector Index (/docs/integrations/vectorstores/neo4jvector) NucliaDB (/docs/integrations/vectorstores/nucliadb) OpenSearch (/docs/integrations/vectorstores/opensearch) Postgres Embedding (/docs/integrations/vectorstores/pgembedding) PGVector (/docs/integrations/vectorstores/pgvector) Pinecone (/docs/integrations/vectorstores/pinecone) Qdrant (/docs/integrations/vectorstores/qdrant) Redis (/docs/integrations/vectorstores/redis) Rockset (/docs/integrations/vectorstores/rockset) ScaNN (/docs/integrations/vectorstores/scann) SingleStoreDB (/docs/integrations/vectorstores/singlestoredb) scikit-learn (/docs/integrations/vectorstores/sklearn) sqlite-vss (/docs/integrations/vectorstores/sqlitevss) StarRocks (/docs/integrations/vectorstores/starrocks) Supabase (Postgres) (/docs/integrations/vectorstores/supabase) Tair (/docs/integrations/vectorstores/tair) Tencent Cloud VectorDB (/docs/integrations/vectorstores/tencentvectordb) Tigris (/docs/integrations/vectorstores/tigris) Typesense (/docs/integrations/vectorstores/typesense) USearch (/docs/integrations/vectorstores/usearch) vearch (/docs/integrations/vectorstores/vearch) Vectara (/docs/integrations/vectorstores/vectara) Weaviate (/docs/integrations/vectorstores/weaviate) Xata (/docs/integrations/vectorstores/xata) Zep (/docs/integrations/vectorstores/zep) Zilliz (/docs/integrations/vectorstores/zilliz) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Vector stores (/docs/integrations/vectorstores/) Matching Engine (https://cloud.google.com/vertex-ai/docs/matching-engine/overview) Create Index and deploy it to an Endpoint (#create-index-and-deploy-it-to-an-endpoint) ‚Äã (#create-vectorstore-from-texts) MatchingEngine (https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.matching_engine.MatchingEngine.html) ‚Äã (#create-index-and-deploy-it-to-an-endpoint) ‚Äã (#imports-constants-and-configs) ‚Äã (#using-tensorflow-universal-sentence-encoder-as-an-embedder) ‚Äã (#inserting-a-test-embedding) ‚Äã (#creating-index) ‚Äã (#creating-endpoint) ‚Äã (#deploy-index) PreviousMarqo (/docs/integrations/vectorstores/marqo) NextMeilisearch (/docs/integrations/vectorstores/meilisearch) Create VectorStore from texts (#create-vectorstore-from-texts) Create Index and deploy it to an Endpoint (#create-index-and-deploy-it-to-an-endpoint) Imports, Constants and Configs (#imports-constants-and-configs) Using Tensorflow Universal Sentence Encoder as an Embedder (#using-tensorflow-universal-sentence-encoder-as-an-embedder) Inserting a test embedding (#inserting-a-test-embedding) Creating Index (#creating-index) Creating Endpoint (#creating-endpoint) Deploy Index (#deploy-index) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)