Typesense is an open source, in-memory search engine, that you can either self-host or run on Typesense Cloud. Typesense focuses on performance by storing the entire index in RAM (with a backup on disk) and also focuses on providing an out-of-the-box developer experience by simplifying available options and setting good defaults. It also lets you combine attribute-based filtering together with vector queries, to fetch the most relevant documents. This notebook shows you how to use Typesense as your VectorStore. Let's first install our dependencies: We want to use OpenAIEmbeddings so we have to get the OpenAI API Key. Let's import our test dataset: Typesense, as all the other vector stores, is a LangChain Retriever, by using cosine similarity. IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by provider Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZilliz Activeloop Deep Lake Alibaba Cloud OpenSearch AnalyticDB Annoy Atlas AwaDB Azure Cognitive Search BagelDB Cassandra Chroma ClickHouse DashVector Dingo DocArray HnswSearch DocArray InMemorySearch Elasticsearch Epsilla Faiss Hologres LanceDB Marqo Google Vertex AI MatchingEngine Meilisearch Milvus MongoDB Atlas MyScale Neo4j Vector Index NucliaDB OpenSearch Postgres Embedding PGVector Pinecone Qdrant Redis Rockset ScaNN SingleStoreDB scikit-learn sqlite-vss StarRocks Supabase (Postgres) Tair Tencent Cloud VectorDB Tigris Typesense USearch vearch Vectara Weaviate Xata Zep Zilliz Grouped by provider  Integrations Vector stores Typesense OpenAIEmbeddings CharacterTextSplitter Typesense TextLoader Similarity Search Typesense as a Retriever Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by providerIntegrationsVector storesTypesenseOn this pageTypesenseTypesense is an open source, in-memory search engine, that you can either self-host or run on Typesense Cloud.Typesense focuses on performance by storing the entire index in RAM (with a backup on disk) and also focuses on providing an out-of-the-box developer experience by simplifying available options and setting good defaults.It also lets you combine attribute-based filtering together with vector queries, to fetch the most relevant documents.This notebook shows you how to use Typesense as your VectorStore.Let's first install our dependencies:pip install typesense openapi-schema-pydantic openai tiktokenWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Typesensefrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterTypesenseTextLoaderLet's import our test dataset:loader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()docsearch = Typesense.from_documents(    docs,    embeddings,    typesense_client_params={        "host": "localhost",  # Use xxx.a1.typesense.net for Typesense Cloud        "port": "8108",  # Use 443 for Typesense Cloud        "protocol": "http",  # Use https for Typesense Cloud        "typesense_api_key": "xyz",        "typesense_collection_name": "lang-chain",    },)Similarity Search‚Äãquery = "What did the president say about Ketanji Brown Jackson"found_docs = docsearch.similarity_search(query)print(found_docs[0].page_content)Typesense as a Retriever‚ÄãTypesense, as all the other vector stores, is a LangChain Retriever, by using cosine similarity.retriever = docsearch.as_retriever()retrieverquery = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]PreviousTigrisNextUSearchSimilarity SearchTypesense as a RetrieverCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by providerIntegrationsVector storesTypesenseOn this pageTypesenseTypesense is an open source, in-memory search engine, that you can either self-host or run on Typesense Cloud.Typesense focuses on performance by storing the entire index in RAM (with a backup on disk) and also focuses on providing an out-of-the-box developer experience by simplifying available options and setting good defaults.It also lets you combine attribute-based filtering together with vector queries, to fetch the most relevant documents.This notebook shows you how to use Typesense as your VectorStore.Let's first install our dependencies:pip install typesense openapi-schema-pydantic openai tiktokenWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Typesensefrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterTypesenseTextLoaderLet's import our test dataset:loader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()docsearch = Typesense.from_documents(    docs,    embeddings,    typesense_client_params={        "host": "localhost",  # Use xxx.a1.typesense.net for Typesense Cloud        "port": "8108",  # Use 443 for Typesense Cloud        "protocol": "http",  # Use https for Typesense Cloud        "typesense_api_key": "xyz",        "typesense_collection_name": "lang-chain",    },)Similarity Search‚Äãquery = "What did the president say about Ketanji Brown Jackson"found_docs = docsearch.similarity_search(query)print(found_docs[0].page_content)Typesense as a Retriever‚ÄãTypesense, as all the other vector stores, is a LangChain Retriever, by using cosine similarity.retriever = docsearch.as_retriever()retrieverquery = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]PreviousTigrisNextUSearchSimilarity SearchTypesense as a Retriever IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by providerIntegrationsVector storesTypesenseOn this pageTypesenseTypesense is an open source, in-memory search engine, that you can either self-host or run on Typesense Cloud.Typesense focuses on performance by storing the entire index in RAM (with a backup on disk) and also focuses on providing an out-of-the-box developer experience by simplifying available options and setting good defaults.It also lets you combine attribute-based filtering together with vector queries, to fetch the most relevant documents.This notebook shows you how to use Typesense as your VectorStore.Let's first install our dependencies:pip install typesense openapi-schema-pydantic openai tiktokenWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Typesensefrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterTypesenseTextLoaderLet's import our test dataset:loader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()docsearch = Typesense.from_documents(    docs,    embeddings,    typesense_client_params={        "host": "localhost",  # Use xxx.a1.typesense.net for Typesense Cloud        "port": "8108",  # Use 443 for Typesense Cloud        "protocol": "http",  # Use https for Typesense Cloud        "typesense_api_key": "xyz",        "typesense_collection_name": "lang-chain",    },)Similarity Search‚Äãquery = "What did the president say about Ketanji Brown Jackson"found_docs = docsearch.similarity_search(query)print(found_docs[0].page_content)Typesense as a Retriever‚ÄãTypesense, as all the other vector stores, is a LangChain Retriever, by using cosine similarity.retriever = docsearch.as_retriever()retrieverquery = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]PreviousTigrisNextUSearchSimilarity SearchTypesense as a Retriever IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsVector storesTypesenseOn this pageTypesenseTypesense is an open source, in-memory search engine, that you can either self-host or run on Typesense Cloud.Typesense focuses on performance by storing the entire index in RAM (with a backup on disk) and also focuses on providing an out-of-the-box developer experience by simplifying available options and setting good defaults.It also lets you combine attribute-based filtering together with vector queries, to fetch the most relevant documents.This notebook shows you how to use Typesense as your VectorStore.Let's first install our dependencies:pip install typesense openapi-schema-pydantic openai tiktokenWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Typesensefrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterTypesenseTextLoaderLet's import our test dataset:loader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()docsearch = Typesense.from_documents(    docs,    embeddings,    typesense_client_params={        "host": "localhost",  # Use xxx.a1.typesense.net for Typesense Cloud        "port": "8108",  # Use 443 for Typesense Cloud        "protocol": "http",  # Use https for Typesense Cloud        "typesense_api_key": "xyz",        "typesense_collection_name": "lang-chain",    },)Similarity Search‚Äãquery = "What did the president say about Ketanji Brown Jackson"found_docs = docsearch.similarity_search(query)print(found_docs[0].page_content)Typesense as a Retriever‚ÄãTypesense, as all the other vector stores, is a LangChain Retriever, by using cosine similarity.retriever = docsearch.as_retriever()retrieverquery = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]PreviousTigrisNextUSearchSimilarity SearchTypesense as a Retriever IntegrationsVector storesTypesenseOn this pageTypesenseTypesense is an open source, in-memory search engine, that you can either self-host or run on Typesense Cloud.Typesense focuses on performance by storing the entire index in RAM (with a backup on disk) and also focuses on providing an out-of-the-box developer experience by simplifying available options and setting good defaults.It also lets you combine attribute-based filtering together with vector queries, to fetch the most relevant documents.This notebook shows you how to use Typesense as your VectorStore.Let's first install our dependencies:pip install typesense openapi-schema-pydantic openai tiktokenWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Typesensefrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterTypesenseTextLoaderLet's import our test dataset:loader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()docsearch = Typesense.from_documents(    docs,    embeddings,    typesense_client_params={        "host": "localhost",  # Use xxx.a1.typesense.net for Typesense Cloud        "port": "8108",  # Use 443 for Typesense Cloud        "protocol": "http",  # Use https for Typesense Cloud        "typesense_api_key": "xyz",        "typesense_collection_name": "lang-chain",    },)Similarity Search‚Äãquery = "What did the president say about Ketanji Brown Jackson"found_docs = docsearch.similarity_search(query)print(found_docs[0].page_content)Typesense as a Retriever‚ÄãTypesense, as all the other vector stores, is a LangChain Retriever, by using cosine similarity.retriever = docsearch.as_retriever()retrieverquery = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]PreviousTigrisNextUSearchSimilarity SearchTypesense as a Retriever IntegrationsVector storesTypesenseOn this pageTypesenseTypesense is an open source, in-memory search engine, that you can either self-host or run on Typesense Cloud.Typesense focuses on performance by storing the entire index in RAM (with a backup on disk) and also focuses on providing an out-of-the-box developer experience by simplifying available options and setting good defaults.It also lets you combine attribute-based filtering together with vector queries, to fetch the most relevant documents.This notebook shows you how to use Typesense as your VectorStore.Let's first install our dependencies:pip install typesense openapi-schema-pydantic openai tiktokenWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Typesensefrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterTypesenseTextLoaderLet's import our test dataset:loader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()docsearch = Typesense.from_documents(    docs,    embeddings,    typesense_client_params={        "host": "localhost",  # Use xxx.a1.typesense.net for Typesense Cloud        "port": "8108",  # Use 443 for Typesense Cloud        "protocol": "http",  # Use https for Typesense Cloud        "typesense_api_key": "xyz",        "typesense_collection_name": "lang-chain",    },)Similarity Search‚Äãquery = "What did the president say about Ketanji Brown Jackson"found_docs = docsearch.similarity_search(query)print(found_docs[0].page_content)Typesense as a Retriever‚ÄãTypesense, as all the other vector stores, is a LangChain Retriever, by using cosine similarity.retriever = docsearch.as_retriever()retrieverquery = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]PreviousTigrisNextUSearch IntegrationsVector storesTypesenseOn this pageTypesenseTypesense is an open source, in-memory search engine, that you can either self-host or run on Typesense Cloud.Typesense focuses on performance by storing the entire index in RAM (with a backup on disk) and also focuses on providing an out-of-the-box developer experience by simplifying available options and setting good defaults.It also lets you combine attribute-based filtering together with vector queries, to fetch the most relevant documents.This notebook shows you how to use Typesense as your VectorStore.Let's first install our dependencies:pip install typesense openapi-schema-pydantic openai tiktokenWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Typesensefrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterTypesenseTextLoaderLet's import our test dataset:loader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()docsearch = Typesense.from_documents(    docs,    embeddings,    typesense_client_params={        "host": "localhost",  # Use xxx.a1.typesense.net for Typesense Cloud        "port": "8108",  # Use 443 for Typesense Cloud        "protocol": "http",  # Use https for Typesense Cloud        "typesense_api_key": "xyz",        "typesense_collection_name": "lang-chain",    },)Similarity Search‚Äãquery = "What did the president say about Ketanji Brown Jackson"found_docs = docsearch.similarity_search(query)print(found_docs[0].page_content)Typesense as a Retriever‚ÄãTypesense, as all the other vector stores, is a LangChain Retriever, by using cosine similarity.retriever = docsearch.as_retriever()retrieverquery = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]PreviousTigrisNextUSearch On this page TypesenseTypesense is an open source, in-memory search engine, that you can either self-host or run on Typesense Cloud.Typesense focuses on performance by storing the entire index in RAM (with a backup on disk) and also focuses on providing an out-of-the-box developer experience by simplifying available options and setting good defaults.It also lets you combine attribute-based filtering together with vector queries, to fetch the most relevant documents.This notebook shows you how to use Typesense as your VectorStore.Let's first install our dependencies:pip install typesense openapi-schema-pydantic openai tiktokenWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Typesensefrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterTypesenseTextLoaderLet's import our test dataset:loader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()docsearch = Typesense.from_documents(    docs,    embeddings,    typesense_client_params={        "host": "localhost",  # Use xxx.a1.typesense.net for Typesense Cloud        "port": "8108",  # Use 443 for Typesense Cloud        "protocol": "http",  # Use https for Typesense Cloud        "typesense_api_key": "xyz",        "typesense_collection_name": "lang-chain",    },)Similarity Search‚Äãquery = "What did the president say about Ketanji Brown Jackson"found_docs = docsearch.similarity_search(query)print(found_docs[0].page_content)Typesense as a Retriever‚ÄãTypesense, as all the other vector stores, is a LangChain Retriever, by using cosine similarity.retriever = docsearch.as_retriever()retrieverquery = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0] pip install typesense openapi-schema-pydantic openai tiktoken pip install typesense openapi-schema-pydantic openai tiktoken  import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:") import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")  from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Typesensefrom langchain.document_loaders import TextLoader from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Typesensefrom langchain.document_loaders import TextLoader  API Reference:OpenAIEmbeddingsCharacterTextSplitterTypesenseTextLoader loader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings() loader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()  docsearch = Typesense.from_documents(    docs,    embeddings,    typesense_client_params={        "host": "localhost",  # Use xxx.a1.typesense.net for Typesense Cloud        "port": "8108",  # Use 443 for Typesense Cloud        "protocol": "http",  # Use https for Typesense Cloud        "typesense_api_key": "xyz",        "typesense_collection_name": "lang-chain",    },) docsearch = Typesense.from_documents(    docs,    embeddings,    typesense_client_params={        "host": "localhost",  # Use xxx.a1.typesense.net for Typesense Cloud        "port": "8108",  # Use 443 for Typesense Cloud        "protocol": "http",  # Use https for Typesense Cloud        "typesense_api_key": "xyz",        "typesense_collection_name": "lang-chain",    },)  query = "What did the president say about Ketanji Brown Jackson"found_docs = docsearch.similarity_search(query) query = "What did the president say about Ketanji Brown Jackson"found_docs = docsearch.similarity_search(query)  print(found_docs[0].page_content) print(found_docs[0].page_content)  retriever = docsearch.as_retriever()retriever retriever = docsearch.as_retriever()retriever  query = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0] query = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]  Previous Tigris Next USearch Similarity SearchTypesense as a Retriever Similarity SearchTypesense as a Retriever CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Activeloop Deep Lake (/docs/integrations/vectorstores/activeloop_deeplake) Alibaba Cloud OpenSearch (/docs/integrations/vectorstores/alibabacloud_opensearch) AnalyticDB (/docs/integrations/vectorstores/analyticdb) Annoy (/docs/integrations/vectorstores/annoy) Atlas (/docs/integrations/vectorstores/atlas) AwaDB (/docs/integrations/vectorstores/awadb) Azure Cognitive Search (/docs/integrations/vectorstores/azuresearch) BagelDB (/docs/integrations/vectorstores/bageldb) Cassandra (/docs/integrations/vectorstores/cassandra) Chroma (/docs/integrations/vectorstores/chroma) ClickHouse (/docs/integrations/vectorstores/clickhouse) DashVector (/docs/integrations/vectorstores/dashvector) Dingo (/docs/integrations/vectorstores/dingo) DocArray HnswSearch (/docs/integrations/vectorstores/docarray_hnsw) DocArray InMemorySearch (/docs/integrations/vectorstores/docarray_in_memory) Elasticsearch (/docs/integrations/vectorstores/elasticsearch) Epsilla (/docs/integrations/vectorstores/epsilla) Faiss (/docs/integrations/vectorstores/faiss) Hologres (/docs/integrations/vectorstores/hologres) LanceDB (/docs/integrations/vectorstores/lancedb) Marqo (/docs/integrations/vectorstores/marqo) Google Vertex AI MatchingEngine (/docs/integrations/vectorstores/matchingengine) Meilisearch (/docs/integrations/vectorstores/meilisearch) Milvus (/docs/integrations/vectorstores/milvus) MongoDB Atlas (/docs/integrations/vectorstores/mongodb_atlas) MyScale (/docs/integrations/vectorstores/myscale) Neo4j Vector Index (/docs/integrations/vectorstores/neo4jvector) NucliaDB (/docs/integrations/vectorstores/nucliadb) OpenSearch (/docs/integrations/vectorstores/opensearch) Postgres Embedding (/docs/integrations/vectorstores/pgembedding) PGVector (/docs/integrations/vectorstores/pgvector) Pinecone (/docs/integrations/vectorstores/pinecone) Qdrant (/docs/integrations/vectorstores/qdrant) Redis (/docs/integrations/vectorstores/redis) Rockset (/docs/integrations/vectorstores/rockset) ScaNN (/docs/integrations/vectorstores/scann) SingleStoreDB (/docs/integrations/vectorstores/singlestoredb) scikit-learn (/docs/integrations/vectorstores/sklearn) sqlite-vss (/docs/integrations/vectorstores/sqlitevss) StarRocks (/docs/integrations/vectorstores/starrocks) Supabase (Postgres) (/docs/integrations/vectorstores/supabase) Tair (/docs/integrations/vectorstores/tair) Tencent Cloud VectorDB (/docs/integrations/vectorstores/tencentvectordb) Tigris (/docs/integrations/vectorstores/tigris) Typesense (/docs/integrations/vectorstores/typesense) USearch (/docs/integrations/vectorstores/usearch) vearch (/docs/integrations/vectorstores/vearch) Vectara (/docs/integrations/vectorstores/vectara) Weaviate (/docs/integrations/vectorstores/weaviate) Xata (/docs/integrations/vectorstores/xata) Zep (/docs/integrations/vectorstores/zep) Zilliz (/docs/integrations/vectorstores/zilliz) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Vector stores (/docs/integrations/vectorstores/) Typesense (https://typesense.org) self-host (https://typesense.org/docs/guide/install-typesense.html#option-2-local-machine-self-hosting) Typesense Cloud (https://cloud.typesense.org/) OpenAIEmbeddings (https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html) CharacterTextSplitter (https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.CharacterTextSplitter.html) Typesense (https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.typesense.Typesense.html) TextLoader (https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.text.TextLoader.html) ‚Äã (#similarity-search) ‚Äã (#typesense-as-a-retriever) PreviousTigris (/docs/integrations/vectorstores/tigris) NextUSearch (/docs/integrations/vectorstores/usearch) Similarity Search (#similarity-search) Typesense as a Retriever (#typesense-as-a-retriever) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)