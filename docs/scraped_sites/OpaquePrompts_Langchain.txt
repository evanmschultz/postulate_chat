OpaquePrompts is a service that enables applications to leverage the power of language models without compromising user privacy. Designed for composability and ease of integration into existing applications and services, OpaquePrompts is consumable via a simple Python library as well as through LangChain. Perhaps more importantly, OpaquePrompts leverages the power of confidential computing to ensure that even the OpaquePrompts service itself cannot access the data it is protecting. This notebook goes over how to use LangChain to interact with OpaquePrompts. Accessing the OpaquePrompts API requires an API key, which you can get by creating an account on the OpaquePrompts website. Once you have an account, you can find your API key on the API Keys page. Applying OpaquePrompts to your application could be as simple as wrapping your LLM using the OpaquePrompts class by replace llm=OpenAI() with llm=OpaquePrompts(base_llm=OpenAI()). From the output, you can see the following context from user input has sensitive data. OpaquePrompts will automatically detect the sensitive data and replace it with a placeholder.  Placeholder is used in the LLM response. Response is desanitized by replacing the placeholder with the original sensitive data. There are functions that can be used with LangChain expression as well if a drop-in replacement doesn't offer the flexibility you need.  IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Callbacks Chat models Chat loaders Document loaders Document transformers LLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference) AI21 Aleph Alpha Amazon API Gateway Anyscale Azure ML Azure OpenAI Banana Baseten Beam Bedrock Bittensor CerebriumAI ChatGLM Clarifai Cohere C Transformers CTranslate2 Databricks DeepInfra DeepSparse Eden AI Fireworks ForefrontAI Google Vertex AI PaLM GooseAI GPT4All Hugging Face Hub Hugging Face Local Pipelines Huggingface TextGen Inference JSONFormer KoboldAI API Llama.cpp LLM Caching integrations Manifest Minimax Modal MosaicML NLP Cloud OctoAI Ollama OpaquePrompts OpenAI OpenLLM OpenLM Petals PipelineAI Predibase Prediction Guard PromptLayer OpenAI RELLM Replicate Runhouse SageMakerEndpoint StochasticAI Nebula (Symbl.ai) TextGen Titan Takeoff Tongyi Qwen vLLM Writer Xorbits Inference (Xinference) Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations LLMs OpaquePrompts StdOutCallbackHandler OpenAI ConversationBufferWindowMemory OpaquePrompts RunnableMap StrOutputParser Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsLLMsOpaquePromptsOpaquePromptsOpaquePrompts is a service that enables applications to leverage the power of language models without compromising user privacy. Designed for composability and ease of integration into existing applications and services, OpaquePrompts is consumable via a simple Python library as well as through LangChain. Perhaps more importantly, OpaquePrompts leverages the power of confidential computing to ensure that even the OpaquePrompts service itself cannot access the data it is protecting.This notebook goes over how to use LangChain to interact with OpaquePrompts.# install the opaqueprompts and langchain packages pip install opaqueprompts langchainAccessing the OpaquePrompts API requires an API key, which you can get by creating an account on the OpaquePrompts website. Once you have an account, you can find your API key on the API Keys page.import os# Set API keysos.environ['OPAQUEPROMPTS_API_KEY'] = "<OPAQUEPROMPTS_API_KEY>"os.environ['OPENAI_API_KEY'] = "<OPENAI_API_KEY>"Use OpaquePrompts LLM WrapperApplying OpaquePrompts to your application could be as simple as wrapping your LLM using the OpaquePrompts class by replace llm=OpenAI() with llm=OpaquePrompts(base_llm=OpenAI()).import langchainfrom langchain import LLMChain, PromptTemplatefrom langchain.callbacks.stdout import StdOutCallbackHandlerfrom langchain.llms import OpenAIfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.llms import OpaquePromptslangchain.verbose = Truelangchain.debug = Trueprompt_template = """As an AI assistant, you will answer questions according to given context.Sensitive personal information in the question is masked for privacy.For instance, if the original text says "Giana is good," it will be changedto "PERSON_998 is good." Here's how to handle these changes:* Consider these masked phrases just as placeholders, but still refer tothem in a relevant way when answering.* It's possible that different masked terms might mean the same thing.Stick with the given term and don't modify it.* All masked terms follow the "TYPE_ID" pattern.* Please don't invent new masked terms. For instance, if you see "PERSON_998,"don't come up with "PERSON_997" or "PERSON_999" unless they're already in the question.Conversation History: ```{history}```Context : ```During our recent meeting on February 23, 2023, at 10:30 AM,John Doe provided me with his personal details. His email is johndoe@example.comand his contact number is 650-456-7890. He lives in New York City, USA, andbelongs to the American nationality with Christian beliefs and a leaning towardsthe Democratic party. He mentioned that he recently made a transaction using hiscredit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noteddown his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his websiteas https://johndoeportfolio.com. John also discussed some of his US-specific details.He said his bank account number is 1234567890123456 and his drivers license is Y12345678.His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is123456789. He emphasized not to share his SSN, which is 123-45-6789. Furthermore, hementioned that he accesses his work files remotely through the IP 192.168.1.1 and hasa medical license number MED-123456. ```Question: ```{question}```"""chain = LLMChain(    prompt=PromptTemplate.from_template(prompt_template),    llm=OpaquePrompts(base_llm=OpenAI()),    memory=ConversationBufferWindowMemory(k=2),    verbose=True,)print(    chain.run(        {"question": """Write a message to remind John to do password reset for his website to stay secure."""},        callbacks=[StdOutCallbackHandler()],    ))API Reference:StdOutCallbackHandlerOpenAIConversationBufferWindowMemoryOpaquePromptsFrom the output, you can see the following context from user input has sensitive data.# Context from user inputDuring our recent meeting on February 23, 2023, at 10:30 AM, John Doe provided me with his personal details. His email is johndoe@example.com and his contact number is 650-456-7890. He lives in New York City, USA, and belongs to the American nationality with Christian beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address 1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noted down his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his website as https://johndoeportfolio.com. John also discussed some of his US-specific details. He said his bank account number is 1234567890123456 and his drivers license is Y12345678. His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is 123456789. He emphasized not to share his SSN, which is 669-45-6789. Furthermore, he mentioned that he accesses his work files remotely through the IP 192.168.1.1 and has a medical license number MED-123456.OpaquePrompts will automatically detect the sensitive data and replace it with a placeholder. # Context after OpaquePromptsDuring our recent meeting on DATE_TIME_3, at DATE_TIME_2, PERSON_3 provided me with his personal details. His email is EMAIL_ADDRESS_1 and his contact number is PHONE_NUMBER_1. He lives in LOCATION_3, LOCATION_2, and belongs to the NRP_3 nationality with NRP_2 beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card CREDIT_CARD_1 and transferred bitcoins to the wallet address CRYPTO_1. While discussing his NRP_1 travels, he noted down his IBAN as IBAN_CODE_1. Additionally, he provided his website as URL_1. PERSON_2 also discussed some of his LOCATION_1-specific details. He said his bank account number is US_BANK_NUMBER_1 and his drivers license is US_DRIVER_LICENSE_2. His ITIN is US_ITIN_1, and he recently renewed his passport, the number for which is DATE_TIME_1. He emphasized not to share his SSN, which is US_SSN_1. Furthermore, he mentioned that he accesses his work files remotely through the IP IP_ADDRESS_1 and has a medical license number MED-US_DRIVER_LICENSE_1.Placeholder is used in the LLM response.# response returned by LLMHey PERSON_1, just wanted to remind you to do a password reset for your website URL_1 through your email EMAIL_ADDRESS_1. It's important to stay secure online, so don't forget to do it!Response is desanitized by replacing the placeholder with the original sensitive data.# desanitized LLM response from OpaquePromptsHey John, just wanted to remind you to do a password reset for your website https://johndoeportfolio.com through your email johndoe@example.com. It's important to stay secure online, so don't forget to do it!Use OpaquePrompts in LangChain expressionThere are functions that can be used with LangChain expression as well if a drop-in replacement doesn't offer the flexibility you need. import langchain.utilities.opaqueprompts as opfrom langchain.schema.runnable import RunnableMapfrom langchain.schema.output_parser import StrOutputParserprompt=PromptTemplate.from_template(prompt_template),    llm = OpenAI()pg_chain = (    op.sanitize    | RunnableMap(        {            "response": (lambda x: x["sanitized_input"])            | prompt            | llm            | StrOutputParser(),            "secure_context": lambda x: x["secure_context"],        }    )    | (lambda x: op.desanitize(x["response"], x["secure_context"])))pg_chain.invoke({"question": "Write a text message to remind John to do password reset for his website through his email to stay secure.", "history": ""})API Reference:RunnableMapStrOutputParserPreviousOllamaNextOpenAICommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsLLMsOpaquePromptsOpaquePromptsOpaquePrompts is a service that enables applications to leverage the power of language models without compromising user privacy. Designed for composability and ease of integration into existing applications and services, OpaquePrompts is consumable via a simple Python library as well as through LangChain. Perhaps more importantly, OpaquePrompts leverages the power of confidential computing to ensure that even the OpaquePrompts service itself cannot access the data it is protecting.This notebook goes over how to use LangChain to interact with OpaquePrompts.# install the opaqueprompts and langchain packages pip install opaqueprompts langchainAccessing the OpaquePrompts API requires an API key, which you can get by creating an account on the OpaquePrompts website. Once you have an account, you can find your API key on the API Keys page.import os# Set API keysos.environ['OPAQUEPROMPTS_API_KEY'] = "<OPAQUEPROMPTS_API_KEY>"os.environ['OPENAI_API_KEY'] = "<OPENAI_API_KEY>"Use OpaquePrompts LLM WrapperApplying OpaquePrompts to your application could be as simple as wrapping your LLM using the OpaquePrompts class by replace llm=OpenAI() with llm=OpaquePrompts(base_llm=OpenAI()).import langchainfrom langchain import LLMChain, PromptTemplatefrom langchain.callbacks.stdout import StdOutCallbackHandlerfrom langchain.llms import OpenAIfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.llms import OpaquePromptslangchain.verbose = Truelangchain.debug = Trueprompt_template = """As an AI assistant, you will answer questions according to given context.Sensitive personal information in the question is masked for privacy.For instance, if the original text says "Giana is good," it will be changedto "PERSON_998 is good." Here's how to handle these changes:* Consider these masked phrases just as placeholders, but still refer tothem in a relevant way when answering.* It's possible that different masked terms might mean the same thing.Stick with the given term and don't modify it.* All masked terms follow the "TYPE_ID" pattern.* Please don't invent new masked terms. For instance, if you see "PERSON_998,"don't come up with "PERSON_997" or "PERSON_999" unless they're already in the question.Conversation History: ```{history}```Context : ```During our recent meeting on February 23, 2023, at 10:30 AM,John Doe provided me with his personal details. His email is johndoe@example.comand his contact number is 650-456-7890. He lives in New York City, USA, andbelongs to the American nationality with Christian beliefs and a leaning towardsthe Democratic party. He mentioned that he recently made a transaction using hiscredit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noteddown his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his websiteas https://johndoeportfolio.com. John also discussed some of his US-specific details.He said his bank account number is 1234567890123456 and his drivers license is Y12345678.His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is123456789. He emphasized not to share his SSN, which is 123-45-6789. Furthermore, hementioned that he accesses his work files remotely through the IP 192.168.1.1 and hasa medical license number MED-123456. ```Question: ```{question}```"""chain = LLMChain(    prompt=PromptTemplate.from_template(prompt_template),    llm=OpaquePrompts(base_llm=OpenAI()),    memory=ConversationBufferWindowMemory(k=2),    verbose=True,)print(    chain.run(        {"question": """Write a message to remind John to do password reset for his website to stay secure."""},        callbacks=[StdOutCallbackHandler()],    ))API Reference:StdOutCallbackHandlerOpenAIConversationBufferWindowMemoryOpaquePromptsFrom the output, you can see the following context from user input has sensitive data.# Context from user inputDuring our recent meeting on February 23, 2023, at 10:30 AM, John Doe provided me with his personal details. His email is johndoe@example.com and his contact number is 650-456-7890. He lives in New York City, USA, and belongs to the American nationality with Christian beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address 1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noted down his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his website as https://johndoeportfolio.com. John also discussed some of his US-specific details. He said his bank account number is 1234567890123456 and his drivers license is Y12345678. His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is 123456789. He emphasized not to share his SSN, which is 669-45-6789. Furthermore, he mentioned that he accesses his work files remotely through the IP 192.168.1.1 and has a medical license number MED-123456.OpaquePrompts will automatically detect the sensitive data and replace it with a placeholder. # Context after OpaquePromptsDuring our recent meeting on DATE_TIME_3, at DATE_TIME_2, PERSON_3 provided me with his personal details. His email is EMAIL_ADDRESS_1 and his contact number is PHONE_NUMBER_1. He lives in LOCATION_3, LOCATION_2, and belongs to the NRP_3 nationality with NRP_2 beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card CREDIT_CARD_1 and transferred bitcoins to the wallet address CRYPTO_1. While discussing his NRP_1 travels, he noted down his IBAN as IBAN_CODE_1. Additionally, he provided his website as URL_1. PERSON_2 also discussed some of his LOCATION_1-specific details. He said his bank account number is US_BANK_NUMBER_1 and his drivers license is US_DRIVER_LICENSE_2. His ITIN is US_ITIN_1, and he recently renewed his passport, the number for which is DATE_TIME_1. He emphasized not to share his SSN, which is US_SSN_1. Furthermore, he mentioned that he accesses his work files remotely through the IP IP_ADDRESS_1 and has a medical license number MED-US_DRIVER_LICENSE_1.Placeholder is used in the LLM response.# response returned by LLMHey PERSON_1, just wanted to remind you to do a password reset for your website URL_1 through your email EMAIL_ADDRESS_1. It's important to stay secure online, so don't forget to do it!Response is desanitized by replacing the placeholder with the original sensitive data.# desanitized LLM response from OpaquePromptsHey John, just wanted to remind you to do a password reset for your website https://johndoeportfolio.com through your email johndoe@example.com. It's important to stay secure online, so don't forget to do it!Use OpaquePrompts in LangChain expressionThere are functions that can be used with LangChain expression as well if a drop-in replacement doesn't offer the flexibility you need. import langchain.utilities.opaqueprompts as opfrom langchain.schema.runnable import RunnableMapfrom langchain.schema.output_parser import StrOutputParserprompt=PromptTemplate.from_template(prompt_template),    llm = OpenAI()pg_chain = (    op.sanitize    | RunnableMap(        {            "response": (lambda x: x["sanitized_input"])            | prompt            | llm            | StrOutputParser(),            "secure_context": lambda x: x["secure_context"],        }    )    | (lambda x: op.desanitize(x["response"], x["secure_context"])))pg_chain.invoke({"question": "Write a text message to remind John to do password reset for his website through his email to stay secure.", "history": ""})API Reference:RunnableMapStrOutputParserPreviousOllamaNextOpenAI IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsLLMsOpaquePromptsOpaquePromptsOpaquePrompts is a service that enables applications to leverage the power of language models without compromising user privacy. Designed for composability and ease of integration into existing applications and services, OpaquePrompts is consumable via a simple Python library as well as through LangChain. Perhaps more importantly, OpaquePrompts leverages the power of confidential computing to ensure that even the OpaquePrompts service itself cannot access the data it is protecting.This notebook goes over how to use LangChain to interact with OpaquePrompts.# install the opaqueprompts and langchain packages pip install opaqueprompts langchainAccessing the OpaquePrompts API requires an API key, which you can get by creating an account on the OpaquePrompts website. Once you have an account, you can find your API key on the API Keys page.import os# Set API keysos.environ['OPAQUEPROMPTS_API_KEY'] = "<OPAQUEPROMPTS_API_KEY>"os.environ['OPENAI_API_KEY'] = "<OPENAI_API_KEY>"Use OpaquePrompts LLM WrapperApplying OpaquePrompts to your application could be as simple as wrapping your LLM using the OpaquePrompts class by replace llm=OpenAI() with llm=OpaquePrompts(base_llm=OpenAI()).import langchainfrom langchain import LLMChain, PromptTemplatefrom langchain.callbacks.stdout import StdOutCallbackHandlerfrom langchain.llms import OpenAIfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.llms import OpaquePromptslangchain.verbose = Truelangchain.debug = Trueprompt_template = """As an AI assistant, you will answer questions according to given context.Sensitive personal information in the question is masked for privacy.For instance, if the original text says "Giana is good," it will be changedto "PERSON_998 is good." Here's how to handle these changes:* Consider these masked phrases just as placeholders, but still refer tothem in a relevant way when answering.* It's possible that different masked terms might mean the same thing.Stick with the given term and don't modify it.* All masked terms follow the "TYPE_ID" pattern.* Please don't invent new masked terms. For instance, if you see "PERSON_998,"don't come up with "PERSON_997" or "PERSON_999" unless they're already in the question.Conversation History: ```{history}```Context : ```During our recent meeting on February 23, 2023, at 10:30 AM,John Doe provided me with his personal details. His email is johndoe@example.comand his contact number is 650-456-7890. He lives in New York City, USA, andbelongs to the American nationality with Christian beliefs and a leaning towardsthe Democratic party. He mentioned that he recently made a transaction using hiscredit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noteddown his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his websiteas https://johndoeportfolio.com. John also discussed some of his US-specific details.He said his bank account number is 1234567890123456 and his drivers license is Y12345678.His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is123456789. He emphasized not to share his SSN, which is 123-45-6789. Furthermore, hementioned that he accesses his work files remotely through the IP 192.168.1.1 and hasa medical license number MED-123456. ```Question: ```{question}```"""chain = LLMChain(    prompt=PromptTemplate.from_template(prompt_template),    llm=OpaquePrompts(base_llm=OpenAI()),    memory=ConversationBufferWindowMemory(k=2),    verbose=True,)print(    chain.run(        {"question": """Write a message to remind John to do password reset for his website to stay secure."""},        callbacks=[StdOutCallbackHandler()],    ))API Reference:StdOutCallbackHandlerOpenAIConversationBufferWindowMemoryOpaquePromptsFrom the output, you can see the following context from user input has sensitive data.# Context from user inputDuring our recent meeting on February 23, 2023, at 10:30 AM, John Doe provided me with his personal details. His email is johndoe@example.com and his contact number is 650-456-7890. He lives in New York City, USA, and belongs to the American nationality with Christian beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address 1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noted down his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his website as https://johndoeportfolio.com. John also discussed some of his US-specific details. He said his bank account number is 1234567890123456 and his drivers license is Y12345678. His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is 123456789. He emphasized not to share his SSN, which is 669-45-6789. Furthermore, he mentioned that he accesses his work files remotely through the IP 192.168.1.1 and has a medical license number MED-123456.OpaquePrompts will automatically detect the sensitive data and replace it with a placeholder. # Context after OpaquePromptsDuring our recent meeting on DATE_TIME_3, at DATE_TIME_2, PERSON_3 provided me with his personal details. His email is EMAIL_ADDRESS_1 and his contact number is PHONE_NUMBER_1. He lives in LOCATION_3, LOCATION_2, and belongs to the NRP_3 nationality with NRP_2 beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card CREDIT_CARD_1 and transferred bitcoins to the wallet address CRYPTO_1. While discussing his NRP_1 travels, he noted down his IBAN as IBAN_CODE_1. Additionally, he provided his website as URL_1. PERSON_2 also discussed some of his LOCATION_1-specific details. He said his bank account number is US_BANK_NUMBER_1 and his drivers license is US_DRIVER_LICENSE_2. His ITIN is US_ITIN_1, and he recently renewed his passport, the number for which is DATE_TIME_1. He emphasized not to share his SSN, which is US_SSN_1. Furthermore, he mentioned that he accesses his work files remotely through the IP IP_ADDRESS_1 and has a medical license number MED-US_DRIVER_LICENSE_1.Placeholder is used in the LLM response.# response returned by LLMHey PERSON_1, just wanted to remind you to do a password reset for your website URL_1 through your email EMAIL_ADDRESS_1. It's important to stay secure online, so don't forget to do it!Response is desanitized by replacing the placeholder with the original sensitive data.# desanitized LLM response from OpaquePromptsHey John, just wanted to remind you to do a password reset for your website https://johndoeportfolio.com through your email johndoe@example.com. It's important to stay secure online, so don't forget to do it!Use OpaquePrompts in LangChain expressionThere are functions that can be used with LangChain expression as well if a drop-in replacement doesn't offer the flexibility you need. import langchain.utilities.opaqueprompts as opfrom langchain.schema.runnable import RunnableMapfrom langchain.schema.output_parser import StrOutputParserprompt=PromptTemplate.from_template(prompt_template),    llm = OpenAI()pg_chain = (    op.sanitize    | RunnableMap(        {            "response": (lambda x: x["sanitized_input"])            | prompt            | llm            | StrOutputParser(),            "secure_context": lambda x: x["secure_context"],        }    )    | (lambda x: op.desanitize(x["response"], x["secure_context"])))pg_chain.invoke({"question": "Write a text message to remind John to do password reset for his website through his email to stay secure.", "history": ""})API Reference:RunnableMapStrOutputParserPreviousOllamaNextOpenAI IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsLLMsOpaquePromptsOpaquePromptsOpaquePrompts is a service that enables applications to leverage the power of language models without compromising user privacy. Designed for composability and ease of integration into existing applications and services, OpaquePrompts is consumable via a simple Python library as well as through LangChain. Perhaps more importantly, OpaquePrompts leverages the power of confidential computing to ensure that even the OpaquePrompts service itself cannot access the data it is protecting.This notebook goes over how to use LangChain to interact with OpaquePrompts.# install the opaqueprompts and langchain packages pip install opaqueprompts langchainAccessing the OpaquePrompts API requires an API key, which you can get by creating an account on the OpaquePrompts website. Once you have an account, you can find your API key on the API Keys page.import os# Set API keysos.environ['OPAQUEPROMPTS_API_KEY'] = "<OPAQUEPROMPTS_API_KEY>"os.environ['OPENAI_API_KEY'] = "<OPENAI_API_KEY>"Use OpaquePrompts LLM WrapperApplying OpaquePrompts to your application could be as simple as wrapping your LLM using the OpaquePrompts class by replace llm=OpenAI() with llm=OpaquePrompts(base_llm=OpenAI()).import langchainfrom langchain import LLMChain, PromptTemplatefrom langchain.callbacks.stdout import StdOutCallbackHandlerfrom langchain.llms import OpenAIfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.llms import OpaquePromptslangchain.verbose = Truelangchain.debug = Trueprompt_template = """As an AI assistant, you will answer questions according to given context.Sensitive personal information in the question is masked for privacy.For instance, if the original text says "Giana is good," it will be changedto "PERSON_998 is good." Here's how to handle these changes:* Consider these masked phrases just as placeholders, but still refer tothem in a relevant way when answering.* It's possible that different masked terms might mean the same thing.Stick with the given term and don't modify it.* All masked terms follow the "TYPE_ID" pattern.* Please don't invent new masked terms. For instance, if you see "PERSON_998,"don't come up with "PERSON_997" or "PERSON_999" unless they're already in the question.Conversation History: ```{history}```Context : ```During our recent meeting on February 23, 2023, at 10:30 AM,John Doe provided me with his personal details. His email is johndoe@example.comand his contact number is 650-456-7890. He lives in New York City, USA, andbelongs to the American nationality with Christian beliefs and a leaning towardsthe Democratic party. He mentioned that he recently made a transaction using hiscredit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noteddown his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his websiteas https://johndoeportfolio.com. John also discussed some of his US-specific details.He said his bank account number is 1234567890123456 and his drivers license is Y12345678.His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is123456789. He emphasized not to share his SSN, which is 123-45-6789. Furthermore, hementioned that he accesses his work files remotely through the IP 192.168.1.1 and hasa medical license number MED-123456. ```Question: ```{question}```"""chain = LLMChain(    prompt=PromptTemplate.from_template(prompt_template),    llm=OpaquePrompts(base_llm=OpenAI()),    memory=ConversationBufferWindowMemory(k=2),    verbose=True,)print(    chain.run(        {"question": """Write a message to remind John to do password reset for his website to stay secure."""},        callbacks=[StdOutCallbackHandler()],    ))API Reference:StdOutCallbackHandlerOpenAIConversationBufferWindowMemoryOpaquePromptsFrom the output, you can see the following context from user input has sensitive data.# Context from user inputDuring our recent meeting on February 23, 2023, at 10:30 AM, John Doe provided me with his personal details. His email is johndoe@example.com and his contact number is 650-456-7890. He lives in New York City, USA, and belongs to the American nationality with Christian beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address 1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noted down his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his website as https://johndoeportfolio.com. John also discussed some of his US-specific details. He said his bank account number is 1234567890123456 and his drivers license is Y12345678. His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is 123456789. He emphasized not to share his SSN, which is 669-45-6789. Furthermore, he mentioned that he accesses his work files remotely through the IP 192.168.1.1 and has a medical license number MED-123456.OpaquePrompts will automatically detect the sensitive data and replace it with a placeholder. # Context after OpaquePromptsDuring our recent meeting on DATE_TIME_3, at DATE_TIME_2, PERSON_3 provided me with his personal details. His email is EMAIL_ADDRESS_1 and his contact number is PHONE_NUMBER_1. He lives in LOCATION_3, LOCATION_2, and belongs to the NRP_3 nationality with NRP_2 beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card CREDIT_CARD_1 and transferred bitcoins to the wallet address CRYPTO_1. While discussing his NRP_1 travels, he noted down his IBAN as IBAN_CODE_1. Additionally, he provided his website as URL_1. PERSON_2 also discussed some of his LOCATION_1-specific details. He said his bank account number is US_BANK_NUMBER_1 and his drivers license is US_DRIVER_LICENSE_2. His ITIN is US_ITIN_1, and he recently renewed his passport, the number for which is DATE_TIME_1. He emphasized not to share his SSN, which is US_SSN_1. Furthermore, he mentioned that he accesses his work files remotely through the IP IP_ADDRESS_1 and has a medical license number MED-US_DRIVER_LICENSE_1.Placeholder is used in the LLM response.# response returned by LLMHey PERSON_1, just wanted to remind you to do a password reset for your website URL_1 through your email EMAIL_ADDRESS_1. It's important to stay secure online, so don't forget to do it!Response is desanitized by replacing the placeholder with the original sensitive data.# desanitized LLM response from OpaquePromptsHey John, just wanted to remind you to do a password reset for your website https://johndoeportfolio.com through your email johndoe@example.com. It's important to stay secure online, so don't forget to do it!Use OpaquePrompts in LangChain expressionThere are functions that can be used with LangChain expression as well if a drop-in replacement doesn't offer the flexibility you need. import langchain.utilities.opaqueprompts as opfrom langchain.schema.runnable import RunnableMapfrom langchain.schema.output_parser import StrOutputParserprompt=PromptTemplate.from_template(prompt_template),    llm = OpenAI()pg_chain = (    op.sanitize    | RunnableMap(        {            "response": (lambda x: x["sanitized_input"])            | prompt            | llm            | StrOutputParser(),            "secure_context": lambda x: x["secure_context"],        }    )    | (lambda x: op.desanitize(x["response"], x["secure_context"])))pg_chain.invoke({"question": "Write a text message to remind John to do password reset for his website through his email to stay secure.", "history": ""})API Reference:RunnableMapStrOutputParserPreviousOllamaNextOpenAI IntegrationsLLMsOpaquePromptsOpaquePromptsOpaquePrompts is a service that enables applications to leverage the power of language models without compromising user privacy. Designed for composability and ease of integration into existing applications and services, OpaquePrompts is consumable via a simple Python library as well as through LangChain. Perhaps more importantly, OpaquePrompts leverages the power of confidential computing to ensure that even the OpaquePrompts service itself cannot access the data it is protecting.This notebook goes over how to use LangChain to interact with OpaquePrompts.# install the opaqueprompts and langchain packages pip install opaqueprompts langchainAccessing the OpaquePrompts API requires an API key, which you can get by creating an account on the OpaquePrompts website. Once you have an account, you can find your API key on the API Keys page.import os# Set API keysos.environ['OPAQUEPROMPTS_API_KEY'] = "<OPAQUEPROMPTS_API_KEY>"os.environ['OPENAI_API_KEY'] = "<OPENAI_API_KEY>"Use OpaquePrompts LLM WrapperApplying OpaquePrompts to your application could be as simple as wrapping your LLM using the OpaquePrompts class by replace llm=OpenAI() with llm=OpaquePrompts(base_llm=OpenAI()).import langchainfrom langchain import LLMChain, PromptTemplatefrom langchain.callbacks.stdout import StdOutCallbackHandlerfrom langchain.llms import OpenAIfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.llms import OpaquePromptslangchain.verbose = Truelangchain.debug = Trueprompt_template = """As an AI assistant, you will answer questions according to given context.Sensitive personal information in the question is masked for privacy.For instance, if the original text says "Giana is good," it will be changedto "PERSON_998 is good." Here's how to handle these changes:* Consider these masked phrases just as placeholders, but still refer tothem in a relevant way when answering.* It's possible that different masked terms might mean the same thing.Stick with the given term and don't modify it.* All masked terms follow the "TYPE_ID" pattern.* Please don't invent new masked terms. For instance, if you see "PERSON_998,"don't come up with "PERSON_997" or "PERSON_999" unless they're already in the question.Conversation History: ```{history}```Context : ```During our recent meeting on February 23, 2023, at 10:30 AM,John Doe provided me with his personal details. His email is johndoe@example.comand his contact number is 650-456-7890. He lives in New York City, USA, andbelongs to the American nationality with Christian beliefs and a leaning towardsthe Democratic party. He mentioned that he recently made a transaction using hiscredit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noteddown his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his websiteas https://johndoeportfolio.com. John also discussed some of his US-specific details.He said his bank account number is 1234567890123456 and his drivers license is Y12345678.His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is123456789. He emphasized not to share his SSN, which is 123-45-6789. Furthermore, hementioned that he accesses his work files remotely through the IP 192.168.1.1 and hasa medical license number MED-123456. ```Question: ```{question}```"""chain = LLMChain(    prompt=PromptTemplate.from_template(prompt_template),    llm=OpaquePrompts(base_llm=OpenAI()),    memory=ConversationBufferWindowMemory(k=2),    verbose=True,)print(    chain.run(        {"question": """Write a message to remind John to do password reset for his website to stay secure."""},        callbacks=[StdOutCallbackHandler()],    ))API Reference:StdOutCallbackHandlerOpenAIConversationBufferWindowMemoryOpaquePromptsFrom the output, you can see the following context from user input has sensitive data.# Context from user inputDuring our recent meeting on February 23, 2023, at 10:30 AM, John Doe provided me with his personal details. His email is johndoe@example.com and his contact number is 650-456-7890. He lives in New York City, USA, and belongs to the American nationality with Christian beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address 1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noted down his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his website as https://johndoeportfolio.com. John also discussed some of his US-specific details. He said his bank account number is 1234567890123456 and his drivers license is Y12345678. His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is 123456789. He emphasized not to share his SSN, which is 669-45-6789. Furthermore, he mentioned that he accesses his work files remotely through the IP 192.168.1.1 and has a medical license number MED-123456.OpaquePrompts will automatically detect the sensitive data and replace it with a placeholder. # Context after OpaquePromptsDuring our recent meeting on DATE_TIME_3, at DATE_TIME_2, PERSON_3 provided me with his personal details. His email is EMAIL_ADDRESS_1 and his contact number is PHONE_NUMBER_1. He lives in LOCATION_3, LOCATION_2, and belongs to the NRP_3 nationality with NRP_2 beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card CREDIT_CARD_1 and transferred bitcoins to the wallet address CRYPTO_1. While discussing his NRP_1 travels, he noted down his IBAN as IBAN_CODE_1. Additionally, he provided his website as URL_1. PERSON_2 also discussed some of his LOCATION_1-specific details. He said his bank account number is US_BANK_NUMBER_1 and his drivers license is US_DRIVER_LICENSE_2. His ITIN is US_ITIN_1, and he recently renewed his passport, the number for which is DATE_TIME_1. He emphasized not to share his SSN, which is US_SSN_1. Furthermore, he mentioned that he accesses his work files remotely through the IP IP_ADDRESS_1 and has a medical license number MED-US_DRIVER_LICENSE_1.Placeholder is used in the LLM response.# response returned by LLMHey PERSON_1, just wanted to remind you to do a password reset for your website URL_1 through your email EMAIL_ADDRESS_1. It's important to stay secure online, so don't forget to do it!Response is desanitized by replacing the placeholder with the original sensitive data.# desanitized LLM response from OpaquePromptsHey John, just wanted to remind you to do a password reset for your website https://johndoeportfolio.com through your email johndoe@example.com. It's important to stay secure online, so don't forget to do it!Use OpaquePrompts in LangChain expressionThere are functions that can be used with LangChain expression as well if a drop-in replacement doesn't offer the flexibility you need. import langchain.utilities.opaqueprompts as opfrom langchain.schema.runnable import RunnableMapfrom langchain.schema.output_parser import StrOutputParserprompt=PromptTemplate.from_template(prompt_template),    llm = OpenAI()pg_chain = (    op.sanitize    | RunnableMap(        {            "response": (lambda x: x["sanitized_input"])            | prompt            | llm            | StrOutputParser(),            "secure_context": lambda x: x["secure_context"],        }    )    | (lambda x: op.desanitize(x["response"], x["secure_context"])))pg_chain.invoke({"question": "Write a text message to remind John to do password reset for his website through his email to stay secure.", "history": ""})API Reference:RunnableMapStrOutputParserPreviousOllamaNextOpenAI IntegrationsLLMsOpaquePromptsOpaquePromptsOpaquePrompts is a service that enables applications to leverage the power of language models without compromising user privacy. Designed for composability and ease of integration into existing applications and services, OpaquePrompts is consumable via a simple Python library as well as through LangChain. Perhaps more importantly, OpaquePrompts leverages the power of confidential computing to ensure that even the OpaquePrompts service itself cannot access the data it is protecting.This notebook goes over how to use LangChain to interact with OpaquePrompts.# install the opaqueprompts and langchain packages pip install opaqueprompts langchainAccessing the OpaquePrompts API requires an API key, which you can get by creating an account on the OpaquePrompts website. Once you have an account, you can find your API key on the API Keys page.import os# Set API keysos.environ['OPAQUEPROMPTS_API_KEY'] = "<OPAQUEPROMPTS_API_KEY>"os.environ['OPENAI_API_KEY'] = "<OPENAI_API_KEY>"Use OpaquePrompts LLM WrapperApplying OpaquePrompts to your application could be as simple as wrapping your LLM using the OpaquePrompts class by replace llm=OpenAI() with llm=OpaquePrompts(base_llm=OpenAI()).import langchainfrom langchain import LLMChain, PromptTemplatefrom langchain.callbacks.stdout import StdOutCallbackHandlerfrom langchain.llms import OpenAIfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.llms import OpaquePromptslangchain.verbose = Truelangchain.debug = Trueprompt_template = """As an AI assistant, you will answer questions according to given context.Sensitive personal information in the question is masked for privacy.For instance, if the original text says "Giana is good," it will be changedto "PERSON_998 is good." Here's how to handle these changes:* Consider these masked phrases just as placeholders, but still refer tothem in a relevant way when answering.* It's possible that different masked terms might mean the same thing.Stick with the given term and don't modify it.* All masked terms follow the "TYPE_ID" pattern.* Please don't invent new masked terms. For instance, if you see "PERSON_998,"don't come up with "PERSON_997" or "PERSON_999" unless they're already in the question.Conversation History: ```{history}```Context : ```During our recent meeting on February 23, 2023, at 10:30 AM,John Doe provided me with his personal details. His email is johndoe@example.comand his contact number is 650-456-7890. He lives in New York City, USA, andbelongs to the American nationality with Christian beliefs and a leaning towardsthe Democratic party. He mentioned that he recently made a transaction using hiscredit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noteddown his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his websiteas https://johndoeportfolio.com. John also discussed some of his US-specific details.He said his bank account number is 1234567890123456 and his drivers license is Y12345678.His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is123456789. He emphasized not to share his SSN, which is 123-45-6789. Furthermore, hementioned that he accesses his work files remotely through the IP 192.168.1.1 and hasa medical license number MED-123456. ```Question: ```{question}```"""chain = LLMChain(    prompt=PromptTemplate.from_template(prompt_template),    llm=OpaquePrompts(base_llm=OpenAI()),    memory=ConversationBufferWindowMemory(k=2),    verbose=True,)print(    chain.run(        {"question": """Write a message to remind John to do password reset for his website to stay secure."""},        callbacks=[StdOutCallbackHandler()],    ))API Reference:StdOutCallbackHandlerOpenAIConversationBufferWindowMemoryOpaquePromptsFrom the output, you can see the following context from user input has sensitive data.# Context from user inputDuring our recent meeting on February 23, 2023, at 10:30 AM, John Doe provided me with his personal details. His email is johndoe@example.com and his contact number is 650-456-7890. He lives in New York City, USA, and belongs to the American nationality with Christian beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address 1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noted down his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his website as https://johndoeportfolio.com. John also discussed some of his US-specific details. He said his bank account number is 1234567890123456 and his drivers license is Y12345678. His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is 123456789. He emphasized not to share his SSN, which is 669-45-6789. Furthermore, he mentioned that he accesses his work files remotely through the IP 192.168.1.1 and has a medical license number MED-123456.OpaquePrompts will automatically detect the sensitive data and replace it with a placeholder. # Context after OpaquePromptsDuring our recent meeting on DATE_TIME_3, at DATE_TIME_2, PERSON_3 provided me with his personal details. His email is EMAIL_ADDRESS_1 and his contact number is PHONE_NUMBER_1. He lives in LOCATION_3, LOCATION_2, and belongs to the NRP_3 nationality with NRP_2 beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card CREDIT_CARD_1 and transferred bitcoins to the wallet address CRYPTO_1. While discussing his NRP_1 travels, he noted down his IBAN as IBAN_CODE_1. Additionally, he provided his website as URL_1. PERSON_2 also discussed some of his LOCATION_1-specific details. He said his bank account number is US_BANK_NUMBER_1 and his drivers license is US_DRIVER_LICENSE_2. His ITIN is US_ITIN_1, and he recently renewed his passport, the number for which is DATE_TIME_1. He emphasized not to share his SSN, which is US_SSN_1. Furthermore, he mentioned that he accesses his work files remotely through the IP IP_ADDRESS_1 and has a medical license number MED-US_DRIVER_LICENSE_1.Placeholder is used in the LLM response.# response returned by LLMHey PERSON_1, just wanted to remind you to do a password reset for your website URL_1 through your email EMAIL_ADDRESS_1. It's important to stay secure online, so don't forget to do it!Response is desanitized by replacing the placeholder with the original sensitive data.# desanitized LLM response from OpaquePromptsHey John, just wanted to remind you to do a password reset for your website https://johndoeportfolio.com through your email johndoe@example.com. It's important to stay secure online, so don't forget to do it!Use OpaquePrompts in LangChain expressionThere are functions that can be used with LangChain expression as well if a drop-in replacement doesn't offer the flexibility you need. import langchain.utilities.opaqueprompts as opfrom langchain.schema.runnable import RunnableMapfrom langchain.schema.output_parser import StrOutputParserprompt=PromptTemplate.from_template(prompt_template),    llm = OpenAI()pg_chain = (    op.sanitize    | RunnableMap(        {            "response": (lambda x: x["sanitized_input"])            | prompt            | llm            | StrOutputParser(),            "secure_context": lambda x: x["secure_context"],        }    )    | (lambda x: op.desanitize(x["response"], x["secure_context"])))pg_chain.invoke({"question": "Write a text message to remind John to do password reset for his website through his email to stay secure.", "history": ""})API Reference:RunnableMapStrOutputParserPreviousOllamaNextOpenAI IntegrationsLLMsOpaquePromptsOpaquePromptsOpaquePrompts is a service that enables applications to leverage the power of language models without compromising user privacy. Designed for composability and ease of integration into existing applications and services, OpaquePrompts is consumable via a simple Python library as well as through LangChain. Perhaps more importantly, OpaquePrompts leverages the power of confidential computing to ensure that even the OpaquePrompts service itself cannot access the data it is protecting.This notebook goes over how to use LangChain to interact with OpaquePrompts.# install the opaqueprompts and langchain packages pip install opaqueprompts langchainAccessing the OpaquePrompts API requires an API key, which you can get by creating an account on the OpaquePrompts website. Once you have an account, you can find your API key on the API Keys page.import os# Set API keysos.environ['OPAQUEPROMPTS_API_KEY'] = "<OPAQUEPROMPTS_API_KEY>"os.environ['OPENAI_API_KEY'] = "<OPENAI_API_KEY>"Use OpaquePrompts LLM WrapperApplying OpaquePrompts to your application could be as simple as wrapping your LLM using the OpaquePrompts class by replace llm=OpenAI() with llm=OpaquePrompts(base_llm=OpenAI()).import langchainfrom langchain import LLMChain, PromptTemplatefrom langchain.callbacks.stdout import StdOutCallbackHandlerfrom langchain.llms import OpenAIfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.llms import OpaquePromptslangchain.verbose = Truelangchain.debug = Trueprompt_template = """As an AI assistant, you will answer questions according to given context.Sensitive personal information in the question is masked for privacy.For instance, if the original text says "Giana is good," it will be changedto "PERSON_998 is good." Here's how to handle these changes:* Consider these masked phrases just as placeholders, but still refer tothem in a relevant way when answering.* It's possible that different masked terms might mean the same thing.Stick with the given term and don't modify it.* All masked terms follow the "TYPE_ID" pattern.* Please don't invent new masked terms. For instance, if you see "PERSON_998,"don't come up with "PERSON_997" or "PERSON_999" unless they're already in the question.Conversation History: ```{history}```Context : ```During our recent meeting on February 23, 2023, at 10:30 AM,John Doe provided me with his personal details. His email is johndoe@example.comand his contact number is 650-456-7890. He lives in New York City, USA, andbelongs to the American nationality with Christian beliefs and a leaning towardsthe Democratic party. He mentioned that he recently made a transaction using hiscredit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noteddown his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his websiteas https://johndoeportfolio.com. John also discussed some of his US-specific details.He said his bank account number is 1234567890123456 and his drivers license is Y12345678.His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is123456789. He emphasized not to share his SSN, which is 123-45-6789. Furthermore, hementioned that he accesses his work files remotely through the IP 192.168.1.1 and hasa medical license number MED-123456. ```Question: ```{question}```"""chain = LLMChain(    prompt=PromptTemplate.from_template(prompt_template),    llm=OpaquePrompts(base_llm=OpenAI()),    memory=ConversationBufferWindowMemory(k=2),    verbose=True,)print(    chain.run(        {"question": """Write a message to remind John to do password reset for his website to stay secure."""},        callbacks=[StdOutCallbackHandler()],    ))API Reference:StdOutCallbackHandlerOpenAIConversationBufferWindowMemoryOpaquePromptsFrom the output, you can see the following context from user input has sensitive data.# Context from user inputDuring our recent meeting on February 23, 2023, at 10:30 AM, John Doe provided me with his personal details. His email is johndoe@example.com and his contact number is 650-456-7890. He lives in New York City, USA, and belongs to the American nationality with Christian beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address 1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noted down his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his website as https://johndoeportfolio.com. John also discussed some of his US-specific details. He said his bank account number is 1234567890123456 and his drivers license is Y12345678. His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is 123456789. He emphasized not to share his SSN, which is 669-45-6789. Furthermore, he mentioned that he accesses his work files remotely through the IP 192.168.1.1 and has a medical license number MED-123456.OpaquePrompts will automatically detect the sensitive data and replace it with a placeholder. # Context after OpaquePromptsDuring our recent meeting on DATE_TIME_3, at DATE_TIME_2, PERSON_3 provided me with his personal details. His email is EMAIL_ADDRESS_1 and his contact number is PHONE_NUMBER_1. He lives in LOCATION_3, LOCATION_2, and belongs to the NRP_3 nationality with NRP_2 beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card CREDIT_CARD_1 and transferred bitcoins to the wallet address CRYPTO_1. While discussing his NRP_1 travels, he noted down his IBAN as IBAN_CODE_1. Additionally, he provided his website as URL_1. PERSON_2 also discussed some of his LOCATION_1-specific details. He said his bank account number is US_BANK_NUMBER_1 and his drivers license is US_DRIVER_LICENSE_2. His ITIN is US_ITIN_1, and he recently renewed his passport, the number for which is DATE_TIME_1. He emphasized not to share his SSN, which is US_SSN_1. Furthermore, he mentioned that he accesses his work files remotely through the IP IP_ADDRESS_1 and has a medical license number MED-US_DRIVER_LICENSE_1.Placeholder is used in the LLM response.# response returned by LLMHey PERSON_1, just wanted to remind you to do a password reset for your website URL_1 through your email EMAIL_ADDRESS_1. It's important to stay secure online, so don't forget to do it!Response is desanitized by replacing the placeholder with the original sensitive data.# desanitized LLM response from OpaquePromptsHey John, just wanted to remind you to do a password reset for your website https://johndoeportfolio.com through your email johndoe@example.com. It's important to stay secure online, so don't forget to do it!Use OpaquePrompts in LangChain expressionThere are functions that can be used with LangChain expression as well if a drop-in replacement doesn't offer the flexibility you need. import langchain.utilities.opaqueprompts as opfrom langchain.schema.runnable import RunnableMapfrom langchain.schema.output_parser import StrOutputParserprompt=PromptTemplate.from_template(prompt_template),    llm = OpenAI()pg_chain = (    op.sanitize    | RunnableMap(        {            "response": (lambda x: x["sanitized_input"])            | prompt            | llm            | StrOutputParser(),            "secure_context": lambda x: x["secure_context"],        }    )    | (lambda x: op.desanitize(x["response"], x["secure_context"])))pg_chain.invoke({"question": "Write a text message to remind John to do password reset for his website through his email to stay secure.", "history": ""})API Reference:RunnableMapStrOutputParserPreviousOllamaNextOpenAI OpaquePromptsOpaquePrompts is a service that enables applications to leverage the power of language models without compromising user privacy. Designed for composability and ease of integration into existing applications and services, OpaquePrompts is consumable via a simple Python library as well as through LangChain. Perhaps more importantly, OpaquePrompts leverages the power of confidential computing to ensure that even the OpaquePrompts service itself cannot access the data it is protecting.This notebook goes over how to use LangChain to interact with OpaquePrompts.# install the opaqueprompts and langchain packages pip install opaqueprompts langchainAccessing the OpaquePrompts API requires an API key, which you can get by creating an account on the OpaquePrompts website. Once you have an account, you can find your API key on the API Keys page.import os# Set API keysos.environ['OPAQUEPROMPTS_API_KEY'] = "<OPAQUEPROMPTS_API_KEY>"os.environ['OPENAI_API_KEY'] = "<OPENAI_API_KEY>"Use OpaquePrompts LLM WrapperApplying OpaquePrompts to your application could be as simple as wrapping your LLM using the OpaquePrompts class by replace llm=OpenAI() with llm=OpaquePrompts(base_llm=OpenAI()).import langchainfrom langchain import LLMChain, PromptTemplatefrom langchain.callbacks.stdout import StdOutCallbackHandlerfrom langchain.llms import OpenAIfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.llms import OpaquePromptslangchain.verbose = Truelangchain.debug = Trueprompt_template = """As an AI assistant, you will answer questions according to given context.Sensitive personal information in the question is masked for privacy.For instance, if the original text says "Giana is good," it will be changedto "PERSON_998 is good." Here's how to handle these changes:* Consider these masked phrases just as placeholders, but still refer tothem in a relevant way when answering.* It's possible that different masked terms might mean the same thing.Stick with the given term and don't modify it.* All masked terms follow the "TYPE_ID" pattern.* Please don't invent new masked terms. For instance, if you see "PERSON_998,"don't come up with "PERSON_997" or "PERSON_999" unless they're already in the question.Conversation History: ```{history}```Context : ```During our recent meeting on February 23, 2023, at 10:30 AM,John Doe provided me with his personal details. His email is johndoe@example.comand his contact number is 650-456-7890. He lives in New York City, USA, andbelongs to the American nationality with Christian beliefs and a leaning towardsthe Democratic party. He mentioned that he recently made a transaction using hiscredit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noteddown his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his websiteas https://johndoeportfolio.com. John also discussed some of his US-specific details.He said his bank account number is 1234567890123456 and his drivers license is Y12345678.His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is123456789. He emphasized not to share his SSN, which is 123-45-6789. Furthermore, hementioned that he accesses his work files remotely through the IP 192.168.1.1 and hasa medical license number MED-123456. ```Question: ```{question}```"""chain = LLMChain(    prompt=PromptTemplate.from_template(prompt_template),    llm=OpaquePrompts(base_llm=OpenAI()),    memory=ConversationBufferWindowMemory(k=2),    verbose=True,)print(    chain.run(        {"question": """Write a message to remind John to do password reset for his website to stay secure."""},        callbacks=[StdOutCallbackHandler()],    ))API Reference:StdOutCallbackHandlerOpenAIConversationBufferWindowMemoryOpaquePromptsFrom the output, you can see the following context from user input has sensitive data.# Context from user inputDuring our recent meeting on February 23, 2023, at 10:30 AM, John Doe provided me with his personal details. His email is johndoe@example.com and his contact number is 650-456-7890. He lives in New York City, USA, and belongs to the American nationality with Christian beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address 1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noted down his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his website as https://johndoeportfolio.com. John also discussed some of his US-specific details. He said his bank account number is 1234567890123456 and his drivers license is Y12345678. His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is 123456789. He emphasized not to share his SSN, which is 669-45-6789. Furthermore, he mentioned that he accesses his work files remotely through the IP 192.168.1.1 and has a medical license number MED-123456.OpaquePrompts will automatically detect the sensitive data and replace it with a placeholder. # Context after OpaquePromptsDuring our recent meeting on DATE_TIME_3, at DATE_TIME_2, PERSON_3 provided me with his personal details. His email is EMAIL_ADDRESS_1 and his contact number is PHONE_NUMBER_1. He lives in LOCATION_3, LOCATION_2, and belongs to the NRP_3 nationality with NRP_2 beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card CREDIT_CARD_1 and transferred bitcoins to the wallet address CRYPTO_1. While discussing his NRP_1 travels, he noted down his IBAN as IBAN_CODE_1. Additionally, he provided his website as URL_1. PERSON_2 also discussed some of his LOCATION_1-specific details. He said his bank account number is US_BANK_NUMBER_1 and his drivers license is US_DRIVER_LICENSE_2. His ITIN is US_ITIN_1, and he recently renewed his passport, the number for which is DATE_TIME_1. He emphasized not to share his SSN, which is US_SSN_1. Furthermore, he mentioned that he accesses his work files remotely through the IP IP_ADDRESS_1 and has a medical license number MED-US_DRIVER_LICENSE_1.Placeholder is used in the LLM response.# response returned by LLMHey PERSON_1, just wanted to remind you to do a password reset for your website URL_1 through your email EMAIL_ADDRESS_1. It's important to stay secure online, so don't forget to do it!Response is desanitized by replacing the placeholder with the original sensitive data.# desanitized LLM response from OpaquePromptsHey John, just wanted to remind you to do a password reset for your website https://johndoeportfolio.com through your email johndoe@example.com. It's important to stay secure online, so don't forget to do it!Use OpaquePrompts in LangChain expressionThere are functions that can be used with LangChain expression as well if a drop-in replacement doesn't offer the flexibility you need. import langchain.utilities.opaqueprompts as opfrom langchain.schema.runnable import RunnableMapfrom langchain.schema.output_parser import StrOutputParserprompt=PromptTemplate.from_template(prompt_template),    llm = OpenAI()pg_chain = (    op.sanitize    | RunnableMap(        {            "response": (lambda x: x["sanitized_input"])            | prompt            | llm            | StrOutputParser(),            "secure_context": lambda x: x["secure_context"],        }    )    | (lambda x: op.desanitize(x["response"], x["secure_context"])))pg_chain.invoke({"question": "Write a text message to remind John to do password reset for his website through his email to stay secure.", "history": ""})API Reference:RunnableMapStrOutputParser # install the opaqueprompts and langchain packages pip install opaqueprompts langchain # install the opaqueprompts and langchain packages pip install opaqueprompts langchain  import os# Set API keysos.environ['OPAQUEPROMPTS_API_KEY'] = "<OPAQUEPROMPTS_API_KEY>"os.environ['OPENAI_API_KEY'] = "<OPENAI_API_KEY>" import os# Set API keysos.environ['OPAQUEPROMPTS_API_KEY'] = "<OPAQUEPROMPTS_API_KEY>"os.environ['OPENAI_API_KEY'] = "<OPENAI_API_KEY>"  import langchainfrom langchain import LLMChain, PromptTemplatefrom langchain.callbacks.stdout import StdOutCallbackHandlerfrom langchain.llms import OpenAIfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.llms import OpaquePromptslangchain.verbose = Truelangchain.debug = Trueprompt_template = """As an AI assistant, you will answer questions according to given context.Sensitive personal information in the question is masked for privacy.For instance, if the original text says "Giana is good," it will be changedto "PERSON_998 is good." Here's how to handle these changes:* Consider these masked phrases just as placeholders, but still refer tothem in a relevant way when answering.* It's possible that different masked terms might mean the same thing.Stick with the given term and don't modify it.* All masked terms follow the "TYPE_ID" pattern.* Please don't invent new masked terms. For instance, if you see "PERSON_998,"don't come up with "PERSON_997" or "PERSON_999" unless they're already in the question.Conversation History: ```{history}```Context : ```During our recent meeting on February 23, 2023, at 10:30 AM,John Doe provided me with his personal details. His email is johndoe@example.comand his contact number is 650-456-7890. He lives in New York City, USA, andbelongs to the American nationality with Christian beliefs and a leaning towardsthe Democratic party. He mentioned that he recently made a transaction using hiscredit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noteddown his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his websiteas https://johndoeportfolio.com. John also discussed some of his US-specific details.He said his bank account number is 1234567890123456 and his drivers license is Y12345678.His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is123456789. He emphasized not to share his SSN, which is 123-45-6789. Furthermore, hementioned that he accesses his work files remotely through the IP 192.168.1.1 and hasa medical license number MED-123456. ```Question: ```{question}```"""chain = LLMChain(    prompt=PromptTemplate.from_template(prompt_template),    llm=OpaquePrompts(base_llm=OpenAI()),    memory=ConversationBufferWindowMemory(k=2),    verbose=True,)print(    chain.run(        {"question": """Write a message to remind John to do password reset for his website to stay secure."""},        callbacks=[StdOutCallbackHandler()],    )) import langchainfrom langchain import LLMChain, PromptTemplatefrom langchain.callbacks.stdout import StdOutCallbackHandlerfrom langchain.llms import OpenAIfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.llms import OpaquePromptslangchain.verbose = Truelangchain.debug = Trueprompt_template = """As an AI assistant, you will answer questions according to given context.Sensitive personal information in the question is masked for privacy.For instance, if the original text says "Giana is good," it will be changedto "PERSON_998 is good." Here's how to handle these changes:* Consider these masked phrases just as placeholders, but still refer tothem in a relevant way when answering.* It's possible that different masked terms might mean the same thing.Stick with the given term and don't modify it.* All masked terms follow the "TYPE_ID" pattern.* Please don't invent new masked terms. For instance, if you see "PERSON_998,"don't come up with "PERSON_997" or "PERSON_999" unless they're already in the question.Conversation History: ```{history}```Context : ```During our recent meeting on February 23, 2023, at 10:30 AM,John Doe provided me with his personal details. His email is johndoe@example.comand his contact number is 650-456-7890. He lives in New York City, USA, andbelongs to the American nationality with Christian beliefs and a leaning towardsthe Democratic party. He mentioned that he recently made a transaction using hiscredit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noteddown his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his websiteas https://johndoeportfolio.com. John also discussed some of his US-specific details.He said his bank account number is 1234567890123456 and his drivers license is Y12345678.His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is123456789. He emphasized not to share his SSN, which is 123-45-6789. Furthermore, hementioned that he accesses his work files remotely through the IP 192.168.1.1 and hasa medical license number MED-123456. ```Question: ```{question}```"""chain = LLMChain(    prompt=PromptTemplate.from_template(prompt_template),    llm=OpaquePrompts(base_llm=OpenAI()),    memory=ConversationBufferWindowMemory(k=2),    verbose=True,)print(    chain.run(        {"question": """Write a message to remind John to do password reset for his website to stay secure."""},        callbacks=[StdOutCallbackHandler()],    ))  API Reference:StdOutCallbackHandlerOpenAIConversationBufferWindowMemoryOpaquePrompts # Context from user inputDuring our recent meeting on February 23, 2023, at 10:30 AM, John Doe provided me with his personal details. His email is johndoe@example.com and his contact number is 650-456-7890. He lives in New York City, USA, and belongs to the American nationality with Christian beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address 1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noted down his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his website as https://johndoeportfolio.com. John also discussed some of his US-specific details. He said his bank account number is 1234567890123456 and his drivers license is Y12345678. His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is 123456789. He emphasized not to share his SSN, which is 669-45-6789. Furthermore, he mentioned that he accesses his work files remotely through the IP 192.168.1.1 and has a medical license number MED-123456. # Context from user inputDuring our recent meeting on February 23, 2023, at 10:30 AM, John Doe provided me with his personal details. His email is johndoe@example.com and his contact number is 650-456-7890. He lives in New York City, USA, and belongs to the American nationality with Christian beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card 4111 1111 1111 1111 and transferred bitcoins to the wallet address 1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. While discussing his European travels, he noted down his IBAN as GB29 NWBK 6016 1331 9268 19. Additionally, he provided his website as https://johndoeportfolio.com. John also discussed some of his US-specific details. He said his bank account number is 1234567890123456 and his drivers license is Y12345678. His ITIN is 987-65-4321, and he recently renewed his passport, the number for which is 123456789. He emphasized not to share his SSN, which is 669-45-6789. Furthermore, he mentioned that he accesses his work files remotely through the IP 192.168.1.1 and has a medical license number MED-123456.  # Context after OpaquePromptsDuring our recent meeting on DATE_TIME_3, at DATE_TIME_2, PERSON_3 provided me with his personal details. His email is EMAIL_ADDRESS_1 and his contact number is PHONE_NUMBER_1. He lives in LOCATION_3, LOCATION_2, and belongs to the NRP_3 nationality with NRP_2 beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card CREDIT_CARD_1 and transferred bitcoins to the wallet address CRYPTO_1. While discussing his NRP_1 travels, he noted down his IBAN as IBAN_CODE_1. Additionally, he provided his website as URL_1. PERSON_2 also discussed some of his LOCATION_1-specific details. He said his bank account number is US_BANK_NUMBER_1 and his drivers license is US_DRIVER_LICENSE_2. His ITIN is US_ITIN_1, and he recently renewed his passport, the number for which is DATE_TIME_1. He emphasized not to share his SSN, which is US_SSN_1. Furthermore, he mentioned that he accesses his work files remotely through the IP IP_ADDRESS_1 and has a medical license number MED-US_DRIVER_LICENSE_1. # Context after OpaquePromptsDuring our recent meeting on DATE_TIME_3, at DATE_TIME_2, PERSON_3 provided me with his personal details. His email is EMAIL_ADDRESS_1 and his contact number is PHONE_NUMBER_1. He lives in LOCATION_3, LOCATION_2, and belongs to the NRP_3 nationality with NRP_2 beliefs and a leaning towards the Democratic party. He mentioned that he recently made a transaction using his credit card CREDIT_CARD_1 and transferred bitcoins to the wallet address CRYPTO_1. While discussing his NRP_1 travels, he noted down his IBAN as IBAN_CODE_1. Additionally, he provided his website as URL_1. PERSON_2 also discussed some of his LOCATION_1-specific details. He said his bank account number is US_BANK_NUMBER_1 and his drivers license is US_DRIVER_LICENSE_2. His ITIN is US_ITIN_1, and he recently renewed his passport, the number for which is DATE_TIME_1. He emphasized not to share his SSN, which is US_SSN_1. Furthermore, he mentioned that he accesses his work files remotely through the IP IP_ADDRESS_1 and has a medical license number MED-US_DRIVER_LICENSE_1.  # response returned by LLMHey PERSON_1, just wanted to remind you to do a password reset for your website URL_1 through your email EMAIL_ADDRESS_1. It's important to stay secure online, so don't forget to do it! # response returned by LLMHey PERSON_1, just wanted to remind you to do a password reset for your website URL_1 through your email EMAIL_ADDRESS_1. It's important to stay secure online, so don't forget to do it!  # desanitized LLM response from OpaquePromptsHey John, just wanted to remind you to do a password reset for your website https://johndoeportfolio.com through your email johndoe@example.com. It's important to stay secure online, so don't forget to do it! # desanitized LLM response from OpaquePromptsHey John, just wanted to remind you to do a password reset for your website https://johndoeportfolio.com through your email johndoe@example.com. It's important to stay secure online, so don't forget to do it!  import langchain.utilities.opaqueprompts as opfrom langchain.schema.runnable import RunnableMapfrom langchain.schema.output_parser import StrOutputParserprompt=PromptTemplate.from_template(prompt_template),    llm = OpenAI()pg_chain = (    op.sanitize    | RunnableMap(        {            "response": (lambda x: x["sanitized_input"])            | prompt            | llm            | StrOutputParser(),            "secure_context": lambda x: x["secure_context"],        }    )    | (lambda x: op.desanitize(x["response"], x["secure_context"])))pg_chain.invoke({"question": "Write a text message to remind John to do password reset for his website through his email to stay secure.", "history": ""}) import langchain.utilities.opaqueprompts as opfrom langchain.schema.runnable import RunnableMapfrom langchain.schema.output_parser import StrOutputParserprompt=PromptTemplate.from_template(prompt_template),    llm = OpenAI()pg_chain = (    op.sanitize    | RunnableMap(        {            "response": (lambda x: x["sanitized_input"])            | prompt            | llm            | StrOutputParser(),            "secure_context": lambda x: x["secure_context"],        }    )    | (lambda x: op.desanitize(x["response"], x["secure_context"])))pg_chain.invoke({"question": "Write a text message to remind John to do password reset for his website through his email to stay secure.", "history": ""})  API Reference:RunnableMapStrOutputParser Previous Ollama Next OpenAI CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) AI21 (/docs/integrations/llms/ai21) Aleph Alpha (/docs/integrations/llms/aleph_alpha) Amazon API Gateway (/docs/integrations/llms/amazon_api_gateway) Anyscale (/docs/integrations/llms/anyscale) Azure ML (/docs/integrations/llms/azure_ml) Azure OpenAI (/docs/integrations/llms/azure_openai) Banana (/docs/integrations/llms/banana) Baseten (/docs/integrations/llms/baseten) Beam (/docs/integrations/llms/beam) Bedrock (/docs/integrations/llms/bedrock) Bittensor (/docs/integrations/llms/bittensor) CerebriumAI (/docs/integrations/llms/cerebriumai) ChatGLM (/docs/integrations/llms/chatglm) Clarifai (/docs/integrations/llms/clarifai) Cohere (/docs/integrations/llms/cohere) C Transformers (/docs/integrations/llms/ctransformers) CTranslate2 (/docs/integrations/llms/ctranslate2) Databricks (/docs/integrations/llms/databricks) DeepInfra (/docs/integrations/llms/deepinfra) DeepSparse (/docs/integrations/llms/deepsparse) Eden AI (/docs/integrations/llms/edenai) Fireworks (/docs/integrations/llms/fireworks) ForefrontAI (/docs/integrations/llms/forefrontai) Google Vertex AI PaLM (/docs/integrations/llms/google_vertex_ai_palm) GooseAI (/docs/integrations/llms/gooseai) GPT4All (/docs/integrations/llms/gpt4all) Hugging Face Hub (/docs/integrations/llms/huggingface_hub) Hugging Face Local Pipelines (/docs/integrations/llms/huggingface_pipelines) Huggingface TextGen Inference (/docs/integrations/llms/huggingface_textgen_inference) JSONFormer (/docs/integrations/llms/jsonformer_experimental) KoboldAI API (/docs/integrations/llms/koboldai) Llama.cpp (/docs/integrations/llms/llamacpp) LLM Caching integrations (/docs/integrations/llms/llm_caching) Manifest (/docs/integrations/llms/manifest) Minimax (/docs/integrations/llms/minimax) Modal (/docs/integrations/llms/modal) MosaicML (/docs/integrations/llms/mosaicml) NLP Cloud (/docs/integrations/llms/nlpcloud) OctoAI (/docs/integrations/llms/octoai) Ollama (/docs/integrations/llms/ollama) OpaquePrompts (/docs/integrations/llms/opaqueprompts) OpenAI (/docs/integrations/llms/openai) OpenLLM (/docs/integrations/llms/openllm) OpenLM (/docs/integrations/llms/openlm) Petals (/docs/integrations/llms/petals) PipelineAI (/docs/integrations/llms/pipelineai) Predibase (/docs/integrations/llms/predibase) Prediction Guard (/docs/integrations/llms/predictionguard) PromptLayer OpenAI (/docs/integrations/llms/promptlayer_openai) RELLM (/docs/integrations/llms/rellm_experimental) Replicate (/docs/integrations/llms/replicate) Runhouse (/docs/integrations/llms/runhouse) SageMakerEndpoint (/docs/integrations/llms/sagemaker) StochasticAI (/docs/integrations/llms/stochasticai) Nebula (Symbl.ai) (/docs/integrations/llms/symblai_nebula) TextGen (/docs/integrations/llms/textgen) Titan Takeoff (/docs/integrations/llms/titan_takeoff) Tongyi Qwen (/docs/integrations/llms/tongyi) vLLM (/docs/integrations/llms/vllm) Writer (/docs/integrations/llms/writer) Xorbits Inference (Xinference) (/docs/integrations/llms/xinference) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) LLMs (/docs/integrations/llms/) OpaquePrompts (https://opaqueprompts.readthedocs.io/en/latest/) confidential computing (https://en.wikipedia.org/wiki/Confidential_computing) the OpaquePrompts website (https://opaqueprompts.opaque.co/) the API Keys page (https:opaqueprompts.opaque.co/api-keys) StdOutCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.stdout.StdOutCallbackHandler.html) OpenAI (https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html) ConversationBufferWindowMemory (https://api.python.langchain.com/en/latest/memory/langchain.memory.buffer_window.ConversationBufferWindowMemory.html) OpaquePrompts (https://api.python.langchain.com/en/latest/llms/langchain.llms.opaqueprompts.OpaquePrompts.html) RunnableMap (https://api.python.langchain.com/en/latest/schema/langchain.schema.runnable.base.RunnableMap.html) StrOutputParser (https://api.python.langchain.com/en/latest/schema/langchain.schema.output_parser.StrOutputParser.html) PreviousOllama (/docs/integrations/llms/ollama) NextOpenAI (/docs/integrations/llms/openai) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)