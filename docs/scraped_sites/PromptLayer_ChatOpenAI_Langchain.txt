This example showcases how to connect to PromptLayer to start recording your ChatOpenAI requests. The promptlayer package is required to use PromptLayer with OpenAI. Install promptlayer using pip. You can create a PromptLayer API Key at www.promptlayer.com by clicking the settings cog in the navbar. Set it as an environment variable called PROMPTLAYER_API_KEY. You can optionally pass in pl_tags to track your requests with PromptLayer's tagging feature. The above request should now appear on your PromptLayer dashboard. If you would like to use any of the PromptLayer tracking features, you need to pass the argument return_pl_id when instantializing the PromptLayer LLM to get the request id.   Using this allows you to track the performance of your model in the PromptLayer dashboard. If you are using a prompt template, you can attach a template to a request as well. Overall, this gives you the opportunity to track the performance of different templates and models in the PromptLayer dashboard. IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Callbacks Chat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAI Anthropic Anthropic Functions Anyscale Azure AzureML Chat Online Endpoint Bedrock Chat ERNIE-Bot Chat Google Cloud Platform Vertex AI PaLM JinaChat Konko üöÖ LiteLLM Llama API Ollama OpenAI PromptLayer ChatOpenAI Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations Chat models PromptLayer ChatOpenAI PromptLayerChatOpenAI HumanMessage Install PromptLayer Imports Set the Environment API Key Use the PromptLayerOpenAI LLM like normal Using PromptLayer Track Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsChat modelsPromptLayer ChatOpenAIOn this pagePromptLayer ChatOpenAIThis example showcases how to connect to PromptLayer to start recording your ChatOpenAI requests.Install PromptLayer‚ÄãThe promptlayer package is required to use PromptLayer with OpenAI. Install promptlayer using pip.pip install promptlayerImports‚Äãimport osfrom langchain.chat_models import PromptLayerChatOpenAIfrom langchain.schema import HumanMessageAPI Reference:PromptLayerChatOpenAIHumanMessageSet the Environment API Key‚ÄãYou can create a PromptLayer API Key at www.promptlayer.com by clicking the settings cog in the navbar.Set it as an environment variable called PROMPTLAYER_API_KEY.os.environ["PROMPTLAYER_API_KEY"] = "**********"Use the PromptLayerOpenAI LLM like normal‚ÄãYou can optionally pass in pl_tags to track your requests with PromptLayer's tagging feature.chat = PromptLayerChatOpenAI(pl_tags=["langchain"])chat([HumanMessage(content="I am a cat and I want")])    AIMessage(content='to take a nap in a cozy spot. I search around for a suitable place and finally settle on a soft cushion on the window sill. I curl up into a ball and close my eyes, relishing the warmth of the sun on my fur. As I drift off to sleep, I can hear the birds chirping outside and feel the gentle breeze blowing through the window. This is the life of a contented cat.', additional_kwargs={})The above request should now appear on your PromptLayer dashboard.Using PromptLayer Track‚ÄãIf you would like to use any of the PromptLayer tracking features, you need to pass the argument return_pl_id when instantializing the PromptLayer LLM to get the request id.  chat = PromptLayerChatOpenAI(return_pl_id=True)chat_results = chat.generate([[HumanMessage(content="I am a cat and I want")]])for res in chat_results.generations:    pl_request_id = res[0].generation_info["pl_request_id"]    promptlayer.track.score(request_id=pl_request_id, score=100)Using this allows you to track the performance of your model in the PromptLayer dashboard. If you are using a prompt template, you can attach a template to a request as well. Overall, this gives you the opportunity to track the performance of different templates and models in the PromptLayer dashboard.PreviousOpenAINextChat loadersInstall PromptLayerImportsSet the Environment API KeyUse the PromptLayerOpenAI LLM like normalUsing PromptLayer TrackCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsChat modelsPromptLayer ChatOpenAIOn this pagePromptLayer ChatOpenAIThis example showcases how to connect to PromptLayer to start recording your ChatOpenAI requests.Install PromptLayer‚ÄãThe promptlayer package is required to use PromptLayer with OpenAI. Install promptlayer using pip.pip install promptlayerImports‚Äãimport osfrom langchain.chat_models import PromptLayerChatOpenAIfrom langchain.schema import HumanMessageAPI Reference:PromptLayerChatOpenAIHumanMessageSet the Environment API Key‚ÄãYou can create a PromptLayer API Key at www.promptlayer.com by clicking the settings cog in the navbar.Set it as an environment variable called PROMPTLAYER_API_KEY.os.environ["PROMPTLAYER_API_KEY"] = "**********"Use the PromptLayerOpenAI LLM like normal‚ÄãYou can optionally pass in pl_tags to track your requests with PromptLayer's tagging feature.chat = PromptLayerChatOpenAI(pl_tags=["langchain"])chat([HumanMessage(content="I am a cat and I want")])    AIMessage(content='to take a nap in a cozy spot. I search around for a suitable place and finally settle on a soft cushion on the window sill. I curl up into a ball and close my eyes, relishing the warmth of the sun on my fur. As I drift off to sleep, I can hear the birds chirping outside and feel the gentle breeze blowing through the window. This is the life of a contented cat.', additional_kwargs={})The above request should now appear on your PromptLayer dashboard.Using PromptLayer Track‚ÄãIf you would like to use any of the PromptLayer tracking features, you need to pass the argument return_pl_id when instantializing the PromptLayer LLM to get the request id.  chat = PromptLayerChatOpenAI(return_pl_id=True)chat_results = chat.generate([[HumanMessage(content="I am a cat and I want")]])for res in chat_results.generations:    pl_request_id = res[0].generation_info["pl_request_id"]    promptlayer.track.score(request_id=pl_request_id, score=100)Using this allows you to track the performance of your model in the PromptLayer dashboard. If you are using a prompt template, you can attach a template to a request as well. Overall, this gives you the opportunity to track the performance of different templates and models in the PromptLayer dashboard.PreviousOpenAINextChat loadersInstall PromptLayerImportsSet the Environment API KeyUse the PromptLayerOpenAI LLM like normalUsing PromptLayer Track IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsChat modelsPromptLayer ChatOpenAIOn this pagePromptLayer ChatOpenAIThis example showcases how to connect to PromptLayer to start recording your ChatOpenAI requests.Install PromptLayer‚ÄãThe promptlayer package is required to use PromptLayer with OpenAI. Install promptlayer using pip.pip install promptlayerImports‚Äãimport osfrom langchain.chat_models import PromptLayerChatOpenAIfrom langchain.schema import HumanMessageAPI Reference:PromptLayerChatOpenAIHumanMessageSet the Environment API Key‚ÄãYou can create a PromptLayer API Key at www.promptlayer.com by clicking the settings cog in the navbar.Set it as an environment variable called PROMPTLAYER_API_KEY.os.environ["PROMPTLAYER_API_KEY"] = "**********"Use the PromptLayerOpenAI LLM like normal‚ÄãYou can optionally pass in pl_tags to track your requests with PromptLayer's tagging feature.chat = PromptLayerChatOpenAI(pl_tags=["langchain"])chat([HumanMessage(content="I am a cat and I want")])    AIMessage(content='to take a nap in a cozy spot. I search around for a suitable place and finally settle on a soft cushion on the window sill. I curl up into a ball and close my eyes, relishing the warmth of the sun on my fur. As I drift off to sleep, I can hear the birds chirping outside and feel the gentle breeze blowing through the window. This is the life of a contented cat.', additional_kwargs={})The above request should now appear on your PromptLayer dashboard.Using PromptLayer Track‚ÄãIf you would like to use any of the PromptLayer tracking features, you need to pass the argument return_pl_id when instantializing the PromptLayer LLM to get the request id.  chat = PromptLayerChatOpenAI(return_pl_id=True)chat_results = chat.generate([[HumanMessage(content="I am a cat and I want")]])for res in chat_results.generations:    pl_request_id = res[0].generation_info["pl_request_id"]    promptlayer.track.score(request_id=pl_request_id, score=100)Using this allows you to track the performance of your model in the PromptLayer dashboard. If you are using a prompt template, you can attach a template to a request as well. Overall, this gives you the opportunity to track the performance of different templates and models in the PromptLayer dashboard.PreviousOpenAINextChat loadersInstall PromptLayerImportsSet the Environment API KeyUse the PromptLayerOpenAI LLM like normalUsing PromptLayer Track IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksChat modelsAnthropicAnthropic FunctionsAnyscaleAzureAzureML Chat Online EndpointBedrock ChatERNIE-Bot ChatGoogle Cloud Platform Vertex AI PaLMJinaChatKonkoüöÖ LiteLLMLlama APIOllamaOpenAIPromptLayer ChatOpenAIChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsChat modelsPromptLayer ChatOpenAIOn this pagePromptLayer ChatOpenAIThis example showcases how to connect to PromptLayer to start recording your ChatOpenAI requests.Install PromptLayer‚ÄãThe promptlayer package is required to use PromptLayer with OpenAI. Install promptlayer using pip.pip install promptlayerImports‚Äãimport osfrom langchain.chat_models import PromptLayerChatOpenAIfrom langchain.schema import HumanMessageAPI Reference:PromptLayerChatOpenAIHumanMessageSet the Environment API Key‚ÄãYou can create a PromptLayer API Key at www.promptlayer.com by clicking the settings cog in the navbar.Set it as an environment variable called PROMPTLAYER_API_KEY.os.environ["PROMPTLAYER_API_KEY"] = "**********"Use the PromptLayerOpenAI LLM like normal‚ÄãYou can optionally pass in pl_tags to track your requests with PromptLayer's tagging feature.chat = PromptLayerChatOpenAI(pl_tags=["langchain"])chat([HumanMessage(content="I am a cat and I want")])    AIMessage(content='to take a nap in a cozy spot. I search around for a suitable place and finally settle on a soft cushion on the window sill. I curl up into a ball and close my eyes, relishing the warmth of the sun on my fur. As I drift off to sleep, I can hear the birds chirping outside and feel the gentle breeze blowing through the window. This is the life of a contented cat.', additional_kwargs={})The above request should now appear on your PromptLayer dashboard.Using PromptLayer Track‚ÄãIf you would like to use any of the PromptLayer tracking features, you need to pass the argument return_pl_id when instantializing the PromptLayer LLM to get the request id.  chat = PromptLayerChatOpenAI(return_pl_id=True)chat_results = chat.generate([[HumanMessage(content="I am a cat and I want")]])for res in chat_results.generations:    pl_request_id = res[0].generation_info["pl_request_id"]    promptlayer.track.score(request_id=pl_request_id, score=100)Using this allows you to track the performance of your model in the PromptLayer dashboard. If you are using a prompt template, you can attach a template to a request as well. Overall, this gives you the opportunity to track the performance of different templates and models in the PromptLayer dashboard.PreviousOpenAINextChat loadersInstall PromptLayerImportsSet the Environment API KeyUse the PromptLayerOpenAI LLM like normalUsing PromptLayer Track IntegrationsChat modelsPromptLayer ChatOpenAIOn this pagePromptLayer ChatOpenAIThis example showcases how to connect to PromptLayer to start recording your ChatOpenAI requests.Install PromptLayer‚ÄãThe promptlayer package is required to use PromptLayer with OpenAI. Install promptlayer using pip.pip install promptlayerImports‚Äãimport osfrom langchain.chat_models import PromptLayerChatOpenAIfrom langchain.schema import HumanMessageAPI Reference:PromptLayerChatOpenAIHumanMessageSet the Environment API Key‚ÄãYou can create a PromptLayer API Key at www.promptlayer.com by clicking the settings cog in the navbar.Set it as an environment variable called PROMPTLAYER_API_KEY.os.environ["PROMPTLAYER_API_KEY"] = "**********"Use the PromptLayerOpenAI LLM like normal‚ÄãYou can optionally pass in pl_tags to track your requests with PromptLayer's tagging feature.chat = PromptLayerChatOpenAI(pl_tags=["langchain"])chat([HumanMessage(content="I am a cat and I want")])    AIMessage(content='to take a nap in a cozy spot. I search around for a suitable place and finally settle on a soft cushion on the window sill. I curl up into a ball and close my eyes, relishing the warmth of the sun on my fur. As I drift off to sleep, I can hear the birds chirping outside and feel the gentle breeze blowing through the window. This is the life of a contented cat.', additional_kwargs={})The above request should now appear on your PromptLayer dashboard.Using PromptLayer Track‚ÄãIf you would like to use any of the PromptLayer tracking features, you need to pass the argument return_pl_id when instantializing the PromptLayer LLM to get the request id.  chat = PromptLayerChatOpenAI(return_pl_id=True)chat_results = chat.generate([[HumanMessage(content="I am a cat and I want")]])for res in chat_results.generations:    pl_request_id = res[0].generation_info["pl_request_id"]    promptlayer.track.score(request_id=pl_request_id, score=100)Using this allows you to track the performance of your model in the PromptLayer dashboard. If you are using a prompt template, you can attach a template to a request as well. Overall, this gives you the opportunity to track the performance of different templates and models in the PromptLayer dashboard.PreviousOpenAINextChat loaders IntegrationsChat modelsPromptLayer ChatOpenAIOn this pagePromptLayer ChatOpenAIThis example showcases how to connect to PromptLayer to start recording your ChatOpenAI requests.Install PromptLayer‚ÄãThe promptlayer package is required to use PromptLayer with OpenAI. Install promptlayer using pip.pip install promptlayerImports‚Äãimport osfrom langchain.chat_models import PromptLayerChatOpenAIfrom langchain.schema import HumanMessageAPI Reference:PromptLayerChatOpenAIHumanMessageSet the Environment API Key‚ÄãYou can create a PromptLayer API Key at www.promptlayer.com by clicking the settings cog in the navbar.Set it as an environment variable called PROMPTLAYER_API_KEY.os.environ["PROMPTLAYER_API_KEY"] = "**********"Use the PromptLayerOpenAI LLM like normal‚ÄãYou can optionally pass in pl_tags to track your requests with PromptLayer's tagging feature.chat = PromptLayerChatOpenAI(pl_tags=["langchain"])chat([HumanMessage(content="I am a cat and I want")])    AIMessage(content='to take a nap in a cozy spot. I search around for a suitable place and finally settle on a soft cushion on the window sill. I curl up into a ball and close my eyes, relishing the warmth of the sun on my fur. As I drift off to sleep, I can hear the birds chirping outside and feel the gentle breeze blowing through the window. This is the life of a contented cat.', additional_kwargs={})The above request should now appear on your PromptLayer dashboard.Using PromptLayer Track‚ÄãIf you would like to use any of the PromptLayer tracking features, you need to pass the argument return_pl_id when instantializing the PromptLayer LLM to get the request id.  chat = PromptLayerChatOpenAI(return_pl_id=True)chat_results = chat.generate([[HumanMessage(content="I am a cat and I want")]])for res in chat_results.generations:    pl_request_id = res[0].generation_info["pl_request_id"]    promptlayer.track.score(request_id=pl_request_id, score=100)Using this allows you to track the performance of your model in the PromptLayer dashboard. If you are using a prompt template, you can attach a template to a request as well. Overall, this gives you the opportunity to track the performance of different templates and models in the PromptLayer dashboard.PreviousOpenAINextChat loaders On this page PromptLayer ChatOpenAIThis example showcases how to connect to PromptLayer to start recording your ChatOpenAI requests.Install PromptLayer‚ÄãThe promptlayer package is required to use PromptLayer with OpenAI. Install promptlayer using pip.pip install promptlayerImports‚Äãimport osfrom langchain.chat_models import PromptLayerChatOpenAIfrom langchain.schema import HumanMessageAPI Reference:PromptLayerChatOpenAIHumanMessageSet the Environment API Key‚ÄãYou can create a PromptLayer API Key at www.promptlayer.com by clicking the settings cog in the navbar.Set it as an environment variable called PROMPTLAYER_API_KEY.os.environ["PROMPTLAYER_API_KEY"] = "**********"Use the PromptLayerOpenAI LLM like normal‚ÄãYou can optionally pass in pl_tags to track your requests with PromptLayer's tagging feature.chat = PromptLayerChatOpenAI(pl_tags=["langchain"])chat([HumanMessage(content="I am a cat and I want")])    AIMessage(content='to take a nap in a cozy spot. I search around for a suitable place and finally settle on a soft cushion on the window sill. I curl up into a ball and close my eyes, relishing the warmth of the sun on my fur. As I drift off to sleep, I can hear the birds chirping outside and feel the gentle breeze blowing through the window. This is the life of a contented cat.', additional_kwargs={})The above request should now appear on your PromptLayer dashboard.Using PromptLayer Track‚ÄãIf you would like to use any of the PromptLayer tracking features, you need to pass the argument return_pl_id when instantializing the PromptLayer LLM to get the request id.  chat = PromptLayerChatOpenAI(return_pl_id=True)chat_results = chat.generate([[HumanMessage(content="I am a cat and I want")]])for res in chat_results.generations:    pl_request_id = res[0].generation_info["pl_request_id"]    promptlayer.track.score(request_id=pl_request_id, score=100)Using this allows you to track the performance of your model in the PromptLayer dashboard. If you are using a prompt template, you can attach a template to a request as well. Overall, this gives you the opportunity to track the performance of different templates and models in the PromptLayer dashboard. pip install promptlayer pip install promptlayer  import osfrom langchain.chat_models import PromptLayerChatOpenAIfrom langchain.schema import HumanMessage import osfrom langchain.chat_models import PromptLayerChatOpenAIfrom langchain.schema import HumanMessage  API Reference:PromptLayerChatOpenAIHumanMessage os.environ["PROMPTLAYER_API_KEY"] = "**********" os.environ["PROMPTLAYER_API_KEY"] = "**********"  chat = PromptLayerChatOpenAI(pl_tags=["langchain"])chat([HumanMessage(content="I am a cat and I want")]) chat = PromptLayerChatOpenAI(pl_tags=["langchain"])chat([HumanMessage(content="I am a cat and I want")])      AIMessage(content='to take a nap in a cozy spot. I search around for a suitable place and finally settle on a soft cushion on the window sill. I curl up into a ball and close my eyes, relishing the warmth of the sun on my fur. As I drift off to sleep, I can hear the birds chirping outside and feel the gentle breeze blowing through the window. This is the life of a contented cat.', additional_kwargs={})     AIMessage(content='to take a nap in a cozy spot. I search around for a suitable place and finally settle on a soft cushion on the window sill. I curl up into a ball and close my eyes, relishing the warmth of the sun on my fur. As I drift off to sleep, I can hear the birds chirping outside and feel the gentle breeze blowing through the window. This is the life of a contented cat.', additional_kwargs={})     AIMessage(content='to take a nap in a cozy spot. I search around for a suitable place and finally settle on a soft cushion on the window sill. I curl up into a ball and close my eyes, relishing the warmth of the sun on my fur. As I drift off to sleep, I can hear the birds chirping outside and feel the gentle breeze blowing through the window. This is the life of a contented cat.', additional_kwargs={})  chat = PromptLayerChatOpenAI(return_pl_id=True)chat_results = chat.generate([[HumanMessage(content="I am a cat and I want")]])for res in chat_results.generations:    pl_request_id = res[0].generation_info["pl_request_id"]    promptlayer.track.score(request_id=pl_request_id, score=100) chat = PromptLayerChatOpenAI(return_pl_id=True)chat_results = chat.generate([[HumanMessage(content="I am a cat and I want")]])for res in chat_results.generations:    pl_request_id = res[0].generation_info["pl_request_id"]    promptlayer.track.score(request_id=pl_request_id, score=100)  Previous OpenAI Next Chat loaders Install PromptLayerImportsSet the Environment API KeyUse the PromptLayerOpenAI LLM like normalUsing PromptLayer Track Install PromptLayerImportsSet the Environment API KeyUse the PromptLayerOpenAI LLM like normalUsing PromptLayer Track CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Anthropic (/docs/integrations/chat/anthropic) Anthropic Functions (/docs/integrations/chat/anthropic_functions) Anyscale (/docs/integrations/chat/anyscale) Azure (/docs/integrations/chat/azure_chat_openai) AzureML Chat Online Endpoint (/docs/integrations/chat/azureml_chat_endpoint) Bedrock Chat (/docs/integrations/chat/bedrock) ERNIE-Bot Chat (/docs/integrations/chat/ernie) Google Cloud Platform Vertex AI PaLM (/docs/integrations/chat/google_vertex_ai_palm) JinaChat (/docs/integrations/chat/jinachat) Konko (/docs/integrations/chat/konko) üöÖ LiteLLM (/docs/integrations/chat/litellm) Llama API (/docs/integrations/chat/llama_api) Ollama (/docs/integrations/chat/ollama) OpenAI (/docs/integrations/chat/openai) PromptLayer ChatOpenAI (/docs/integrations/chat/promptlayer_chatopenai) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Chat models (/docs/integrations/chat/) PromptLayer (https://www.promptlayer.com) ‚Äã (#install-promptlayer) ‚Äã (#imports) PromptLayerChatOpenAI (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.promptlayer_openai.PromptLayerChatOpenAI.html) HumanMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.HumanMessage.html) ‚Äã (#set-the-environment-api-key) www.promptlayer.com (https://www.promptlayer.com) ‚Äã (#use-the-promptlayeropenai-llm-like-normal) PromptLayer dashboard (https://www.promptlayer.com) ‚Äã (#using-promptlayer-track) PromptLayer tracking features (https://magniv.notion.site/Track-4deee1b1f7a34c1680d085f82567dab9) PreviousOpenAI (/docs/integrations/chat/openai) NextChat loaders (/docs/integrations/chat_loaders/) Install PromptLayer (#install-promptlayer) Imports (#imports) Set the Environment API Key (#set-the-environment-api-key) Use the PromptLayerOpenAI LLM like normal (#use-the-promptlayeropenai-llm-like-normal) Using PromptLayer Track (#using-promptlayer-track) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)