Figma is a collaborative web application for interface design. This notebook covers how to load data from the Figma REST API into a format that can be ingested into LangChain, along with example usage for code generation. The Figma API Requires an access token, node_ids, and a file key. The file key can be pulled from the URL.  https://www.figma.com/file/{filekey}/sampleFilename Node IDs are also available in the URL. Click on anything and look for the '?node-id={node_id}' param. Access token instructions are in the Figma help center article: https://help.figma.com/hc/en-us/articles/8085703771159-Manage-personal-access-tokens Returns the following in response.content: IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Callbacks Chat models Chat loaders Document loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcripts Etherscan Loader acreom Airbyte CDK Airbyte Gong Airbyte Hubspot Airbyte JSON Airbyte Salesforce Airbyte Shopify Airbyte Stripe Airbyte Typeform Airbyte Zendesk Support Airtable Alibaba Cloud MaxCompute Apify Dataset ArcGIS Arxiv AssemblyAI Audio Transcripts Async Chromium AsyncHtmlLoader AWS S3 Directory AWS S3 File AZLyrics Azure Blob Storage Container Azure Blob Storage File Azure Document Intelligence BibTeX BiliBili Blackboard Blockchain Brave Search Browserless ChatGPT Data College Confidential Concurrent Loader Confluence CoNLL-U Copy Paste CSV Cube Semantic Layer Datadog Logs Diffbot Discord Docugami Dropbox DuckDB Email Embaas EPub EverNote example_data Microsoft Excel Facebook Chat Fauna Figma Geopandas Git GitBook GitHub Google BigQuery Google Cloud Storage Directory Google Cloud Storage File Google Drive Grobid Gutenberg Hacker News Huawei OBS Directory Huawei OBS File HuggingFace dataset iFixit Images Image captions IMSDb Iugu Joplin Jupyter Notebook LarkSuite (FeiShu) Mastodon MediaWikiDump MergeDocLoader mhtml Microsoft OneDrive Microsoft PowerPoint Microsoft SharePoint Microsoft Word Modern Treasury News URL Notion DB 1/2 Notion DB 2/2 Nuclia Understanding API document loader Obsidian Open Document Format (ODT) Open City Data Org-mode Pandas DataFrame Amazon Textract Polars DataFrame Psychic PubMed PySpark DataFrame Loader ReadTheDocs Documentation Recursive URL Loader Reddit Roam Rockset RSS Feeds RST Sitemap Slack Snowflake Source Code Spreedly Stripe Subtitle Telegram Tencent COS Directory Tencent COS File TensorFlow Datasets 2Markdown TOML Trello TSV Twitter Unstructured File URL Weather WebBaseLoader WhatsApp Chat Wikipedia XML Xorbits Pandas DataFrame Loading documents from a YouTube url YouTube transcripts Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations Document loaders Figma FigmaFileLoader CharacterTextSplitter ChatOpenAI VectorstoreIndexCreator ConversationChain LLMChain ConversationBufferWindowMemory ChatPromptTemplate SystemMessagePromptTemplate AIMessagePromptTemplate HumanMessagePromptTemplate Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsDocument loadersFigmaFigmaFigma is a collaborative web application for interface design.This notebook covers how to load data from the Figma REST API into a format that can be ingested into LangChain, along with example usage for code generation.import osfrom langchain.document_loaders.figma import FigmaFileLoaderfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.chat_models import ChatOpenAIfrom langchain.indexes import VectorstoreIndexCreatorfrom langchain.chains import ConversationChain, LLMChainfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)API Reference:FigmaFileLoaderCharacterTextSplitterChatOpenAIVectorstoreIndexCreatorConversationChainLLMChainConversationBufferWindowMemoryChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateThe Figma API Requires an access token, node_ids, and a file key.The file key can be pulled from the URL.  https://www.figma.com/file/{filekey}/sampleFilenameNode IDs are also available in the URL. Click on anything and look for the '?node-id={node_id}' param.Access token instructions are in the Figma help center article: https://help.figma.com/hc/en-us/articles/8085703771159-Manage-personal-access-tokensfigma_loader = FigmaFileLoader(    os.environ.get("ACCESS_TOKEN"),    os.environ.get("NODE_IDS"),    os.environ.get("FILE_KEY"),)# see https://python.langchain.com/en/latest/modules/data_connection/getting_started.html for more detailsindex = VectorstoreIndexCreator().from_loaders([figma_loader])figma_doc_retriever = index.vectorstore.as_retriever()def generate_code(human_input):    # I have no idea if the Jon Carmack thing makes for better code. YMMV.    # See https://python.langchain.com/en/latest/modules/models/chat/getting_started.html for chat info    system_prompt_template = """You are expert coder Jon Carmack. Use the provided design context to create idomatic HTML/CSS code as possible based on the user request.    Everything must be inline in one file and your response must be directly renderable by the browser.    Figma file nodes and metadata: {context}"""    human_prompt_template = "Code the {text}. Ensure it's mobile responsive"    system_message_prompt = SystemMessagePromptTemplate.from_template(        system_prompt_template    )    human_message_prompt = HumanMessagePromptTemplate.from_template(        human_prompt_template    )    # delete the gpt-4 model_name to use the default gpt-3.5 turbo for faster results    gpt_4 = ChatOpenAI(temperature=0.02, model_name="gpt-4")    # Use the retriever's 'get_relevant_documents' method if needed to filter down longer docs    relevant_nodes = figma_doc_retriever.get_relevant_documents(human_input)    conversation = [system_message_prompt, human_message_prompt]    chat_prompt = ChatPromptTemplate.from_messages(conversation)    response = gpt_4(        chat_prompt.format_prompt(            context=relevant_nodes, text=human_input        ).to_messages()    )    return responseresponse = generate_code("page top header")Returns the following in response.content:<!DOCTYPE html>\n<html lang="en">\n<head>\n    <meta charset="UTF-8">\n    <meta name="viewport" content="width=device-width, initial-scale=1.0">\n    <style>\n        @import url(\'https://fonts.googleapis.com/css2?family=DM+Sans:wght@500;700&family=Inter:wght@600&display=swap\');\n\n        body {\n            margin: 0;\n            font-family: \'DM Sans\', sans-serif;\n        }\n\n        .header {\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            padding: 20px;\n            background-color: #fff;\n            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n        }\n\n        .header h1 {\n            font-size: 16px;\n            font-weight: 700;\n            margin: 0;\n        }\n\n        .header nav {\n            display: flex;\n            align-items: center;\n        }\n\n        .header nav a {\n            font-size: 14px;\n            font-weight: 500;\n            text-decoration: none;\n            color: #000;\n            margin-left: 20px;\n        }\n\n        @media (max-width: 768px) {\n            .header nav {\n                display: none;\n            }\n        }\n    </style>\n</head>\n<body>\n    <header class="header">\n        <h1>Company Contact</h1>\n        <nav>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n        </nav>\n    </header>\n</body>\n</html>PreviousFaunaNextGeopandasCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsDocument loadersFigmaFigmaFigma is a collaborative web application for interface design.This notebook covers how to load data from the Figma REST API into a format that can be ingested into LangChain, along with example usage for code generation.import osfrom langchain.document_loaders.figma import FigmaFileLoaderfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.chat_models import ChatOpenAIfrom langchain.indexes import VectorstoreIndexCreatorfrom langchain.chains import ConversationChain, LLMChainfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)API Reference:FigmaFileLoaderCharacterTextSplitterChatOpenAIVectorstoreIndexCreatorConversationChainLLMChainConversationBufferWindowMemoryChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateThe Figma API Requires an access token, node_ids, and a file key.The file key can be pulled from the URL.  https://www.figma.com/file/{filekey}/sampleFilenameNode IDs are also available in the URL. Click on anything and look for the '?node-id={node_id}' param.Access token instructions are in the Figma help center article: https://help.figma.com/hc/en-us/articles/8085703771159-Manage-personal-access-tokensfigma_loader = FigmaFileLoader(    os.environ.get("ACCESS_TOKEN"),    os.environ.get("NODE_IDS"),    os.environ.get("FILE_KEY"),)# see https://python.langchain.com/en/latest/modules/data_connection/getting_started.html for more detailsindex = VectorstoreIndexCreator().from_loaders([figma_loader])figma_doc_retriever = index.vectorstore.as_retriever()def generate_code(human_input):    # I have no idea if the Jon Carmack thing makes for better code. YMMV.    # See https://python.langchain.com/en/latest/modules/models/chat/getting_started.html for chat info    system_prompt_template = """You are expert coder Jon Carmack. Use the provided design context to create idomatic HTML/CSS code as possible based on the user request.    Everything must be inline in one file and your response must be directly renderable by the browser.    Figma file nodes and metadata: {context}"""    human_prompt_template = "Code the {text}. Ensure it's mobile responsive"    system_message_prompt = SystemMessagePromptTemplate.from_template(        system_prompt_template    )    human_message_prompt = HumanMessagePromptTemplate.from_template(        human_prompt_template    )    # delete the gpt-4 model_name to use the default gpt-3.5 turbo for faster results    gpt_4 = ChatOpenAI(temperature=0.02, model_name="gpt-4")    # Use the retriever's 'get_relevant_documents' method if needed to filter down longer docs    relevant_nodes = figma_doc_retriever.get_relevant_documents(human_input)    conversation = [system_message_prompt, human_message_prompt]    chat_prompt = ChatPromptTemplate.from_messages(conversation)    response = gpt_4(        chat_prompt.format_prompt(            context=relevant_nodes, text=human_input        ).to_messages()    )    return responseresponse = generate_code("page top header")Returns the following in response.content:<!DOCTYPE html>\n<html lang="en">\n<head>\n    <meta charset="UTF-8">\n    <meta name="viewport" content="width=device-width, initial-scale=1.0">\n    <style>\n        @import url(\'https://fonts.googleapis.com/css2?family=DM+Sans:wght@500;700&family=Inter:wght@600&display=swap\');\n\n        body {\n            margin: 0;\n            font-family: \'DM Sans\', sans-serif;\n        }\n\n        .header {\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            padding: 20px;\n            background-color: #fff;\n            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n        }\n\n        .header h1 {\n            font-size: 16px;\n            font-weight: 700;\n            margin: 0;\n        }\n\n        .header nav {\n            display: flex;\n            align-items: center;\n        }\n\n        .header nav a {\n            font-size: 14px;\n            font-weight: 500;\n            text-decoration: none;\n            color: #000;\n            margin-left: 20px;\n        }\n\n        @media (max-width: 768px) {\n            .header nav {\n                display: none;\n            }\n        }\n    </style>\n</head>\n<body>\n    <header class="header">\n        <h1>Company Contact</h1>\n        <nav>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n        </nav>\n    </header>\n</body>\n</html>PreviousFaunaNextGeopandas IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsDocument loadersFigmaFigmaFigma is a collaborative web application for interface design.This notebook covers how to load data from the Figma REST API into a format that can be ingested into LangChain, along with example usage for code generation.import osfrom langchain.document_loaders.figma import FigmaFileLoaderfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.chat_models import ChatOpenAIfrom langchain.indexes import VectorstoreIndexCreatorfrom langchain.chains import ConversationChain, LLMChainfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)API Reference:FigmaFileLoaderCharacterTextSplitterChatOpenAIVectorstoreIndexCreatorConversationChainLLMChainConversationBufferWindowMemoryChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateThe Figma API Requires an access token, node_ids, and a file key.The file key can be pulled from the URL.  https://www.figma.com/file/{filekey}/sampleFilenameNode IDs are also available in the URL. Click on anything and look for the '?node-id={node_id}' param.Access token instructions are in the Figma help center article: https://help.figma.com/hc/en-us/articles/8085703771159-Manage-personal-access-tokensfigma_loader = FigmaFileLoader(    os.environ.get("ACCESS_TOKEN"),    os.environ.get("NODE_IDS"),    os.environ.get("FILE_KEY"),)# see https://python.langchain.com/en/latest/modules/data_connection/getting_started.html for more detailsindex = VectorstoreIndexCreator().from_loaders([figma_loader])figma_doc_retriever = index.vectorstore.as_retriever()def generate_code(human_input):    # I have no idea if the Jon Carmack thing makes for better code. YMMV.    # See https://python.langchain.com/en/latest/modules/models/chat/getting_started.html for chat info    system_prompt_template = """You are expert coder Jon Carmack. Use the provided design context to create idomatic HTML/CSS code as possible based on the user request.    Everything must be inline in one file and your response must be directly renderable by the browser.    Figma file nodes and metadata: {context}"""    human_prompt_template = "Code the {text}. Ensure it's mobile responsive"    system_message_prompt = SystemMessagePromptTemplate.from_template(        system_prompt_template    )    human_message_prompt = HumanMessagePromptTemplate.from_template(        human_prompt_template    )    # delete the gpt-4 model_name to use the default gpt-3.5 turbo for faster results    gpt_4 = ChatOpenAI(temperature=0.02, model_name="gpt-4")    # Use the retriever's 'get_relevant_documents' method if needed to filter down longer docs    relevant_nodes = figma_doc_retriever.get_relevant_documents(human_input)    conversation = [system_message_prompt, human_message_prompt]    chat_prompt = ChatPromptTemplate.from_messages(conversation)    response = gpt_4(        chat_prompt.format_prompt(            context=relevant_nodes, text=human_input        ).to_messages()    )    return responseresponse = generate_code("page top header")Returns the following in response.content:<!DOCTYPE html>\n<html lang="en">\n<head>\n    <meta charset="UTF-8">\n    <meta name="viewport" content="width=device-width, initial-scale=1.0">\n    <style>\n        @import url(\'https://fonts.googleapis.com/css2?family=DM+Sans:wght@500;700&family=Inter:wght@600&display=swap\');\n\n        body {\n            margin: 0;\n            font-family: \'DM Sans\', sans-serif;\n        }\n\n        .header {\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            padding: 20px;\n            background-color: #fff;\n            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n        }\n\n        .header h1 {\n            font-size: 16px;\n            font-weight: 700;\n            margin: 0;\n        }\n\n        .header nav {\n            display: flex;\n            align-items: center;\n        }\n\n        .header nav a {\n            font-size: 14px;\n            font-weight: 500;\n            text-decoration: none;\n            color: #000;\n            margin-left: 20px;\n        }\n\n        @media (max-width: 768px) {\n            .header nav {\n                display: none;\n            }\n        }\n    </style>\n</head>\n<body>\n    <header class="header">\n        <h1>Company Contact</h1>\n        <nav>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n        </nav>\n    </header>\n</body>\n</html>PreviousFaunaNextGeopandas IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders example_data Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsDocument loadersFigmaFigmaFigma is a collaborative web application for interface design.This notebook covers how to load data from the Figma REST API into a format that can be ingested into LangChain, along with example usage for code generation.import osfrom langchain.document_loaders.figma import FigmaFileLoaderfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.chat_models import ChatOpenAIfrom langchain.indexes import VectorstoreIndexCreatorfrom langchain.chains import ConversationChain, LLMChainfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)API Reference:FigmaFileLoaderCharacterTextSplitterChatOpenAIVectorstoreIndexCreatorConversationChainLLMChainConversationBufferWindowMemoryChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateThe Figma API Requires an access token, node_ids, and a file key.The file key can be pulled from the URL.  https://www.figma.com/file/{filekey}/sampleFilenameNode IDs are also available in the URL. Click on anything and look for the '?node-id={node_id}' param.Access token instructions are in the Figma help center article: https://help.figma.com/hc/en-us/articles/8085703771159-Manage-personal-access-tokensfigma_loader = FigmaFileLoader(    os.environ.get("ACCESS_TOKEN"),    os.environ.get("NODE_IDS"),    os.environ.get("FILE_KEY"),)# see https://python.langchain.com/en/latest/modules/data_connection/getting_started.html for more detailsindex = VectorstoreIndexCreator().from_loaders([figma_loader])figma_doc_retriever = index.vectorstore.as_retriever()def generate_code(human_input):    # I have no idea if the Jon Carmack thing makes for better code. YMMV.    # See https://python.langchain.com/en/latest/modules/models/chat/getting_started.html for chat info    system_prompt_template = """You are expert coder Jon Carmack. Use the provided design context to create idomatic HTML/CSS code as possible based on the user request.    Everything must be inline in one file and your response must be directly renderable by the browser.    Figma file nodes and metadata: {context}"""    human_prompt_template = "Code the {text}. Ensure it's mobile responsive"    system_message_prompt = SystemMessagePromptTemplate.from_template(        system_prompt_template    )    human_message_prompt = HumanMessagePromptTemplate.from_template(        human_prompt_template    )    # delete the gpt-4 model_name to use the default gpt-3.5 turbo for faster results    gpt_4 = ChatOpenAI(temperature=0.02, model_name="gpt-4")    # Use the retriever's 'get_relevant_documents' method if needed to filter down longer docs    relevant_nodes = figma_doc_retriever.get_relevant_documents(human_input)    conversation = [system_message_prompt, human_message_prompt]    chat_prompt = ChatPromptTemplate.from_messages(conversation)    response = gpt_4(        chat_prompt.format_prompt(            context=relevant_nodes, text=human_input        ).to_messages()    )    return responseresponse = generate_code("page top header")Returns the following in response.content:<!DOCTYPE html>\n<html lang="en">\n<head>\n    <meta charset="UTF-8">\n    <meta name="viewport" content="width=device-width, initial-scale=1.0">\n    <style>\n        @import url(\'https://fonts.googleapis.com/css2?family=DM+Sans:wght@500;700&family=Inter:wght@600&display=swap\');\n\n        body {\n            margin: 0;\n            font-family: \'DM Sans\', sans-serif;\n        }\n\n        .header {\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            padding: 20px;\n            background-color: #fff;\n            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n        }\n\n        .header h1 {\n            font-size: 16px;\n            font-weight: 700;\n            margin: 0;\n        }\n\n        .header nav {\n            display: flex;\n            align-items: center;\n        }\n\n        .header nav a {\n            font-size: 14px;\n            font-weight: 500;\n            text-decoration: none;\n            color: #000;\n            margin-left: 20px;\n        }\n\n        @media (max-width: 768px) {\n            .header nav {\n                display: none;\n            }\n        }\n    </style>\n</head>\n<body>\n    <header class="header">\n        <h1>Company Contact</h1>\n        <nav>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n        </nav>\n    </header>\n</body>\n</html>PreviousFaunaNextGeopandas IntegrationsDocument loadersFigmaFigmaFigma is a collaborative web application for interface design.This notebook covers how to load data from the Figma REST API into a format that can be ingested into LangChain, along with example usage for code generation.import osfrom langchain.document_loaders.figma import FigmaFileLoaderfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.chat_models import ChatOpenAIfrom langchain.indexes import VectorstoreIndexCreatorfrom langchain.chains import ConversationChain, LLMChainfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)API Reference:FigmaFileLoaderCharacterTextSplitterChatOpenAIVectorstoreIndexCreatorConversationChainLLMChainConversationBufferWindowMemoryChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateThe Figma API Requires an access token, node_ids, and a file key.The file key can be pulled from the URL.  https://www.figma.com/file/{filekey}/sampleFilenameNode IDs are also available in the URL. Click on anything and look for the '?node-id={node_id}' param.Access token instructions are in the Figma help center article: https://help.figma.com/hc/en-us/articles/8085703771159-Manage-personal-access-tokensfigma_loader = FigmaFileLoader(    os.environ.get("ACCESS_TOKEN"),    os.environ.get("NODE_IDS"),    os.environ.get("FILE_KEY"),)# see https://python.langchain.com/en/latest/modules/data_connection/getting_started.html for more detailsindex = VectorstoreIndexCreator().from_loaders([figma_loader])figma_doc_retriever = index.vectorstore.as_retriever()def generate_code(human_input):    # I have no idea if the Jon Carmack thing makes for better code. YMMV.    # See https://python.langchain.com/en/latest/modules/models/chat/getting_started.html for chat info    system_prompt_template = """You are expert coder Jon Carmack. Use the provided design context to create idomatic HTML/CSS code as possible based on the user request.    Everything must be inline in one file and your response must be directly renderable by the browser.    Figma file nodes and metadata: {context}"""    human_prompt_template = "Code the {text}. Ensure it's mobile responsive"    system_message_prompt = SystemMessagePromptTemplate.from_template(        system_prompt_template    )    human_message_prompt = HumanMessagePromptTemplate.from_template(        human_prompt_template    )    # delete the gpt-4 model_name to use the default gpt-3.5 turbo for faster results    gpt_4 = ChatOpenAI(temperature=0.02, model_name="gpt-4")    # Use the retriever's 'get_relevant_documents' method if needed to filter down longer docs    relevant_nodes = figma_doc_retriever.get_relevant_documents(human_input)    conversation = [system_message_prompt, human_message_prompt]    chat_prompt = ChatPromptTemplate.from_messages(conversation)    response = gpt_4(        chat_prompt.format_prompt(            context=relevant_nodes, text=human_input        ).to_messages()    )    return responseresponse = generate_code("page top header")Returns the following in response.content:<!DOCTYPE html>\n<html lang="en">\n<head>\n    <meta charset="UTF-8">\n    <meta name="viewport" content="width=device-width, initial-scale=1.0">\n    <style>\n        @import url(\'https://fonts.googleapis.com/css2?family=DM+Sans:wght@500;700&family=Inter:wght@600&display=swap\');\n\n        body {\n            margin: 0;\n            font-family: \'DM Sans\', sans-serif;\n        }\n\n        .header {\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            padding: 20px;\n            background-color: #fff;\n            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n        }\n\n        .header h1 {\n            font-size: 16px;\n            font-weight: 700;\n            margin: 0;\n        }\n\n        .header nav {\n            display: flex;\n            align-items: center;\n        }\n\n        .header nav a {\n            font-size: 14px;\n            font-weight: 500;\n            text-decoration: none;\n            color: #000;\n            margin-left: 20px;\n        }\n\n        @media (max-width: 768px) {\n            .header nav {\n                display: none;\n            }\n        }\n    </style>\n</head>\n<body>\n    <header class="header">\n        <h1>Company Contact</h1>\n        <nav>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n        </nav>\n    </header>\n</body>\n</html>PreviousFaunaNextGeopandas IntegrationsDocument loadersFigmaFigmaFigma is a collaborative web application for interface design.This notebook covers how to load data from the Figma REST API into a format that can be ingested into LangChain, along with example usage for code generation.import osfrom langchain.document_loaders.figma import FigmaFileLoaderfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.chat_models import ChatOpenAIfrom langchain.indexes import VectorstoreIndexCreatorfrom langchain.chains import ConversationChain, LLMChainfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)API Reference:FigmaFileLoaderCharacterTextSplitterChatOpenAIVectorstoreIndexCreatorConversationChainLLMChainConversationBufferWindowMemoryChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateThe Figma API Requires an access token, node_ids, and a file key.The file key can be pulled from the URL.  https://www.figma.com/file/{filekey}/sampleFilenameNode IDs are also available in the URL. Click on anything and look for the '?node-id={node_id}' param.Access token instructions are in the Figma help center article: https://help.figma.com/hc/en-us/articles/8085703771159-Manage-personal-access-tokensfigma_loader = FigmaFileLoader(    os.environ.get("ACCESS_TOKEN"),    os.environ.get("NODE_IDS"),    os.environ.get("FILE_KEY"),)# see https://python.langchain.com/en/latest/modules/data_connection/getting_started.html for more detailsindex = VectorstoreIndexCreator().from_loaders([figma_loader])figma_doc_retriever = index.vectorstore.as_retriever()def generate_code(human_input):    # I have no idea if the Jon Carmack thing makes for better code. YMMV.    # See https://python.langchain.com/en/latest/modules/models/chat/getting_started.html for chat info    system_prompt_template = """You are expert coder Jon Carmack. Use the provided design context to create idomatic HTML/CSS code as possible based on the user request.    Everything must be inline in one file and your response must be directly renderable by the browser.    Figma file nodes and metadata: {context}"""    human_prompt_template = "Code the {text}. Ensure it's mobile responsive"    system_message_prompt = SystemMessagePromptTemplate.from_template(        system_prompt_template    )    human_message_prompt = HumanMessagePromptTemplate.from_template(        human_prompt_template    )    # delete the gpt-4 model_name to use the default gpt-3.5 turbo for faster results    gpt_4 = ChatOpenAI(temperature=0.02, model_name="gpt-4")    # Use the retriever's 'get_relevant_documents' method if needed to filter down longer docs    relevant_nodes = figma_doc_retriever.get_relevant_documents(human_input)    conversation = [system_message_prompt, human_message_prompt]    chat_prompt = ChatPromptTemplate.from_messages(conversation)    response = gpt_4(        chat_prompt.format_prompt(            context=relevant_nodes, text=human_input        ).to_messages()    )    return responseresponse = generate_code("page top header")Returns the following in response.content:<!DOCTYPE html>\n<html lang="en">\n<head>\n    <meta charset="UTF-8">\n    <meta name="viewport" content="width=device-width, initial-scale=1.0">\n    <style>\n        @import url(\'https://fonts.googleapis.com/css2?family=DM+Sans:wght@500;700&family=Inter:wght@600&display=swap\');\n\n        body {\n            margin: 0;\n            font-family: \'DM Sans\', sans-serif;\n        }\n\n        .header {\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            padding: 20px;\n            background-color: #fff;\n            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n        }\n\n        .header h1 {\n            font-size: 16px;\n            font-weight: 700;\n            margin: 0;\n        }\n\n        .header nav {\n            display: flex;\n            align-items: center;\n        }\n\n        .header nav a {\n            font-size: 14px;\n            font-weight: 500;\n            text-decoration: none;\n            color: #000;\n            margin-left: 20px;\n        }\n\n        @media (max-width: 768px) {\n            .header nav {\n                display: none;\n            }\n        }\n    </style>\n</head>\n<body>\n    <header class="header">\n        <h1>Company Contact</h1>\n        <nav>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n        </nav>\n    </header>\n</body>\n</html>PreviousFaunaNextGeopandas IntegrationsDocument loadersFigmaFigmaFigma is a collaborative web application for interface design.This notebook covers how to load data from the Figma REST API into a format that can be ingested into LangChain, along with example usage for code generation.import osfrom langchain.document_loaders.figma import FigmaFileLoaderfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.chat_models import ChatOpenAIfrom langchain.indexes import VectorstoreIndexCreatorfrom langchain.chains import ConversationChain, LLMChainfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)API Reference:FigmaFileLoaderCharacterTextSplitterChatOpenAIVectorstoreIndexCreatorConversationChainLLMChainConversationBufferWindowMemoryChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateThe Figma API Requires an access token, node_ids, and a file key.The file key can be pulled from the URL.  https://www.figma.com/file/{filekey}/sampleFilenameNode IDs are also available in the URL. Click on anything and look for the '?node-id={node_id}' param.Access token instructions are in the Figma help center article: https://help.figma.com/hc/en-us/articles/8085703771159-Manage-personal-access-tokensfigma_loader = FigmaFileLoader(    os.environ.get("ACCESS_TOKEN"),    os.environ.get("NODE_IDS"),    os.environ.get("FILE_KEY"),)# see https://python.langchain.com/en/latest/modules/data_connection/getting_started.html for more detailsindex = VectorstoreIndexCreator().from_loaders([figma_loader])figma_doc_retriever = index.vectorstore.as_retriever()def generate_code(human_input):    # I have no idea if the Jon Carmack thing makes for better code. YMMV.    # See https://python.langchain.com/en/latest/modules/models/chat/getting_started.html for chat info    system_prompt_template = """You are expert coder Jon Carmack. Use the provided design context to create idomatic HTML/CSS code as possible based on the user request.    Everything must be inline in one file and your response must be directly renderable by the browser.    Figma file nodes and metadata: {context}"""    human_prompt_template = "Code the {text}. Ensure it's mobile responsive"    system_message_prompt = SystemMessagePromptTemplate.from_template(        system_prompt_template    )    human_message_prompt = HumanMessagePromptTemplate.from_template(        human_prompt_template    )    # delete the gpt-4 model_name to use the default gpt-3.5 turbo for faster results    gpt_4 = ChatOpenAI(temperature=0.02, model_name="gpt-4")    # Use the retriever's 'get_relevant_documents' method if needed to filter down longer docs    relevant_nodes = figma_doc_retriever.get_relevant_documents(human_input)    conversation = [system_message_prompt, human_message_prompt]    chat_prompt = ChatPromptTemplate.from_messages(conversation)    response = gpt_4(        chat_prompt.format_prompt(            context=relevant_nodes, text=human_input        ).to_messages()    )    return responseresponse = generate_code("page top header")Returns the following in response.content:<!DOCTYPE html>\n<html lang="en">\n<head>\n    <meta charset="UTF-8">\n    <meta name="viewport" content="width=device-width, initial-scale=1.0">\n    <style>\n        @import url(\'https://fonts.googleapis.com/css2?family=DM+Sans:wght@500;700&family=Inter:wght@600&display=swap\');\n\n        body {\n            margin: 0;\n            font-family: \'DM Sans\', sans-serif;\n        }\n\n        .header {\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            padding: 20px;\n            background-color: #fff;\n            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n        }\n\n        .header h1 {\n            font-size: 16px;\n            font-weight: 700;\n            margin: 0;\n        }\n\n        .header nav {\n            display: flex;\n            align-items: center;\n        }\n\n        .header nav a {\n            font-size: 14px;\n            font-weight: 500;\n            text-decoration: none;\n            color: #000;\n            margin-left: 20px;\n        }\n\n        @media (max-width: 768px) {\n            .header nav {\n                display: none;\n            }\n        }\n    </style>\n</head>\n<body>\n    <header class="header">\n        <h1>Company Contact</h1>\n        <nav>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n        </nav>\n    </header>\n</body>\n</html>PreviousFaunaNextGeopandas FigmaFigma is a collaborative web application for interface design.This notebook covers how to load data from the Figma REST API into a format that can be ingested into LangChain, along with example usage for code generation.import osfrom langchain.document_loaders.figma import FigmaFileLoaderfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.chat_models import ChatOpenAIfrom langchain.indexes import VectorstoreIndexCreatorfrom langchain.chains import ConversationChain, LLMChainfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)API Reference:FigmaFileLoaderCharacterTextSplitterChatOpenAIVectorstoreIndexCreatorConversationChainLLMChainConversationBufferWindowMemoryChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplateThe Figma API Requires an access token, node_ids, and a file key.The file key can be pulled from the URL.  https://www.figma.com/file/{filekey}/sampleFilenameNode IDs are also available in the URL. Click on anything and look for the '?node-id={node_id}' param.Access token instructions are in the Figma help center article: https://help.figma.com/hc/en-us/articles/8085703771159-Manage-personal-access-tokensfigma_loader = FigmaFileLoader(    os.environ.get("ACCESS_TOKEN"),    os.environ.get("NODE_IDS"),    os.environ.get("FILE_KEY"),)# see https://python.langchain.com/en/latest/modules/data_connection/getting_started.html for more detailsindex = VectorstoreIndexCreator().from_loaders([figma_loader])figma_doc_retriever = index.vectorstore.as_retriever()def generate_code(human_input):    # I have no idea if the Jon Carmack thing makes for better code. YMMV.    # See https://python.langchain.com/en/latest/modules/models/chat/getting_started.html for chat info    system_prompt_template = """You are expert coder Jon Carmack. Use the provided design context to create idomatic HTML/CSS code as possible based on the user request.    Everything must be inline in one file and your response must be directly renderable by the browser.    Figma file nodes and metadata: {context}"""    human_prompt_template = "Code the {text}. Ensure it's mobile responsive"    system_message_prompt = SystemMessagePromptTemplate.from_template(        system_prompt_template    )    human_message_prompt = HumanMessagePromptTemplate.from_template(        human_prompt_template    )    # delete the gpt-4 model_name to use the default gpt-3.5 turbo for faster results    gpt_4 = ChatOpenAI(temperature=0.02, model_name="gpt-4")    # Use the retriever's 'get_relevant_documents' method if needed to filter down longer docs    relevant_nodes = figma_doc_retriever.get_relevant_documents(human_input)    conversation = [system_message_prompt, human_message_prompt]    chat_prompt = ChatPromptTemplate.from_messages(conversation)    response = gpt_4(        chat_prompt.format_prompt(            context=relevant_nodes, text=human_input        ).to_messages()    )    return responseresponse = generate_code("page top header")Returns the following in response.content:<!DOCTYPE html>\n<html lang="en">\n<head>\n    <meta charset="UTF-8">\n    <meta name="viewport" content="width=device-width, initial-scale=1.0">\n    <style>\n        @import url(\'https://fonts.googleapis.com/css2?family=DM+Sans:wght@500;700&family=Inter:wght@600&display=swap\');\n\n        body {\n            margin: 0;\n            font-family: \'DM Sans\', sans-serif;\n        }\n\n        .header {\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            padding: 20px;\n            background-color: #fff;\n            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n        }\n\n        .header h1 {\n            font-size: 16px;\n            font-weight: 700;\n            margin: 0;\n        }\n\n        .header nav {\n            display: flex;\n            align-items: center;\n        }\n\n        .header nav a {\n            font-size: 14px;\n            font-weight: 500;\n            text-decoration: none;\n            color: #000;\n            margin-left: 20px;\n        }\n\n        @media (max-width: 768px) {\n            .header nav {\n                display: none;\n            }\n        }\n    </style>\n</head>\n<body>\n    <header class="header">\n        <h1>Company Contact</h1>\n        <nav>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n        </nav>\n    </header>\n</body>\n</html> import osfrom langchain.document_loaders.figma import FigmaFileLoaderfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.chat_models import ChatOpenAIfrom langchain.indexes import VectorstoreIndexCreatorfrom langchain.chains import ConversationChain, LLMChainfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,) import osfrom langchain.document_loaders.figma import FigmaFileLoaderfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.chat_models import ChatOpenAIfrom langchain.indexes import VectorstoreIndexCreatorfrom langchain.chains import ConversationChain, LLMChainfrom langchain.memory import ConversationBufferWindowMemoryfrom langchain.prompts.chat import (    ChatPromptTemplate,    SystemMessagePromptTemplate,    AIMessagePromptTemplate,    HumanMessagePromptTemplate,)  API Reference:FigmaFileLoaderCharacterTextSplitterChatOpenAIVectorstoreIndexCreatorConversationChainLLMChainConversationBufferWindowMemoryChatPromptTemplateSystemMessagePromptTemplateAIMessagePromptTemplateHumanMessagePromptTemplate figma_loader = FigmaFileLoader(    os.environ.get("ACCESS_TOKEN"),    os.environ.get("NODE_IDS"),    os.environ.get("FILE_KEY"),) figma_loader = FigmaFileLoader(    os.environ.get("ACCESS_TOKEN"),    os.environ.get("NODE_IDS"),    os.environ.get("FILE_KEY"),)  # see https://python.langchain.com/en/latest/modules/data_connection/getting_started.html for more detailsindex = VectorstoreIndexCreator().from_loaders([figma_loader])figma_doc_retriever = index.vectorstore.as_retriever() # see https://python.langchain.com/en/latest/modules/data_connection/getting_started.html for more detailsindex = VectorstoreIndexCreator().from_loaders([figma_loader])figma_doc_retriever = index.vectorstore.as_retriever()  def generate_code(human_input):    # I have no idea if the Jon Carmack thing makes for better code. YMMV.    # See https://python.langchain.com/en/latest/modules/models/chat/getting_started.html for chat info    system_prompt_template = """You are expert coder Jon Carmack. Use the provided design context to create idomatic HTML/CSS code as possible based on the user request.    Everything must be inline in one file and your response must be directly renderable by the browser.    Figma file nodes and metadata: {context}"""    human_prompt_template = "Code the {text}. Ensure it's mobile responsive"    system_message_prompt = SystemMessagePromptTemplate.from_template(        system_prompt_template    )    human_message_prompt = HumanMessagePromptTemplate.from_template(        human_prompt_template    )    # delete the gpt-4 model_name to use the default gpt-3.5 turbo for faster results    gpt_4 = ChatOpenAI(temperature=0.02, model_name="gpt-4")    # Use the retriever's 'get_relevant_documents' method if needed to filter down longer docs    relevant_nodes = figma_doc_retriever.get_relevant_documents(human_input)    conversation = [system_message_prompt, human_message_prompt]    chat_prompt = ChatPromptTemplate.from_messages(conversation)    response = gpt_4(        chat_prompt.format_prompt(            context=relevant_nodes, text=human_input        ).to_messages()    )    return response def generate_code(human_input):    # I have no idea if the Jon Carmack thing makes for better code. YMMV.    # See https://python.langchain.com/en/latest/modules/models/chat/getting_started.html for chat info    system_prompt_template = """You are expert coder Jon Carmack. Use the provided design context to create idomatic HTML/CSS code as possible based on the user request.    Everything must be inline in one file and your response must be directly renderable by the browser.    Figma file nodes and metadata: {context}"""    human_prompt_template = "Code the {text}. Ensure it's mobile responsive"    system_message_prompt = SystemMessagePromptTemplate.from_template(        system_prompt_template    )    human_message_prompt = HumanMessagePromptTemplate.from_template(        human_prompt_template    )    # delete the gpt-4 model_name to use the default gpt-3.5 turbo for faster results    gpt_4 = ChatOpenAI(temperature=0.02, model_name="gpt-4")    # Use the retriever's 'get_relevant_documents' method if needed to filter down longer docs    relevant_nodes = figma_doc_retriever.get_relevant_documents(human_input)    conversation = [system_message_prompt, human_message_prompt]    chat_prompt = ChatPromptTemplate.from_messages(conversation)    response = gpt_4(        chat_prompt.format_prompt(            context=relevant_nodes, text=human_input        ).to_messages()    )    return response  response = generate_code("page top header") response = generate_code("page top header")  <!DOCTYPE html>\n<html lang="en">\n<head>\n    <meta charset="UTF-8">\n    <meta name="viewport" content="width=device-width, initial-scale=1.0">\n    <style>\n        @import url(\'https://fonts.googleapis.com/css2?family=DM+Sans:wght@500;700&family=Inter:wght@600&display=swap\');\n\n        body {\n            margin: 0;\n            font-family: \'DM Sans\', sans-serif;\n        }\n\n        .header {\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            padding: 20px;\n            background-color: #fff;\n            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n        }\n\n        .header h1 {\n            font-size: 16px;\n            font-weight: 700;\n            margin: 0;\n        }\n\n        .header nav {\n            display: flex;\n            align-items: center;\n        }\n\n        .header nav a {\n            font-size: 14px;\n            font-weight: 500;\n            text-decoration: none;\n            color: #000;\n            margin-left: 20px;\n        }\n\n        @media (max-width: 768px) {\n            .header nav {\n                display: none;\n            }\n        }\n    </style>\n</head>\n<body>\n    <header class="header">\n        <h1>Company Contact</h1>\n        <nav>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n        </nav>\n    </header>\n</body>\n</html> <!DOCTYPE html>\n<html lang="en">\n<head>\n    <meta charset="UTF-8">\n    <meta name="viewport" content="width=device-width, initial-scale=1.0">\n    <style>\n        @import url(\'https://fonts.googleapis.com/css2?family=DM+Sans:wght@500;700&family=Inter:wght@600&display=swap\');\n\n        body {\n            margin: 0;\n            font-family: \'DM Sans\', sans-serif;\n        }\n\n        .header {\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            padding: 20px;\n            background-color: #fff;\n            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n        }\n\n        .header h1 {\n            font-size: 16px;\n            font-weight: 700;\n            margin: 0;\n        }\n\n        .header nav {\n            display: flex;\n            align-items: center;\n        }\n\n        .header nav a {\n            font-size: 14px;\n            font-weight: 500;\n            text-decoration: none;\n            color: #000;\n            margin-left: 20px;\n        }\n\n        @media (max-width: 768px) {\n            .header nav {\n                display: none;\n            }\n        }\n    </style>\n</head>\n<body>\n    <header class="header">\n        <h1>Company Contact</h1>\n        <nav>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n            <a href="#">Lorem Ipsum</a>\n        </nav>\n    </header>\n</body>\n</html>  Previous Fauna Next Geopandas CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Etherscan Loader (/docs/integrations/document_loaders/Etherscan) acreom (/docs/integrations/document_loaders/acreom) Airbyte CDK (/docs/integrations/document_loaders/airbyte_cdk) Airbyte Gong (/docs/integrations/document_loaders/airbyte_gong) Airbyte Hubspot (/docs/integrations/document_loaders/airbyte_hubspot) Airbyte JSON (/docs/integrations/document_loaders/airbyte_json) Airbyte Salesforce (/docs/integrations/document_loaders/airbyte_salesforce) Airbyte Shopify (/docs/integrations/document_loaders/airbyte_shopify) Airbyte Stripe (/docs/integrations/document_loaders/airbyte_stripe) Airbyte Typeform (/docs/integrations/document_loaders/airbyte_typeform) Airbyte Zendesk Support (/docs/integrations/document_loaders/airbyte_zendesk_support) Airtable (/docs/integrations/document_loaders/airtable) Alibaba Cloud MaxCompute (/docs/integrations/document_loaders/alibaba_cloud_maxcompute) Apify Dataset (/docs/integrations/document_loaders/apify_dataset) ArcGIS (/docs/integrations/document_loaders/arcgis) Arxiv (/docs/integrations/document_loaders/arxiv) AssemblyAI Audio Transcripts (/docs/integrations/document_loaders/assemblyai) Async Chromium (/docs/integrations/document_loaders/async_chromium) AsyncHtmlLoader (/docs/integrations/document_loaders/async_html) AWS S3 Directory (/docs/integrations/document_loaders/aws_s3_directory) AWS S3 File (/docs/integrations/document_loaders/aws_s3_file) AZLyrics (/docs/integrations/document_loaders/azlyrics) Azure Blob Storage Container (/docs/integrations/document_loaders/azure_blob_storage_container) Azure Blob Storage File (/docs/integrations/document_loaders/azure_blob_storage_file) Azure Document Intelligence (/docs/integrations/document_loaders/azure_document_intelligence) BibTeX (/docs/integrations/document_loaders/bibtex) BiliBili (/docs/integrations/document_loaders/bilibili) Blackboard (/docs/integrations/document_loaders/blackboard) Blockchain (/docs/integrations/document_loaders/blockchain) Brave Search (/docs/integrations/document_loaders/brave_search) Browserless (/docs/integrations/document_loaders/browserless) ChatGPT Data (/docs/integrations/document_loaders/chatgpt_loader) College Confidential (/docs/integrations/document_loaders/college_confidential) Concurrent Loader (/docs/integrations/document_loaders/concurrent) Confluence (/docs/integrations/document_loaders/confluence) CoNLL-U (/docs/integrations/document_loaders/conll-u) Copy Paste (/docs/integrations/document_loaders/copypaste) CSV (/docs/integrations/document_loaders/csv) Cube Semantic Layer (/docs/integrations/document_loaders/cube_semantic) Datadog Logs (/docs/integrations/document_loaders/datadog_logs) Diffbot (/docs/integrations/document_loaders/diffbot) Discord (/docs/integrations/document_loaders/discord) Docugami (/docs/integrations/document_loaders/docugami) Dropbox (/docs/integrations/document_loaders/dropbox) DuckDB (/docs/integrations/document_loaders/duckdb) Email (/docs/integrations/document_loaders/email) Embaas (/docs/integrations/document_loaders/embaas) EPub (/docs/integrations/document_loaders/epub) EverNote (/docs/integrations/document_loaders/evernote) example_data (/docs/integrations/document_loaders/example_data/notebook) Microsoft Excel (/docs/integrations/document_loaders/excel) Facebook Chat (/docs/integrations/document_loaders/facebook_chat) Fauna (/docs/integrations/document_loaders/fauna) Figma (/docs/integrations/document_loaders/figma) Geopandas (/docs/integrations/document_loaders/geopandas) Git (/docs/integrations/document_loaders/git) GitBook (/docs/integrations/document_loaders/gitbook) GitHub (/docs/integrations/document_loaders/github) Google BigQuery (/docs/integrations/document_loaders/google_bigquery) Google Cloud Storage Directory (/docs/integrations/document_loaders/google_cloud_storage_directory) Google Cloud Storage File (/docs/integrations/document_loaders/google_cloud_storage_file) Google Drive (/docs/integrations/document_loaders/google_drive) Grobid (/docs/integrations/document_loaders/grobid) Gutenberg (/docs/integrations/document_loaders/gutenberg) Hacker News (/docs/integrations/document_loaders/hacker_news) Huawei OBS Directory (/docs/integrations/document_loaders/huawei_obs_directory) Huawei OBS File (/docs/integrations/document_loaders/huawei_obs_file) HuggingFace dataset (/docs/integrations/document_loaders/hugging_face_dataset) iFixit (/docs/integrations/document_loaders/ifixit) Images (/docs/integrations/document_loaders/image) Image captions (/docs/integrations/document_loaders/image_captions) IMSDb (/docs/integrations/document_loaders/imsdb) Iugu (/docs/integrations/document_loaders/iugu) Joplin (/docs/integrations/document_loaders/joplin) Jupyter Notebook (/docs/integrations/document_loaders/jupyter_notebook) LarkSuite (FeiShu) (/docs/integrations/document_loaders/larksuite) Mastodon (/docs/integrations/document_loaders/mastodon) MediaWikiDump (/docs/integrations/document_loaders/mediawikidump) MergeDocLoader (/docs/integrations/document_loaders/merge_doc_loader) mhtml (/docs/integrations/document_loaders/mhtml) Microsoft OneDrive (/docs/integrations/document_loaders/microsoft_onedrive) Microsoft PowerPoint (/docs/integrations/document_loaders/microsoft_powerpoint) Microsoft SharePoint (/docs/integrations/document_loaders/microsoft_sharepoint) Microsoft Word (/docs/integrations/document_loaders/microsoft_word) Modern Treasury (/docs/integrations/document_loaders/modern_treasury) News URL (/docs/integrations/document_loaders/news) Notion DB 1/2 (/docs/integrations/document_loaders/notion) Notion DB 2/2 (/docs/integrations/document_loaders/notiondb) Nuclia Understanding API document loader (/docs/integrations/document_loaders/nuclia) Obsidian (/docs/integrations/document_loaders/obsidian) Open Document Format (ODT) (/docs/integrations/document_loaders/odt) Open City Data (/docs/integrations/document_loaders/open_city_data) Org-mode (/docs/integrations/document_loaders/org_mode) Pandas DataFrame (/docs/integrations/document_loaders/pandas_dataframe) Amazon Textract (/docs/integrations/document_loaders/pdf-amazonTextractPDFLoader) Polars DataFrame (/docs/integrations/document_loaders/polars_dataframe) Psychic (/docs/integrations/document_loaders/psychic) PubMed (/docs/integrations/document_loaders/pubmed) PySpark DataFrame Loader (/docs/integrations/document_loaders/pyspark_dataframe) ReadTheDocs Documentation (/docs/integrations/document_loaders/readthedocs_documentation) Recursive URL Loader (/docs/integrations/document_loaders/recursive_url_loader) Reddit (/docs/integrations/document_loaders/reddit) Roam (/docs/integrations/document_loaders/roam) Rockset (/docs/integrations/document_loaders/rockset) RSS Feeds (/docs/integrations/document_loaders/rss) RST (/docs/integrations/document_loaders/rst) Sitemap (/docs/integrations/document_loaders/sitemap) Slack (/docs/integrations/document_loaders/slack) Snowflake (/docs/integrations/document_loaders/snowflake) Source Code (/docs/integrations/document_loaders/source_code) Spreedly (/docs/integrations/document_loaders/spreedly) Stripe (/docs/integrations/document_loaders/stripe) Subtitle (/docs/integrations/document_loaders/subtitle) Telegram (/docs/integrations/document_loaders/telegram) Tencent COS Directory (/docs/integrations/document_loaders/tencent_cos_directory) Tencent COS File (/docs/integrations/document_loaders/tencent_cos_file) TensorFlow Datasets (/docs/integrations/document_loaders/tensorflow_datasets) 2Markdown (/docs/integrations/document_loaders/tomarkdown) TOML (/docs/integrations/document_loaders/toml) Trello (/docs/integrations/document_loaders/trello) TSV (/docs/integrations/document_loaders/tsv) Twitter (/docs/integrations/document_loaders/twitter) Unstructured File (/docs/integrations/document_loaders/unstructured_file) URL (/docs/integrations/document_loaders/url) Weather (/docs/integrations/document_loaders/weather) WebBaseLoader (/docs/integrations/document_loaders/web_base) WhatsApp Chat (/docs/integrations/document_loaders/whatsapp_chat) Wikipedia (/docs/integrations/document_loaders/wikipedia) XML (/docs/integrations/document_loaders/xml) Xorbits Pandas DataFrame (/docs/integrations/document_loaders/xorbits) Loading documents from a YouTube url (/docs/integrations/document_loaders/youtube_audio) YouTube transcripts (/docs/integrations/document_loaders/youtube_transcript) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Document loaders (/docs/integrations/document_loaders/) Figma (https://www.figma.com/) FigmaFileLoader (https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.figma.FigmaFileLoader.html) CharacterTextSplitter (https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.CharacterTextSplitter.html) ChatOpenAI (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html) VectorstoreIndexCreator (https://api.python.langchain.com/en/latest/indexes/langchain.indexes.vectorstore.VectorstoreIndexCreator.html) ConversationChain (https://api.python.langchain.com/en/latest/chains/langchain.chains.conversation.base.ConversationChain.html) LLMChain (https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html) ConversationBufferWindowMemory (https://api.python.langchain.com/en/latest/memory/langchain.memory.buffer_window.ConversationBufferWindowMemory.html) ChatPromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.chat.ChatPromptTemplate.html) SystemMessagePromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.chat.SystemMessagePromptTemplate.html) AIMessagePromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.chat.AIMessagePromptTemplate.html) HumanMessagePromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.chat.HumanMessagePromptTemplate.html) https://www.figma.com/file/{filekey}/sampleFilename (https://www.figma.com/file/%7Bfilekey%7D/sampleFilename) https://help.figma.com/hc/en-us/articles/8085703771159-Manage-personal-access-tokens (https://help.figma.com/hc/en-us/articles/8085703771159-Manage-personal-access-tokens) PreviousFauna (/docs/integrations/document_loaders/fauna) NextGeopandas (/docs/integrations/document_loaders/geopandas) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)