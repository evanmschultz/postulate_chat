This page covers how to use the Log10 within LangChain. Log10 is an open source proxiless LLM data management and application development platform that lets you log, debug and tag your Langchain calls. Integration with log10 is a simple one-line log10_callback integration as shown below: Log10 + Langchain + Logs docs More details + screenshots including instructions for self-hosting logs You can also intermix direct OpenAI calls and Langchain LLM calls: Example of debugging More Langchain examples IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz Activeloop Deep Lake AI21 Labs Aim AINetwork Airbyte Airtable Aleph Alpha Alibaba Cloud Opensearch Amazon API Gateway AnalyticDB Annoy Anyscale Apify ArangoDB Argilla Arthur Arxiv Atlas AwaDB AWS S3 Directory AZLyrics Azure Blob Storage Azure Cognitive Search Azure OpenAI BagelDB Banana Baseten Beam Bedrock BiliBili NIBittensor Blackboard Brave Search Cassandra CerebriumAI Chaindesk Chroma Clarifai ClearML ClickHouse CnosDB Cohere College Confidential Comet Confident AI Confluence C Transformers DashVector Databricks Datadog Tracing Datadog Logs DataForSEO DeepInfra DeepSparse Diffbot Dingo Discord DocArray Docugami DuckDB Elasticsearch Epsilla EverNote Facebook Chat Facebook Faiss Figma Fireworks Flyte ForefrontAI Git GitBook Golden Google BigQuery Google Cloud Storage Google Drive Google Search Google Serper Google Vertex AI MatchingEngine GooseAI GPT4All Graphsignal Grobid Gutenberg Hacker News Hazy Research Helicone Hologres Hugging Face iFixit IMSDb Infino Jina Konko LanceDB LangChain Decorators ‚ú® Llama.cpp Log10 Marqo MediaWikiDump Meilisearch Metal Microsoft OneDrive Microsoft PowerPoint Microsoft Word Milvus Minimax MLflow AI Gateway MLflow Modal ModelScope Modern Treasury Momento MongoDB Atlas Motherduck MyScale Neo4j NLPCloud Notion DB Obsidian OpenAI OpenLLM OpenSearch OpenWeatherMap Petals Postgres Embedding PGVector Pinecone PipelineAI Portkey Predibase Prediction Guard PromptLayer Psychic PubMed Qdrant Ray Serve Rebuff Reddit Redis Replicate Roam Rockset Runhouse RWKV-4 SageMaker Endpoint SageMaker Tracking ScaNN SearxNG Search API SerpAPI Shale Protocol SingleStoreDB scikit-learn Slack spaCy Spreedly StarRocks StochasticAI Stripe Supabase (Postgres) Nebula Tair Telegram TencentVectorDB TensorFlow Datasets Tigris 2Markdown Trello TruLens Twitter Typesense Unstructured USearch Vearch Vectara Vespa WandB Tracing Weights & Biases Weather Weaviate WhatsApp WhyLabs Wikipedia Wolfram Alpha Writer Xata Xorbits Inference (Xinference) Yeager.ai YouTube Zep Zilliz  Integrations Grouped by provider Log10 Create your free account at log10.io Add your LOG10_TOKEN and LOG10_ORG_ID from the Settings and Organization tabs respectively as environment variables. Also add LOG10_URL=https://log10.io and your usual LLM API key: for e.g. OPENAI_API_KEY or ANTHROPIC_API_KEY to your environment ChatOpenAI HumanMessage ChatAnthropic ChatOpenAI HumanMessage What is Log10? Quick start How to enable Log10 data management for Langchain How to use tags with Log10 How to debug Langchain calls Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZillizIntegrationsGrouped by providerLog10On this pageLog10This page covers how to use the Log10 within LangChain.What is Log10?‚ÄãLog10 is an open source proxiless LLM data management and application development platform that lets you log, debug and tag your Langchain calls.Quick start‚ÄãCreate your free account at log10.ioAdd your LOG10_TOKEN and LOG10_ORG_ID from the Settings and Organization tabs respectively as environment variables.Also add LOG10_URL=https://log10.io and your usual LLM API key: for e.g. OPENAI_API_KEY or ANTHROPIC_API_KEY to your environmentHow to enable Log10 data management for Langchain‚ÄãIntegration with log10 is a simple one-line log10_callback integration as shown below:from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback])API Reference:ChatOpenAIHumanMessageLog10 + Langchain + Logs docsMore details + screenshots including instructions for self-hosting logsHow to use tags with Log10‚Äãfrom langchain import OpenAIfrom langchain.chat_models import ChatAnthropicfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback], temperature=0.5, tags=["test"])completion = llm.predict_messages(messages, tags=["foobar"])print(completion)llm = ChatAnthropic(model="claude-2", callbacks=[log10_callback], temperature=0.7, tags=["baz"])llm.predict_messages(messages)print(completion)llm = OpenAI(model_name="text-davinci-003", callbacks=[log10_callback], temperature=0.5)completion = llm.predict("You are a ping pong machine.\nPing?\n")print(completion)API Reference:ChatAnthropicChatOpenAIHumanMessageYou can also intermix direct OpenAI calls and Langchain LLM calls:import osfrom log10.load import log10, log10_sessionimport openaifrom langchain import OpenAIlog10(openai)with log10_session(tags=["foo", "bar"]):    # Log a direct OpenAI call    response = openai.Completion.create(        model="text-ada-001",        prompt="Where is the Eiffel Tower?",        temperature=0,        max_tokens=1024,        top_p=1,        frequency_penalty=0,        presence_penalty=0,    )    print(response)    # Log a call via Langchain    llm = OpenAI(model_name="text-ada-001", temperature=0.5)    response = llm.predict("You are a ping pong machine.\nPing?\n")    print(response)How to debug Langchain calls‚ÄãExample of debuggingMore Langchain examplesPreviousLlama.cppNextMarqoWhat is Log10?Quick startHow to enable Log10 data management for LangchainHow to use tags with Log10How to debug Langchain callsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZillizIntegrationsGrouped by providerLog10On this pageLog10This page covers how to use the Log10 within LangChain.What is Log10?‚ÄãLog10 is an open source proxiless LLM data management and application development platform that lets you log, debug and tag your Langchain calls.Quick start‚ÄãCreate your free account at log10.ioAdd your LOG10_TOKEN and LOG10_ORG_ID from the Settings and Organization tabs respectively as environment variables.Also add LOG10_URL=https://log10.io and your usual LLM API key: for e.g. OPENAI_API_KEY or ANTHROPIC_API_KEY to your environmentHow to enable Log10 data management for Langchain‚ÄãIntegration with log10 is a simple one-line log10_callback integration as shown below:from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback])API Reference:ChatOpenAIHumanMessageLog10 + Langchain + Logs docsMore details + screenshots including instructions for self-hosting logsHow to use tags with Log10‚Äãfrom langchain import OpenAIfrom langchain.chat_models import ChatAnthropicfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback], temperature=0.5, tags=["test"])completion = llm.predict_messages(messages, tags=["foobar"])print(completion)llm = ChatAnthropic(model="claude-2", callbacks=[log10_callback], temperature=0.7, tags=["baz"])llm.predict_messages(messages)print(completion)llm = OpenAI(model_name="text-davinci-003", callbacks=[log10_callback], temperature=0.5)completion = llm.predict("You are a ping pong machine.\nPing?\n")print(completion)API Reference:ChatAnthropicChatOpenAIHumanMessageYou can also intermix direct OpenAI calls and Langchain LLM calls:import osfrom log10.load import log10, log10_sessionimport openaifrom langchain import OpenAIlog10(openai)with log10_session(tags=["foo", "bar"]):    # Log a direct OpenAI call    response = openai.Completion.create(        model="text-ada-001",        prompt="Where is the Eiffel Tower?",        temperature=0,        max_tokens=1024,        top_p=1,        frequency_penalty=0,        presence_penalty=0,    )    print(response)    # Log a call via Langchain    llm = OpenAI(model_name="text-ada-001", temperature=0.5)    response = llm.predict("You are a ping pong machine.\nPing?\n")    print(response)How to debug Langchain calls‚ÄãExample of debuggingMore Langchain examplesPreviousLlama.cppNextMarqoWhat is Log10?Quick startHow to enable Log10 data management for LangchainHow to use tags with Log10How to debug Langchain calls IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZillizIntegrationsGrouped by providerLog10On this pageLog10This page covers how to use the Log10 within LangChain.What is Log10?‚ÄãLog10 is an open source proxiless LLM data management and application development platform that lets you log, debug and tag your Langchain calls.Quick start‚ÄãCreate your free account at log10.ioAdd your LOG10_TOKEN and LOG10_ORG_ID from the Settings and Organization tabs respectively as environment variables.Also add LOG10_URL=https://log10.io and your usual LLM API key: for e.g. OPENAI_API_KEY or ANTHROPIC_API_KEY to your environmentHow to enable Log10 data management for Langchain‚ÄãIntegration with log10 is a simple one-line log10_callback integration as shown below:from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback])API Reference:ChatOpenAIHumanMessageLog10 + Langchain + Logs docsMore details + screenshots including instructions for self-hosting logsHow to use tags with Log10‚Äãfrom langchain import OpenAIfrom langchain.chat_models import ChatAnthropicfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback], temperature=0.5, tags=["test"])completion = llm.predict_messages(messages, tags=["foobar"])print(completion)llm = ChatAnthropic(model="claude-2", callbacks=[log10_callback], temperature=0.7, tags=["baz"])llm.predict_messages(messages)print(completion)llm = OpenAI(model_name="text-davinci-003", callbacks=[log10_callback], temperature=0.5)completion = llm.predict("You are a ping pong machine.\nPing?\n")print(completion)API Reference:ChatAnthropicChatOpenAIHumanMessageYou can also intermix direct OpenAI calls and Langchain LLM calls:import osfrom log10.load import log10, log10_sessionimport openaifrom langchain import OpenAIlog10(openai)with log10_session(tags=["foo", "bar"]):    # Log a direct OpenAI call    response = openai.Completion.create(        model="text-ada-001",        prompt="Where is the Eiffel Tower?",        temperature=0,        max_tokens=1024,        top_p=1,        frequency_penalty=0,        presence_penalty=0,    )    print(response)    # Log a call via Langchain    llm = OpenAI(model_name="text-ada-001", temperature=0.5)    response = llm.predict("You are a ping pong machine.\nPing?\n")    print(response)How to debug Langchain calls‚ÄãExample of debuggingMore Langchain examplesPreviousLlama.cppNextMarqoWhat is Log10?Quick startHow to enable Log10 data management for LangchainHow to use tags with Log10How to debug Langchain calls IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider Portkey Vectara IntegrationsGrouped by providerLog10On this pageLog10This page covers how to use the Log10 within LangChain.What is Log10?‚ÄãLog10 is an open source proxiless LLM data management and application development platform that lets you log, debug and tag your Langchain calls.Quick start‚ÄãCreate your free account at log10.ioAdd your LOG10_TOKEN and LOG10_ORG_ID from the Settings and Organization tabs respectively as environment variables.Also add LOG10_URL=https://log10.io and your usual LLM API key: for e.g. OPENAI_API_KEY or ANTHROPIC_API_KEY to your environmentHow to enable Log10 data management for Langchain‚ÄãIntegration with log10 is a simple one-line log10_callback integration as shown below:from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback])API Reference:ChatOpenAIHumanMessageLog10 + Langchain + Logs docsMore details + screenshots including instructions for self-hosting logsHow to use tags with Log10‚Äãfrom langchain import OpenAIfrom langchain.chat_models import ChatAnthropicfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback], temperature=0.5, tags=["test"])completion = llm.predict_messages(messages, tags=["foobar"])print(completion)llm = ChatAnthropic(model="claude-2", callbacks=[log10_callback], temperature=0.7, tags=["baz"])llm.predict_messages(messages)print(completion)llm = OpenAI(model_name="text-davinci-003", callbacks=[log10_callback], temperature=0.5)completion = llm.predict("You are a ping pong machine.\nPing?\n")print(completion)API Reference:ChatAnthropicChatOpenAIHumanMessageYou can also intermix direct OpenAI calls and Langchain LLM calls:import osfrom log10.load import log10, log10_sessionimport openaifrom langchain import OpenAIlog10(openai)with log10_session(tags=["foo", "bar"]):    # Log a direct OpenAI call    response = openai.Completion.create(        model="text-ada-001",        prompt="Where is the Eiffel Tower?",        temperature=0,        max_tokens=1024,        top_p=1,        frequency_penalty=0,        presence_penalty=0,    )    print(response)    # Log a call via Langchain    llm = OpenAI(model_name="text-ada-001", temperature=0.5)    response = llm.predict("You are a ping pong machine.\nPing?\n")    print(response)How to debug Langchain calls‚ÄãExample of debuggingMore Langchain examplesPreviousLlama.cppNextMarqoWhat is Log10?Quick startHow to enable Log10 data management for LangchainHow to use tags with Log10How to debug Langchain calls IntegrationsGrouped by providerLog10On this pageLog10This page covers how to use the Log10 within LangChain.What is Log10?‚ÄãLog10 is an open source proxiless LLM data management and application development platform that lets you log, debug and tag your Langchain calls.Quick start‚ÄãCreate your free account at log10.ioAdd your LOG10_TOKEN and LOG10_ORG_ID from the Settings and Organization tabs respectively as environment variables.Also add LOG10_URL=https://log10.io and your usual LLM API key: for e.g. OPENAI_API_KEY or ANTHROPIC_API_KEY to your environmentHow to enable Log10 data management for Langchain‚ÄãIntegration with log10 is a simple one-line log10_callback integration as shown below:from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback])API Reference:ChatOpenAIHumanMessageLog10 + Langchain + Logs docsMore details + screenshots including instructions for self-hosting logsHow to use tags with Log10‚Äãfrom langchain import OpenAIfrom langchain.chat_models import ChatAnthropicfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback], temperature=0.5, tags=["test"])completion = llm.predict_messages(messages, tags=["foobar"])print(completion)llm = ChatAnthropic(model="claude-2", callbacks=[log10_callback], temperature=0.7, tags=["baz"])llm.predict_messages(messages)print(completion)llm = OpenAI(model_name="text-davinci-003", callbacks=[log10_callback], temperature=0.5)completion = llm.predict("You are a ping pong machine.\nPing?\n")print(completion)API Reference:ChatAnthropicChatOpenAIHumanMessageYou can also intermix direct OpenAI calls and Langchain LLM calls:import osfrom log10.load import log10, log10_sessionimport openaifrom langchain import OpenAIlog10(openai)with log10_session(tags=["foo", "bar"]):    # Log a direct OpenAI call    response = openai.Completion.create(        model="text-ada-001",        prompt="Where is the Eiffel Tower?",        temperature=0,        max_tokens=1024,        top_p=1,        frequency_penalty=0,        presence_penalty=0,    )    print(response)    # Log a call via Langchain    llm = OpenAI(model_name="text-ada-001", temperature=0.5)    response = llm.predict("You are a ping pong machine.\nPing?\n")    print(response)How to debug Langchain calls‚ÄãExample of debuggingMore Langchain examplesPreviousLlama.cppNextMarqoWhat is Log10?Quick startHow to enable Log10 data management for LangchainHow to use tags with Log10How to debug Langchain calls IntegrationsGrouped by providerLog10On this pageLog10This page covers how to use the Log10 within LangChain.What is Log10?‚ÄãLog10 is an open source proxiless LLM data management and application development platform that lets you log, debug and tag your Langchain calls.Quick start‚ÄãCreate your free account at log10.ioAdd your LOG10_TOKEN and LOG10_ORG_ID from the Settings and Organization tabs respectively as environment variables.Also add LOG10_URL=https://log10.io and your usual LLM API key: for e.g. OPENAI_API_KEY or ANTHROPIC_API_KEY to your environmentHow to enable Log10 data management for Langchain‚ÄãIntegration with log10 is a simple one-line log10_callback integration as shown below:from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback])API Reference:ChatOpenAIHumanMessageLog10 + Langchain + Logs docsMore details + screenshots including instructions for self-hosting logsHow to use tags with Log10‚Äãfrom langchain import OpenAIfrom langchain.chat_models import ChatAnthropicfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback], temperature=0.5, tags=["test"])completion = llm.predict_messages(messages, tags=["foobar"])print(completion)llm = ChatAnthropic(model="claude-2", callbacks=[log10_callback], temperature=0.7, tags=["baz"])llm.predict_messages(messages)print(completion)llm = OpenAI(model_name="text-davinci-003", callbacks=[log10_callback], temperature=0.5)completion = llm.predict("You are a ping pong machine.\nPing?\n")print(completion)API Reference:ChatAnthropicChatOpenAIHumanMessageYou can also intermix direct OpenAI calls and Langchain LLM calls:import osfrom log10.load import log10, log10_sessionimport openaifrom langchain import OpenAIlog10(openai)with log10_session(tags=["foo", "bar"]):    # Log a direct OpenAI call    response = openai.Completion.create(        model="text-ada-001",        prompt="Where is the Eiffel Tower?",        temperature=0,        max_tokens=1024,        top_p=1,        frequency_penalty=0,        presence_penalty=0,    )    print(response)    # Log a call via Langchain    llm = OpenAI(model_name="text-ada-001", temperature=0.5)    response = llm.predict("You are a ping pong machine.\nPing?\n")    print(response)How to debug Langchain calls‚ÄãExample of debuggingMore Langchain examplesPreviousLlama.cppNextMarqo IntegrationsGrouped by providerLog10On this pageLog10This page covers how to use the Log10 within LangChain.What is Log10?‚ÄãLog10 is an open source proxiless LLM data management and application development platform that lets you log, debug and tag your Langchain calls.Quick start‚ÄãCreate your free account at log10.ioAdd your LOG10_TOKEN and LOG10_ORG_ID from the Settings and Organization tabs respectively as environment variables.Also add LOG10_URL=https://log10.io and your usual LLM API key: for e.g. OPENAI_API_KEY or ANTHROPIC_API_KEY to your environmentHow to enable Log10 data management for Langchain‚ÄãIntegration with log10 is a simple one-line log10_callback integration as shown below:from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback])API Reference:ChatOpenAIHumanMessageLog10 + Langchain + Logs docsMore details + screenshots including instructions for self-hosting logsHow to use tags with Log10‚Äãfrom langchain import OpenAIfrom langchain.chat_models import ChatAnthropicfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback], temperature=0.5, tags=["test"])completion = llm.predict_messages(messages, tags=["foobar"])print(completion)llm = ChatAnthropic(model="claude-2", callbacks=[log10_callback], temperature=0.7, tags=["baz"])llm.predict_messages(messages)print(completion)llm = OpenAI(model_name="text-davinci-003", callbacks=[log10_callback], temperature=0.5)completion = llm.predict("You are a ping pong machine.\nPing?\n")print(completion)API Reference:ChatAnthropicChatOpenAIHumanMessageYou can also intermix direct OpenAI calls and Langchain LLM calls:import osfrom log10.load import log10, log10_sessionimport openaifrom langchain import OpenAIlog10(openai)with log10_session(tags=["foo", "bar"]):    # Log a direct OpenAI call    response = openai.Completion.create(        model="text-ada-001",        prompt="Where is the Eiffel Tower?",        temperature=0,        max_tokens=1024,        top_p=1,        frequency_penalty=0,        presence_penalty=0,    )    print(response)    # Log a call via Langchain    llm = OpenAI(model_name="text-ada-001", temperature=0.5)    response = llm.predict("You are a ping pong machine.\nPing?\n")    print(response)How to debug Langchain calls‚ÄãExample of debuggingMore Langchain examplesPreviousLlama.cppNextMarqo On this page Log10This page covers how to use the Log10 within LangChain.What is Log10?‚ÄãLog10 is an open source proxiless LLM data management and application development platform that lets you log, debug and tag your Langchain calls.Quick start‚ÄãCreate your free account at log10.ioAdd your LOG10_TOKEN and LOG10_ORG_ID from the Settings and Organization tabs respectively as environment variables.Also add LOG10_URL=https://log10.io and your usual LLM API key: for e.g. OPENAI_API_KEY or ANTHROPIC_API_KEY to your environmentHow to enable Log10 data management for Langchain‚ÄãIntegration with log10 is a simple one-line log10_callback integration as shown below:from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback])API Reference:ChatOpenAIHumanMessageLog10 + Langchain + Logs docsMore details + screenshots including instructions for self-hosting logsHow to use tags with Log10‚Äãfrom langchain import OpenAIfrom langchain.chat_models import ChatAnthropicfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback], temperature=0.5, tags=["test"])completion = llm.predict_messages(messages, tags=["foobar"])print(completion)llm = ChatAnthropic(model="claude-2", callbacks=[log10_callback], temperature=0.7, tags=["baz"])llm.predict_messages(messages)print(completion)llm = OpenAI(model_name="text-davinci-003", callbacks=[log10_callback], temperature=0.5)completion = llm.predict("You are a ping pong machine.\nPing?\n")print(completion)API Reference:ChatAnthropicChatOpenAIHumanMessageYou can also intermix direct OpenAI calls and Langchain LLM calls:import osfrom log10.load import log10, log10_sessionimport openaifrom langchain import OpenAIlog10(openai)with log10_session(tags=["foo", "bar"]):    # Log a direct OpenAI call    response = openai.Completion.create(        model="text-ada-001",        prompt="Where is the Eiffel Tower?",        temperature=0,        max_tokens=1024,        top_p=1,        frequency_penalty=0,        presence_penalty=0,    )    print(response)    # Log a call via Langchain    llm = OpenAI(model_name="text-ada-001", temperature=0.5)    response = llm.predict("You are a ping pong machine.\nPing?\n")    print(response)How to debug Langchain calls‚ÄãExample of debuggingMore Langchain examples from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback]) from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback])  API Reference:ChatOpenAIHumanMessage from langchain import OpenAIfrom langchain.chat_models import ChatAnthropicfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback], temperature=0.5, tags=["test"])completion = llm.predict_messages(messages, tags=["foobar"])print(completion)llm = ChatAnthropic(model="claude-2", callbacks=[log10_callback], temperature=0.7, tags=["baz"])llm.predict_messages(messages)print(completion)llm = OpenAI(model_name="text-davinci-003", callbacks=[log10_callback], temperature=0.5)completion = llm.predict("You are a ping pong machine.\nPing?\n")print(completion) from langchain import OpenAIfrom langchain.chat_models import ChatAnthropicfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessagefrom log10.langchain import Log10Callbackfrom log10.llm import Log10Configlog10_callback = Log10Callback(log10_config=Log10Config())messages = [    HumanMessage(content="You are a ping pong machine"),    HumanMessage(content="Ping?"),]llm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback], temperature=0.5, tags=["test"])completion = llm.predict_messages(messages, tags=["foobar"])print(completion)llm = ChatAnthropic(model="claude-2", callbacks=[log10_callback], temperature=0.7, tags=["baz"])llm.predict_messages(messages)print(completion)llm = OpenAI(model_name="text-davinci-003", callbacks=[log10_callback], temperature=0.5)completion = llm.predict("You are a ping pong machine.\nPing?\n")print(completion)  API Reference:ChatAnthropicChatOpenAIHumanMessage import osfrom log10.load import log10, log10_sessionimport openaifrom langchain import OpenAIlog10(openai)with log10_session(tags=["foo", "bar"]):    # Log a direct OpenAI call    response = openai.Completion.create(        model="text-ada-001",        prompt="Where is the Eiffel Tower?",        temperature=0,        max_tokens=1024,        top_p=1,        frequency_penalty=0,        presence_penalty=0,    )    print(response)    # Log a call via Langchain    llm = OpenAI(model_name="text-ada-001", temperature=0.5)    response = llm.predict("You are a ping pong machine.\nPing?\n")    print(response) import osfrom log10.load import log10, log10_sessionimport openaifrom langchain import OpenAIlog10(openai)with log10_session(tags=["foo", "bar"]):    # Log a direct OpenAI call    response = openai.Completion.create(        model="text-ada-001",        prompt="Where is the Eiffel Tower?",        temperature=0,        max_tokens=1024,        top_p=1,        frequency_penalty=0,        presence_penalty=0,    )    print(response)    # Log a call via Langchain    llm = OpenAI(model_name="text-ada-001", temperature=0.5)    response = llm.predict("You are a ping pong machine.\nPing?\n")    print(response)  Previous Llama.cpp Next Marqo What is Log10?Quick startHow to enable Log10 data management for LangchainHow to use tags with Log10How to debug Langchain calls What is Log10?Quick startHow to enable Log10 data management for LangchainHow to use tags with Log10How to debug Langchain calls CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/) Activeloop Deep Lake (/docs/integrations/providers/activeloop_deeplake) AI21 Labs (/docs/integrations/providers/ai21) Aim (/docs/integrations/providers/aim_tracking) AINetwork (/docs/integrations/providers/ainetwork) Airbyte (/docs/integrations/providers/airbyte) Airtable (/docs/integrations/providers/airtable) Aleph Alpha (/docs/integrations/providers/aleph_alpha) Alibaba Cloud Opensearch (/docs/integrations/providers/alibabacloud_opensearch) Amazon API Gateway (/docs/integrations/providers/amazon_api_gateway) AnalyticDB (/docs/integrations/providers/analyticdb) Annoy (/docs/integrations/providers/annoy) Anyscale (/docs/integrations/providers/anyscale) Apify (/docs/integrations/providers/apify) ArangoDB (/docs/integrations/providers/arangodb) Argilla (/docs/integrations/providers/argilla) Arthur (/docs/integrations/providers/arthur_tracking) Arxiv (/docs/integrations/providers/arxiv) Atlas (/docs/integrations/providers/atlas) AwaDB (/docs/integrations/providers/awadb) AWS S3 Directory (/docs/integrations/providers/aws_s3) AZLyrics (/docs/integrations/providers/azlyrics) Azure Blob Storage (/docs/integrations/providers/azure_blob_storage) Azure Cognitive Search (/docs/integrations/providers/azure_cognitive_search_) Azure OpenAI (/docs/integrations/providers/azure_openai) BagelDB (/docs/integrations/providers/bageldb) Banana (/docs/integrations/providers/bananadev) Baseten (/docs/integrations/providers/baseten) Beam (/docs/integrations/providers/beam) Bedrock (/docs/integrations/providers/bedrock) BiliBili (/docs/integrations/providers/bilibili) NIBittensor (/docs/integrations/providers/bittensor) Blackboard (/docs/integrations/providers/blackboard) Brave Search (/docs/integrations/providers/brave_search) Cassandra (/docs/integrations/providers/cassandra) CerebriumAI (/docs/integrations/providers/cerebriumai) Chaindesk (/docs/integrations/providers/chaindesk) Chroma (/docs/integrations/providers/chroma) Clarifai (/docs/integrations/providers/clarifai) ClearML (/docs/integrations/providers/clearml_tracking) ClickHouse (/docs/integrations/providers/clickhouse) CnosDB (/docs/integrations/providers/cnosdb) Cohere (/docs/integrations/providers/cohere) College Confidential (/docs/integrations/providers/college_confidential) Comet (/docs/integrations/providers/comet_tracking) Confident AI (/docs/integrations/providers/confident) Confluence (/docs/integrations/providers/confluence) C Transformers (/docs/integrations/providers/ctransformers) DashVector (/docs/integrations/providers/dashvector) Databricks (/docs/integrations/providers/databricks) Datadog Tracing (/docs/integrations/providers/datadog) Datadog Logs (/docs/integrations/providers/datadog_logs) DataForSEO (/docs/integrations/providers/dataforseo) DeepInfra (/docs/integrations/providers/deepinfra) DeepSparse (/docs/integrations/providers/deepsparse) Diffbot (/docs/integrations/providers/diffbot) Dingo (/docs/integrations/providers/dingo) Discord (/docs/integrations/providers/discord) DocArray (/docs/integrations/providers/docarray) Docugami (/docs/integrations/providers/docugami) DuckDB (/docs/integrations/providers/duckdb) Elasticsearch (/docs/integrations/providers/elasticsearch) Epsilla (/docs/integrations/providers/epsilla) EverNote (/docs/integrations/providers/evernote) Facebook Chat (/docs/integrations/providers/facebook_chat) Facebook Faiss (/docs/integrations/providers/facebook_faiss) Figma (/docs/integrations/providers/figma) Fireworks (/docs/integrations/providers/fireworks) Flyte (/docs/integrations/providers/flyte) ForefrontAI (/docs/integrations/providers/forefrontai) Git (/docs/integrations/providers/git) GitBook (/docs/integrations/providers/gitbook) Golden (/docs/integrations/providers/golden) Google BigQuery (/docs/integrations/providers/google_bigquery) Google Cloud Storage (/docs/integrations/providers/google_cloud_storage) Google Drive (/docs/integrations/providers/google_drive) Google Search (/docs/integrations/providers/google_search) Google Serper (/docs/integrations/providers/google_serper) Google Vertex AI MatchingEngine (/docs/integrations/providers/google_vertex_ai_matchingengine) GooseAI (/docs/integrations/providers/gooseai) GPT4All (/docs/integrations/providers/gpt4all) Graphsignal (/docs/integrations/providers/graphsignal) Grobid (/docs/integrations/providers/grobid) Gutenberg (/docs/integrations/providers/gutenberg) Hacker News (/docs/integrations/providers/hacker_news) Hazy Research (/docs/integrations/providers/hazy_research) Helicone (/docs/integrations/providers/helicone) Hologres (/docs/integrations/providers/hologres) Hugging Face (/docs/integrations/providers/huggingface) iFixit (/docs/integrations/providers/ifixit) IMSDb (/docs/integrations/providers/imsdb) Infino (/docs/integrations/providers/infino) Jina (/docs/integrations/providers/jina) Konko (/docs/integrations/providers/konko) LanceDB (/docs/integrations/providers/lancedb) LangChain Decorators ‚ú® (/docs/integrations/providers/langchain_decorators) Llama.cpp (/docs/integrations/providers/llamacpp) Log10 (/docs/integrations/providers/log10) Marqo (/docs/integrations/providers/marqo) MediaWikiDump (/docs/integrations/providers/mediawikidump) Meilisearch (/docs/integrations/providers/meilisearch) Metal (/docs/integrations/providers/metal) Microsoft OneDrive (/docs/integrations/providers/microsoft_onedrive) Microsoft PowerPoint (/docs/integrations/providers/microsoft_powerpoint) Microsoft Word (/docs/integrations/providers/microsoft_word) Milvus (/docs/integrations/providers/milvus) Minimax (/docs/integrations/providers/minimax) MLflow AI Gateway (/docs/integrations/providers/mlflow_ai_gateway) MLflow (/docs/integrations/providers/mlflow_tracking) Modal (/docs/integrations/providers/modal) ModelScope (/docs/integrations/providers/modelscope) Modern Treasury (/docs/integrations/providers/modern_treasury) Momento (/docs/integrations/providers/momento) MongoDB Atlas (/docs/integrations/providers/mongodb_atlas) Motherduck (/docs/integrations/providers/motherduck) MyScale (/docs/integrations/providers/myscale) Neo4j (/docs/integrations/providers/neo4j) NLPCloud (/docs/integrations/providers/nlpcloud) Notion DB (/docs/integrations/providers/notion) Obsidian (/docs/integrations/providers/obsidian) OpenAI (/docs/integrations/providers/openai) OpenLLM (/docs/integrations/providers/openllm) OpenSearch (/docs/integrations/providers/opensearch) OpenWeatherMap (/docs/integrations/providers/openweathermap) Petals (/docs/integrations/providers/petals) Postgres Embedding (/docs/integrations/providers/pg_embedding) PGVector (/docs/integrations/providers/pgvector) Pinecone (/docs/integrations/providers/pinecone) PipelineAI (/docs/integrations/providers/pipelineai) Portkey (/docs/integrations/providers/portkey/) Predibase (/docs/integrations/providers/predibase) Prediction Guard (/docs/integrations/providers/predictionguard) PromptLayer (/docs/integrations/providers/promptlayer) Psychic (/docs/integrations/providers/psychic) PubMed (/docs/integrations/providers/pubmed) Qdrant (/docs/integrations/providers/qdrant) Ray Serve (/docs/integrations/providers/ray_serve) Rebuff (/docs/integrations/providers/rebuff) Reddit (/docs/integrations/providers/reddit) Redis (/docs/integrations/providers/redis) Replicate (/docs/integrations/providers/replicate) Roam (/docs/integrations/providers/roam) Rockset (/docs/integrations/providers/rockset) Runhouse (/docs/integrations/providers/runhouse) RWKV-4 (/docs/integrations/providers/rwkv) SageMaker Endpoint (/docs/integrations/providers/sagemaker_endpoint) SageMaker Tracking (/docs/integrations/providers/sagemaker_tracking) ScaNN (/docs/integrations/providers/scann) SearxNG Search API (/docs/integrations/providers/searx) SerpAPI (/docs/integrations/providers/serpapi) Shale Protocol (/docs/integrations/providers/shaleprotocol) SingleStoreDB (/docs/integrations/providers/singlestoredb) scikit-learn (/docs/integrations/providers/sklearn) Slack (/docs/integrations/providers/slack) spaCy (/docs/integrations/providers/spacy) Spreedly (/docs/integrations/providers/spreedly) StarRocks (/docs/integrations/providers/starrocks) StochasticAI (/docs/integrations/providers/stochasticai) Stripe (/docs/integrations/providers/stripe) Supabase (Postgres) (/docs/integrations/providers/supabase) Nebula (/docs/integrations/providers/symblai_nebula) Tair (/docs/integrations/providers/tair) Telegram (/docs/integrations/providers/telegram) TencentVectorDB (/docs/integrations/providers/tencentvectordb) TensorFlow Datasets (/docs/integrations/providers/tensorflow_datasets) Tigris (/docs/integrations/providers/tigris) 2Markdown (/docs/integrations/providers/tomarkdown) Trello (/docs/integrations/providers/trello) TruLens (/docs/integrations/providers/trulens) Twitter (/docs/integrations/providers/twitter) Typesense (/docs/integrations/providers/typesense) Unstructured (/docs/integrations/providers/unstructured) USearch (/docs/integrations/providers/usearch) Vearch (/docs/integrations/providers/vearch) Vectara (/docs/integrations/providers/vectara/) Vespa (/docs/integrations/providers/vespa) WandB Tracing (/docs/integrations/providers/wandb_tracing) Weights & Biases (/docs/integrations/providers/wandb_tracking) Weather (/docs/integrations/providers/weather) Weaviate (/docs/integrations/providers/weaviate) WhatsApp (/docs/integrations/providers/whatsapp) WhyLabs (/docs/integrations/providers/whylabs_profiling) Wikipedia (/docs/integrations/providers/wikipedia) Wolfram Alpha (/docs/integrations/providers/wolfram_alpha) Writer (/docs/integrations/providers/writer) Xata (/docs/integrations/providers/xata) Xorbits Inference (Xinference) (/docs/integrations/providers/xinference) Yeager.ai (/docs/integrations/providers/yeagerai) YouTube (/docs/integrations/providers/youtube) Zep (/docs/integrations/providers/zep) Zilliz (/docs/integrations/providers/zilliz)  (/) Integrations (/docs/integrations) Grouped by provider (/docs/integrations/providers/) Log10 (https://log10.io) ‚Äã (#what-is-log10) open source (https://github.com/log10-io/log10) ‚Äã (#quick-start) log10.io (https://log10.io) ‚Äã (#how-to-enable-log10-data-management-for-langchain) ChatOpenAI (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html) HumanMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.HumanMessage.html) Log10 + Langchain + Logs docs (https://github.com/log10-io/log10/blob/main/logging.md#langchain-logger) More details + screenshots (https://log10.io/docs/logs) ‚Äã (#how-to-use-tags-with-log10) ChatAnthropic (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.anthropic.ChatAnthropic.html) ChatOpenAI (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html) HumanMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.HumanMessage.html) ‚Äã (#how-to-debug-langchain-calls) Example of debugging (https://log10.io/docs/prompt_chain_debugging) More Langchain examples (https://github.com/log10-io/log10/tree/main/examples#langchain) PreviousLlama.cpp (/docs/integrations/providers/llamacpp) NextMarqo (/docs/integrations/providers/marqo) What is Log10? (#what-is-log10) Quick start (#quick-start) How to enable Log10 data management for Langchain (#how-to-enable-log10-data-management-for-langchain) How to use tags with Log10 (#how-to-use-tags-with-log10) How to debug Langchain calls (#how-to-debug-langchain-calls) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)