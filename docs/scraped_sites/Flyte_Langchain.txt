Flyte is an open-source orchestrator that facilitates building production-grade data and ML pipelines. It is built for scalability and reproducibility, leveraging Kubernetes as its underlying platform. The purpose of this notebook is to demonstrate the integration of a FlyteCallback into your Flyte task, enabling you to effectively monitor and track your LangChain experiments. A Flyte task serves as the foundational building block of Flyte. To execute LangChain experiments, you need to write Flyte tasks that define the specific steps and operations involved. NOTE: The getting started guide offers detailed, step-by-step instructions on installing Flyte locally and running your initial Flyte pipeline. First, import the necessary dependencies to support your LangChain experiments. Set up the necessary environment variables to utilize the OpenAI API and Serp API: Replace <your_openai_api_key> and <your_serp_api_key> with your respective API keys obtained from OpenAI and Serp API. To guarantee reproducibility of your pipelines, Flyte tasks are containerized. Each Flyte task must be associated with an image, which can either be shared across the entire Flyte workflow or provided separately for each task. To streamline the process of supplying the required dependencies for each Flyte task, you can initialize an ImageSpec object. This approach automatically triggers a Docker build, alleviating the need for users to manually create a Docker image. You have the flexibility to push the Docker image to a registry of your preference. Docker Hub or GitHub Container Registry (GHCR) is a convenient option to begin with. Once you have selected a registry, you can proceed to create Flyte tasks that log the LangChain metrics to Flyte Deck. The following examples demonstrate tasks related to OpenAI LLM, chains and agent with tools: These tasks serve as a starting point for running your LangChain experiments within Flyte. To execute the Flyte tasks on the configured Flyte backend, use the following command: This command will initiate the execution of the langchain_llm task on the Flyte backend. You can trigger the remaining two tasks in a similar manner. The metrics will be displayed on the Flyte UI as follows:  IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz Activeloop Deep Lake AI21 Labs Aim AINetwork Airbyte Airtable Aleph Alpha Alibaba Cloud Opensearch Amazon API Gateway AnalyticDB Annoy Anyscale Apify ArangoDB Argilla Arthur Arxiv Atlas AwaDB AWS S3 Directory AZLyrics Azure Blob Storage Azure Cognitive Search Azure OpenAI BagelDB Banana Baseten Beam Bedrock BiliBili NIBittensor Blackboard Brave Search Cassandra CerebriumAI Chaindesk Chroma Clarifai ClearML ClickHouse CnosDB Cohere College Confidential Comet Confident AI Confluence C Transformers DashVector Databricks Datadog Tracing Datadog Logs DataForSEO DeepInfra DeepSparse Diffbot Dingo Discord DocArray Docugami DuckDB Elasticsearch Epsilla EverNote Facebook Chat Facebook Faiss Figma Fireworks Flyte ForefrontAI Git GitBook Golden Google BigQuery Google Cloud Storage Google Drive Google Search Google Serper Google Vertex AI MatchingEngine GooseAI GPT4All Graphsignal Grobid Gutenberg Hacker News Hazy Research Helicone Hologres Hugging Face iFixit IMSDb Infino Jina Konko LanceDB LangChain Decorators ‚ú® Llama.cpp Log10 Marqo MediaWikiDump Meilisearch Metal Microsoft OneDrive Microsoft PowerPoint Microsoft Word Milvus Minimax MLflow AI Gateway MLflow Modal ModelScope Modern Treasury Momento MongoDB Atlas Motherduck MyScale Neo4j NLPCloud Notion DB Obsidian OpenAI OpenLLM OpenSearch OpenWeatherMap Petals Postgres Embedding PGVector Pinecone PipelineAI Portkey Predibase Prediction Guard PromptLayer Psychic PubMed Qdrant Ray Serve Rebuff Reddit Redis Replicate Roam Rockset Runhouse RWKV-4 SageMaker Endpoint SageMaker Tracking ScaNN SearxNG Search API SerpAPI Shale Protocol SingleStoreDB scikit-learn Slack spaCy Spreedly StarRocks StochasticAI Stripe Supabase (Postgres) Nebula Tair Telegram TencentVectorDB TensorFlow Datasets Tigris 2Markdown Trello TruLens Twitter Typesense Unstructured USearch Vearch Vectara Vespa WandB Tracing Weights & Biases Weather Weaviate WhatsApp WhyLabs Wikipedia Wolfram Alpha Writer Xata Xorbits Inference (Xinference) Yeager.ai YouTube Zep Zilliz  Integrations Grouped by provider Flyte Install the Flytekit library by running the command pip install flytekit. Install the Flytekit-Envd plugin by running the command pip install flytekitplugins-envd. Install LangChain by running the command pip install langchain. Install Docker on your system. AgentType initialize_agent load_tools FlyteCallbackHandler LLMChain ChatOpenAI PromptTemplate HumanMessage Installation & Setup Flyte TasksLLMChainAgent LLM Chain Agent Execute the Flyte Tasks on Kubernetes Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZillizIntegrationsGrouped by providerFlyteOn this pageFlyteFlyte is an open-source orchestrator that facilitates building production-grade data and ML pipelines. It is built for scalability and reproducibility, leveraging Kubernetes as its underlying platform.The purpose of this notebook is to demonstrate the integration of a FlyteCallback into your Flyte task, enabling you to effectively monitor and track your LangChain experiments.Installation & Setup‚ÄãInstall the Flytekit library by running the command pip install flytekit.Install the Flytekit-Envd plugin by running the command pip install flytekitplugins-envd.Install LangChain by running the command pip install langchain.Install Docker on your system.Flyte Tasks‚ÄãA Flyte task serves as the foundational building block of Flyte. To execute LangChain experiments, you need to write Flyte tasks that define the specific steps and operations involved.NOTE: The getting started guide offers detailed, step-by-step instructions on installing Flyte locally and running your initial Flyte pipeline.First, import the necessary dependencies to support your LangChain experiments.import osfrom flytekit import ImageSpec, taskfrom langchain.agents import AgentType, initialize_agent, load_toolsfrom langchain.callbacks import FlyteCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.chat_models import ChatOpenAIfrom langchain.prompts import PromptTemplatefrom langchain.schema import HumanMessageAPI Reference:AgentTypeinitialize_agentload_toolsFlyteCallbackHandlerLLMChainChatOpenAIPromptTemplateHumanMessageSet up the necessary environment variables to utilize the OpenAI API and Serp API:# Set OpenAI API keyos.environ["OPENAI_API_KEY"] = "<your_openai_api_key>"# Set Serp API keyos.environ["SERPAPI_API_KEY"] = "<your_serp_api_key>"Replace <your_openai_api_key> and <your_serp_api_key> with your respective API keys obtained from OpenAI and Serp API.To guarantee reproducibility of your pipelines, Flyte tasks are containerized. Each Flyte task must be associated with an image, which can either be shared across the entire Flyte workflow or provided separately for each task.To streamline the process of supplying the required dependencies for each Flyte task, you can initialize an ImageSpec object. This approach automatically triggers a Docker build, alleviating the need for users to manually create a Docker image.custom_image = ImageSpec(    name="langchain-flyte",    packages=[        "langchain",        "openai",        "spacy",        "https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0.tar.gz",        "textstat",        "google-search-results",    ],    registry="<your-registry>",)You have the flexibility to push the Docker image to a registry of your preference. Docker Hub or GitHub Container Registry (GHCR) is a convenient option to begin with.Once you have selected a registry, you can proceed to create Flyte tasks that log the LangChain metrics to Flyte Deck.The following examples demonstrate tasks related to OpenAI LLM, chains and agent with tools:LLM‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_llm() -> str:    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0.2,        callbacks=[FlyteCallbackHandler()],    )    return llm([HumanMessage(content="Tell me a joke")]).contentChain‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_chain() -> list[dict[str, str]]:    template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    prompt_template = PromptTemplate(input_variables=["title"], template=template)    synopsis_chain = LLMChain(        llm=llm, prompt=prompt_template, callbacks=[FlyteCallbackHandler()]    )    test_prompts = [        {            "title": "documentary about good video games that push the boundary of game design"        },    ]    return synopsis_chain.apply(test_prompts)Agent‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_agent() -> str:    llm = OpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    tools = load_tools(        ["serpapi", "llm-math"], llm=llm, callbacks=[FlyteCallbackHandler()]    )    agent = initialize_agent(        tools,        llm,        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,        callbacks=[FlyteCallbackHandler()],        verbose=True,    )    return agent.run(        "Who is Leonardo DiCaprio's girlfriend? Could you calculate her current age and raise it to the power of 0.43?"    )These tasks serve as a starting point for running your LangChain experiments within Flyte.Execute the Flyte Tasks on Kubernetes‚ÄãTo execute the Flyte tasks on the configured Flyte backend, use the following command:pyflyte run --image <your-image> langchain_flyte.py langchain_llmThis command will initiate the execution of the langchain_llm task on the Flyte backend. You can trigger the remaining two tasks in a similar manner.The metrics will be displayed on the Flyte UI as follows:PreviousFireworksNextForefrontAIInstallation & SetupFlyte TasksLLMChainAgentExecute the Flyte Tasks on KubernetesCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZillizIntegrationsGrouped by providerFlyteOn this pageFlyteFlyte is an open-source orchestrator that facilitates building production-grade data and ML pipelines. Docker Hub or GitHub Container Registry (GHCR) is a convenient option to begin with.Once you have selected a registry, you can proceed to create Flyte tasks that log the LangChain metrics to Flyte Deck.The following examples demonstrate tasks related to OpenAI LLM, chains and agent with tools:LLM‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_llm() -> str:    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0.2,        callbacks=[FlyteCallbackHandler()],    )    return llm([HumanMessage(content="Tell me a joke")]).contentChain‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_chain() -> list[dict[str, str]]:    template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    prompt_template = PromptTemplate(input_variables=["title"], template=template)    synopsis_chain = LLMChain(        llm=llm, prompt=prompt_template, callbacks=[FlyteCallbackHandler()]    )    test_prompts = [        {            "title": "documentary about good video games that push the boundary of game design"        },    ]    return synopsis_chain.apply(test_prompts)Agent‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_agent() -> str:    llm = OpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    tools = load_tools(        ["serpapi", "llm-math"], llm=llm, callbacks=[FlyteCallbackHandler()]    )    agent = initialize_agent(        tools,        llm,        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,        callbacks=[FlyteCallbackHandler()],        verbose=True,    )    return agent.run(        "Who is Leonardo DiCaprio's girlfriend? Could you calculate her current age and raise it to the power of 0.43?"    )These tasks serve as a starting point for running your LangChain experiments within Flyte.Execute the Flyte Tasks on Kubernetes‚ÄãTo execute the Flyte tasks on the configured Flyte backend, use the following command:pyflyte run --image <your-image> langchain_flyte.py langchain_llmThis command will initiate the execution of the langchain_llm task on the Flyte backend. You can trigger the remaining two tasks in a similar manner.The metrics will be displayed on the Flyte UI as follows:PreviousFireworksNextForefrontAIInstallation & SetupFlyte TasksLLMChainAgentExecute the Flyte Tasks on Kubernetes IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZillizIntegrationsGrouped by providerFlyteOn this pageFlyteFlyte is an open-source orchestrator that facilitates building production-grade data and ML pipelines. Docker Hub or GitHub Container Registry (GHCR) is a convenient option to begin with.Once you have selected a registry, you can proceed to create Flyte tasks that log the LangChain metrics to Flyte Deck.The following examples demonstrate tasks related to OpenAI LLM, chains and agent with tools:LLM‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_llm() -> str:    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0.2,        callbacks=[FlyteCallbackHandler()],    )    return llm([HumanMessage(content="Tell me a joke")]).contentChain‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_chain() -> list[dict[str, str]]:    template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    prompt_template = PromptTemplate(input_variables=["title"], template=template)    synopsis_chain = LLMChain(        llm=llm, prompt=prompt_template, callbacks=[FlyteCallbackHandler()]    )    test_prompts = [        {            "title": "documentary about good video games that push the boundary of game design"        },    ]    return synopsis_chain.apply(test_prompts)Agent‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_agent() -> str:    llm = OpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    tools = load_tools(        ["serpapi", "llm-math"], llm=llm, callbacks=[FlyteCallbackHandler()]    )    agent = initialize_agent(        tools,        llm,        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,        callbacks=[FlyteCallbackHandler()],        verbose=True,    )    return agent.run(        "Who is Leonardo DiCaprio's girlfriend? Could you calculate her current age and raise it to the power of 0.43?"    )These tasks serve as a starting point for running your LangChain experiments within Flyte.Execute the Flyte Tasks on Kubernetes‚ÄãTo execute the Flyte tasks on the configured Flyte backend, use the following command:pyflyte run --image <your-image> langchain_flyte.py langchain_llmThis command will initiate the execution of the langchain_llm task on the Flyte backend. You can trigger the remaining two tasks in a similar manner.The metrics will be displayed on the Flyte UI as follows:PreviousFireworksNextForefrontAIInstallation & SetupFlyte TasksLLMChainAgentExecute the Flyte Tasks on Kubernetes IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider Portkey Vectara IntegrationsGrouped by providerFlyteOn this pageFlyteFlyte is an open-source orchestrator that facilitates building production-grade data and ML pipelines. Docker Hub or GitHub Container Registry (GHCR) is a convenient option to begin with.Once you have selected a registry, you can proceed to create Flyte tasks that log the LangChain metrics to Flyte Deck.The following examples demonstrate tasks related to OpenAI LLM, chains and agent with tools:LLM‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_llm() -> str:    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0.2,        callbacks=[FlyteCallbackHandler()],    )    return llm([HumanMessage(content="Tell me a joke")]).contentChain‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_chain() -> list[dict[str, str]]:    template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    prompt_template = PromptTemplate(input_variables=["title"], template=template)    synopsis_chain = LLMChain(        llm=llm, prompt=prompt_template, callbacks=[FlyteCallbackHandler()]    )    test_prompts = [        {            "title": "documentary about good video games that push the boundary of game design"        },    ]    return synopsis_chain.apply(test_prompts)Agent‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_agent() -> str:    llm = OpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    tools = load_tools(        ["serpapi", "llm-math"], llm=llm, callbacks=[FlyteCallbackHandler()]    )    agent = initialize_agent(        tools,        llm,        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,        callbacks=[FlyteCallbackHandler()],        verbose=True,    )    return agent.run(        "Who is Leonardo DiCaprio's girlfriend? Could you calculate her current age and raise it to the power of 0.43?"    )These tasks serve as a starting point for running your LangChain experiments within Flyte.Execute the Flyte Tasks on Kubernetes‚ÄãTo execute the Flyte tasks on the configured Flyte backend, use the following command:pyflyte run --image <your-image> langchain_flyte.py langchain_llmThis command will initiate the execution of the langchain_llm task on the Flyte backend. You can trigger the remaining two tasks in a similar manner.The metrics will be displayed on the Flyte UI as follows:PreviousFireworksNextForefrontAIInstallation & SetupFlyte TasksLLMChainAgentExecute the Flyte Tasks on Kubernetes IntegrationsGrouped by providerFlyteOn this pageFlyteFlyte is an open-source orchestrator that facilitates building production-grade data and ML pipelines. Docker Hub or GitHub Container Registry (GHCR) is a convenient option to begin with.Once you have selected a registry, you can proceed to create Flyte tasks that log the LangChain metrics to Flyte Deck.The following examples demonstrate tasks related to OpenAI LLM, chains and agent with tools:LLM‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_llm() -> str:    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0.2,        callbacks=[FlyteCallbackHandler()],    )    return llm([HumanMessage(content="Tell me a joke")]).contentChain‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_chain() -> list[dict[str, str]]:    template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    prompt_template = PromptTemplate(input_variables=["title"], template=template)    synopsis_chain = LLMChain(        llm=llm, prompt=prompt_template, callbacks=[FlyteCallbackHandler()]    )    test_prompts = [        {            "title": "documentary about good video games that push the boundary of game design"        },    ]    return synopsis_chain.apply(test_prompts)Agent‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_agent() -> str:    llm = OpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    tools = load_tools(        ["serpapi", "llm-math"], llm=llm, callbacks=[FlyteCallbackHandler()]    )    agent = initialize_agent(        tools,        llm,        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,        callbacks=[FlyteCallbackHandler()],        verbose=True,    )    return agent.run(        "Who is Leonardo DiCaprio's girlfriend? Could you calculate her current age and raise it to the power of 0.43?"    )These tasks serve as a starting point for running your LangChain experiments within Flyte.Execute the Flyte Tasks on Kubernetes‚ÄãTo execute the Flyte tasks on the configured Flyte backend, use the following command:pyflyte run --image <your-image> langchain_flyte.py langchain_llmThis command will initiate the execution of the langchain_llm task on the Flyte backend. You can trigger the remaining two tasks in a similar manner.The metrics will be displayed on the Flyte UI as follows:PreviousFireworksNextForefrontAI IntegrationsGrouped by providerFlyteOn this pageFlyteFlyte is an open-source orchestrator that facilitates building production-grade data and ML pipelines. Docker Hub or GitHub Container Registry (GHCR) is a convenient option to begin with.Once you have selected a registry, you can proceed to create Flyte tasks that log the LangChain metrics to Flyte Deck.The following examples demonstrate tasks related to OpenAI LLM, chains and agent with tools:LLM‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_llm() -> str:    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0.2,        callbacks=[FlyteCallbackHandler()],    )    return llm([HumanMessage(content="Tell me a joke")]).contentChain‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_chain() -> list[dict[str, str]]:    template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    prompt_template = PromptTemplate(input_variables=["title"], template=template)    synopsis_chain = LLMChain(        llm=llm, prompt=prompt_template, callbacks=[FlyteCallbackHandler()]    )    test_prompts = [        {            "title": "documentary about good video games that push the boundary of game design"        },    ]    return synopsis_chain.apply(test_prompts)Agent‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_agent() -> str:    llm = OpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    tools = load_tools(        ["serpapi", "llm-math"], llm=llm, callbacks=[FlyteCallbackHandler()]    )    agent = initialize_agent(        tools,        llm,        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,        callbacks=[FlyteCallbackHandler()],        verbose=True,    )    return agent.run(        "Who is Leonardo DiCaprio's girlfriend? Could you calculate her current age and raise it to the power of 0.43?"    )These tasks serve as a starting point for running your LangChain experiments within Flyte.Execute the Flyte Tasks on Kubernetes‚ÄãTo execute the Flyte tasks on the configured Flyte backend, use the following command:pyflyte run --image <your-image> langchain_flyte.py langchain_llmThis command will initiate the execution of the langchain_llm task on the Flyte backend. You can trigger the remaining two tasks in a similar manner.The metrics will be displayed on the Flyte UI as follows:PreviousFireworksNextForefrontAI On this page FlyteFlyte is an open-source orchestrator that facilitates building production-grade data and ML pipelines. Docker Hub or GitHub Container Registry (GHCR) is a convenient option to begin with.Once you have selected a registry, you can proceed to create Flyte tasks that log the LangChain metrics to Flyte Deck.The following examples demonstrate tasks related to OpenAI LLM, chains and agent with tools:LLM‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_llm() -> str:    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0.2,        callbacks=[FlyteCallbackHandler()],    )    return llm([HumanMessage(content="Tell me a joke")]).contentChain‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_chain() -> list[dict[str, str]]:    template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    prompt_template = PromptTemplate(input_variables=["title"], template=template)    synopsis_chain = LLMChain(        llm=llm, prompt=prompt_template, callbacks=[FlyteCallbackHandler()]    )    test_prompts = [        {            "title": "documentary about good video games that push the boundary of game design"        },    ]    return synopsis_chain.apply(test_prompts)Agent‚Äã@task(disable_deck=False, container_image=custom_image)def langchain_agent() -> str:    llm = OpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    tools = load_tools(        ["serpapi", "llm-math"], llm=llm, callbacks=[FlyteCallbackHandler()]    )    agent = initialize_agent(        tools,        llm,        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,        callbacks=[FlyteCallbackHandler()],        verbose=True,    )    return agent.run(        "Who is Leonardo DiCaprio's girlfriend? Could you calculate her current age and raise it to the power of 0.43?"    )These tasks serve as a starting point for running your LangChain experiments within Flyte.Execute the Flyte Tasks on Kubernetes‚ÄãTo execute the Flyte tasks on the configured Flyte backend, use the following command:pyflyte run --image <your-image> langchain_flyte.py langchain_llmThis command will initiate the execution of the langchain_llm task on the Flyte backend. You can trigger the remaining two tasks in a similar manner.The metrics will be displayed on the Flyte UI as follows: import osfrom flytekit import ImageSpec, taskfrom langchain.agents import AgentType, initialize_agent, load_toolsfrom langchain.callbacks import FlyteCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.chat_models import ChatOpenAIfrom langchain.prompts import PromptTemplatefrom langchain.schema import HumanMessage import osfrom flytekit import ImageSpec, taskfrom langchain.agents import AgentType, initialize_agent, load_toolsfrom langchain.callbacks import FlyteCallbackHandlerfrom langchain.chains import LLMChainfrom langchain.chat_models import ChatOpenAIfrom langchain.prompts import PromptTemplatefrom langchain.schema import HumanMessage  API Reference:AgentTypeinitialize_agentload_toolsFlyteCallbackHandlerLLMChainChatOpenAIPromptTemplateHumanMessage # Set OpenAI API keyos.environ["OPENAI_API_KEY"] = "<your_openai_api_key>"# Set Serp API keyos.environ["SERPAPI_API_KEY"] = "<your_serp_api_key>" # Set OpenAI API keyos.environ["OPENAI_API_KEY"] = "<your_openai_api_key>"# Set Serp API keyos.environ["SERPAPI_API_KEY"] = "<your_serp_api_key>"  custom_image = ImageSpec(    name="langchain-flyte",    packages=[        "langchain",        "openai",        "spacy",        "https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0.tar.gz",        "textstat",        "google-search-results",    ],    registry="<your-registry>",) custom_image = ImageSpec(    name="langchain-flyte",    packages=[        "langchain",        "openai",        "spacy",        "https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0.tar.gz",        "textstat",        "google-search-results",    ],    registry="<your-registry>",)  @task(disable_deck=False, container_image=custom_image)def langchain_llm() -> str:    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0.2,        callbacks=[FlyteCallbackHandler()],    )    return llm([HumanMessage(content="Tell me a joke")]).content @task(disable_deck=False, container_image=custom_image)def langchain_llm() -> str:    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0.2,        callbacks=[FlyteCallbackHandler()],    )    return llm([HumanMessage(content="Tell me a joke")]).content  @task(disable_deck=False, container_image=custom_image)def langchain_chain() -> list[dict[str, str]]:    template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    prompt_template = PromptTemplate(input_variables=["title"], template=template)    synopsis_chain = LLMChain(        llm=llm, prompt=prompt_template, callbacks=[FlyteCallbackHandler()]    )    test_prompts = [        {            "title": "documentary about good video games that push the boundary of game design"        },    ]    return synopsis_chain.apply(test_prompts) @task(disable_deck=False, container_image=custom_image)def langchain_chain() -> list[dict[str, str]]:    template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""    llm = ChatOpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    prompt_template = PromptTemplate(input_variables=["title"], template=template)    synopsis_chain = LLMChain(        llm=llm, prompt=prompt_template, callbacks=[FlyteCallbackHandler()]    )    test_prompts = [        {            "title": "documentary about good video games that push the boundary of game design"        },    ]    return synopsis_chain.apply(test_prompts)  @task(disable_deck=False, container_image=custom_image)def langchain_agent() -> str:    llm = OpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    tools = load_tools(        ["serpapi", "llm-math"], llm=llm, callbacks=[FlyteCallbackHandler()]    )    agent = initialize_agent(        tools,        llm,        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,        callbacks=[FlyteCallbackHandler()],        verbose=True,    )    return agent.run(        "Who is Leonardo DiCaprio's girlfriend? Could you calculate her current age and raise it to the power of 0.43?"    ) @task(disable_deck=False, container_image=custom_image)def langchain_agent() -> str:    llm = OpenAI(        model_name="gpt-3.5-turbo",        temperature=0,        callbacks=[FlyteCallbackHandler()],    )    tools = load_tools(        ["serpapi", "llm-math"], llm=llm, callbacks=[FlyteCallbackHandler()]    )    agent = initialize_agent(        tools,        llm,        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,        callbacks=[FlyteCallbackHandler()],        verbose=True,    )    return agent.run(        "Who is Leonardo DiCaprio's girlfriend? Could you calculate her current age and raise it to the power of 0.43?"    )  pyflyte run --image <your-image> langchain_flyte.py langchain_llm pyflyte run --image <your-image> langchain_flyte.py langchain_llm  Previous Fireworks Next ForefrontAI Installation & SetupFlyte TasksLLMChainAgentExecute the Flyte Tasks on Kubernetes Installation & SetupFlyte TasksLLMChainAgentExecute the Flyte Tasks on Kubernetes CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/) Activeloop Deep Lake (/docs/integrations/providers/activeloop_deeplake) AI21 Labs (/docs/integrations/providers/ai21) Aim (/docs/integrations/providers/aim_tracking) AINetwork (/docs/integrations/providers/ainetwork) Airbyte (/docs/integrations/providers/airbyte) Airtable (/docs/integrations/providers/airtable) Aleph Alpha (/docs/integrations/providers/aleph_alpha) Alibaba Cloud Opensearch (/docs/integrations/providers/alibabacloud_opensearch) Amazon API Gateway (/docs/integrations/providers/amazon_api_gateway) AnalyticDB (/docs/integrations/providers/analyticdb) Annoy (/docs/integrations/providers/annoy) Anyscale (/docs/integrations/providers/anyscale) Apify (/docs/integrations/providers/apify) ArangoDB (/docs/integrations/providers/arangodb) Argilla (/docs/integrations/providers/argilla) Arthur (/docs/integrations/providers/arthur_tracking) Arxiv (/docs/integrations/providers/arxiv) Atlas (/docs/integrations/providers/atlas) AwaDB (/docs/integrations/providers/awadb) AWS S3 Directory (/docs/integrations/providers/aws_s3) AZLyrics (/docs/integrations/providers/azlyrics) Azure Blob Storage (/docs/integrations/providers/azure_blob_storage) Azure Cognitive Search (/docs/integrations/providers/azure_cognitive_search_) Azure OpenAI (/docs/integrations/providers/azure_openai) BagelDB (/docs/integrations/providers/bageldb) Banana (/docs/integrations/providers/bananadev) Baseten (/docs/integrations/providers/baseten) Beam (/docs/integrations/providers/beam) Bedrock (/docs/integrations/providers/bedrock) BiliBili (/docs/integrations/providers/bilibili) NIBittensor (/docs/integrations/providers/bittensor) Blackboard (/docs/integrations/providers/blackboard) Brave Search (/docs/integrations/providers/brave_search) Cassandra (/docs/integrations/providers/cassandra) CerebriumAI (/docs/integrations/providers/cerebriumai) Chaindesk (/docs/integrations/providers/chaindesk) Chroma (/docs/integrations/providers/chroma) Clarifai (/docs/integrations/providers/clarifai) ClearML (/docs/integrations/providers/clearml_tracking) ClickHouse (/docs/integrations/providers/clickhouse) CnosDB (/docs/integrations/providers/cnosdb) Cohere (/docs/integrations/providers/cohere) College Confidential (/docs/integrations/providers/college_confidential) Comet (/docs/integrations/providers/comet_tracking) Confident AI (/docs/integrations/providers/confident) Confluence (/docs/integrations/providers/confluence) C Transformers (/docs/integrations/providers/ctransformers) DashVector (/docs/integrations/providers/dashvector) Databricks (/docs/integrations/providers/databricks) Datadog Tracing (/docs/integrations/providers/datadog) Datadog Logs (/docs/integrations/providers/datadog_logs) DataForSEO (/docs/integrations/providers/dataforseo) DeepInfra (/docs/integrations/providers/deepinfra) DeepSparse (/docs/integrations/providers/deepsparse) Diffbot (/docs/integrations/providers/diffbot) Dingo (/docs/integrations/providers/dingo) Discord (/docs/integrations/providers/discord) DocArray (/docs/integrations/providers/docarray) Docugami (/docs/integrations/providers/docugami) DuckDB (/docs/integrations/providers/duckdb) Elasticsearch (/docs/integrations/providers/elasticsearch) Epsilla (/docs/integrations/providers/epsilla) EverNote (/docs/integrations/providers/evernote) Facebook Chat (/docs/integrations/providers/facebook_chat) Facebook Faiss (/docs/integrations/providers/facebook_faiss) Figma (/docs/integrations/providers/figma) Fireworks (/docs/integrations/providers/fireworks) Flyte (/docs/integrations/providers/flyte) ForefrontAI (/docs/integrations/providers/forefrontai) Git (/docs/integrations/providers/git) GitBook (/docs/integrations/providers/gitbook) Golden (/docs/integrations/providers/golden) Google BigQuery (/docs/integrations/providers/google_bigquery) Google Cloud Storage (/docs/integrations/providers/google_cloud_storage) Google Drive (/docs/integrations/providers/google_drive) Google Search (/docs/integrations/providers/google_search) Google Serper (/docs/integrations/providers/google_serper) Google Vertex AI MatchingEngine (/docs/integrations/providers/google_vertex_ai_matchingengine) GooseAI (/docs/integrations/providers/gooseai) GPT4All (/docs/integrations/providers/gpt4all) Graphsignal (/docs/integrations/providers/graphsignal) Grobid (/docs/integrations/providers/grobid) Gutenberg (/docs/integrations/providers/gutenberg) Hacker News (/docs/integrations/providers/hacker_news) Hazy Research (/docs/integrations/providers/hazy_research) Helicone (/docs/integrations/providers/helicone) Hologres (/docs/integrations/providers/hologres) Hugging Face (/docs/integrations/providers/huggingface) iFixit (/docs/integrations/providers/ifixit) IMSDb (/docs/integrations/providers/imsdb) Infino (/docs/integrations/providers/infino) Jina (/docs/integrations/providers/jina) Konko (/docs/integrations/providers/konko) LanceDB (/docs/integrations/providers/lancedb) LangChain Decorators ‚ú® (/docs/integrations/providers/langchain_decorators) Llama.cpp (/docs/integrations/providers/llamacpp) Log10 (/docs/integrations/providers/log10) Marqo (/docs/integrations/providers/marqo) MediaWikiDump (/docs/integrations/providers/mediawikidump) Meilisearch (/docs/integrations/providers/meilisearch) Metal (/docs/integrations/providers/metal) Microsoft OneDrive (/docs/integrations/providers/microsoft_onedrive) Microsoft PowerPoint (/docs/integrations/providers/microsoft_powerpoint) Microsoft Word (/docs/integrations/providers/microsoft_word) Milvus (/docs/integrations/providers/milvus) Minimax (/docs/integrations/providers/minimax) MLflow AI Gateway (/docs/integrations/providers/mlflow_ai_gateway) MLflow (/docs/integrations/providers/mlflow_tracking) Modal (/docs/integrations/providers/modal) ModelScope (/docs/integrations/providers/modelscope) Modern Treasury (/docs/integrations/providers/modern_treasury) Momento (/docs/integrations/providers/momento) MongoDB Atlas (/docs/integrations/providers/mongodb_atlas) Motherduck (/docs/integrations/providers/motherduck) MyScale (/docs/integrations/providers/myscale) Neo4j (/docs/integrations/providers/neo4j) NLPCloud (/docs/integrations/providers/nlpcloud) Notion DB (/docs/integrations/providers/notion) Obsidian (/docs/integrations/providers/obsidian) OpenAI (/docs/integrations/providers/openai) OpenLLM (/docs/integrations/providers/openllm) OpenSearch (/docs/integrations/providers/opensearch) OpenWeatherMap (/docs/integrations/providers/openweathermap) Petals (/docs/integrations/providers/petals) Postgres Embedding (/docs/integrations/providers/pg_embedding) PGVector (/docs/integrations/providers/pgvector) Pinecone (/docs/integrations/providers/pinecone) PipelineAI (/docs/integrations/providers/pipelineai) Portkey (/docs/integrations/providers/portkey/) Predibase (/docs/integrations/providers/predibase) Prediction Guard (/docs/integrations/providers/predictionguard) PromptLayer (/docs/integrations/providers/promptlayer) Psychic (/docs/integrations/providers/psychic) PubMed (/docs/integrations/providers/pubmed) Qdrant (/docs/integrations/providers/qdrant) Ray Serve (/docs/integrations/providers/ray_serve) Rebuff (/docs/integrations/providers/rebuff) Reddit (/docs/integrations/providers/reddit) Redis (/docs/integrations/providers/redis) Replicate (/docs/integrations/providers/replicate) Roam (/docs/integrations/providers/roam) Rockset (/docs/integrations/providers/rockset) Runhouse (/docs/integrations/providers/runhouse) RWKV-4 (/docs/integrations/providers/rwkv) SageMaker Endpoint (/docs/integrations/providers/sagemaker_endpoint) SageMaker Tracking (/docs/integrations/providers/sagemaker_tracking) ScaNN (/docs/integrations/providers/scann) SearxNG Search API (/docs/integrations/providers/searx) SerpAPI (/docs/integrations/providers/serpapi) Shale Protocol (/docs/integrations/providers/shaleprotocol) SingleStoreDB (/docs/integrations/providers/singlestoredb) scikit-learn (/docs/integrations/providers/sklearn) Slack (/docs/integrations/providers/slack) spaCy (/docs/integrations/providers/spacy) Spreedly (/docs/integrations/providers/spreedly) StarRocks (/docs/integrations/providers/starrocks) StochasticAI (/docs/integrations/providers/stochasticai) Stripe (/docs/integrations/providers/stripe) Supabase (Postgres) (/docs/integrations/providers/supabase) Nebula (/docs/integrations/providers/symblai_nebula) Tair (/docs/integrations/providers/tair) Telegram (/docs/integrations/providers/telegram) TencentVectorDB (/docs/integrations/providers/tencentvectordb) TensorFlow Datasets (/docs/integrations/providers/tensorflow_datasets) Tigris (/docs/integrations/providers/tigris) 2Markdown (/docs/integrations/providers/tomarkdown) Trello (/docs/integrations/providers/trello) TruLens (/docs/integrations/providers/trulens) Twitter (/docs/integrations/providers/twitter) Typesense (/docs/integrations/providers/typesense) Unstructured (/docs/integrations/providers/unstructured) USearch (/docs/integrations/providers/usearch) Vearch (/docs/integrations/providers/vearch) Vectara (/docs/integrations/providers/vectara/) Vespa (/docs/integrations/providers/vespa) WandB Tracing (/docs/integrations/providers/wandb_tracing) Weights & Biases (/docs/integrations/providers/wandb_tracking) Weather (/docs/integrations/providers/weather) Weaviate (/docs/integrations/providers/weaviate) WhatsApp (/docs/integrations/providers/whatsapp) WhyLabs (/docs/integrations/providers/whylabs_profiling) Wikipedia (/docs/integrations/providers/wikipedia) Wolfram Alpha (/docs/integrations/providers/wolfram_alpha) Writer (/docs/integrations/providers/writer) Xata (/docs/integrations/providers/xata) Xorbits Inference (Xinference) (/docs/integrations/providers/xinference) Yeager.ai (/docs/integrations/providers/yeagerai) YouTube (/docs/integrations/providers/youtube) Zep (/docs/integrations/providers/zep) Zilliz (/docs/integrations/providers/zilliz)  (/) Integrations (/docs/integrations) Grouped by provider (/docs/integrations/providers/) Flyte (https://github.com/flyteorg/flyte) ‚Äã (#installation--setup) Docker (https://docs.docker.com/engine/install/) ‚Äã (#flyte-tasks) task (https://docs.flyte.org/projects/cookbook/en/latest/auto/core/flyte_basics/task.html) getting started guide (https://docs.flyte.org/projects/cookbook/en/latest/index.html) AgentType (https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_types.AgentType.html) initialize_agent (https://api.python.langchain.com/en/latest/agents/langchain.agents.initialize.initialize_agent.html) load_tools (https://api.python.langchain.com/en/latest/agents/langchain.agents.load_tools.load_tools.html) FlyteCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.flyte_callback.FlyteCallbackHandler.html) LLMChain (https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html) ChatOpenAI (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html) PromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html) HumanMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.HumanMessage.html) workflow (https://docs.flyte.org/projects/cookbook/en/latest/auto/core/flyte_basics/basic_workflow.html) ImageSpec (https://docs.flyte.org/projects/cookbook/en/latest/auto/core/image_spec/image_spec.html) Docker Hub (https://hub.docker.com/) GitHub Container Registry (GHCR) (https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry) ‚Äã (#llm) ‚Äã (#chain) ‚Äã (#agent) ‚Äã (#execute-the-flyte-tasks-on-kubernetes) PreviousFireworks (/docs/integrations/providers/fireworks) NextForefrontAI (/docs/integrations/providers/forefrontai) Installation & Setup (#installation--setup) Flyte Tasks (#flyte-tasks) LLM (#llm) Chain (#chain) Agent (#agent) Execute the Flyte Tasks on Kubernetes (#execute-the-flyte-tasks-on-kubernetes) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)