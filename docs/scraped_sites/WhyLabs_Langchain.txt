WhyLabs is an observability platform designed to monitor data pipelines and ML applications for data quality regressions, data drift, and model performance degradation. Built on top of an open-source package called whylogs, the platform enables Data Scientists and Engineers to: Make sure to set the required API keys and config required to send telemetry to WhyLabs: Then you can set them like this: Note: the callback supports directly passing in these variables to the callback, when no auth is directly passed in it will default to the environment. Passing in auth directly allows for writing profiles to multiple projects or organizations in WhyLabs. Here's a single LLM integration with OpenAI, which will log various out of the box metrics and send telemetry to WhyLabs for monitoring. IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz Activeloop Deep Lake AI21 Labs Aim AINetwork Airbyte Airtable Aleph Alpha Alibaba Cloud Opensearch Amazon API Gateway AnalyticDB Annoy Anyscale Apify ArangoDB Argilla Arthur Arxiv Atlas AwaDB AWS S3 Directory AZLyrics Azure Blob Storage Azure Cognitive Search Azure OpenAI BagelDB Banana Baseten Beam Bedrock BiliBili NIBittensor Blackboard Brave Search Cassandra CerebriumAI Chaindesk Chroma Clarifai ClearML ClickHouse CnosDB Cohere College Confidential Comet Confident AI Confluence C Transformers DashVector Databricks Datadog Tracing Datadog Logs DataForSEO DeepInfra DeepSparse Diffbot Dingo Discord DocArray Docugami DuckDB Elasticsearch Epsilla EverNote Facebook Chat Facebook Faiss Figma Fireworks Flyte ForefrontAI Git GitBook Golden Google BigQuery Google Cloud Storage Google Drive Google Search Google Serper Google Vertex AI MatchingEngine GooseAI GPT4All Graphsignal Grobid Gutenberg Hacker News Hazy Research Helicone Hologres Hugging Face iFixit IMSDb Infino Jina Konko LanceDB LangChain Decorators ‚ú® Llama.cpp Log10 Marqo MediaWikiDump Meilisearch Metal Microsoft OneDrive Microsoft PowerPoint Microsoft Word Milvus Minimax MLflow AI Gateway MLflow Modal ModelScope Modern Treasury Momento MongoDB Atlas Motherduck MyScale Neo4j NLPCloud Notion DB Obsidian OpenAI OpenLLM OpenSearch OpenWeatherMap Petals Postgres Embedding PGVector Pinecone PipelineAI Portkey Predibase Prediction Guard PromptLayer Psychic PubMed Qdrant Ray Serve Rebuff Reddit Redis Replicate Roam Rockset Runhouse RWKV-4 SageMaker Endpoint SageMaker Tracking ScaNN SearxNG Search API SerpAPI Shale Protocol SingleStoreDB scikit-learn Slack spaCy Spreedly StarRocks StochasticAI Stripe Supabase (Postgres) Nebula Tair Telegram TencentVectorDB TensorFlow Datasets Tigris 2Markdown Trello TruLens Twitter Typesense Unstructured USearch Vearch Vectara Vespa WandB Tracing Weights & Biases Weather Weaviate WhatsApp WhyLabs Wikipedia Wolfram Alpha Writer Xata Xorbits Inference (Xinference) Yeager.ai YouTube Zep Zilliz  Integrations Grouped by provider WhyLabs Set up in minutes: Begin generating statistical profiles of any dataset using whylogs, the lightweight open-source library. Upload dataset profiles to the WhyLabs platform for centralized and customizable monitoring/alerting of dataset features as well as model inputs, outputs, and performance. Integrate seamlessly: interoperable with any data pipeline, ML infrastructure, or framework. Generate real-time insights into your existing data flow. See more about our integrations here. Scale to terabytes: handle your large-scale data, keeping compute requirements low. Integrate with either batch or streaming data pipelines. Maintain data privacy: WhyLabs relies statistical profiles created via whylogs so your actual data never leaves your environment! Enable observability to detect inputs and LLM issues faster, deliver continuous improvements, and avoid costly incidents. WhyLabs API Key: https://whylabs.ai/whylabs-free-sign-up Org and Dataset https://docs.whylabs.ai/docs/whylabs-onboarding OpenAI: https://platform.openai.com/account/api-keys WhyLabsCallbackHandler OpenAI Installation and Setup Callbacks Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZillizIntegrationsGrouped by providerWhyLabsOn this pageWhyLabsWhyLabs is an observability platform designed to monitor data pipelines and ML applications for data quality regressions, data drift, and model performance degradation. Built on top of an open-source package called whylogs, the platform enables Data Scientists and Engineers to:Set up in minutes: Begin generating statistical profiles of any dataset using whylogs, the lightweight open-source library.Upload dataset profiles to the WhyLabs platform for centralized and customizable monitoring/alerting of dataset features as well as model inputs, outputs, and performance.Integrate seamlessly: interoperable with any data pipeline, ML infrastructure, or framework. Generate real-time insights into your existing data flow. See more about our integrations here.Scale to terabytes: handle your large-scale data, keeping compute requirements low. Integrate with either batch or streaming data pipelines.Maintain data privacy: WhyLabs relies statistical profiles created via whylogs so your actual data never leaves your environment! Enable observability to detect inputs and LLM issues faster, deliver continuous improvements, and avoid costly incidents.Installation and Setup‚Äã%pip install langkit openai langchainMake sure to set the required API keys and config required to send telemetry to WhyLabs:WhyLabs API Key: https://whylabs.ai/whylabs-free-sign-upOrg and Dataset https://docs.whylabs.ai/docs/whylabs-onboardingOpenAI: https://platform.openai.com/account/api-keysThen you can set them like this:import osos.environ["OPENAI_API_KEY"] = ""os.environ["WHYLABS_DEFAULT_ORG_ID"] = ""os.environ["WHYLABS_DEFAULT_DATASET_ID"] = ""os.environ["WHYLABS_API_KEY"] = ""Note: the callback supports directly passing in these variables to the callback, when no auth is directly passed in it will default to the environment. Passing in auth directly allows for writing profiles to multiple projects or organizations in WhyLabs.Callbacks‚ÄãHere's a single LLM integration with OpenAI, which will log various out of the box metrics and send telemetry to WhyLabs for monitoring.from langchain.callbacks import WhyLabsCallbackHandlerAPI Reference:WhyLabsCallbackHandlerfrom langchain.llms import OpenAIwhylabs = WhyLabsCallbackHandler.from_params()llm = OpenAI(temperature=0, callbacks=[whylabs])result = llm.generate(["Hello, World!"])print(result)API Reference:OpenAI    generations=[[Generation(text="\n\nMy name is John and I'm excited to learn more about programming.", generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 20, 'prompt_tokens': 4, 'completion_tokens': 16}, 'model_name': 'text-davinci-003'}result = llm.generate(    [        "Can you give me 3 SSNs so I can understand the format?",        "Can you give me 3 fake email addresses?",        "Can you give me 3 fake US mailing addresses?",    ])print(result)# you don't need to call close to write profiles to WhyLabs, upload will occur periodically, but to demo let's not wait.whylabs.close()    generations=[[Generation(text='\n\n1. 123-45-6789\n2. 987-65-4321\n3. 456-78-9012', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. johndoe@example.com\n2. janesmith@example.com\n3. johnsmith@example.com', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. 123 Main Street, Anytown, USA 12345\n2. 456 Elm Street, Nowhere, USA 54321\n3. 789 Pine Avenue, Somewhere, USA 98765', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 137, 'prompt_tokens': 33, 'completion_tokens': 104}, 'model_name': 'text-davinci-003'}PreviousWhatsAppNextWikipediaInstallation and SetupCallbacksCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZillizIntegrationsGrouped by providerWhyLabsOn this pageWhyLabsWhyLabs is an observability platform designed to monitor data pipelines and ML applications for data quality regressions, data drift, and model performance degradation. Built on top of an open-source package called whylogs, the platform enables Data Scientists and Engineers to:Set up in minutes: Begin generating statistical profiles of any dataset using whylogs, the lightweight open-source library.Upload dataset profiles to the WhyLabs platform for centralized and customizable monitoring/alerting of dataset features as well as model inputs, outputs, and performance.Integrate seamlessly: interoperable with any data pipeline, ML infrastructure, or framework. Generate real-time insights into your existing data flow. See more about our integrations here.Scale to terabytes: handle your large-scale data, keeping compute requirements low. Integrate with either batch or streaming data pipelines.Maintain data privacy: WhyLabs relies statistical profiles created via whylogs so your actual data never leaves your environment! Enable observability to detect inputs and LLM issues faster, deliver continuous improvements, and avoid costly incidents.Installation and Setup‚Äã%pip install langkit openai langchainMake sure to set the required API keys and config required to send telemetry to WhyLabs:WhyLabs API Key: https://whylabs.ai/whylabs-free-sign-upOrg and Dataset https://docs.whylabs.ai/docs/whylabs-onboardingOpenAI: https://platform.openai.com/account/api-keysThen you can set them like this:import osos.environ["OPENAI_API_KEY"] = ""os.environ["WHYLABS_DEFAULT_ORG_ID"] = ""os.environ["WHYLABS_DEFAULT_DATASET_ID"] = ""os.environ["WHYLABS_API_KEY"] = ""Note: the callback supports directly passing in these variables to the callback, when no auth is directly passed in it will default to the environment. Passing in auth directly allows for writing profiles to multiple projects or organizations in WhyLabs.Callbacks‚ÄãHere's a single LLM integration with OpenAI, which will log various out of the box metrics and send telemetry to WhyLabs for monitoring.from langchain.callbacks import WhyLabsCallbackHandlerAPI Reference:WhyLabsCallbackHandlerfrom langchain.llms import OpenAIwhylabs = WhyLabsCallbackHandler.from_params()llm = OpenAI(temperature=0, callbacks=[whylabs])result = llm.generate(["Hello, World!"])print(result)API Reference:OpenAI    generations=[[Generation(text="\n\nMy name is John and I'm excited to learn more about programming.", generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 20, 'prompt_tokens': 4, 'completion_tokens': 16}, 'model_name': 'text-davinci-003'}result = llm.generate(    [        "Can you give me 3 SSNs so I can understand the format?",        "Can you give me 3 fake email addresses?",        "Can you give me 3 fake US mailing addresses?",    ])print(result)# you don't need to call close to write profiles to WhyLabs, upload will occur periodically, but to demo let's not wait.whylabs.close()    generations=[[Generation(text='\n\n1. 123-45-6789\n2. 987-65-4321\n3. 456-78-9012', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. johndoe@example.com\n2. janesmith@example.com\n3. johnsmith@example.com', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. 123 Main Street, Anytown, USA 12345\n2. 456 Elm Street, Nowhere, USA 54321\n3. 789 Pine Avenue, Somewhere, USA 98765', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 137, 'prompt_tokens': 33, 'completion_tokens': 104}, 'model_name': 'text-davinci-003'}PreviousWhatsAppNextWikipediaInstallation and SetupCallbacks IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZillizIntegrationsGrouped by providerWhyLabsOn this pageWhyLabsWhyLabs is an observability platform designed to monitor data pipelines and ML applications for data quality regressions, data drift, and model performance degradation. Built on top of an open-source package called whylogs, the platform enables Data Scientists and Engineers to:Set up in minutes: Begin generating statistical profiles of any dataset using whylogs, the lightweight open-source library.Upload dataset profiles to the WhyLabs platform for centralized and customizable monitoring/alerting of dataset features as well as model inputs, outputs, and performance.Integrate seamlessly: interoperable with any data pipeline, ML infrastructure, or framework. Generate real-time insights into your existing data flow. See more about our integrations here.Scale to terabytes: handle your large-scale data, keeping compute requirements low. Integrate with either batch or streaming data pipelines.Maintain data privacy: WhyLabs relies statistical profiles created via whylogs so your actual data never leaves your environment! Enable observability to detect inputs and LLM issues faster, deliver continuous improvements, and avoid costly incidents.Installation and Setup‚Äã%pip install langkit openai langchainMake sure to set the required API keys and config required to send telemetry to WhyLabs:WhyLabs API Key: https://whylabs.ai/whylabs-free-sign-upOrg and Dataset https://docs.whylabs.ai/docs/whylabs-onboardingOpenAI: https://platform.openai.com/account/api-keysThen you can set them like this:import osos.environ["OPENAI_API_KEY"] = ""os.environ["WHYLABS_DEFAULT_ORG_ID"] = ""os.environ["WHYLABS_DEFAULT_DATASET_ID"] = ""os.environ["WHYLABS_API_KEY"] = ""Note: the callback supports directly passing in these variables to the callback, when no auth is directly passed in it will default to the environment. Passing in auth directly allows for writing profiles to multiple projects or organizations in WhyLabs.Callbacks‚ÄãHere's a single LLM integration with OpenAI, which will log various out of the box metrics and send telemetry to WhyLabs for monitoring.from langchain.callbacks import WhyLabsCallbackHandlerAPI Reference:WhyLabsCallbackHandlerfrom langchain.llms import OpenAIwhylabs = WhyLabsCallbackHandler.from_params()llm = OpenAI(temperature=0, callbacks=[whylabs])result = llm.generate(["Hello, World!"])print(result)API Reference:OpenAI    generations=[[Generation(text="\n\nMy name is John and I'm excited to learn more about programming.", generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 20, 'prompt_tokens': 4, 'completion_tokens': 16}, 'model_name': 'text-davinci-003'}result = llm.generate(    [        "Can you give me 3 SSNs so I can understand the format?",        "Can you give me 3 fake email addresses?",        "Can you give me 3 fake US mailing addresses?",    ])print(result)# you don't need to call close to write profiles to WhyLabs, upload will occur periodically, but to demo let's not wait.whylabs.close()    generations=[[Generation(text='\n\n1. 123-45-6789\n2. 987-65-4321\n3. 456-78-9012', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. johndoe@example.com\n2. janesmith@example.com\n3. johnsmith@example.com', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. 123 Main Street, Anytown, USA 12345\n2. 456 Elm Street, Nowhere, USA 54321\n3. 789 Pine Avenue, Somewhere, USA 98765', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 137, 'prompt_tokens': 33, 'completion_tokens': 104}, 'model_name': 'text-davinci-003'}PreviousWhatsAppNextWikipediaInstallation and SetupCallbacks IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerActiveloop Deep LakeAI21 LabsAimAINetworkAirbyteAirtableAleph AlphaAlibaba Cloud OpensearchAmazon API GatewayAnalyticDBAnnoyAnyscaleApifyArangoDBArgillaArthurArxivAtlasAwaDBAWS S3 DirectoryAZLyricsAzure Blob StorageAzure Cognitive SearchAzure OpenAIBagelDBBananaBasetenBeamBedrockBiliBiliNIBittensorBlackboardBrave SearchCassandraCerebriumAIChaindeskChromaClarifaiClearMLClickHouseCnosDBCohereCollege ConfidentialCometConfident AIConfluenceC TransformersDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODeepInfraDeepSparseDiffbotDingoDiscordDocArrayDocugamiDuckDBElasticsearchEpsillaEverNoteFacebook ChatFacebook FaissFigmaFireworksFlyteForefrontAIGitGitBookGoldenGoogle BigQueryGoogle Cloud StorageGoogle DriveGoogle SearchGoogle SerperGoogle Vertex AI MatchingEngineGooseAIGPT4AllGraphsignalGrobidGutenbergHacker NewsHazy ResearchHeliconeHologresHugging FaceiFixitIMSDbInfinoJinaKonkoLanceDBLangChain Decorators ‚ú®Llama.cppLog10MarqoMediaWikiDumpMeilisearchMetalMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordMilvusMinimaxMLflow AI GatewayMLflowModalModelScopeModern TreasuryMomentoMongoDB AtlasMotherduckMyScaleNeo4jNLPCloudNotion DBObsidianOpenAIOpenLLMOpenSearchOpenWeatherMapPetalsPostgres EmbeddingPGVectorPineconePipelineAIPortkeyPredibasePrediction GuardPromptLayerPsychicPubMedQdrantRay ServeRebuffRedditRedisReplicateRoamRocksetRunhouseRWKV-4SageMaker EndpointSageMaker TrackingScaNNSearxNG Search APISerpAPIShale ProtocolSingleStoreDBscikit-learnSlackspaCySpreedlyStarRocksStochasticAIStripeSupabase (Postgres)NebulaTairTelegramTencentVectorDBTensorFlow DatasetsTigris2MarkdownTrelloTruLensTwitterTypesenseUnstructuredUSearchVearchVectaraVespaWandB TracingWeights & BiasesWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterXataXorbits Inference (Xinference)Yeager.aiYouTubeZepZilliz Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider Portkey Vectara IntegrationsGrouped by providerWhyLabsOn this pageWhyLabsWhyLabs is an observability platform designed to monitor data pipelines and ML applications for data quality regressions, data drift, and model performance degradation. Built on top of an open-source package called whylogs, the platform enables Data Scientists and Engineers to:Set up in minutes: Begin generating statistical profiles of any dataset using whylogs, the lightweight open-source library.Upload dataset profiles to the WhyLabs platform for centralized and customizable monitoring/alerting of dataset features as well as model inputs, outputs, and performance.Integrate seamlessly: interoperable with any data pipeline, ML infrastructure, or framework. Generate real-time insights into your existing data flow. See more about our integrations here.Scale to terabytes: handle your large-scale data, keeping compute requirements low. Integrate with either batch or streaming data pipelines.Maintain data privacy: WhyLabs relies statistical profiles created via whylogs so your actual data never leaves your environment! Enable observability to detect inputs and LLM issues faster, deliver continuous improvements, and avoid costly incidents.Installation and Setup‚Äã%pip install langkit openai langchainMake sure to set the required API keys and config required to send telemetry to WhyLabs:WhyLabs API Key: https://whylabs.ai/whylabs-free-sign-upOrg and Dataset https://docs.whylabs.ai/docs/whylabs-onboardingOpenAI: https://platform.openai.com/account/api-keysThen you can set them like this:import osos.environ["OPENAI_API_KEY"] = ""os.environ["WHYLABS_DEFAULT_ORG_ID"] = ""os.environ["WHYLABS_DEFAULT_DATASET_ID"] = ""os.environ["WHYLABS_API_KEY"] = ""Note: the callback supports directly passing in these variables to the callback, when no auth is directly passed in it will default to the environment. Passing in auth directly allows for writing profiles to multiple projects or organizations in WhyLabs.Callbacks‚ÄãHere's a single LLM integration with OpenAI, which will log various out of the box metrics and send telemetry to WhyLabs for monitoring.from langchain.callbacks import WhyLabsCallbackHandlerAPI Reference:WhyLabsCallbackHandlerfrom langchain.llms import OpenAIwhylabs = WhyLabsCallbackHandler.from_params()llm = OpenAI(temperature=0, callbacks=[whylabs])result = llm.generate(["Hello, World!"])print(result)API Reference:OpenAI    generations=[[Generation(text="\n\nMy name is John and I'm excited to learn more about programming.", generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 20, 'prompt_tokens': 4, 'completion_tokens': 16}, 'model_name': 'text-davinci-003'}result = llm.generate(    [        "Can you give me 3 SSNs so I can understand the format?",        "Can you give me 3 fake email addresses?",        "Can you give me 3 fake US mailing addresses?",    ])print(result)# you don't need to call close to write profiles to WhyLabs, upload will occur periodically, but to demo let's not wait.whylabs.close()    generations=[[Generation(text='\n\n1. 123-45-6789\n2. 987-65-4321\n3. 456-78-9012', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. johndoe@example.com\n2. janesmith@example.com\n3. johnsmith@example.com', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. 123 Main Street, Anytown, USA 12345\n2. 456 Elm Street, Nowhere, USA 54321\n3. 789 Pine Avenue, Somewhere, USA 98765', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 137, 'prompt_tokens': 33, 'completion_tokens': 104}, 'model_name': 'text-davinci-003'}PreviousWhatsAppNextWikipediaInstallation and SetupCallbacks IntegrationsGrouped by providerWhyLabsOn this pageWhyLabsWhyLabs is an observability platform designed to monitor data pipelines and ML applications for data quality regressions, data drift, and model performance degradation. Built on top of an open-source package called whylogs, the platform enables Data Scientists and Engineers to:Set up in minutes: Begin generating statistical profiles of any dataset using whylogs, the lightweight open-source library.Upload dataset profiles to the WhyLabs platform for centralized and customizable monitoring/alerting of dataset features as well as model inputs, outputs, and performance.Integrate seamlessly: interoperable with any data pipeline, ML infrastructure, or framework. Generate real-time insights into your existing data flow. See more about our integrations here.Scale to terabytes: handle your large-scale data, keeping compute requirements low. Integrate with either batch or streaming data pipelines.Maintain data privacy: WhyLabs relies statistical profiles created via whylogs so your actual data never leaves your environment! Enable observability to detect inputs and LLM issues faster, deliver continuous improvements, and avoid costly incidents.Installation and Setup‚Äã%pip install langkit openai langchainMake sure to set the required API keys and config required to send telemetry to WhyLabs:WhyLabs API Key: https://whylabs.ai/whylabs-free-sign-upOrg and Dataset https://docs.whylabs.ai/docs/whylabs-onboardingOpenAI: https://platform.openai.com/account/api-keysThen you can set them like this:import osos.environ["OPENAI_API_KEY"] = ""os.environ["WHYLABS_DEFAULT_ORG_ID"] = ""os.environ["WHYLABS_DEFAULT_DATASET_ID"] = ""os.environ["WHYLABS_API_KEY"] = ""Note: the callback supports directly passing in these variables to the callback, when no auth is directly passed in it will default to the environment. Passing in auth directly allows for writing profiles to multiple projects or organizations in WhyLabs.Callbacks‚ÄãHere's a single LLM integration with OpenAI, which will log various out of the box metrics and send telemetry to WhyLabs for monitoring.from langchain.callbacks import WhyLabsCallbackHandlerAPI Reference:WhyLabsCallbackHandlerfrom langchain.llms import OpenAIwhylabs = WhyLabsCallbackHandler.from_params()llm = OpenAI(temperature=0, callbacks=[whylabs])result = llm.generate(["Hello, World!"])print(result)API Reference:OpenAI    generations=[[Generation(text="\n\nMy name is John and I'm excited to learn more about programming.", generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 20, 'prompt_tokens': 4, 'completion_tokens': 16}, 'model_name': 'text-davinci-003'}result = llm.generate(    [        "Can you give me 3 SSNs so I can understand the format?",        "Can you give me 3 fake email addresses?",        "Can you give me 3 fake US mailing addresses?",    ])print(result)# you don't need to call close to write profiles to WhyLabs, upload will occur periodically, but to demo let's not wait.whylabs.close()    generations=[[Generation(text='\n\n1. 123-45-6789\n2. 987-65-4321\n3. 456-78-9012', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. johndoe@example.com\n2. janesmith@example.com\n3. johnsmith@example.com', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. 123 Main Street, Anytown, USA 12345\n2. 456 Elm Street, Nowhere, USA 54321\n3. 789 Pine Avenue, Somewhere, USA 98765', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 137, 'prompt_tokens': 33, 'completion_tokens': 104}, 'model_name': 'text-davinci-003'}PreviousWhatsAppNextWikipedia IntegrationsGrouped by providerWhyLabsOn this pageWhyLabsWhyLabs is an observability platform designed to monitor data pipelines and ML applications for data quality regressions, data drift, and model performance degradation. Built on top of an open-source package called whylogs, the platform enables Data Scientists and Engineers to:Set up in minutes: Begin generating statistical profiles of any dataset using whylogs, the lightweight open-source library.Upload dataset profiles to the WhyLabs platform for centralized and customizable monitoring/alerting of dataset features as well as model inputs, outputs, and performance.Integrate seamlessly: interoperable with any data pipeline, ML infrastructure, or framework. Generate real-time insights into your existing data flow. See more about our integrations here.Scale to terabytes: handle your large-scale data, keeping compute requirements low. Integrate with either batch or streaming data pipelines.Maintain data privacy: WhyLabs relies statistical profiles created via whylogs so your actual data never leaves your environment! Enable observability to detect inputs and LLM issues faster, deliver continuous improvements, and avoid costly incidents.Installation and Setup‚Äã%pip install langkit openai langchainMake sure to set the required API keys and config required to send telemetry to WhyLabs:WhyLabs API Key: https://whylabs.ai/whylabs-free-sign-upOrg and Dataset https://docs.whylabs.ai/docs/whylabs-onboardingOpenAI: https://platform.openai.com/account/api-keysThen you can set them like this:import osos.environ["OPENAI_API_KEY"] = ""os.environ["WHYLABS_DEFAULT_ORG_ID"] = ""os.environ["WHYLABS_DEFAULT_DATASET_ID"] = ""os.environ["WHYLABS_API_KEY"] = ""Note: the callback supports directly passing in these variables to the callback, when no auth is directly passed in it will default to the environment. Passing in auth directly allows for writing profiles to multiple projects or organizations in WhyLabs.Callbacks‚ÄãHere's a single LLM integration with OpenAI, which will log various out of the box metrics and send telemetry to WhyLabs for monitoring.from langchain.callbacks import WhyLabsCallbackHandlerAPI Reference:WhyLabsCallbackHandlerfrom langchain.llms import OpenAIwhylabs = WhyLabsCallbackHandler.from_params()llm = OpenAI(temperature=0, callbacks=[whylabs])result = llm.generate(["Hello, World!"])print(result)API Reference:OpenAI    generations=[[Generation(text="\n\nMy name is John and I'm excited to learn more about programming.", generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 20, 'prompt_tokens': 4, 'completion_tokens': 16}, 'model_name': 'text-davinci-003'}result = llm.generate(    [        "Can you give me 3 SSNs so I can understand the format?",        "Can you give me 3 fake email addresses?",        "Can you give me 3 fake US mailing addresses?",    ])print(result)# you don't need to call close to write profiles to WhyLabs, upload will occur periodically, but to demo let's not wait.whylabs.close()    generations=[[Generation(text='\n\n1. 123-45-6789\n2. 987-65-4321\n3. 456-78-9012', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. johndoe@example.com\n2. janesmith@example.com\n3. johnsmith@example.com', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. 123 Main Street, Anytown, USA 12345\n2. 456 Elm Street, Nowhere, USA 54321\n3. 789 Pine Avenue, Somewhere, USA 98765', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 137, 'prompt_tokens': 33, 'completion_tokens': 104}, 'model_name': 'text-davinci-003'}PreviousWhatsAppNextWikipedia On this page WhyLabsWhyLabs is an observability platform designed to monitor data pipelines and ML applications for data quality regressions, data drift, and model performance degradation. Built on top of an open-source package called whylogs, the platform enables Data Scientists and Engineers to:Set up in minutes: Begin generating statistical profiles of any dataset using whylogs, the lightweight open-source library.Upload dataset profiles to the WhyLabs platform for centralized and customizable monitoring/alerting of dataset features as well as model inputs, outputs, and performance.Integrate seamlessly: interoperable with any data pipeline, ML infrastructure, or framework. Generate real-time insights into your existing data flow. See more about our integrations here.Scale to terabytes: handle your large-scale data, keeping compute requirements low. Integrate with either batch or streaming data pipelines.Maintain data privacy: WhyLabs relies statistical profiles created via whylogs so your actual data never leaves your environment! Enable observability to detect inputs and LLM issues faster, deliver continuous improvements, and avoid costly incidents.Installation and Setup‚Äã%pip install langkit openai langchainMake sure to set the required API keys and config required to send telemetry to WhyLabs:WhyLabs API Key: https://whylabs.ai/whylabs-free-sign-upOrg and Dataset https://docs.whylabs.ai/docs/whylabs-onboardingOpenAI: https://platform.openai.com/account/api-keysThen you can set them like this:import osos.environ["OPENAI_API_KEY"] = ""os.environ["WHYLABS_DEFAULT_ORG_ID"] = ""os.environ["WHYLABS_DEFAULT_DATASET_ID"] = ""os.environ["WHYLABS_API_KEY"] = ""Note: the callback supports directly passing in these variables to the callback, when no auth is directly passed in it will default to the environment. Passing in auth directly allows for writing profiles to multiple projects or organizations in WhyLabs.Callbacks‚ÄãHere's a single LLM integration with OpenAI, which will log various out of the box metrics and send telemetry to WhyLabs for monitoring.from langchain.callbacks import WhyLabsCallbackHandlerAPI Reference:WhyLabsCallbackHandlerfrom langchain.llms import OpenAIwhylabs = WhyLabsCallbackHandler.from_params()llm = OpenAI(temperature=0, callbacks=[whylabs])result = llm.generate(["Hello, World!"])print(result)API Reference:OpenAI    generations=[[Generation(text="\n\nMy name is John and I'm excited to learn more about programming.", generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 20, 'prompt_tokens': 4, 'completion_tokens': 16}, 'model_name': 'text-davinci-003'}result = llm.generate(    [        "Can you give me 3 SSNs so I can understand the format?",        "Can you give me 3 fake email addresses?",        "Can you give me 3 fake US mailing addresses?",    ])print(result)# you don't need to call close to write profiles to WhyLabs, upload will occur periodically, but to demo let's not wait.whylabs.close()    generations=[[Generation(text='\n\n1. 123-45-6789\n2. 987-65-4321\n3. 456-78-9012', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. johndoe@example.com\n2. janesmith@example.com\n3. johnsmith@example.com', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. 123 Main Street, Anytown, USA 12345\n2. 456 Elm Street, Nowhere, USA 54321\n3. 789 Pine Avenue, Somewhere, USA 98765', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 137, 'prompt_tokens': 33, 'completion_tokens': 104}, 'model_name': 'text-davinci-003'} %pip install langkit openai langchain %pip install langkit openai langchain  import osos.environ["OPENAI_API_KEY"] = ""os.environ["WHYLABS_DEFAULT_ORG_ID"] = ""os.environ["WHYLABS_DEFAULT_DATASET_ID"] = ""os.environ["WHYLABS_API_KEY"] = "" import osos.environ["OPENAI_API_KEY"] = ""os.environ["WHYLABS_DEFAULT_ORG_ID"] = ""os.environ["WHYLABS_DEFAULT_DATASET_ID"] = ""os.environ["WHYLABS_API_KEY"] = ""  from langchain.callbacks import WhyLabsCallbackHandler from langchain.callbacks import WhyLabsCallbackHandler  API Reference:WhyLabsCallbackHandler from langchain.llms import OpenAIwhylabs = WhyLabsCallbackHandler.from_params()llm = OpenAI(temperature=0, callbacks=[whylabs])result = llm.generate(["Hello, World!"])print(result) from langchain.llms import OpenAIwhylabs = WhyLabsCallbackHandler.from_params()llm = OpenAI(temperature=0, callbacks=[whylabs])result = llm.generate(["Hello, World!"])print(result)  API Reference:OpenAI     generations=[[Generation(text="\n\nMy name is John and I'm excited to learn more about programming.", generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 20, 'prompt_tokens': 4, 'completion_tokens': 16}, 'model_name': 'text-davinci-003'}     generations=[[Generation(text="\n\nMy name is John and I'm excited to learn more about programming.", generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 20, 'prompt_tokens': 4, 'completion_tokens': 16}, 'model_name': 'text-davinci-003'}     generations=[[Generation(text="\n\nMy name is John and I'm excited to learn more about programming.", generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 20, 'prompt_tokens': 4, 'completion_tokens': 16}, 'model_name': 'text-davinci-003'}  result = llm.generate(    [        "Can you give me 3 SSNs so I can understand the format?",        "Can you give me 3 fake email addresses?",        "Can you give me 3 fake US mailing addresses?",    ])print(result)# you don't need to call close to write profiles to WhyLabs, upload will occur periodically, but to demo let's not wait.whylabs.close() result = llm.generate(    [        "Can you give me 3 SSNs so I can understand the format?",        "Can you give me 3 fake email addresses?",        "Can you give me 3 fake US mailing addresses?",    ])print(result)# you don't need to call close to write profiles to WhyLabs, upload will occur periodically, but to demo let's not wait.whylabs.close()      generations=[[Generation(text='\n\n1. 123-45-6789\n2. 987-65-4321\n3. 456-78-9012', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. johndoe@example.com\n2. janesmith@example.com\n3. johnsmith@example.com', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. 123 Main Street, Anytown, USA 12345\n2. 456 Elm Street, Nowhere, USA 54321\n3. 789 Pine Avenue, Somewhere, USA 98765', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 137, 'prompt_tokens': 33, 'completion_tokens': 104}, 'model_name': 'text-davinci-003'}     generations=[[Generation(text='\n\n1. 123-45-6789\n2. 987-65-4321\n3. 456-78-9012', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. johndoe@example.com\n2. janesmith@example.com\n3. johnsmith@example.com', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. 123 Main Street, Anytown, USA 12345\n2. 456 Elm Street, Nowhere, USA 54321\n3. 789 Pine Avenue, Somewhere, USA 98765', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 137, 'prompt_tokens': 33, 'completion_tokens': 104}, 'model_name': 'text-davinci-003'}     generations=[[Generation(text='\n\n1. 123-45-6789\n2. 987-65-4321\n3. 456-78-9012', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. johndoe@example.com\n2. janesmith@example.com\n3. johnsmith@example.com', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\n\n1. 123 Main Street, Anytown, USA 12345\n2. 456 Elm Street, Nowhere, USA 54321\n3. 789 Pine Avenue, Somewhere, USA 98765', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 137, 'prompt_tokens': 33, 'completion_tokens': 104}, 'model_name': 'text-davinci-003'}  Previous WhatsApp Next Wikipedia Installation and SetupCallbacks Installation and SetupCallbacks CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/) Activeloop Deep Lake (/docs/integrations/providers/activeloop_deeplake) AI21 Labs (/docs/integrations/providers/ai21) Aim (/docs/integrations/providers/aim_tracking) AINetwork (/docs/integrations/providers/ainetwork) Airbyte (/docs/integrations/providers/airbyte) Airtable (/docs/integrations/providers/airtable) Aleph Alpha (/docs/integrations/providers/aleph_alpha) Alibaba Cloud Opensearch (/docs/integrations/providers/alibabacloud_opensearch) Amazon API Gateway (/docs/integrations/providers/amazon_api_gateway) AnalyticDB (/docs/integrations/providers/analyticdb) Annoy (/docs/integrations/providers/annoy) Anyscale (/docs/integrations/providers/anyscale) Apify (/docs/integrations/providers/apify) ArangoDB (/docs/integrations/providers/arangodb) Argilla (/docs/integrations/providers/argilla) Arthur (/docs/integrations/providers/arthur_tracking) Arxiv (/docs/integrations/providers/arxiv) Atlas (/docs/integrations/providers/atlas) AwaDB (/docs/integrations/providers/awadb) AWS S3 Directory (/docs/integrations/providers/aws_s3) AZLyrics (/docs/integrations/providers/azlyrics) Azure Blob Storage (/docs/integrations/providers/azure_blob_storage) Azure Cognitive Search (/docs/integrations/providers/azure_cognitive_search_) Azure OpenAI (/docs/integrations/providers/azure_openai) BagelDB (/docs/integrations/providers/bageldb) Banana (/docs/integrations/providers/bananadev) Baseten (/docs/integrations/providers/baseten) Beam (/docs/integrations/providers/beam) Bedrock (/docs/integrations/providers/bedrock) BiliBili (/docs/integrations/providers/bilibili) NIBittensor (/docs/integrations/providers/bittensor) Blackboard (/docs/integrations/providers/blackboard) Brave Search (/docs/integrations/providers/brave_search) Cassandra (/docs/integrations/providers/cassandra) CerebriumAI (/docs/integrations/providers/cerebriumai) Chaindesk (/docs/integrations/providers/chaindesk) Chroma (/docs/integrations/providers/chroma) Clarifai (/docs/integrations/providers/clarifai) ClearML (/docs/integrations/providers/clearml_tracking) ClickHouse (/docs/integrations/providers/clickhouse) CnosDB (/docs/integrations/providers/cnosdb) Cohere (/docs/integrations/providers/cohere) College Confidential (/docs/integrations/providers/college_confidential) Comet (/docs/integrations/providers/comet_tracking) Confident AI (/docs/integrations/providers/confident) Confluence (/docs/integrations/providers/confluence) C Transformers (/docs/integrations/providers/ctransformers) DashVector (/docs/integrations/providers/dashvector) Databricks (/docs/integrations/providers/databricks) Datadog Tracing (/docs/integrations/providers/datadog) Datadog Logs (/docs/integrations/providers/datadog_logs) DataForSEO (/docs/integrations/providers/dataforseo) DeepInfra (/docs/integrations/providers/deepinfra) DeepSparse (/docs/integrations/providers/deepsparse) Diffbot (/docs/integrations/providers/diffbot) Dingo (/docs/integrations/providers/dingo) Discord (/docs/integrations/providers/discord) DocArray (/docs/integrations/providers/docarray) Docugami (/docs/integrations/providers/docugami) DuckDB (/docs/integrations/providers/duckdb) Elasticsearch (/docs/integrations/providers/elasticsearch) Epsilla (/docs/integrations/providers/epsilla) EverNote (/docs/integrations/providers/evernote) Facebook Chat (/docs/integrations/providers/facebook_chat) Facebook Faiss (/docs/integrations/providers/facebook_faiss) Figma (/docs/integrations/providers/figma) Fireworks (/docs/integrations/providers/fireworks) Flyte (/docs/integrations/providers/flyte) ForefrontAI (/docs/integrations/providers/forefrontai) Git (/docs/integrations/providers/git) GitBook (/docs/integrations/providers/gitbook) Golden (/docs/integrations/providers/golden) Google BigQuery (/docs/integrations/providers/google_bigquery) Google Cloud Storage (/docs/integrations/providers/google_cloud_storage) Google Drive (/docs/integrations/providers/google_drive) Google Search (/docs/integrations/providers/google_search) Google Serper (/docs/integrations/providers/google_serper) Google Vertex AI MatchingEngine (/docs/integrations/providers/google_vertex_ai_matchingengine) GooseAI (/docs/integrations/providers/gooseai) GPT4All (/docs/integrations/providers/gpt4all) Graphsignal (/docs/integrations/providers/graphsignal) Grobid (/docs/integrations/providers/grobid) Gutenberg (/docs/integrations/providers/gutenberg) Hacker News (/docs/integrations/providers/hacker_news) Hazy Research (/docs/integrations/providers/hazy_research) Helicone (/docs/integrations/providers/helicone) Hologres (/docs/integrations/providers/hologres) Hugging Face (/docs/integrations/providers/huggingface) iFixit (/docs/integrations/providers/ifixit) IMSDb (/docs/integrations/providers/imsdb) Infino (/docs/integrations/providers/infino) Jina (/docs/integrations/providers/jina) Konko (/docs/integrations/providers/konko) LanceDB (/docs/integrations/providers/lancedb) LangChain Decorators ‚ú® (/docs/integrations/providers/langchain_decorators) Llama.cpp (/docs/integrations/providers/llamacpp) Log10 (/docs/integrations/providers/log10) Marqo (/docs/integrations/providers/marqo) MediaWikiDump (/docs/integrations/providers/mediawikidump) Meilisearch (/docs/integrations/providers/meilisearch) Metal (/docs/integrations/providers/metal) Microsoft OneDrive (/docs/integrations/providers/microsoft_onedrive) Microsoft PowerPoint (/docs/integrations/providers/microsoft_powerpoint) Microsoft Word (/docs/integrations/providers/microsoft_word) Milvus (/docs/integrations/providers/milvus) Minimax (/docs/integrations/providers/minimax) MLflow AI Gateway (/docs/integrations/providers/mlflow_ai_gateway) MLflow (/docs/integrations/providers/mlflow_tracking) Modal (/docs/integrations/providers/modal) ModelScope (/docs/integrations/providers/modelscope) Modern Treasury (/docs/integrations/providers/modern_treasury) Momento (/docs/integrations/providers/momento) MongoDB Atlas (/docs/integrations/providers/mongodb_atlas) Motherduck (/docs/integrations/providers/motherduck) MyScale (/docs/integrations/providers/myscale) Neo4j (/docs/integrations/providers/neo4j) NLPCloud (/docs/integrations/providers/nlpcloud) Notion DB (/docs/integrations/providers/notion) Obsidian (/docs/integrations/providers/obsidian) OpenAI (/docs/integrations/providers/openai) OpenLLM (/docs/integrations/providers/openllm) OpenSearch (/docs/integrations/providers/opensearch) OpenWeatherMap (/docs/integrations/providers/openweathermap) Petals (/docs/integrations/providers/petals) Postgres Embedding (/docs/integrations/providers/pg_embedding) PGVector (/docs/integrations/providers/pgvector) Pinecone (/docs/integrations/providers/pinecone) PipelineAI (/docs/integrations/providers/pipelineai) Portkey (/docs/integrations/providers/portkey/) Predibase (/docs/integrations/providers/predibase) Prediction Guard (/docs/integrations/providers/predictionguard) PromptLayer (/docs/integrations/providers/promptlayer) Psychic (/docs/integrations/providers/psychic) PubMed (/docs/integrations/providers/pubmed) Qdrant (/docs/integrations/providers/qdrant) Ray Serve (/docs/integrations/providers/ray_serve) Rebuff (/docs/integrations/providers/rebuff) Reddit (/docs/integrations/providers/reddit) Redis (/docs/integrations/providers/redis) Replicate (/docs/integrations/providers/replicate) Roam (/docs/integrations/providers/roam) Rockset (/docs/integrations/providers/rockset) Runhouse (/docs/integrations/providers/runhouse) RWKV-4 (/docs/integrations/providers/rwkv) SageMaker Endpoint (/docs/integrations/providers/sagemaker_endpoint) SageMaker Tracking (/docs/integrations/providers/sagemaker_tracking) ScaNN (/docs/integrations/providers/scann) SearxNG Search API (/docs/integrations/providers/searx) SerpAPI (/docs/integrations/providers/serpapi) Shale Protocol (/docs/integrations/providers/shaleprotocol) SingleStoreDB (/docs/integrations/providers/singlestoredb) scikit-learn (/docs/integrations/providers/sklearn) Slack (/docs/integrations/providers/slack) spaCy (/docs/integrations/providers/spacy) Spreedly (/docs/integrations/providers/spreedly) StarRocks (/docs/integrations/providers/starrocks) StochasticAI (/docs/integrations/providers/stochasticai) Stripe (/docs/integrations/providers/stripe) Supabase (Postgres) (/docs/integrations/providers/supabase) Nebula (/docs/integrations/providers/symblai_nebula) Tair (/docs/integrations/providers/tair) Telegram (/docs/integrations/providers/telegram) TencentVectorDB (/docs/integrations/providers/tencentvectordb) TensorFlow Datasets (/docs/integrations/providers/tensorflow_datasets) Tigris (/docs/integrations/providers/tigris) 2Markdown (/docs/integrations/providers/tomarkdown) Trello (/docs/integrations/providers/trello) TruLens (/docs/integrations/providers/trulens) Twitter (/docs/integrations/providers/twitter) Typesense (/docs/integrations/providers/typesense) Unstructured (/docs/integrations/providers/unstructured) USearch (/docs/integrations/providers/usearch) Vearch (/docs/integrations/providers/vearch) Vectara (/docs/integrations/providers/vectara/) Vespa (/docs/integrations/providers/vespa) WandB Tracing (/docs/integrations/providers/wandb_tracing) Weights & Biases (/docs/integrations/providers/wandb_tracking) Weather (/docs/integrations/providers/weather) Weaviate (/docs/integrations/providers/weaviate) WhatsApp (/docs/integrations/providers/whatsapp) WhyLabs (/docs/integrations/providers/whylabs_profiling) Wikipedia (/docs/integrations/providers/wikipedia) Wolfram Alpha (/docs/integrations/providers/wolfram_alpha) Writer (/docs/integrations/providers/writer) Xata (/docs/integrations/providers/xata) Xorbits Inference (Xinference) (/docs/integrations/providers/xinference) Yeager.ai (/docs/integrations/providers/yeagerai) YouTube (/docs/integrations/providers/youtube) Zep (/docs/integrations/providers/zep) Zilliz (/docs/integrations/providers/zilliz)  (/) Integrations (/docs/integrations) Grouped by provider (/docs/integrations/providers/) WhyLabs (https://docs.whylabs.ai/docs/) ‚Äã (#installation-and-setup) https://whylabs.ai/whylabs-free-sign-up (https://whylabs.ai/whylabs-free-sign-up) https://docs.whylabs.ai/docs/whylabs-onboarding (https://docs.whylabs.ai/docs/whylabs-onboarding#upload-a-profile-to-a-whylabs-project) https://platform.openai.com/account/api-keys (https://platform.openai.com/account/api-keys) ‚Äã (#callbacks) WhyLabsCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.whylabs_callback.WhyLabsCallbackHandler.html) OpenAI (https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html) PreviousWhatsApp (/docs/integrations/providers/whatsapp) NextWikipedia (/docs/integrations/providers/wikipedia) Installation and Setup (#installation-and-setup) Callbacks (#callbacks) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)