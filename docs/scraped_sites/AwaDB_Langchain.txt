AwaDB is an AI Native database for the search and storage of embedding vectors used by LLM Applications. This notebook explains how to use AwaEmbeddings in LangChain. Users can use Embedding.set_model() to specify the embedding model. \ The input of this function is a string which represents the model's name. \ The list of currently supported models can be obtained here \ \  The default model is all-mpnet-base-v2, it can be used without setting. IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAleph AlphaAwaDBAzureOpenAIBedrockBGE on Hugging FaceClarifaiCohereDashScopeDeepInfraEDEN AIElasticsearchEmbaasERNIE Embedding-V1Fake EmbeddingsGoogle Vertex AI PaLMGPT4AllHugging FaceInstructEmbeddingsJinaLlama-cppLocalAIMiniMaxModelScopeMosaicMLNLP CloudOpenAISageMakerSelf HostedSentence TransformersSpaCyTensorflowHubXorbits inference (Xinference)Agents & ToolkitsToolsVector storesGrouped by provider Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding modelsAleph AlphaAwaDBAzureOpenAIBedrockBGE on Hugging FaceClarifaiCohereDashScopeDeepInfraEDEN AIElasticsearchEmbaasERNIE Embedding-V1Fake EmbeddingsGoogle Vertex AI PaLMGPT4AllHugging FaceInstructEmbeddingsJinaLlama-cppLocalAIMiniMaxModelScopeMosaicMLNLP CloudOpenAISageMakerSelf HostedSentence TransformersSpaCyTensorflowHubXorbits inference (Xinference) Aleph Alpha AwaDB AzureOpenAI Bedrock BGE on Hugging Face Clarifai Cohere DashScope DeepInfra EDEN AI Elasticsearch Embaas ERNIE Embedding-V1 Fake Embeddings Google Vertex AI PaLM GPT4All Hugging Face InstructEmbeddings Jina Llama-cpp LocalAI MiniMax ModelScope MosaicML NLP Cloud OpenAI SageMaker Self Hosted Sentence Transformers SpaCy TensorflowHub Xorbits inference (Xinference) Agents & Toolkits Tools Vector stores Grouped by provider  Integrations Text embedding models AwaDB AwaEmbeddings import the library Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAleph AlphaAwaDBAzureOpenAIBedrockBGE on Hugging FaceClarifaiCohereDashScopeDeepInfraEDEN AIElasticsearchEmbaasERNIE Embedding-V1Fake EmbeddingsGoogle Vertex AI PaLMGPT4AllHugging FaceInstructEmbeddingsJinaLlama-cppLocalAIMiniMaxModelScopeMosaicMLNLP CloudOpenAISageMakerSelf HostedSentence TransformersSpaCyTensorflowHubXorbits inference (Xinference)Agents & ToolkitsToolsVector storesGrouped by providerIntegrationsText embedding modelsAwaDBOn this pageAwaDBAwaDB is an AI Native database for the search and storage of embedding vectors used by LLM Applications.This notebook explains how to use AwaEmbeddings in LangChain.# pip install awadbimport the library‚Äãfrom langchain.embeddings import AwaEmbeddingsAPI Reference:AwaEmbeddingsEmbedding = AwaEmbeddings()Set embedding modelUsers can use Embedding.set_model() to specify the embedding model. \ The list of currently supported models can be obtained here \ \ The default model is all-mpnet-base-v2, it can be used without setting.text = "our embedding test"Embedding.set_model("all-mpnet-base-v2")res_query = Embedding.embed_query("The test information")res_document = Embedding.embed_documents(["test1", "another test"])PreviousAleph AlphaNextAzureOpenAIimport the libraryCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAleph AlphaAwaDBAzureOpenAIBedrockBGE on Hugging FaceClarifaiCohereDashScopeDeepInfraEDEN AIElasticsearchEmbaasERNIE Embedding-V1Fake EmbeddingsGoogle Vertex AI PaLMGPT4AllHugging FaceInstructEmbeddingsJinaLlama-cppLocalAIMiniMaxModelScopeMosaicMLNLP CloudOpenAISageMakerSelf HostedSentence TransformersSpaCyTensorflowHubXorbits inference (Xinference)Agents & ToolkitsToolsVector storesGrouped by providerIntegrationsText embedding modelsAwaDBOn this pageAwaDBAwaDB is an AI Native database for the search and storage of embedding vectors used by LLM Applications.This notebook explains how to use AwaEmbeddings in LangChain.# pip install awadbimport the library‚Äãfrom langchain.embeddings import AwaEmbeddingsAPI Reference:AwaEmbeddingsEmbedding = AwaEmbeddings()Set embedding modelUsers can use Embedding.set_model() to specify the embedding model. \ The list of currently supported models can be obtained here \ \ The default model is all-mpnet-base-v2, it can be used without setting.text = "our embedding test"Embedding.set_model("all-mpnet-base-v2")res_query = Embedding.embed_query("The test information")res_document = Embedding.embed_documents(["test1", "another test"])PreviousAleph AlphaNextAzureOpenAIimport the library IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAleph AlphaAwaDBAzureOpenAIBedrockBGE on Hugging FaceClarifaiCohereDashScopeDeepInfraEDEN AIElasticsearchEmbaasERNIE Embedding-V1Fake EmbeddingsGoogle Vertex AI PaLMGPT4AllHugging FaceInstructEmbeddingsJinaLlama-cppLocalAIMiniMaxModelScopeMosaicMLNLP CloudOpenAISageMakerSelf HostedSentence TransformersSpaCyTensorflowHubXorbits inference (Xinference)Agents & ToolkitsToolsVector storesGrouped by providerIntegrationsText embedding modelsAwaDBOn this pageAwaDBAwaDB is an AI Native database for the search and storage of embedding vectors used by LLM Applications.This notebook explains how to use AwaEmbeddings in LangChain.# pip install awadbimport the library‚Äãfrom langchain.embeddings import AwaEmbeddingsAPI Reference:AwaEmbeddingsEmbedding = AwaEmbeddings()Set embedding modelUsers can use Embedding.set_model() to specify the embedding model. \ The list of currently supported models can be obtained here \ \ The default model is all-mpnet-base-v2, it can be used without setting.text = "our embedding test"Embedding.set_model("all-mpnet-base-v2")res_query = Embedding.embed_query("The test information")res_document = Embedding.embed_documents(["test1", "another test"])PreviousAleph AlphaNextAzureOpenAIimport the library IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAleph AlphaAwaDBAzureOpenAIBedrockBGE on Hugging FaceClarifaiCohereDashScopeDeepInfraEDEN AIElasticsearchEmbaasERNIE Embedding-V1Fake EmbeddingsGoogle Vertex AI PaLMGPT4AllHugging FaceInstructEmbeddingsJinaLlama-cppLocalAIMiniMaxModelScopeMosaicMLNLP CloudOpenAISageMakerSelf HostedSentence TransformersSpaCyTensorflowHubXorbits inference (Xinference)Agents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAleph AlphaAwaDBAzureOpenAIBedrockBGE on Hugging FaceClarifaiCohereDashScopeDeepInfraEDEN AIElasticsearchEmbaasERNIE Embedding-V1Fake EmbeddingsGoogle Vertex AI PaLMGPT4AllHugging FaceInstructEmbeddingsJinaLlama-cppLocalAIMiniMaxModelScopeMosaicMLNLP CloudOpenAISageMakerSelf HostedSentence TransformersSpaCyTensorflowHubXorbits inference (Xinference)Agents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsText embedding modelsAwaDBOn this pageAwaDBAwaDB is an AI Native database for the search and storage of embedding vectors used by LLM Applications.This notebook explains how to use AwaEmbeddings in LangChain.# pip install awadbimport the library‚Äãfrom langchain.embeddings import AwaEmbeddingsAPI Reference:AwaEmbeddingsEmbedding = AwaEmbeddings()Set embedding modelUsers can use Embedding.set_model() to specify the embedding model. \ The list of currently supported models can be obtained here \ \ The default model is all-mpnet-base-v2, it can be used without setting.text = "our embedding test"Embedding.set_model("all-mpnet-base-v2")res_query = Embedding.embed_query("The test information")res_document = Embedding.embed_documents(["test1", "another test"])PreviousAleph AlphaNextAzureOpenAIimport the library IntegrationsText embedding modelsAwaDBOn this pageAwaDBAwaDB is an AI Native database for the search and storage of embedding vectors used by LLM Applications.This notebook explains how to use AwaEmbeddings in LangChain.# pip install awadbimport the library‚Äãfrom langchain.embeddings import AwaEmbeddingsAPI Reference:AwaEmbeddingsEmbedding = AwaEmbeddings()Set embedding modelUsers can use Embedding.set_model() to specify the embedding model. \ The list of currently supported models can be obtained here \ \ The default model is all-mpnet-base-v2, it can be used without setting.text = "our embedding test"Embedding.set_model("all-mpnet-base-v2")res_query = Embedding.embed_query("The test information")res_document = Embedding.embed_documents(["test1", "another test"])PreviousAleph AlphaNextAzureOpenAI IntegrationsText embedding modelsAwaDBOn this pageAwaDBAwaDB is an AI Native database for the search and storage of embedding vectors used by LLM Applications.This notebook explains how to use AwaEmbeddings in LangChain.# pip install awadbimport the library‚Äãfrom langchain.embeddings import AwaEmbeddingsAPI Reference:AwaEmbeddingsEmbedding = AwaEmbeddings()Set embedding modelUsers can use Embedding.set_model() to specify the embedding model. \ The list of currently supported models can be obtained here \ \ The default model is all-mpnet-base-v2, it can be used without setting.text = "our embedding test"Embedding.set_model("all-mpnet-base-v2")res_query = Embedding.embed_query("The test information")res_document = Embedding.embed_documents(["test1", "another test"])PreviousAleph AlphaNextAzureOpenAI On this page AwaDBAwaDB is an AI Native database for the search and storage of embedding vectors used by LLM Applications.This notebook explains how to use AwaEmbeddings in LangChain.# pip install awadbimport the library‚Äãfrom langchain.embeddings import AwaEmbeddingsAPI Reference:AwaEmbeddingsEmbedding = AwaEmbeddings()Set embedding modelUsers can use Embedding.set_model() to specify the embedding model. \ The list of currently supported models can be obtained here \ \ The default model is all-mpnet-base-v2, it can be used without setting.text = "our embedding test"Embedding.set_model("all-mpnet-base-v2")res_query = Embedding.embed_query("The test information")res_document = Embedding.embed_documents(["test1", "another test"]) # pip install awadb # pip install awadb  from langchain.embeddings import AwaEmbeddings from langchain.embeddings import AwaEmbeddings  API Reference:AwaEmbeddings Embedding = AwaEmbeddings() Embedding = AwaEmbeddings()  text = "our embedding test"Embedding.set_model("all-mpnet-base-v2") text = "our embedding test"Embedding.set_model("all-mpnet-base-v2")  res_query = Embedding.embed_query("The test information")res_document = Embedding.embed_documents(["test1", "another test"]) res_query = Embedding.embed_query("The test information")res_document = Embedding.embed_documents(["test1", "another test"])  Previous Aleph Alpha Next AzureOpenAI import the library import the library CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Aleph Alpha (/docs/integrations/text_embedding/aleph_alpha) AwaDB (/docs/integrations/text_embedding/awadb) AzureOpenAI (/docs/integrations/text_embedding/azureopenai) Bedrock (/docs/integrations/text_embedding/bedrock) BGE on Hugging Face (/docs/integrations/text_embedding/bge_huggingface) Clarifai (/docs/integrations/text_embedding/clarifai) Cohere (/docs/integrations/text_embedding/cohere) DashScope (/docs/integrations/text_embedding/dashscope) DeepInfra (/docs/integrations/text_embedding/deepinfra) EDEN AI (/docs/integrations/text_embedding/edenai) Elasticsearch (/docs/integrations/text_embedding/elasticsearch) Embaas (/docs/integrations/text_embedding/embaas) ERNIE Embedding-V1 (/docs/integrations/text_embedding/ernie) Fake Embeddings (/docs/integrations/text_embedding/fake) Google Vertex AI PaLM (/docs/integrations/text_embedding/google_vertex_ai_palm) GPT4All (/docs/integrations/text_embedding/gpt4all) Hugging Face (/docs/integrations/text_embedding/huggingfacehub) InstructEmbeddings (/docs/integrations/text_embedding/instruct_embeddings) Jina (/docs/integrations/text_embedding/jina) Llama-cpp (/docs/integrations/text_embedding/llamacpp) LocalAI (/docs/integrations/text_embedding/localai) MiniMax (/docs/integrations/text_embedding/minimax) ModelScope (/docs/integrations/text_embedding/modelscope_hub) MosaicML (/docs/integrations/text_embedding/mosaicml) NLP Cloud (/docs/integrations/text_embedding/nlp_cloud) OpenAI (/docs/integrations/text_embedding/openai) SageMaker (/docs/integrations/text_embedding/sagemaker-endpoint) Self Hosted (/docs/integrations/text_embedding/self-hosted) Sentence Transformers (/docs/integrations/text_embedding/sentence_transformers) SpaCy (/docs/integrations/text_embedding/spacy_embedding) TensorflowHub (/docs/integrations/text_embedding/tensorflowhub) Xorbits inference (Xinference) (/docs/integrations/text_embedding/xinference) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Text embedding models (/docs/integrations/text_embedding/) AwaDB (https://github.com/awa-ai/awadb) ‚Äã (#import-the-library) AwaEmbeddings (https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.awa.AwaEmbeddings.html) here (https://github.com/awa-ai/awadb) PreviousAleph Alpha (/docs/integrations/text_embedding/aleph_alpha) NextAzureOpenAI (/docs/integrations/text_embedding/azureopenai) import the library (#import-the-library) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)