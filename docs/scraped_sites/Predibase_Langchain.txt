Predibase allows you to train, finetune, and deploy any ML model‚Äîfrom linear regression to large language model.  This example demonstrates using Langchain with models deployed on Predibase To run this notebook, you'll need a Predibase account and an API key. You'll also need to install the Predibase Python package: IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Callbacks Chat models Chat loaders Document loaders Document transformers LLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference) AI21 Aleph Alpha Amazon API Gateway Anyscale Azure ML Azure OpenAI Banana Baseten Beam Bedrock Bittensor CerebriumAI ChatGLM Clarifai Cohere C Transformers CTranslate2 Databricks DeepInfra DeepSparse Eden AI Fireworks ForefrontAI Google Vertex AI PaLM GooseAI GPT4All Hugging Face Hub Hugging Face Local Pipelines Huggingface TextGen Inference JSONFormer KoboldAI API Llama.cpp LLM Caching integrations Manifest Minimax Modal MosaicML NLP Cloud OctoAI Ollama OpaquePrompts OpenAI OpenLLM OpenLM Petals PipelineAI Predibase Prediction Guard PromptLayer OpenAI RELLM Replicate Runhouse SageMakerEndpoint StochasticAI Nebula (Symbl.ai) TextGen Titan Takeoff Tongyi Qwen vLLM Writer Xorbits Inference (Xinference) Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations LLMs Predibase Predibase LLMChain PromptTemplate SimpleSequentialChain Predibase Initial Call Chain Call Setup SequentialChain Fine-tuned LLM (Use your own fine-tuned LLM from Predibase) Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsLLMsPredibaseOn this pagePredibasePredibase allows you to train, finetune, and deploy any ML model‚Äîfrom linear regression to large language model. This example demonstrates using Langchain with models deployed on PredibaseSetupTo run this notebook, you'll need a Predibase account and an API key.You'll also need to install the Predibase Python package:pip install predibaseimport osos.environ["PREDIBASE_API_TOKEN"] = "{PREDIBASE_API_TOKEN}"Initial Call‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))API Reference:Predibaseresponse = model("Can you recommend me a nice dry wine?")print(response)Chain Call Setup‚Äãllm = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))SequentialChain‚Äãfrom langchain.chains import LLMChainfrom langchain.prompts import PromptTemplateAPI Reference:LLMChainPromptTemplate# This is an LLMChain to write a synopsis given a title of a play.template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)# This is an LLMChain to write a review of a play given a synopsis.template = """You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.Play Synopsis:{synopsis}Review from a New York Times play critic of the above play:"""prompt_template = PromptTemplate(input_variables=["synopsis"], template=template)review_chain = LLMChain(llm=llm, prompt=prompt_template)# This is the overall chain where we run these two chains in sequence.from langchain.chains import SimpleSequentialChainoverall_chain = SimpleSequentialChain(    chains=[synopsis_chain, review_chain], verbose=True)API Reference:SimpleSequentialChainreview = overall_chain.run("Tragedy at sunset on the beach")Fine-tuned LLM (Use your own fine-tuned LLM from Predibase)‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="my-finetuned-LLM", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))# replace my-finetuned-LLM with the name of your model in PredibaseAPI Reference:Predibase# response = model("Can you help categorize the following emails into positive, negative, and neutral?")PreviousPipelineAINextPrediction GuardInitial CallChain Call SetupSequentialChainFine-tuned LLM (Use your own fine-tuned LLM from Predibase)CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsLLMsPredibaseOn this pagePredibasePredibase allows you to train, finetune, and deploy any ML model‚Äîfrom linear regression to large language model. This example demonstrates using Langchain with models deployed on PredibaseSetupTo run this notebook, you'll need a Predibase account and an API key.You'll also need to install the Predibase Python package:pip install predibaseimport osos.environ["PREDIBASE_API_TOKEN"] = "{PREDIBASE_API_TOKEN}"Initial Call‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))API Reference:Predibaseresponse = model("Can you recommend me a nice dry wine?")print(response)Chain Call Setup‚Äãllm = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))SequentialChain‚Äãfrom langchain.chains import LLMChainfrom langchain.prompts import PromptTemplateAPI Reference:LLMChainPromptTemplate# This is an LLMChain to write a synopsis given a title of a play.template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)# This is an LLMChain to write a review of a play given a synopsis.template = """You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.Play Synopsis:{synopsis}Review from a New York Times play critic of the above play:"""prompt_template = PromptTemplate(input_variables=["synopsis"], template=template)review_chain = LLMChain(llm=llm, prompt=prompt_template)# This is the overall chain where we run these two chains in sequence.from langchain.chains import SimpleSequentialChainoverall_chain = SimpleSequentialChain(    chains=[synopsis_chain, review_chain], verbose=True)API Reference:SimpleSequentialChainreview = overall_chain.run("Tragedy at sunset on the beach")Fine-tuned LLM (Use your own fine-tuned LLM from Predibase)‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="my-finetuned-LLM", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))# replace my-finetuned-LLM with the name of your model in PredibaseAPI Reference:Predibase# response = model("Can you help categorize the following emails into positive, negative, and neutral?")PreviousPipelineAINextPrediction GuardInitial CallChain Call SetupSequentialChainFine-tuned LLM (Use your own fine-tuned LLM from Predibase) IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsLLMsPredibaseOn this pagePredibasePredibase allows you to train, finetune, and deploy any ML model‚Äîfrom linear regression to large language model. This example demonstrates using Langchain with models deployed on PredibaseSetupTo run this notebook, you'll need a Predibase account and an API key.You'll also need to install the Predibase Python package:pip install predibaseimport osos.environ["PREDIBASE_API_TOKEN"] = "{PREDIBASE_API_TOKEN}"Initial Call‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))API Reference:Predibaseresponse = model("Can you recommend me a nice dry wine?")print(response)Chain Call Setup‚Äãllm = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))SequentialChain‚Äãfrom langchain.chains import LLMChainfrom langchain.prompts import PromptTemplateAPI Reference:LLMChainPromptTemplate# This is an LLMChain to write a synopsis given a title of a play.template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)# This is an LLMChain to write a review of a play given a synopsis.template = """You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.Play Synopsis:{synopsis}Review from a New York Times play critic of the above play:"""prompt_template = PromptTemplate(input_variables=["synopsis"], template=template)review_chain = LLMChain(llm=llm, prompt=prompt_template)# This is the overall chain where we run these two chains in sequence.from langchain.chains import SimpleSequentialChainoverall_chain = SimpleSequentialChain(    chains=[synopsis_chain, review_chain], verbose=True)API Reference:SimpleSequentialChainreview = overall_chain.run("Tragedy at sunset on the beach")Fine-tuned LLM (Use your own fine-tuned LLM from Predibase)‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="my-finetuned-LLM", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))# replace my-finetuned-LLM with the name of your model in PredibaseAPI Reference:Predibase# response = model("Can you help categorize the following emails into positive, negative, and neutral?")PreviousPipelineAINextPrediction GuardInitial CallChain Call SetupSequentialChainFine-tuned LLM (Use your own fine-tuned LLM from Predibase) IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsAI21Aleph AlphaAmazon API GatewayAnyscaleAzure MLAzure OpenAIBananaBasetenBeamBedrockBittensorCerebriumAIChatGLMClarifaiCohereC TransformersCTranslate2DatabricksDeepInfraDeepSparseEden AIFireworksForefrontAIGoogle Vertex AI PaLMGooseAIGPT4AllHugging Face HubHugging Face Local PipelinesHuggingface TextGen InferenceJSONFormerKoboldAI APILlama.cppLLM Caching integrationsManifestMinimaxModalMosaicMLNLP CloudOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTongyi QwenvLLMWriterXorbits Inference (Xinference)MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsLLMsPredibaseOn this pagePredibasePredibase allows you to train, finetune, and deploy any ML model‚Äîfrom linear regression to large language model. This example demonstrates using Langchain with models deployed on PredibaseSetupTo run this notebook, you'll need a Predibase account and an API key.You'll also need to install the Predibase Python package:pip install predibaseimport osos.environ["PREDIBASE_API_TOKEN"] = "{PREDIBASE_API_TOKEN}"Initial Call‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))API Reference:Predibaseresponse = model("Can you recommend me a nice dry wine?")print(response)Chain Call Setup‚Äãllm = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))SequentialChain‚Äãfrom langchain.chains import LLMChainfrom langchain.prompts import PromptTemplateAPI Reference:LLMChainPromptTemplate# This is an LLMChain to write a synopsis given a title of a play.template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)# This is an LLMChain to write a review of a play given a synopsis.template = """You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.Play Synopsis:{synopsis}Review from a New York Times play critic of the above play:"""prompt_template = PromptTemplate(input_variables=["synopsis"], template=template)review_chain = LLMChain(llm=llm, prompt=prompt_template)# This is the overall chain where we run these two chains in sequence.from langchain.chains import SimpleSequentialChainoverall_chain = SimpleSequentialChain(    chains=[synopsis_chain, review_chain], verbose=True)API Reference:SimpleSequentialChainreview = overall_chain.run("Tragedy at sunset on the beach")Fine-tuned LLM (Use your own fine-tuned LLM from Predibase)‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="my-finetuned-LLM", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))# replace my-finetuned-LLM with the name of your model in PredibaseAPI Reference:Predibase# response = model("Can you help categorize the following emails into positive, negative, and neutral?")PreviousPipelineAINextPrediction GuardInitial CallChain Call SetupSequentialChainFine-tuned LLM (Use your own fine-tuned LLM from Predibase) IntegrationsLLMsPredibaseOn this pagePredibasePredibase allows you to train, finetune, and deploy any ML model‚Äîfrom linear regression to large language model. This example demonstrates using Langchain with models deployed on PredibaseSetupTo run this notebook, you'll need a Predibase account and an API key.You'll also need to install the Predibase Python package:pip install predibaseimport osos.environ["PREDIBASE_API_TOKEN"] = "{PREDIBASE_API_TOKEN}"Initial Call‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))API Reference:Predibaseresponse = model("Can you recommend me a nice dry wine?")print(response)Chain Call Setup‚Äãllm = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))SequentialChain‚Äãfrom langchain.chains import LLMChainfrom langchain.prompts import PromptTemplateAPI Reference:LLMChainPromptTemplate# This is an LLMChain to write a synopsis given a title of a play.template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)# This is an LLMChain to write a review of a play given a synopsis.template = """You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.Play Synopsis:{synopsis}Review from a New York Times play critic of the above play:"""prompt_template = PromptTemplate(input_variables=["synopsis"], template=template)review_chain = LLMChain(llm=llm, prompt=prompt_template)# This is the overall chain where we run these two chains in sequence.from langchain.chains import SimpleSequentialChainoverall_chain = SimpleSequentialChain(    chains=[synopsis_chain, review_chain], verbose=True)API Reference:SimpleSequentialChainreview = overall_chain.run("Tragedy at sunset on the beach")Fine-tuned LLM (Use your own fine-tuned LLM from Predibase)‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="my-finetuned-LLM", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))# replace my-finetuned-LLM with the name of your model in PredibaseAPI Reference:Predibase# response = model("Can you help categorize the following emails into positive, negative, and neutral?")PreviousPipelineAINextPrediction GuardInitial CallChain Call SetupSequentialChainFine-tuned LLM (Use your own fine-tuned LLM from Predibase) IntegrationsLLMsPredibaseOn this pagePredibasePredibase allows you to train, finetune, and deploy any ML model‚Äîfrom linear regression to large language model. This example demonstrates using Langchain with models deployed on PredibaseSetupTo run this notebook, you'll need a Predibase account and an API key.You'll also need to install the Predibase Python package:pip install predibaseimport osos.environ["PREDIBASE_API_TOKEN"] = "{PREDIBASE_API_TOKEN}"Initial Call‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))API Reference:Predibaseresponse = model("Can you recommend me a nice dry wine?")print(response)Chain Call Setup‚Äãllm = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))SequentialChain‚Äãfrom langchain.chains import LLMChainfrom langchain.prompts import PromptTemplateAPI Reference:LLMChainPromptTemplate# This is an LLMChain to write a synopsis given a title of a play.template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)# This is an LLMChain to write a review of a play given a synopsis.template = """You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.Play Synopsis:{synopsis}Review from a New York Times play critic of the above play:"""prompt_template = PromptTemplate(input_variables=["synopsis"], template=template)review_chain = LLMChain(llm=llm, prompt=prompt_template)# This is the overall chain where we run these two chains in sequence.from langchain.chains import SimpleSequentialChainoverall_chain = SimpleSequentialChain(    chains=[synopsis_chain, review_chain], verbose=True)API Reference:SimpleSequentialChainreview = overall_chain.run("Tragedy at sunset on the beach")Fine-tuned LLM (Use your own fine-tuned LLM from Predibase)‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="my-finetuned-LLM", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))# replace my-finetuned-LLM with the name of your model in PredibaseAPI Reference:Predibase# response = model("Can you help categorize the following emails into positive, negative, and neutral?")PreviousPipelineAINextPrediction Guard IntegrationsLLMsPredibaseOn this pagePredibasePredibase allows you to train, finetune, and deploy any ML model‚Äîfrom linear regression to large language model. This example demonstrates using Langchain with models deployed on PredibaseSetupTo run this notebook, you'll need a Predibase account and an API key.You'll also need to install the Predibase Python package:pip install predibaseimport osos.environ["PREDIBASE_API_TOKEN"] = "{PREDIBASE_API_TOKEN}"Initial Call‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))API Reference:Predibaseresponse = model("Can you recommend me a nice dry wine?")print(response)Chain Call Setup‚Äãllm = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))SequentialChain‚Äãfrom langchain.chains import LLMChainfrom langchain.prompts import PromptTemplateAPI Reference:LLMChainPromptTemplate# This is an LLMChain to write a synopsis given a title of a play.template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)# This is an LLMChain to write a review of a play given a synopsis.template = """You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.Play Synopsis:{synopsis}Review from a New York Times play critic of the above play:"""prompt_template = PromptTemplate(input_variables=["synopsis"], template=template)review_chain = LLMChain(llm=llm, prompt=prompt_template)# This is the overall chain where we run these two chains in sequence.from langchain.chains import SimpleSequentialChainoverall_chain = SimpleSequentialChain(    chains=[synopsis_chain, review_chain], verbose=True)API Reference:SimpleSequentialChainreview = overall_chain.run("Tragedy at sunset on the beach")Fine-tuned LLM (Use your own fine-tuned LLM from Predibase)‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="my-finetuned-LLM", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))# replace my-finetuned-LLM with the name of your model in PredibaseAPI Reference:Predibase# response = model("Can you help categorize the following emails into positive, negative, and neutral?")PreviousPipelineAINextPrediction Guard On this page PredibasePredibase allows you to train, finetune, and deploy any ML model‚Äîfrom linear regression to large language model. This example demonstrates using Langchain with models deployed on PredibaseSetupTo run this notebook, you'll need a Predibase account and an API key.You'll also need to install the Predibase Python package:pip install predibaseimport osos.environ["PREDIBASE_API_TOKEN"] = "{PREDIBASE_API_TOKEN}"Initial Call‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))API Reference:Predibaseresponse = model("Can you recommend me a nice dry wine?")print(response)Chain Call Setup‚Äãllm = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))SequentialChain‚Äãfrom langchain.chains import LLMChainfrom langchain.prompts import PromptTemplateAPI Reference:LLMChainPromptTemplate# This is an LLMChain to write a synopsis given a title of a play.template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)# This is an LLMChain to write a review of a play given a synopsis.template = """You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.Play Synopsis:{synopsis}Review from a New York Times play critic of the above play:"""prompt_template = PromptTemplate(input_variables=["synopsis"], template=template)review_chain = LLMChain(llm=llm, prompt=prompt_template)# This is the overall chain where we run these two chains in sequence.from langchain.chains import SimpleSequentialChainoverall_chain = SimpleSequentialChain(    chains=[synopsis_chain, review_chain], verbose=True)API Reference:SimpleSequentialChainreview = overall_chain.run("Tragedy at sunset on the beach")Fine-tuned LLM (Use your own fine-tuned LLM from Predibase)‚Äãfrom langchain.llms import Predibasemodel = Predibase(    model="my-finetuned-LLM", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))# replace my-finetuned-LLM with the name of your model in PredibaseAPI Reference:Predibase# response = model("Can you help categorize the following emails into positive, negative, and neutral?") pip install predibaseimport osos.environ["PREDIBASE_API_TOKEN"] = "{PREDIBASE_API_TOKEN}" pip install predibaseimport osos.environ["PREDIBASE_API_TOKEN"] = "{PREDIBASE_API_TOKEN}"  from langchain.llms import Predibasemodel = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN")) from langchain.llms import Predibasemodel = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))  API Reference:Predibase response = model("Can you recommend me a nice dry wine?")print(response) response = model("Can you recommend me a nice dry wine?")print(response)  llm = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN")) llm = Predibase(    model="vicuna-13b", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))  from langchain.chains import LLMChainfrom langchain.prompts import PromptTemplate from langchain.chains import LLMChainfrom langchain.prompts import PromptTemplate  API Reference:LLMChainPromptTemplate # This is an LLMChain to write a synopsis given a title of a play.template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template) # This is an LLMChain to write a synopsis given a title of a play.template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.Title: {title}Playwright: This is a synopsis for the above play:"""prompt_template = PromptTemplate(input_variables=["title"], template=template)synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)  # This is an LLMChain to write a review of a play given a synopsis.template = """You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.Play Synopsis:{synopsis}Review from a New York Times play critic of the above play:"""prompt_template = PromptTemplate(input_variables=["synopsis"], template=template)review_chain = LLMChain(llm=llm, prompt=prompt_template) # This is an LLMChain to write a review of a play given a synopsis.template = """You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.Play Synopsis:{synopsis}Review from a New York Times play critic of the above play:"""prompt_template = PromptTemplate(input_variables=["synopsis"], template=template)review_chain = LLMChain(llm=llm, prompt=prompt_template)  # This is the overall chain where we run these two chains in sequence.from langchain.chains import SimpleSequentialChainoverall_chain = SimpleSequentialChain(    chains=[synopsis_chain, review_chain], verbose=True) # This is the overall chain where we run these two chains in sequence.from langchain.chains import SimpleSequentialChainoverall_chain = SimpleSequentialChain(    chains=[synopsis_chain, review_chain], verbose=True)  API Reference:SimpleSequentialChain review = overall_chain.run("Tragedy at sunset on the beach") review = overall_chain.run("Tragedy at sunset on the beach")  from langchain.llms import Predibasemodel = Predibase(    model="my-finetuned-LLM", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))# replace my-finetuned-LLM with the name of your model in Predibase from langchain.llms import Predibasemodel = Predibase(    model="my-finetuned-LLM", predibase_api_key=os.environ.get("PREDIBASE_API_TOKEN"))# replace my-finetuned-LLM with the name of your model in Predibase  API Reference:Predibase # response = model("Can you help categorize the following emails into positive, negative, and neutral?") # response = model("Can you help categorize the following emails into positive, negative, and neutral?")  Previous PipelineAI Next Prediction Guard Initial CallChain Call SetupSequentialChainFine-tuned LLM (Use your own fine-tuned LLM from Predibase) Initial CallChain Call SetupSequentialChainFine-tuned LLM (Use your own fine-tuned LLM from Predibase) CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) AI21 (/docs/integrations/llms/ai21) Aleph Alpha (/docs/integrations/llms/aleph_alpha) Amazon API Gateway (/docs/integrations/llms/amazon_api_gateway) Anyscale (/docs/integrations/llms/anyscale) Azure ML (/docs/integrations/llms/azure_ml) Azure OpenAI (/docs/integrations/llms/azure_openai) Banana (/docs/integrations/llms/banana) Baseten (/docs/integrations/llms/baseten) Beam (/docs/integrations/llms/beam) Bedrock (/docs/integrations/llms/bedrock) Bittensor (/docs/integrations/llms/bittensor) CerebriumAI (/docs/integrations/llms/cerebriumai) ChatGLM (/docs/integrations/llms/chatglm) Clarifai (/docs/integrations/llms/clarifai) Cohere (/docs/integrations/llms/cohere) C Transformers (/docs/integrations/llms/ctransformers) CTranslate2 (/docs/integrations/llms/ctranslate2) Databricks (/docs/integrations/llms/databricks) DeepInfra (/docs/integrations/llms/deepinfra) DeepSparse (/docs/integrations/llms/deepsparse) Eden AI (/docs/integrations/llms/edenai) Fireworks (/docs/integrations/llms/fireworks) ForefrontAI (/docs/integrations/llms/forefrontai) Google Vertex AI PaLM (/docs/integrations/llms/google_vertex_ai_palm) GooseAI (/docs/integrations/llms/gooseai) GPT4All (/docs/integrations/llms/gpt4all) Hugging Face Hub (/docs/integrations/llms/huggingface_hub) Hugging Face Local Pipelines (/docs/integrations/llms/huggingface_pipelines) Huggingface TextGen Inference (/docs/integrations/llms/huggingface_textgen_inference) JSONFormer (/docs/integrations/llms/jsonformer_experimental) KoboldAI API (/docs/integrations/llms/koboldai) Llama.cpp (/docs/integrations/llms/llamacpp) LLM Caching integrations (/docs/integrations/llms/llm_caching) Manifest (/docs/integrations/llms/manifest) Minimax (/docs/integrations/llms/minimax) Modal (/docs/integrations/llms/modal) MosaicML (/docs/integrations/llms/mosaicml) NLP Cloud (/docs/integrations/llms/nlpcloud) OctoAI (/docs/integrations/llms/octoai) Ollama (/docs/integrations/llms/ollama) OpaquePrompts (/docs/integrations/llms/opaqueprompts) OpenAI (/docs/integrations/llms/openai) OpenLLM (/docs/integrations/llms/openllm) OpenLM (/docs/integrations/llms/openlm) Petals (/docs/integrations/llms/petals) PipelineAI (/docs/integrations/llms/pipelineai) Predibase (/docs/integrations/llms/predibase) Prediction Guard (/docs/integrations/llms/predictionguard) PromptLayer OpenAI (/docs/integrations/llms/promptlayer_openai) RELLM (/docs/integrations/llms/rellm_experimental) Replicate (/docs/integrations/llms/replicate) Runhouse (/docs/integrations/llms/runhouse) SageMakerEndpoint (/docs/integrations/llms/sagemaker) StochasticAI (/docs/integrations/llms/stochasticai) Nebula (Symbl.ai) (/docs/integrations/llms/symblai_nebula) TextGen (/docs/integrations/llms/textgen) Titan Takeoff (/docs/integrations/llms/titan_takeoff) Tongyi Qwen (/docs/integrations/llms/tongyi) vLLM (/docs/integrations/llms/vllm) Writer (/docs/integrations/llms/writer) Xorbits Inference (Xinference) (/docs/integrations/llms/xinference) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) LLMs (/docs/integrations/llms/) Predibase (https://predibase.com/) Predibase account (https://predibase.com/free-trial/?utm_source=langchain) API key (https://docs.predibase.com/sdk-guide/intro) ‚Äã (#initial-call) Predibase (https://api.python.langchain.com/en/latest/llms/langchain.llms.predibase.Predibase.html) ‚Äã (#chain-call-setup) ‚Äã (#sequentialchain) LLMChain (https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html) PromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html) SimpleSequentialChain (https://api.python.langchain.com/en/latest/chains/langchain.chains.sequential.SimpleSequentialChain.html) ‚Äã (#fine-tuned-llm-use-your-own-fine-tuned-llm-from-predibase) Predibase (https://api.python.langchain.com/en/latest/llms/langchain.llms.predibase.Predibase.html) PreviousPipelineAI (/docs/integrations/llms/pipelineai) NextPrediction Guard (/docs/integrations/llms/predictionguard) Initial Call (#initial-call) Chain Call Setup (#chain-call-setup) SequentialChain (#sequentialchain) Fine-tuned LLM (Use your own fine-tuned LLM from Predibase) (#fine-tuned-llm-use-your-own-fine-tuned-llm-from-predibase) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)