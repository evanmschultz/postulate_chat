Label Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback. In this guide, you will learn how to connect a LangChain pipeline to Label Studio to: First install latest versions of Label Studio and Label Studio API client: Next, run label-studio on the command line to start the local LabelStudio instance at http://localhost:8080. See the Label Studio installation guide for more options. You'll need a token to make API calls. Open your LabelStudio instance in your browser, go to Account & Settings > Access Token and copy the key. Set environment variables with your LabelStudio URL, API key and OpenAI API key: The data used for labeling is stored in projects within Label Studio. Every project is identified by an XML configuration that details the specifications for input and output data.  Create a project that takes human input in text format and outputs an editable LLM response in a text area: You can collect input LLM prompts and output responses in a LabelStudio project, connecting it via LabelStudioCallbackHandler: In the Label Studio, open My Project. You will see the prompts, responses, and metadata like the model name.  You can also track and display full chat dialogues in LabelStudio, with the ability to rate and modify the last response: In Label Studio, open "New Project with Chat". Click on a created task to view dialog history and edit/annotate responses. You can modify the default labeling configuration in LabelStudio to add more target labels like response sentiment, relevance, and many other types annotator's feedback. New labeling configuration can be added from UI: go to Settings > Labeling Interface and set up a custom configuration with additional tags like Choices for sentiment or Rating for relevance. Keep in mind that TextArea tag should be presented in any configuration to display the LLM responses. Alternatively, you can specify the labeling configuration on the initial call before project creation: Note that if the project doesn't exist, it will be created with the specified labeling configuration. The LabelStudioCallbackHandler accepts several optional parameters: IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider CallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlit Argilla Confident Context Infino Label Studio LLMonitor PromptLayer Streamlit Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations Callbacks Label Studio Aggregate all input prompts, conversations, and responses in a single LabelStudio project. This consolidates all the data in one place for easier labeling and analysis. Refine prompts and responses to create a dataset for supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) scenarios. The labeled data can be used to further train the LLM to improve its performance. Evaluate model responses through human feedback. LabelStudio provides an interface for humans to review and provide feedback on model responses, allowing evaluation and iteration. To create a project in Label Studio, click on the "Create" button.  Enter a name for your project in the "Project Name" field, such as My Project. Navigate to Labeling Setup > Custom Template and paste the XML configuration provided above. OpenAI LabelStudioCallbackHandler Open Label Studio and click on the "Create" button. Enter a name for your project in the "Project Name" field, such as New Project with Chat. Navigate to Labeling Setup > Custom Template and paste the following XML configuration: ChatOpenAI HumanMessage SystemMessage LabelStudioCallbackHandler api_key - Label Studio API key. Overrides environmental variable LABEL_STUDIO_API_KEY. url - Label Studio URL. Overrides LABEL_STUDIO_URL, default http://localhost:8080. project_id - Existing Label Studio project ID. Overrides LABEL_STUDIO_PROJECT_ID. Stores data in this project. project_name - Project name if project ID not specified. Creates a new project. Default is "LangChain-%Y-%m-%d" formatted with the current date. project_config - custom labeling configuration mode: use this shortcut to create target configuration from scratch:"prompt" - Single prompt, single response. Default."chat" - Multi-turn chat mode. "prompt" - Single prompt, single response. Default. "chat" - Multi-turn chat mode. Installation and setup Collecting LLMs prompts and responses Collecting Chat model Dialogues Custom Labeling Configuration Other parameters Discord Twitter Python JS/TS Homepage Blog Skip to main content🦜️🔗 LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsCallbacksLabel StudioOn this pageLabel StudioLabel Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback.In this guide, you will learn how to connect a LangChain pipeline to Label Studio to:Aggregate all input prompts, conversations, and responses in a single LabelStudio project. This consolidates all the data in one place for easier labeling and analysis.Refine prompts and responses to create a dataset for supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) scenarios. The labeled data can be used to further train the LLM to improve its performance.Evaluate model responses through human feedback. LabelStudio provides an interface for humans to review and provide feedback on model responses, allowing evaluation and iteration.Installation and setup​First install latest versions of Label Studio and Label Studio API client:pip install -U label-studio label-studio-sdk openaiNext, run label-studio on the command line to start the local LabelStudio instance at http://localhost:8080. See the Label Studio installation guide for more options.You'll need a token to make API calls.Open your LabelStudio instance in your browser, go to Account & Settings > Access Token and copy the key.Set environment variables with your LabelStudio URL, API key and OpenAI API key:import osos.environ['LABEL_STUDIO_URL'] = '<YOUR-LABEL-STUDIO-URL>'  # e.g. http://localhost:8080os.environ['LABEL_STUDIO_API_KEY'] = '<YOUR-LABEL-STUDIO-API-KEY>'os.environ['OPENAI_API_KEY'] = '<YOUR-OPENAI-API-KEY>'Collecting LLMs prompts and responses​The data used for labeling is stored in projects within Label Studio. Every project is identified by an XML configuration that details the specifications for input and output data. Create a project that takes human input in text format and outputs an editable LLM response in a text area:<View><Style>    .prompt-box {        background-color: white;        border-radius: 10px;        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);        padding: 20px;    }</Style><View className="root">    <View className="prompt-box">        <Text name="prompt" value="$prompt"/>    </View>    <TextArea name="response" toName="prompt"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="prompt"/></View>To create a project in Label Studio, click on the "Create" button. Enter a name for your project in the "Project Name" field, such as My Project.Navigate to Labeling Setup > Custom Template and paste the XML configuration provided above.You can collect input LLM prompts and output responses in a LabelStudio project, connecting it via LabelStudioCallbackHandler:from langchain.llms import OpenAIfrom langchain.callbacks import LabelStudioCallbackHandlerllm = OpenAI(    temperature=0,    callbacks=[        LabelStudioCallbackHandler(            project_name="My Project"    )])print(llm("Tell me a joke"))API Reference:OpenAILabelStudioCallbackHandlerIn the Label Studio, open My Project. You will see the prompts, responses, and metadata like the model name. Collecting Chat model Dialogues​You can also track and display full chat dialogues in LabelStudio, with the ability to rate and modify the last response:Open Label Studio and click on the "Create" button.Enter a name for your project in the "Project Name" field, such as New Project with Chat.Navigate to Labeling Setup > Custom Template and paste the following XML configuration:<View><View className="root">     <Paragraphs name="dialogue"               value="$prompt"               layout="dialogue"               textKey="content"               nameKey="role"               granularity="sentence"/>  <Header value="Final response:"/>    <TextArea name="response" toName="dialogue"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="dialogue"/></View>from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessage, SystemMessagefrom langchain.callbacks import LabelStudioCallbackHandlerchat_llm = ChatOpenAI(callbacks=[    LabelStudioCallbackHandler(        mode="chat",        project_name="New Project with Chat",    )])llm_results = chat_llm([    SystemMessage(content="Always use a lot of emojis"),    HumanMessage(content="Tell me a joke")])API Reference:ChatOpenAIHumanMessageSystemMessageLabelStudioCallbackHandlerIn Label Studio, open "New Project with Chat". Click on a created task to view dialog history and edit/annotate responses.Custom Labeling Configuration​You can modify the default labeling configuration in LabelStudio to add more target labels like response sentiment, relevance, and many other types annotator's feedback.New labeling configuration can be added from UI: go to Settings > Labeling Interface and set up a custom configuration with additional tags like Choices for sentiment or Rating for relevance. Keep in mind that TextArea tag should be presented in any configuration to display the LLM responses.Alternatively, you can specify the labeling configuration on the initial call before project creation:ls = LabelStudioCallbackHandler(project_config='''<View><Text name="prompt" value="$prompt"/><TextArea name="response" toName="prompt"/><TextArea name="user_feedback" toName="prompt"/><Rating name="rating" toName="prompt"/><Choices name="sentiment" toName="prompt">    <Choice value="Positive"/>    <Choice value="Negative"/></Choices></View>''')Note that if the project doesn't exist, it will be created with the specified labeling configuration.Other parameters​The LabelStudioCallbackHandler accepts several optional parameters:api_key - Label Studio API key. Overrides environmental variable LABEL_STUDIO_API_KEY.url - Label Studio URL. Overrides LABEL_STUDIO_URL, default http://localhost:8080.project_id - Existing Label Studio project ID. Overrides LABEL_STUDIO_PROJECT_ID. Stores data in this project.project_name - Project name if project ID not specified. Creates a new project. Default is "LangChain-%Y-%m-%d" formatted with the current date.project_config - custom labeling configurationmode: use this shortcut to create target configuration from scratch:"prompt" - Single prompt, single response. Default."chat" - Multi-turn chat mode.PreviousInfinoNextLLMonitorInstallation and setupCollecting LLMs prompts and responsesCollecting Chat model DialoguesCustom Labeling ConfigurationOther parametersCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright © 2023 LangChain, Inc. Skip to main content 🦜️🔗 LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK 🦜️🔗 LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsCallbacksLabel StudioOn this pageLabel StudioLabel Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback.In this guide, you will learn how to connect a LangChain pipeline to Label Studio to:Aggregate all input prompts, conversations, and responses in a single LabelStudio project. This consolidates all the data in one place for easier labeling and analysis.Refine prompts and responses to create a dataset for supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) scenarios. The labeled data can be used to further train the LLM to improve its performance.Evaluate model responses through human feedback. LabelStudio provides an interface for humans to review and provide feedback on model responses, allowing evaluation and iteration.Installation and setup​First install latest versions of Label Studio and Label Studio API client:pip install -U label-studio label-studio-sdk openaiNext, run label-studio on the command line to start the local LabelStudio instance at http://localhost:8080. See the Label Studio installation guide for more options.You'll need a token to make API calls.Open your LabelStudio instance in your browser, go to Account & Settings > Access Token and copy the key.Set environment variables with your LabelStudio URL, API key and OpenAI API key:import osos.environ['LABEL_STUDIO_URL'] = '<YOUR-LABEL-STUDIO-URL>'  # e.g. http://localhost:8080os.environ['LABEL_STUDIO_API_KEY'] = '<YOUR-LABEL-STUDIO-API-KEY>'os.environ['OPENAI_API_KEY'] = '<YOUR-OPENAI-API-KEY>'Collecting LLMs prompts and responses​The data used for labeling is stored in projects within Label Studio. Every project is identified by an XML configuration that details the specifications for input and output data. Create a project that takes human input in text format and outputs an editable LLM response in a text area:<View><Style>    .prompt-box {        background-color: white;        border-radius: 10px;        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);        padding: 20px;    }</Style><View className="root">    <View className="prompt-box">        <Text name="prompt" value="$prompt"/>    </View>    <TextArea name="response" toName="prompt"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="prompt"/></View>To create a project in Label Studio, click on the "Create" button. Enter a name for your project in the "Project Name" field, such as My Project.Navigate to Labeling Setup > Custom Template and paste the XML configuration provided above.You can collect input LLM prompts and output responses in a LabelStudio project, connecting it via LabelStudioCallbackHandler:from langchain.llms import OpenAIfrom langchain.callbacks import LabelStudioCallbackHandlerllm = OpenAI(    temperature=0,    callbacks=[        LabelStudioCallbackHandler(            project_name="My Project"    )])print(llm("Tell me a joke"))API Reference:OpenAILabelStudioCallbackHandlerIn the Label Studio, open My Project. You will see the prompts, responses, and metadata like the model name. Collecting Chat model Dialogues​You can also track and display full chat dialogues in LabelStudio, with the ability to rate and modify the last response:Open Label Studio and click on the "Create" button.Enter a name for your project in the "Project Name" field, such as New Project with Chat.Navigate to Labeling Setup > Custom Template and paste the following XML configuration:<View><View className="root">     <Paragraphs name="dialogue"               value="$prompt"               layout="dialogue"               textKey="content"               nameKey="role"               granularity="sentence"/>  <Header value="Final response:"/>    <TextArea name="response" toName="dialogue"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="dialogue"/></View>from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessage, SystemMessagefrom langchain.callbacks import LabelStudioCallbackHandlerchat_llm = ChatOpenAI(callbacks=[    LabelStudioCallbackHandler(        mode="chat",        project_name="New Project with Chat",    )])llm_results = chat_llm([    SystemMessage(content="Always use a lot of emojis"),    HumanMessage(content="Tell me a joke")])API Reference:ChatOpenAIHumanMessageSystemMessageLabelStudioCallbackHandlerIn Label Studio, open "New Project with Chat". Click on a created task to view dialog history and edit/annotate responses.Custom Labeling Configuration​You can modify the default labeling configuration in LabelStudio to add more target labels like response sentiment, relevance, and many other types annotator's feedback.New labeling configuration can be added from UI: go to Settings > Labeling Interface and set up a custom configuration with additional tags like Choices for sentiment or Rating for relevance. Keep in mind that TextArea tag should be presented in any configuration to display the LLM responses.Alternatively, you can specify the labeling configuration on the initial call before project creation:ls = LabelStudioCallbackHandler(project_config='''<View><Text name="prompt" value="$prompt"/><TextArea name="response" toName="prompt"/><TextArea name="user_feedback" toName="prompt"/><Rating name="rating" toName="prompt"/><Choices name="sentiment" toName="prompt">    <Choice value="Positive"/>    <Choice value="Negative"/></Choices></View>''')Note that if the project doesn't exist, it will be created with the specified labeling configuration.Other parameters​The LabelStudioCallbackHandler accepts several optional parameters:api_key - Label Studio API key. Overrides environmental variable LABEL_STUDIO_API_KEY.url - Label Studio URL. Overrides LABEL_STUDIO_URL, default http://localhost:8080.project_id - Existing Label Studio project ID. Overrides LABEL_STUDIO_PROJECT_ID. Stores data in this project.project_name - Project name if project ID not specified. Creates a new project. Default is "LangChain-%Y-%m-%d" formatted with the current date.project_config - custom labeling configurationmode: use this shortcut to create target configuration from scratch:"prompt" - Single prompt, single response. Default."chat" - Multi-turn chat mode.PreviousInfinoNextLLMonitorInstallation and setupCollecting LLMs prompts and responsesCollecting Chat model DialoguesCustom Labeling ConfigurationOther parameters IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsCallbacksLabel StudioOn this pageLabel StudioLabel Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback.In this guide, you will learn how to connect a LangChain pipeline to Label Studio to:Aggregate all input prompts, conversations, and responses in a single LabelStudio project. This consolidates all the data in one place for easier labeling and analysis.Refine prompts and responses to create a dataset for supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) scenarios. The labeled data can be used to further train the LLM to improve its performance.Evaluate model responses through human feedback. LabelStudio provides an interface for humans to review and provide feedback on model responses, allowing evaluation and iteration.Installation and setup​First install latest versions of Label Studio and Label Studio API client:pip install -U label-studio label-studio-sdk openaiNext, run label-studio on the command line to start the local LabelStudio instance at http://localhost:8080. See the Label Studio installation guide for more options.You'll need a token to make API calls.Open your LabelStudio instance in your browser, go to Account & Settings > Access Token and copy the key.Set environment variables with your LabelStudio URL, API key and OpenAI API key:import osos.environ['LABEL_STUDIO_URL'] = '<YOUR-LABEL-STUDIO-URL>'  # e.g. http://localhost:8080os.environ['LABEL_STUDIO_API_KEY'] = '<YOUR-LABEL-STUDIO-API-KEY>'os.environ['OPENAI_API_KEY'] = '<YOUR-OPENAI-API-KEY>'Collecting LLMs prompts and responses​The data used for labeling is stored in projects within Label Studio. Every project is identified by an XML configuration that details the specifications for input and output data. Create a project that takes human input in text format and outputs an editable LLM response in a text area:<View><Style>    .prompt-box {        background-color: white;        border-radius: 10px;        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);        padding: 20px;    }</Style><View className="root">    <View className="prompt-box">        <Text name="prompt" value="$prompt"/>    </View>    <TextArea name="response" toName="prompt"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="prompt"/></View>To create a project in Label Studio, click on the "Create" button. Enter a name for your project in the "Project Name" field, such as My Project.Navigate to Labeling Setup > Custom Template and paste the XML configuration provided above.You can collect input LLM prompts and output responses in a LabelStudio project, connecting it via LabelStudioCallbackHandler:from langchain.llms import OpenAIfrom langchain.callbacks import LabelStudioCallbackHandlerllm = OpenAI(    temperature=0,    callbacks=[        LabelStudioCallbackHandler(            project_name="My Project"    )])print(llm("Tell me a joke"))API Reference:OpenAILabelStudioCallbackHandlerIn the Label Studio, open My Project. You will see the prompts, responses, and metadata like the model name. Collecting Chat model Dialogues​You can also track and display full chat dialogues in LabelStudio, with the ability to rate and modify the last response:Open Label Studio and click on the "Create" button.Enter a name for your project in the "Project Name" field, such as New Project with Chat.Navigate to Labeling Setup > Custom Template and paste the following XML configuration:<View><View className="root">     <Paragraphs name="dialogue"               value="$prompt"               layout="dialogue"               textKey="content"               nameKey="role"               granularity="sentence"/>  <Header value="Final response:"/>    <TextArea name="response" toName="dialogue"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="dialogue"/></View>from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessage, SystemMessagefrom langchain.callbacks import LabelStudioCallbackHandlerchat_llm = ChatOpenAI(callbacks=[    LabelStudioCallbackHandler(        mode="chat",        project_name="New Project with Chat",    )])llm_results = chat_llm([    SystemMessage(content="Always use a lot of emojis"),    HumanMessage(content="Tell me a joke")])API Reference:ChatOpenAIHumanMessageSystemMessageLabelStudioCallbackHandlerIn Label Studio, open "New Project with Chat". Click on a created task to view dialog history and edit/annotate responses.Custom Labeling Configuration​You can modify the default labeling configuration in LabelStudio to add more target labels like response sentiment, relevance, and many other types annotator's feedback.New labeling configuration can be added from UI: go to Settings > Labeling Interface and set up a custom configuration with additional tags like Choices for sentiment or Rating for relevance. Keep in mind that TextArea tag should be presented in any configuration to display the LLM responses.Alternatively, you can specify the labeling configuration on the initial call before project creation:ls = LabelStudioCallbackHandler(project_config='''<View><Text name="prompt" value="$prompt"/><TextArea name="response" toName="prompt"/><TextArea name="user_feedback" toName="prompt"/><Rating name="rating" toName="prompt"/><Choices name="sentiment" toName="prompt">    <Choice value="Positive"/>    <Choice value="Negative"/></Choices></View>''')Note that if the project doesn't exist, it will be created with the specified labeling configuration.Other parameters​The LabelStudioCallbackHandler accepts several optional parameters:api_key - Label Studio API key. Overrides environmental variable LABEL_STUDIO_API_KEY.url - Label Studio URL. Overrides LABEL_STUDIO_URL, default http://localhost:8080.project_id - Existing Label Studio project ID. Overrides LABEL_STUDIO_PROJECT_ID. Stores data in this project.project_name - Project name if project ID not specified. Creates a new project. Default is "LangChain-%Y-%m-%d" formatted with the current date.project_config - custom labeling configurationmode: use this shortcut to create target configuration from scratch:"prompt" - Single prompt, single response. Default."chat" - Multi-turn chat mode.PreviousInfinoNextLLMonitorInstallation and setupCollecting LLMs prompts and responsesCollecting Chat model DialoguesCustom Labeling ConfigurationOther parameters IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksArgillaConfidentContextInfinoLabel StudioLLMonitorPromptLayerStreamlitChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsCallbacksLabel StudioOn this pageLabel StudioLabel Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback.In this guide, you will learn how to connect a LangChain pipeline to Label Studio to:Aggregate all input prompts, conversations, and responses in a single LabelStudio project. This consolidates all the data in one place for easier labeling and analysis.Refine prompts and responses to create a dataset for supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) scenarios. The labeled data can be used to further train the LLM to improve its performance.Evaluate model responses through human feedback. LabelStudio provides an interface for humans to review and provide feedback on model responses, allowing evaluation and iteration.Installation and setup​First install latest versions of Label Studio and Label Studio API client:pip install -U label-studio label-studio-sdk openaiNext, run label-studio on the command line to start the local LabelStudio instance at http://localhost:8080. See the Label Studio installation guide for more options.You'll need a token to make API calls.Open your LabelStudio instance in your browser, go to Account & Settings > Access Token and copy the key.Set environment variables with your LabelStudio URL, API key and OpenAI API key:import osos.environ['LABEL_STUDIO_URL'] = '<YOUR-LABEL-STUDIO-URL>'  # e.g. http://localhost:8080os.environ['LABEL_STUDIO_API_KEY'] = '<YOUR-LABEL-STUDIO-API-KEY>'os.environ['OPENAI_API_KEY'] = '<YOUR-OPENAI-API-KEY>'Collecting LLMs prompts and responses​The data used for labeling is stored in projects within Label Studio. Every project is identified by an XML configuration that details the specifications for input and output data. Create a project that takes human input in text format and outputs an editable LLM response in a text area:<View><Style>    .prompt-box {        background-color: white;        border-radius: 10px;        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);        padding: 20px;    }</Style><View className="root">    <View className="prompt-box">        <Text name="prompt" value="$prompt"/>    </View>    <TextArea name="response" toName="prompt"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="prompt"/></View>To create a project in Label Studio, click on the "Create" button. Enter a name for your project in the "Project Name" field, such as My Project.Navigate to Labeling Setup > Custom Template and paste the XML configuration provided above.You can collect input LLM prompts and output responses in a LabelStudio project, connecting it via LabelStudioCallbackHandler:from langchain.llms import OpenAIfrom langchain.callbacks import LabelStudioCallbackHandlerllm = OpenAI(    temperature=0,    callbacks=[        LabelStudioCallbackHandler(            project_name="My Project"    )])print(llm("Tell me a joke"))API Reference:OpenAILabelStudioCallbackHandlerIn the Label Studio, open My Project. You will see the prompts, responses, and metadata like the model name. Collecting Chat model Dialogues​You can also track and display full chat dialogues in LabelStudio, with the ability to rate and modify the last response:Open Label Studio and click on the "Create" button.Enter a name for your project in the "Project Name" field, such as New Project with Chat.Navigate to Labeling Setup > Custom Template and paste the following XML configuration:<View><View className="root">     <Paragraphs name="dialogue"               value="$prompt"               layout="dialogue"               textKey="content"               nameKey="role"               granularity="sentence"/>  <Header value="Final response:"/>    <TextArea name="response" toName="dialogue"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="dialogue"/></View>from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessage, SystemMessagefrom langchain.callbacks import LabelStudioCallbackHandlerchat_llm = ChatOpenAI(callbacks=[    LabelStudioCallbackHandler(        mode="chat",        project_name="New Project with Chat",    )])llm_results = chat_llm([    SystemMessage(content="Always use a lot of emojis"),    HumanMessage(content="Tell me a joke")])API Reference:ChatOpenAIHumanMessageSystemMessageLabelStudioCallbackHandlerIn Label Studio, open "New Project with Chat". Click on a created task to view dialog history and edit/annotate responses.Custom Labeling Configuration​You can modify the default labeling configuration in LabelStudio to add more target labels like response sentiment, relevance, and many other types annotator's feedback.New labeling configuration can be added from UI: go to Settings > Labeling Interface and set up a custom configuration with additional tags like Choices for sentiment or Rating for relevance. Keep in mind that TextArea tag should be presented in any configuration to display the LLM responses.Alternatively, you can specify the labeling configuration on the initial call before project creation:ls = LabelStudioCallbackHandler(project_config='''<View><Text name="prompt" value="$prompt"/><TextArea name="response" toName="prompt"/><TextArea name="user_feedback" toName="prompt"/><Rating name="rating" toName="prompt"/><Choices name="sentiment" toName="prompt">    <Choice value="Positive"/>    <Choice value="Negative"/></Choices></View>''')Note that if the project doesn't exist, it will be created with the specified labeling configuration.Other parameters​The LabelStudioCallbackHandler accepts several optional parameters:api_key - Label Studio API key. Overrides environmental variable LABEL_STUDIO_API_KEY.url - Label Studio URL. Overrides LABEL_STUDIO_URL, default http://localhost:8080.project_id - Existing Label Studio project ID. Overrides LABEL_STUDIO_PROJECT_ID. Stores data in this project.project_name - Project name if project ID not specified. Creates a new project. Default is "LangChain-%Y-%m-%d" formatted with the current date.project_config - custom labeling configurationmode: use this shortcut to create target configuration from scratch:"prompt" - Single prompt, single response. Default."chat" - Multi-turn chat mode.PreviousInfinoNextLLMonitorInstallation and setupCollecting LLMs prompts and responsesCollecting Chat model DialoguesCustom Labeling ConfigurationOther parameters IntegrationsCallbacksLabel StudioOn this pageLabel StudioLabel Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback.In this guide, you will learn how to connect a LangChain pipeline to Label Studio to:Aggregate all input prompts, conversations, and responses in a single LabelStudio project. This consolidates all the data in one place for easier labeling and analysis.Refine prompts and responses to create a dataset for supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) scenarios. The labeled data can be used to further train the LLM to improve its performance.Evaluate model responses through human feedback. LabelStudio provides an interface for humans to review and provide feedback on model responses, allowing evaluation and iteration.Installation and setup​First install latest versions of Label Studio and Label Studio API client:pip install -U label-studio label-studio-sdk openaiNext, run label-studio on the command line to start the local LabelStudio instance at http://localhost:8080. See the Label Studio installation guide for more options.You'll need a token to make API calls.Open your LabelStudio instance in your browser, go to Account & Settings > Access Token and copy the key.Set environment variables with your LabelStudio URL, API key and OpenAI API key:import osos.environ['LABEL_STUDIO_URL'] = '<YOUR-LABEL-STUDIO-URL>'  # e.g. http://localhost:8080os.environ['LABEL_STUDIO_API_KEY'] = '<YOUR-LABEL-STUDIO-API-KEY>'os.environ['OPENAI_API_KEY'] = '<YOUR-OPENAI-API-KEY>'Collecting LLMs prompts and responses​The data used for labeling is stored in projects within Label Studio. Every project is identified by an XML configuration that details the specifications for input and output data. Create a project that takes human input in text format and outputs an editable LLM response in a text area:<View><Style>    .prompt-box {        background-color: white;        border-radius: 10px;        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);        padding: 20px;    }</Style><View className="root">    <View className="prompt-box">        <Text name="prompt" value="$prompt"/>    </View>    <TextArea name="response" toName="prompt"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="prompt"/></View>To create a project in Label Studio, click on the "Create" button. Enter a name for your project in the "Project Name" field, such as My Project.Navigate to Labeling Setup > Custom Template and paste the XML configuration provided above.You can collect input LLM prompts and output responses in a LabelStudio project, connecting it via LabelStudioCallbackHandler:from langchain.llms import OpenAIfrom langchain.callbacks import LabelStudioCallbackHandlerllm = OpenAI(    temperature=0,    callbacks=[        LabelStudioCallbackHandler(            project_name="My Project"    )])print(llm("Tell me a joke"))API Reference:OpenAILabelStudioCallbackHandlerIn the Label Studio, open My Project. You will see the prompts, responses, and metadata like the model name. Collecting Chat model Dialogues​You can also track and display full chat dialogues in LabelStudio, with the ability to rate and modify the last response:Open Label Studio and click on the "Create" button.Enter a name for your project in the "Project Name" field, such as New Project with Chat.Navigate to Labeling Setup > Custom Template and paste the following XML configuration:<View><View className="root">     <Paragraphs name="dialogue"               value="$prompt"               layout="dialogue"               textKey="content"               nameKey="role"               granularity="sentence"/>  <Header value="Final response:"/>    <TextArea name="response" toName="dialogue"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="dialogue"/></View>from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessage, SystemMessagefrom langchain.callbacks import LabelStudioCallbackHandlerchat_llm = ChatOpenAI(callbacks=[    LabelStudioCallbackHandler(        mode="chat",        project_name="New Project with Chat",    )])llm_results = chat_llm([    SystemMessage(content="Always use a lot of emojis"),    HumanMessage(content="Tell me a joke")])API Reference:ChatOpenAIHumanMessageSystemMessageLabelStudioCallbackHandlerIn Label Studio, open "New Project with Chat". Click on a created task to view dialog history and edit/annotate responses.Custom Labeling Configuration​You can modify the default labeling configuration in LabelStudio to add more target labels like response sentiment, relevance, and many other types annotator's feedback.New labeling configuration can be added from UI: go to Settings > Labeling Interface and set up a custom configuration with additional tags like Choices for sentiment or Rating for relevance. Keep in mind that TextArea tag should be presented in any configuration to display the LLM responses.Alternatively, you can specify the labeling configuration on the initial call before project creation:ls = LabelStudioCallbackHandler(project_config='''<View><Text name="prompt" value="$prompt"/><TextArea name="response" toName="prompt"/><TextArea name="user_feedback" toName="prompt"/><Rating name="rating" toName="prompt"/><Choices name="sentiment" toName="prompt">    <Choice value="Positive"/>    <Choice value="Negative"/></Choices></View>''')Note that if the project doesn't exist, it will be created with the specified labeling configuration.Other parameters​The LabelStudioCallbackHandler accepts several optional parameters:api_key - Label Studio API key. Overrides environmental variable LABEL_STUDIO_API_KEY.url - Label Studio URL. Overrides LABEL_STUDIO_URL, default http://localhost:8080.project_id - Existing Label Studio project ID. Overrides LABEL_STUDIO_PROJECT_ID. Stores data in this project.project_name - Project name if project ID not specified. Creates a new project. Default is "LangChain-%Y-%m-%d" formatted with the current date.project_config - custom labeling configurationmode: use this shortcut to create target configuration from scratch:"prompt" - Single prompt, single response. Default."chat" - Multi-turn chat mode.PreviousInfinoNextLLMonitorInstallation and setupCollecting LLMs prompts and responsesCollecting Chat model DialoguesCustom Labeling ConfigurationOther parameters IntegrationsCallbacksLabel StudioOn this pageLabel StudioLabel Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback.In this guide, you will learn how to connect a LangChain pipeline to Label Studio to:Aggregate all input prompts, conversations, and responses in a single LabelStudio project. This consolidates all the data in one place for easier labeling and analysis.Refine prompts and responses to create a dataset for supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) scenarios. The labeled data can be used to further train the LLM to improve its performance.Evaluate model responses through human feedback. LabelStudio provides an interface for humans to review and provide feedback on model responses, allowing evaluation and iteration.Installation and setup​First install latest versions of Label Studio and Label Studio API client:pip install -U label-studio label-studio-sdk openaiNext, run label-studio on the command line to start the local LabelStudio instance at http://localhost:8080. See the Label Studio installation guide for more options.You'll need a token to make API calls.Open your LabelStudio instance in your browser, go to Account & Settings > Access Token and copy the key.Set environment variables with your LabelStudio URL, API key and OpenAI API key:import osos.environ['LABEL_STUDIO_URL'] = '<YOUR-LABEL-STUDIO-URL>'  # e.g. http://localhost:8080os.environ['LABEL_STUDIO_API_KEY'] = '<YOUR-LABEL-STUDIO-API-KEY>'os.environ['OPENAI_API_KEY'] = '<YOUR-OPENAI-API-KEY>'Collecting LLMs prompts and responses​The data used for labeling is stored in projects within Label Studio. Every project is identified by an XML configuration that details the specifications for input and output data. Create a project that takes human input in text format and outputs an editable LLM response in a text area:<View><Style>    .prompt-box {        background-color: white;        border-radius: 10px;        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);        padding: 20px;    }</Style><View className="root">    <View className="prompt-box">        <Text name="prompt" value="$prompt"/>    </View>    <TextArea name="response" toName="prompt"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="prompt"/></View>To create a project in Label Studio, click on the "Create" button. Enter a name for your project in the "Project Name" field, such as My Project.Navigate to Labeling Setup > Custom Template and paste the XML configuration provided above.You can collect input LLM prompts and output responses in a LabelStudio project, connecting it via LabelStudioCallbackHandler:from langchain.llms import OpenAIfrom langchain.callbacks import LabelStudioCallbackHandlerllm = OpenAI(    temperature=0,    callbacks=[        LabelStudioCallbackHandler(            project_name="My Project"    )])print(llm("Tell me a joke"))API Reference:OpenAILabelStudioCallbackHandlerIn the Label Studio, open My Project. You will see the prompts, responses, and metadata like the model name. Collecting Chat model Dialogues​You can also track and display full chat dialogues in LabelStudio, with the ability to rate and modify the last response:Open Label Studio and click on the "Create" button.Enter a name for your project in the "Project Name" field, such as New Project with Chat.Navigate to Labeling Setup > Custom Template and paste the following XML configuration:<View><View className="root">     <Paragraphs name="dialogue"               value="$prompt"               layout="dialogue"               textKey="content"               nameKey="role"               granularity="sentence"/>  <Header value="Final response:"/>    <TextArea name="response" toName="dialogue"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="dialogue"/></View>from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessage, SystemMessagefrom langchain.callbacks import LabelStudioCallbackHandlerchat_llm = ChatOpenAI(callbacks=[    LabelStudioCallbackHandler(        mode="chat",        project_name="New Project with Chat",    )])llm_results = chat_llm([    SystemMessage(content="Always use a lot of emojis"),    HumanMessage(content="Tell me a joke")])API Reference:ChatOpenAIHumanMessageSystemMessageLabelStudioCallbackHandlerIn Label Studio, open "New Project with Chat". Click on a created task to view dialog history and edit/annotate responses.Custom Labeling Configuration​You can modify the default labeling configuration in LabelStudio to add more target labels like response sentiment, relevance, and many other types annotator's feedback.New labeling configuration can be added from UI: go to Settings > Labeling Interface and set up a custom configuration with additional tags like Choices for sentiment or Rating for relevance. Keep in mind that TextArea tag should be presented in any configuration to display the LLM responses.Alternatively, you can specify the labeling configuration on the initial call before project creation:ls = LabelStudioCallbackHandler(project_config='''<View><Text name="prompt" value="$prompt"/><TextArea name="response" toName="prompt"/><TextArea name="user_feedback" toName="prompt"/><Rating name="rating" toName="prompt"/><Choices name="sentiment" toName="prompt">    <Choice value="Positive"/>    <Choice value="Negative"/></Choices></View>''')Note that if the project doesn't exist, it will be created with the specified labeling configuration.Other parameters​The LabelStudioCallbackHandler accepts several optional parameters:api_key - Label Studio API key. Overrides environmental variable LABEL_STUDIO_API_KEY.url - Label Studio URL. Overrides LABEL_STUDIO_URL, default http://localhost:8080.project_id - Existing Label Studio project ID. Overrides LABEL_STUDIO_PROJECT_ID. Stores data in this project.project_name - Project name if project ID not specified. Creates a new project. Default is "LangChain-%Y-%m-%d" formatted with the current date.project_config - custom labeling configurationmode: use this shortcut to create target configuration from scratch:"prompt" - Single prompt, single response. Default."chat" - Multi-turn chat mode.PreviousInfinoNextLLMonitor IntegrationsCallbacksLabel StudioOn this pageLabel StudioLabel Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback.In this guide, you will learn how to connect a LangChain pipeline to Label Studio to:Aggregate all input prompts, conversations, and responses in a single LabelStudio project. This consolidates all the data in one place for easier labeling and analysis.Refine prompts and responses to create a dataset for supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) scenarios. The labeled data can be used to further train the LLM to improve its performance.Evaluate model responses through human feedback. LabelStudio provides an interface for humans to review and provide feedback on model responses, allowing evaluation and iteration.Installation and setup​First install latest versions of Label Studio and Label Studio API client:pip install -U label-studio label-studio-sdk openaiNext, run label-studio on the command line to start the local LabelStudio instance at http://localhost:8080. See the Label Studio installation guide for more options.You'll need a token to make API calls.Open your LabelStudio instance in your browser, go to Account & Settings > Access Token and copy the key.Set environment variables with your LabelStudio URL, API key and OpenAI API key:import osos.environ['LABEL_STUDIO_URL'] = '<YOUR-LABEL-STUDIO-URL>'  # e.g. http://localhost:8080os.environ['LABEL_STUDIO_API_KEY'] = '<YOUR-LABEL-STUDIO-API-KEY>'os.environ['OPENAI_API_KEY'] = '<YOUR-OPENAI-API-KEY>'Collecting LLMs prompts and responses​The data used for labeling is stored in projects within Label Studio. Every project is identified by an XML configuration that details the specifications for input and output data. Create a project that takes human input in text format and outputs an editable LLM response in a text area:<View><Style>    .prompt-box {        background-color: white;        border-radius: 10px;        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);        padding: 20px;    }</Style><View className="root">    <View className="prompt-box">        <Text name="prompt" value="$prompt"/>    </View>    <TextArea name="response" toName="prompt"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="prompt"/></View>To create a project in Label Studio, click on the "Create" button. Enter a name for your project in the "Project Name" field, such as My Project.Navigate to Labeling Setup > Custom Template and paste the XML configuration provided above.You can collect input LLM prompts and output responses in a LabelStudio project, connecting it via LabelStudioCallbackHandler:from langchain.llms import OpenAIfrom langchain.callbacks import LabelStudioCallbackHandlerllm = OpenAI(    temperature=0,    callbacks=[        LabelStudioCallbackHandler(            project_name="My Project"    )])print(llm("Tell me a joke"))API Reference:OpenAILabelStudioCallbackHandlerIn the Label Studio, open My Project. You will see the prompts, responses, and metadata like the model name. Collecting Chat model Dialogues​You can also track and display full chat dialogues in LabelStudio, with the ability to rate and modify the last response:Open Label Studio and click on the "Create" button.Enter a name for your project in the "Project Name" field, such as New Project with Chat.Navigate to Labeling Setup > Custom Template and paste the following XML configuration:<View><View className="root">     <Paragraphs name="dialogue"               value="$prompt"               layout="dialogue"               textKey="content"               nameKey="role"               granularity="sentence"/>  <Header value="Final response:"/>    <TextArea name="response" toName="dialogue"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="dialogue"/></View>from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessage, SystemMessagefrom langchain.callbacks import LabelStudioCallbackHandlerchat_llm = ChatOpenAI(callbacks=[    LabelStudioCallbackHandler(        mode="chat",        project_name="New Project with Chat",    )])llm_results = chat_llm([    SystemMessage(content="Always use a lot of emojis"),    HumanMessage(content="Tell me a joke")])API Reference:ChatOpenAIHumanMessageSystemMessageLabelStudioCallbackHandlerIn Label Studio, open "New Project with Chat". Click on a created task to view dialog history and edit/annotate responses.Custom Labeling Configuration​You can modify the default labeling configuration in LabelStudio to add more target labels like response sentiment, relevance, and many other types annotator's feedback.New labeling configuration can be added from UI: go to Settings > Labeling Interface and set up a custom configuration with additional tags like Choices for sentiment or Rating for relevance. Keep in mind that TextArea tag should be presented in any configuration to display the LLM responses.Alternatively, you can specify the labeling configuration on the initial call before project creation:ls = LabelStudioCallbackHandler(project_config='''<View><Text name="prompt" value="$prompt"/><TextArea name="response" toName="prompt"/><TextArea name="user_feedback" toName="prompt"/><Rating name="rating" toName="prompt"/><Choices name="sentiment" toName="prompt">    <Choice value="Positive"/>    <Choice value="Negative"/></Choices></View>''')Note that if the project doesn't exist, it will be created with the specified labeling configuration.Other parameters​The LabelStudioCallbackHandler accepts several optional parameters:api_key - Label Studio API key. Overrides environmental variable LABEL_STUDIO_API_KEY.url - Label Studio URL. Overrides LABEL_STUDIO_URL, default http://localhost:8080.project_id - Existing Label Studio project ID. Overrides LABEL_STUDIO_PROJECT_ID. Stores data in this project.project_name - Project name if project ID not specified. Creates a new project. Default is "LangChain-%Y-%m-%d" formatted with the current date.project_config - custom labeling configurationmode: use this shortcut to create target configuration from scratch:"prompt" - Single prompt, single response. Default."chat" - Multi-turn chat mode.PreviousInfinoNextLLMonitor On this page Label StudioLabel Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback.In this guide, you will learn how to connect a LangChain pipeline to Label Studio to:Aggregate all input prompts, conversations, and responses in a single LabelStudio project. This consolidates all the data in one place for easier labeling and analysis.Refine prompts and responses to create a dataset for supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) scenarios. The labeled data can be used to further train the LLM to improve its performance.Evaluate model responses through human feedback. LabelStudio provides an interface for humans to review and provide feedback on model responses, allowing evaluation and iteration.Installation and setup​First install latest versions of Label Studio and Label Studio API client:pip install -U label-studio label-studio-sdk openaiNext, run label-studio on the command line to start the local LabelStudio instance at http://localhost:8080. See the Label Studio installation guide for more options.You'll need a token to make API calls.Open your LabelStudio instance in your browser, go to Account & Settings > Access Token and copy the key.Set environment variables with your LabelStudio URL, API key and OpenAI API key:import osos.environ['LABEL_STUDIO_URL'] = '<YOUR-LABEL-STUDIO-URL>'  # e.g. http://localhost:8080os.environ['LABEL_STUDIO_API_KEY'] = '<YOUR-LABEL-STUDIO-API-KEY>'os.environ['OPENAI_API_KEY'] = '<YOUR-OPENAI-API-KEY>'Collecting LLMs prompts and responses​The data used for labeling is stored in projects within Label Studio. Every project is identified by an XML configuration that details the specifications for input and output data. Create a project that takes human input in text format and outputs an editable LLM response in a text area:<View><Style>    .prompt-box {        background-color: white;        border-radius: 10px;        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);        padding: 20px;    }</Style><View className="root">    <View className="prompt-box">        <Text name="prompt" value="$prompt"/>    </View>    <TextArea name="response" toName="prompt"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="prompt"/></View>To create a project in Label Studio, click on the "Create" button. Enter a name for your project in the "Project Name" field, such as My Project.Navigate to Labeling Setup > Custom Template and paste the XML configuration provided above.You can collect input LLM prompts and output responses in a LabelStudio project, connecting it via LabelStudioCallbackHandler:from langchain.llms import OpenAIfrom langchain.callbacks import LabelStudioCallbackHandlerllm = OpenAI(    temperature=0,    callbacks=[        LabelStudioCallbackHandler(            project_name="My Project"    )])print(llm("Tell me a joke"))API Reference:OpenAILabelStudioCallbackHandlerIn the Label Studio, open My Project. You will see the prompts, responses, and metadata like the model name. Collecting Chat model Dialogues​You can also track and display full chat dialogues in LabelStudio, with the ability to rate and modify the last response:Open Label Studio and click on the "Create" button.Enter a name for your project in the "Project Name" field, such as New Project with Chat.Navigate to Labeling Setup > Custom Template and paste the following XML configuration:<View><View className="root">     <Paragraphs name="dialogue"               value="$prompt"               layout="dialogue"               textKey="content"               nameKey="role"               granularity="sentence"/>  <Header value="Final response:"/>    <TextArea name="response" toName="dialogue"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="dialogue"/></View>from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessage, SystemMessagefrom langchain.callbacks import LabelStudioCallbackHandlerchat_llm = ChatOpenAI(callbacks=[    LabelStudioCallbackHandler(        mode="chat",        project_name="New Project with Chat",    )])llm_results = chat_llm([    SystemMessage(content="Always use a lot of emojis"),    HumanMessage(content="Tell me a joke")])API Reference:ChatOpenAIHumanMessageSystemMessageLabelStudioCallbackHandlerIn Label Studio, open "New Project with Chat". Click on a created task to view dialog history and edit/annotate responses.Custom Labeling Configuration​You can modify the default labeling configuration in LabelStudio to add more target labels like response sentiment, relevance, and many other types annotator's feedback.New labeling configuration can be added from UI: go to Settings > Labeling Interface and set up a custom configuration with additional tags like Choices for sentiment or Rating for relevance. Keep in mind that TextArea tag should be presented in any configuration to display the LLM responses.Alternatively, you can specify the labeling configuration on the initial call before project creation:ls = LabelStudioCallbackHandler(project_config='''<View><Text name="prompt" value="$prompt"/><TextArea name="response" toName="prompt"/><TextArea name="user_feedback" toName="prompt"/><Rating name="rating" toName="prompt"/><Choices name="sentiment" toName="prompt">    <Choice value="Positive"/>    <Choice value="Negative"/></Choices></View>''')Note that if the project doesn't exist, it will be created with the specified labeling configuration.Other parameters​The LabelStudioCallbackHandler accepts several optional parameters:api_key - Label Studio API key. Overrides environmental variable LABEL_STUDIO_API_KEY.url - Label Studio URL. Overrides LABEL_STUDIO_URL, default http://localhost:8080.project_id - Existing Label Studio project ID. Overrides LABEL_STUDIO_PROJECT_ID. Stores data in this project.project_name - Project name if project ID not specified. Creates a new project. Default is "LangChain-%Y-%m-%d" formatted with the current date.project_config - custom labeling configurationmode: use this shortcut to create target configuration from scratch:"prompt" - Single prompt, single response. Default."chat" - Multi-turn chat mode.  pip install -U label-studio label-studio-sdk openai pip install -U label-studio label-studio-sdk openai  import osos.environ['LABEL_STUDIO_URL'] = '<YOUR-LABEL-STUDIO-URL>'  # e.g. http://localhost:8080os.environ['LABEL_STUDIO_API_KEY'] = '<YOUR-LABEL-STUDIO-API-KEY>'os.environ['OPENAI_API_KEY'] = '<YOUR-OPENAI-API-KEY>' import osos.environ['LABEL_STUDIO_URL'] = '<YOUR-LABEL-STUDIO-URL>'  # e.g. http://localhost:8080os.environ['LABEL_STUDIO_API_KEY'] = '<YOUR-LABEL-STUDIO-API-KEY>'os.environ['OPENAI_API_KEY'] = '<YOUR-OPENAI-API-KEY>'  <View><Style>    .prompt-box {        background-color: white;        border-radius: 10px;        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);        padding: 20px;    }</Style><View className="root">    <View className="prompt-box">        <Text name="prompt" value="$prompt"/>    </View>    <TextArea name="response" toName="prompt"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="prompt"/></View> <View><Style>    .prompt-box {        background-color: white;        border-radius: 10px;        box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);        padding: 20px;    }</Style><View className="root">    <View className="prompt-box">        <Text name="prompt" value="$prompt"/>    </View>    <TextArea name="response" toName="prompt"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="prompt"/></View>  from langchain.llms import OpenAIfrom langchain.callbacks import LabelStudioCallbackHandlerllm = OpenAI(    temperature=0,    callbacks=[        LabelStudioCallbackHandler(            project_name="My Project"    )])print(llm("Tell me a joke")) from langchain.llms import OpenAIfrom langchain.callbacks import LabelStudioCallbackHandlerllm = OpenAI(    temperature=0,    callbacks=[        LabelStudioCallbackHandler(            project_name="My Project"    )])print(llm("Tell me a joke"))  API Reference:OpenAILabelStudioCallbackHandler <View><View className="root">     <Paragraphs name="dialogue"               value="$prompt"               layout="dialogue"               textKey="content"               nameKey="role"               granularity="sentence"/>  <Header value="Final response:"/>    <TextArea name="response" toName="dialogue"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="dialogue"/></View> <View><View className="root">     <Paragraphs name="dialogue"               value="$prompt"               layout="dialogue"               textKey="content"               nameKey="role"               granularity="sentence"/>  <Header value="Final response:"/>    <TextArea name="response" toName="dialogue"              maxSubmissions="1" editable="true"              required="true"/></View><Header value="Rate the response:"/><Rating name="rating" toName="dialogue"/></View>  from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessage, SystemMessagefrom langchain.callbacks import LabelStudioCallbackHandlerchat_llm = ChatOpenAI(callbacks=[    LabelStudioCallbackHandler(        mode="chat",        project_name="New Project with Chat",    )])llm_results = chat_llm([    SystemMessage(content="Always use a lot of emojis"),    HumanMessage(content="Tell me a joke")]) from langchain.chat_models import ChatOpenAIfrom langchain.schema import HumanMessage, SystemMessagefrom langchain.callbacks import LabelStudioCallbackHandlerchat_llm = ChatOpenAI(callbacks=[    LabelStudioCallbackHandler(        mode="chat",        project_name="New Project with Chat",    )])llm_results = chat_llm([    SystemMessage(content="Always use a lot of emojis"),    HumanMessage(content="Tell me a joke")])  API Reference:ChatOpenAIHumanMessageSystemMessageLabelStudioCallbackHandler ls = LabelStudioCallbackHandler(project_config='''<View><Text name="prompt" value="$prompt"/><TextArea name="response" toName="prompt"/><TextArea name="user_feedback" toName="prompt"/><Rating name="rating" toName="prompt"/><Choices name="sentiment" toName="prompt">    <Choice value="Positive"/>    <Choice value="Negative"/></Choices></View>''') ls = LabelStudioCallbackHandler(project_config='''<View><Text name="prompt" value="$prompt"/><TextArea name="response" toName="prompt"/><TextArea name="user_feedback" toName="prompt"/><Rating name="rating" toName="prompt"/><Choices name="sentiment" toName="prompt">    <Choice value="Positive"/>    <Choice value="Negative"/></Choices></View>''')  Previous Infino Next LLMonitor Installation and setupCollecting LLMs prompts and responsesCollecting Chat model DialoguesCustom Labeling ConfigurationOther parameters Installation and setupCollecting LLMs prompts and responsesCollecting Chat model DialoguesCustom Labeling ConfigurationOther parameters CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright © 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright © 2023 LangChain, Inc. Copyright © 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) 🦜️🔗 LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Argilla (/docs/integrations/callbacks/argilla) Confident (/docs/integrations/callbacks/confident) Context (/docs/integrations/callbacks/context) Infino (/docs/integrations/callbacks/infino) Label Studio (/docs/integrations/callbacks/labelstudio) LLMonitor (/docs/integrations/callbacks/llmonitor) PromptLayer (/docs/integrations/callbacks/promptlayer) Streamlit (/docs/integrations/callbacks/streamlit) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) ​ (#installation-and-setup) Label Studio installation guide (https://labelstud.io/guide/install) ​ (#collecting-llms-prompts-and-responses) OpenAI (https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html) LabelStudioCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.labelstudio_callback.LabelStudioCallbackHandler.html) ​ (#collecting-chat-model-dialogues) ChatOpenAI (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html) HumanMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.HumanMessage.html) SystemMessage (https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.SystemMessage.html) LabelStudioCallbackHandler (https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.labelstudio_callback.LabelStudioCallbackHandler.html) ​ (#custom-labeling-configuration) other types annotator's feedback (https://labelstud.io/tags/) TextArea tag (https://labelstud.io/tags/textarea) ​ (#other-parameters) custom labeling configuration (#custom-labeling-configuration) PreviousInfino (/docs/integrations/callbacks/infino) NextLLMonitor (/docs/integrations/callbacks/llmonitor) Installation and setup (#installation-and-setup) Collecting LLMs prompts and responses (#collecting-llms-prompts-and-responses) Collecting Chat model Dialogues (#collecting-chat-model-dialogues) Custom Labeling Configuration (#custom-labeling-configuration) Other parameters (#other-parameters) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)