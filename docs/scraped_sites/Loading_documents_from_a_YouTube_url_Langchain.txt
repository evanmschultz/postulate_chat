Building chat or QA applications on YouTube videos is a topic of high interest. Below we show how to easily go from a YouTube url to text to chat! We wil use the OpenAIWhisperParser, which will use the OpenAI Whisper API to transcribe audio to text, and the  OpenAIWhisperParserLocal for local support and running on private clouds or on premise. Note: You will need to have an OPENAI_API_KEY supplied. We will use yt_dlp to download audio for YouTube urls. We will use pydub to split downloaded audio files (such that we adhere to Whisper API's 25MB file size limit). Use YoutubeAudioLoader to fetch / download the audio files. Then, ues OpenAIWhisperParser() to transcribe them to text. Let's take the first lecture of Andrej Karpathy's YouTube course as an example!  Given Documents, we can easily enable chat / question+answering. IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Callbacks Chat models Chat loaders Document loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcripts Etherscan Loader acreom Airbyte CDK Airbyte Gong Airbyte Hubspot Airbyte JSON Airbyte Salesforce Airbyte Shopify Airbyte Stripe Airbyte Typeform Airbyte Zendesk Support Airtable Alibaba Cloud MaxCompute Apify Dataset ArcGIS Arxiv AssemblyAI Audio Transcripts Async Chromium AsyncHtmlLoader AWS S3 Directory AWS S3 File AZLyrics Azure Blob Storage Container Azure Blob Storage File Azure Document Intelligence BibTeX BiliBili Blackboard Blockchain Brave Search Browserless ChatGPT Data College Confidential Concurrent Loader Confluence CoNLL-U Copy Paste CSV Cube Semantic Layer Datadog Logs Diffbot Discord Docugami Dropbox DuckDB Email Embaas EPub EverNote example_data Microsoft Excel Facebook Chat Fauna Figma Geopandas Git GitBook GitHub Google BigQuery Google Cloud Storage Directory Google Cloud Storage File Google Drive Grobid Gutenberg Hacker News Huawei OBS Directory Huawei OBS File HuggingFace dataset iFixit Images Image captions IMSDb Iugu Joplin Jupyter Notebook LarkSuite (FeiShu) Mastodon MediaWikiDump MergeDocLoader mhtml Microsoft OneDrive Microsoft PowerPoint Microsoft SharePoint Microsoft Word Modern Treasury News URL Notion DB 1/2 Notion DB 2/2 Nuclia Understanding API document loader Obsidian Open Document Format (ODT) Open City Data Org-mode Pandas DataFrame Amazon Textract Polars DataFrame Psychic PubMed PySpark DataFrame Loader ReadTheDocs Documentation Recursive URL Loader Reddit Roam Rockset RSS Feeds RST Sitemap Slack Snowflake Source Code Spreedly Stripe Subtitle Telegram Tencent COS Directory Tencent COS File TensorFlow Datasets 2Markdown TOML Trello TSV Twitter Unstructured File URL Weather WebBaseLoader WhatsApp Chat Wikipedia XML Xorbits Pandas DataFrame Loading documents from a YouTube url YouTube transcripts Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations Document loaders Loading documents from a YouTube url GenericLoader OpenAIWhisperParser YoutubeAudioLoader RetrievalQA FAISS ChatOpenAI OpenAIEmbeddings RecursiveCharacterTextSplitter YouTube url to text Building a chat app from YouTube video Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsDocument loadersLoading documents from a YouTube urlOn this pageLoading documents from a YouTube urlBuilding chat or QA applications on YouTube videos is a topic of high interest.Below we show how to easily go from a YouTube url to text to chat!We wil use the OpenAIWhisperParser, which will use the OpenAI Whisper API to transcribe audio to text, and the  OpenAIWhisperParserLocal for local support and running on private clouds or on premise.Note: You will need to have an OPENAI_API_KEY supplied.from langchain.document_loaders.generic import GenericLoaderfrom langchain.document_loaders.parsers import OpenAIWhisperParser, OpenAIWhisperParserLocalfrom langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoaderAPI Reference:GenericLoaderOpenAIWhisperParserYoutubeAudioLoaderWe will use yt_dlp to download audio for YouTube urls.We will use pydub to split downloaded audio files (such that we adhere to Whisper API's 25MB file size limit).pip install yt_dlp pip install pydub pip install librosaYouTube url to text‚ÄãUse YoutubeAudioLoader to fetch / download the audio files.Then, ues OpenAIWhisperParser() to transcribe them to text.Let's take the first lecture of Andrej Karpathy's YouTube course as an example! # set a flag to switch between local and remote parsing# change this to True if you want to use local parsinglocal = False# Two Karpathy lecture videosurls = ["https://youtu.be/kCc8FmEb1nY", "https://youtu.be/VMj-3S1tku0"]# Directory to save audio filessave_dir = "~/Downloads/YouTube"# Transcribe the videos to textif local:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParserLocal())else:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser())docs = loader.load()    [youtube] Extracting URL: https://youtu.be/kCc8FmEb1nY    [youtube] kCc8FmEb1nY: Downloading webpage    [youtube] kCc8FmEb1nY: Downloading android player API JSON    [info] kCc8FmEb1nY: Downloading 1 format(s): 140    [dashsegments] Total fragments: 11    [download] Destination: /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a    [download] 100% of  107.73MiB in 00:00:18 at 5.92MiB/s                       [FixupM4a] Correcting container of "/Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a"    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a; file is already in target format m4a    [youtube] Extracting URL: https://youtu.be/VMj-3S1tku0    [youtube] VMj-3S1tku0: Downloading webpage    [youtube] VMj-3S1tku0: Downloading android player API JSON    [info] VMj-3S1tku0: Downloading 1 format(s): 140    [download] /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a has already been downloaded    [download] 100% of  134.98MiB    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a; file is already in target format m4a# Returns a list of Documents, which can be easily viewed or parseddocs[0].page_content[0:500]    "Hello, my name is Andrej and I've been training deep neural networks for a bit more than a decade. And in this lecture I'd like to show you what neural network training looks like under the hood. So in particular we are going to start with a blank Jupyter notebook and by the end of this lecture we will define and train a neural net and you'll get to see everything that goes on under the hood and exactly sort of how that works on an intuitive level. Now specifically what I would like to do is I w"Building a chat app from YouTube video‚ÄãGiven Documents, we can easily enable chat / question+answering.from langchain.chains import RetrievalQAfrom langchain.vectorstores import FAISSfrom langchain.chat_models import ChatOpenAIfrom langchain.embeddings import OpenAIEmbeddingsfrom langchain.text_splitter import RecursiveCharacterTextSplitterAPI Reference:RetrievalQAFAISSChatOpenAIOpenAIEmbeddingsRecursiveCharacterTextSplitter# Combine doccombined_docs = [doc.page_content for doc in docs]text = " ".join(combined_docs)# Split themtext_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)splits = text_splitter.split_text(text)# Build an indexembeddings = OpenAIEmbeddings()vectordb = FAISS.from_texts(splits, embeddings)# Build a QA chainqa_chain = RetrievalQA.from_chain_type(    llm=ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0),    chain_type="stuff",    retriever=vectordb.as_retriever(),)# Ask a question!query = "Why do we need to zero out the gradient before backprop at each step?"qa_chain.run(query)    "We need to zero out the gradient before backprop at each step because the backward pass accumulates gradients in the grad attribute of each parameter. If we don't reset the grad to zero before each backward pass, the gradients will accumulate and add up, leading to incorrect updates and slower convergence. By resetting the grad to zero before each backward pass, we ensure that the gradients are calculated correctly and that the optimization process works as intended."query = "What is the difference between an encoder and decoder?"qa_chain.run(query)    'In the context of transformers, an encoder is a component that reads in a sequence of input tokens and generates a sequence of hidden representations. On the other hand, a decoder is a component that takes in a sequence of hidden representations and generates a sequence of output tokens. The main difference between the two is that the encoder is used to encode the input sequence into a fixed-length representation, while the decoder is used to decode the fixed-length representation into an output sequence. In machine translation, for example, the encoder reads in the source language sentence and generates a fixed-length representation, which is then used by the decoder to generate the target language sentence.'query = "For any token, what are x, k, v, and q?"qa_chain.run(query)    'For any token, x is the input vector that contains the private information of that token, k and q are the key and query vectors respectively, which are produced by forwarding linear modules on x, and v is the vector that is calculated by propagating the same linear module on x again. The key vector represents what the token contains, and the query vector represents what the token is looking for. The vector v is the information that the token will communicate to other tokens if it finds them interesting, and it gets aggregated for the purposes of the self-attention mechanism.'PreviousXorbits Pandas DataFrameNextYouTube transcriptsYouTube url to textBuilding a chat app from YouTube videoCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsDocument loadersLoading documents from a YouTube urlOn this pageLoading documents from a YouTube urlBuilding chat or QA applications on YouTube videos is a topic of high interest.Below we show how to easily go from a YouTube url to text to chat!We wil use the OpenAIWhisperParser, which will use the OpenAI Whisper API to transcribe audio to text, and the  OpenAIWhisperParserLocal for local support and running on private clouds or on premise.Note: You will need to have an OPENAI_API_KEY supplied.from langchain.document_loaders.generic import GenericLoaderfrom langchain.document_loaders.parsers import OpenAIWhisperParser, OpenAIWhisperParserLocalfrom langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoaderAPI Reference:GenericLoaderOpenAIWhisperParserYoutubeAudioLoaderWe will use yt_dlp to download audio for YouTube urls.We will use pydub to split downloaded audio files (such that we adhere to Whisper API's 25MB file size limit).pip install yt_dlp pip install pydub pip install librosaYouTube url to text‚ÄãUse YoutubeAudioLoader to fetch / download the audio files.Then, ues OpenAIWhisperParser() to transcribe them to text.Let's take the first lecture of Andrej Karpathy's YouTube course as an example! # set a flag to switch between local and remote parsing# change this to True if you want to use local parsinglocal = False# Two Karpathy lecture videosurls = ["https://youtu.be/kCc8FmEb1nY", "https://youtu.be/VMj-3S1tku0"]# Directory to save audio filessave_dir = "~/Downloads/YouTube"# Transcribe the videos to textif local:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParserLocal())else:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser())docs = loader.load()    [youtube] Extracting URL: https://youtu.be/kCc8FmEb1nY    [youtube] kCc8FmEb1nY: Downloading webpage    [youtube] kCc8FmEb1nY: Downloading android player API JSON    [info] kCc8FmEb1nY: Downloading 1 format(s): 140    [dashsegments] Total fragments: 11    [download] Destination: /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a    [download] 100% of  107.73MiB in 00:00:18 at 5.92MiB/s                       [FixupM4a] Correcting container of "/Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a"    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a; file is already in target format m4a    [youtube] Extracting URL: https://youtu.be/VMj-3S1tku0    [youtube] VMj-3S1tku0: Downloading webpage    [youtube] VMj-3S1tku0: Downloading android player API JSON    [info] VMj-3S1tku0: Downloading 1 format(s): 140    [download] /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a has already been downloaded    [download] 100% of  134.98MiB    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a; file is already in target format m4a# Returns a list of Documents, which can be easily viewed or parseddocs[0].page_content[0:500]    "Hello, my name is Andrej and I've been training deep neural networks for a bit more than a decade. And in this lecture I'd like to show you what neural network training looks like under the hood. So in particular we are going to start with a blank Jupyter notebook and by the end of this lecture we will define and train a neural net and you'll get to see everything that goes on under the hood and exactly sort of how that works on an intuitive level. Now specifically what I would like to do is I w"Building a chat app from YouTube video‚ÄãGiven Documents, we can easily enable chat / question+answering.from langchain.chains import RetrievalQAfrom langchain.vectorstores import FAISSfrom langchain.chat_models import ChatOpenAIfrom langchain.embeddings import OpenAIEmbeddingsfrom langchain.text_splitter import RecursiveCharacterTextSplitterAPI Reference:RetrievalQAFAISSChatOpenAIOpenAIEmbeddingsRecursiveCharacterTextSplitter# Combine doccombined_docs = [doc.page_content for doc in docs]text = " ".join(combined_docs)# Split themtext_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)splits = text_splitter.split_text(text)# Build an indexembeddings = OpenAIEmbeddings()vectordb = FAISS.from_texts(splits, embeddings)# Build a QA chainqa_chain = RetrievalQA.from_chain_type(    llm=ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0),    chain_type="stuff",    retriever=vectordb.as_retriever(),)# Ask a question!query = "Why do we need to zero out the gradient before backprop at each step?"qa_chain.run(query)    "We need to zero out the gradient before backprop at each step because the backward pass accumulates gradients in the grad attribute of each parameter. If we don't reset the grad to zero before each backward pass, the gradients will accumulate and add up, leading to incorrect updates and slower convergence. By resetting the grad to zero before each backward pass, we ensure that the gradients are calculated correctly and that the optimization process works as intended."query = "What is the difference between an encoder and decoder?"qa_chain.run(query)    'In the context of transformers, an encoder is a component that reads in a sequence of input tokens and generates a sequence of hidden representations. On the other hand, a decoder is a component that takes in a sequence of hidden representations and generates a sequence of output tokens. The main difference between the two is that the encoder is used to encode the input sequence into a fixed-length representation, while the decoder is used to decode the fixed-length representation into an output sequence. In machine translation, for example, the encoder reads in the source language sentence and generates a fixed-length representation, which is then used by the decoder to generate the target language sentence.'query = "For any token, what are x, k, v, and q?"qa_chain.run(query)    'For any token, x is the input vector that contains the private information of that token, k and q are the key and query vectors respectively, which are produced by forwarding linear modules on x, and v is the vector that is calculated by propagating the same linear module on x again. The key vector represents what the token contains, and the query vector represents what the token is looking for. The vector v is the information that the token will communicate to other tokens if it finds them interesting, and it gets aggregated for the purposes of the self-attention mechanism.'PreviousXorbits Pandas DataFrameNextYouTube transcriptsYouTube url to textBuilding a chat app from YouTube video IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsDocument loadersLoading documents from a YouTube urlOn this pageLoading documents from a YouTube urlBuilding chat or QA applications on YouTube videos is a topic of high interest.Below we show how to easily go from a YouTube url to text to chat!We wil use the OpenAIWhisperParser, which will use the OpenAI Whisper API to transcribe audio to text, and the  OpenAIWhisperParserLocal for local support and running on private clouds or on premise.Note: You will need to have an OPENAI_API_KEY supplied.from langchain.document_loaders.generic import GenericLoaderfrom langchain.document_loaders.parsers import OpenAIWhisperParser, OpenAIWhisperParserLocalfrom langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoaderAPI Reference:GenericLoaderOpenAIWhisperParserYoutubeAudioLoaderWe will use yt_dlp to download audio for YouTube urls.We will use pydub to split downloaded audio files (such that we adhere to Whisper API's 25MB file size limit).pip install yt_dlp pip install pydub pip install librosaYouTube url to text‚ÄãUse YoutubeAudioLoader to fetch / download the audio files.Then, ues OpenAIWhisperParser() to transcribe them to text.Let's take the first lecture of Andrej Karpathy's YouTube course as an example! # set a flag to switch between local and remote parsing# change this to True if you want to use local parsinglocal = False# Two Karpathy lecture videosurls = ["https://youtu.be/kCc8FmEb1nY", "https://youtu.be/VMj-3S1tku0"]# Directory to save audio filessave_dir = "~/Downloads/YouTube"# Transcribe the videos to textif local:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParserLocal())else:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser())docs = loader.load()    [youtube] Extracting URL: https://youtu.be/kCc8FmEb1nY    [youtube] kCc8FmEb1nY: Downloading webpage    [youtube] kCc8FmEb1nY: Downloading android player API JSON    [info] kCc8FmEb1nY: Downloading 1 format(s): 140    [dashsegments] Total fragments: 11    [download] Destination: /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a    [download] 100% of  107.73MiB in 00:00:18 at 5.92MiB/s                       [FixupM4a] Correcting container of "/Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a"    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a; file is already in target format m4a    [youtube] Extracting URL: https://youtu.be/VMj-3S1tku0    [youtube] VMj-3S1tku0: Downloading webpage    [youtube] VMj-3S1tku0: Downloading android player API JSON    [info] VMj-3S1tku0: Downloading 1 format(s): 140    [download] /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a has already been downloaded    [download] 100% of  134.98MiB    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a; file is already in target format m4a# Returns a list of Documents, which can be easily viewed or parseddocs[0].page_content[0:500]    "Hello, my name is Andrej and I've been training deep neural networks for a bit more than a decade. And in this lecture I'd like to show you what neural network training looks like under the hood. So in particular we are going to start with a blank Jupyter notebook and by the end of this lecture we will define and train a neural net and you'll get to see everything that goes on under the hood and exactly sort of how that works on an intuitive level. Now specifically what I would like to do is I w"Building a chat app from YouTube video‚ÄãGiven Documents, we can easily enable chat / question+answering.from langchain.chains import RetrievalQAfrom langchain.vectorstores import FAISSfrom langchain.chat_models import ChatOpenAIfrom langchain.embeddings import OpenAIEmbeddingsfrom langchain.text_splitter import RecursiveCharacterTextSplitterAPI Reference:RetrievalQAFAISSChatOpenAIOpenAIEmbeddingsRecursiveCharacterTextSplitter# Combine doccombined_docs = [doc.page_content for doc in docs]text = " ".join(combined_docs)# Split themtext_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)splits = text_splitter.split_text(text)# Build an indexembeddings = OpenAIEmbeddings()vectordb = FAISS.from_texts(splits, embeddings)# Build a QA chainqa_chain = RetrievalQA.from_chain_type(    llm=ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0),    chain_type="stuff",    retriever=vectordb.as_retriever(),)# Ask a question!query = "Why do we need to zero out the gradient before backprop at each step?"qa_chain.run(query)    "We need to zero out the gradient before backprop at each step because the backward pass accumulates gradients in the grad attribute of each parameter. If we don't reset the grad to zero before each backward pass, the gradients will accumulate and add up, leading to incorrect updates and slower convergence. By resetting the grad to zero before each backward pass, we ensure that the gradients are calculated correctly and that the optimization process works as intended."query = "What is the difference between an encoder and decoder?"qa_chain.run(query)    'In the context of transformers, an encoder is a component that reads in a sequence of input tokens and generates a sequence of hidden representations. On the other hand, a decoder is a component that takes in a sequence of hidden representations and generates a sequence of output tokens. The main difference between the two is that the encoder is used to encode the input sequence into a fixed-length representation, while the decoder is used to decode the fixed-length representation into an output sequence. In machine translation, for example, the encoder reads in the source language sentence and generates a fixed-length representation, which is then used by the decoder to generate the target language sentence.'query = "For any token, what are x, k, v, and q?"qa_chain.run(query)    'For any token, x is the input vector that contains the private information of that token, k and q are the key and query vectors respectively, which are produced by forwarding linear modules on x, and v is the vector that is calculated by propagating the same linear module on x again. The key vector represents what the token contains, and the query vector represents what the token is looking for. The vector v is the information that the token will communicate to other tokens if it finds them interesting, and it gets aggregated for the purposes of the self-attention mechanism.'PreviousXorbits Pandas DataFrameNextYouTube transcriptsYouTube url to textBuilding a chat app from YouTube video IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersEtherscan LoaderacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlLoaderAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryNews URLNotion DB 1/2Notion DB 2/2Nuclia Understanding API document loaderObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRocksetRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders example_data Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsDocument loadersLoading documents from a YouTube urlOn this pageLoading documents from a YouTube urlBuilding chat or QA applications on YouTube videos is a topic of high interest.Below we show how to easily go from a YouTube url to text to chat!We wil use the OpenAIWhisperParser, which will use the OpenAI Whisper API to transcribe audio to text, and the  OpenAIWhisperParserLocal for local support and running on private clouds or on premise.Note: You will need to have an OPENAI_API_KEY supplied.from langchain.document_loaders.generic import GenericLoaderfrom langchain.document_loaders.parsers import OpenAIWhisperParser, OpenAIWhisperParserLocalfrom langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoaderAPI Reference:GenericLoaderOpenAIWhisperParserYoutubeAudioLoaderWe will use yt_dlp to download audio for YouTube urls.We will use pydub to split downloaded audio files (such that we adhere to Whisper API's 25MB file size limit).pip install yt_dlp pip install pydub pip install librosaYouTube url to text‚ÄãUse YoutubeAudioLoader to fetch / download the audio files.Then, ues OpenAIWhisperParser() to transcribe them to text.Let's take the first lecture of Andrej Karpathy's YouTube course as an example! # set a flag to switch between local and remote parsing# change this to True if you want to use local parsinglocal = False# Two Karpathy lecture videosurls = ["https://youtu.be/kCc8FmEb1nY", "https://youtu.be/VMj-3S1tku0"]# Directory to save audio filessave_dir = "~/Downloads/YouTube"# Transcribe the videos to textif local:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParserLocal())else:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser())docs = loader.load()    [youtube] Extracting URL: https://youtu.be/kCc8FmEb1nY    [youtube] kCc8FmEb1nY: Downloading webpage    [youtube] kCc8FmEb1nY: Downloading android player API JSON    [info] kCc8FmEb1nY: Downloading 1 format(s): 140    [dashsegments] Total fragments: 11    [download] Destination: /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a    [download] 100% of  107.73MiB in 00:00:18 at 5.92MiB/s                       [FixupM4a] Correcting container of "/Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a"    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a; file is already in target format m4a    [youtube] Extracting URL: https://youtu.be/VMj-3S1tku0    [youtube] VMj-3S1tku0: Downloading webpage    [youtube] VMj-3S1tku0: Downloading android player API JSON    [info] VMj-3S1tku0: Downloading 1 format(s): 140    [download] /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a has already been downloaded    [download] 100% of  134.98MiB    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a; file is already in target format m4a# Returns a list of Documents, which can be easily viewed or parseddocs[0].page_content[0:500]    "Hello, my name is Andrej and I've been training deep neural networks for a bit more than a decade. And in this lecture I'd like to show you what neural network training looks like under the hood. So in particular we are going to start with a blank Jupyter notebook and by the end of this lecture we will define and train a neural net and you'll get to see everything that goes on under the hood and exactly sort of how that works on an intuitive level. Now specifically what I would like to do is I w"Building a chat app from YouTube video‚ÄãGiven Documents, we can easily enable chat / question+answering.from langchain.chains import RetrievalQAfrom langchain.vectorstores import FAISSfrom langchain.chat_models import ChatOpenAIfrom langchain.embeddings import OpenAIEmbeddingsfrom langchain.text_splitter import RecursiveCharacterTextSplitterAPI Reference:RetrievalQAFAISSChatOpenAIOpenAIEmbeddingsRecursiveCharacterTextSplitter# Combine doccombined_docs = [doc.page_content for doc in docs]text = " ".join(combined_docs)# Split themtext_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)splits = text_splitter.split_text(text)# Build an indexembeddings = OpenAIEmbeddings()vectordb = FAISS.from_texts(splits, embeddings)# Build a QA chainqa_chain = RetrievalQA.from_chain_type(    llm=ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0),    chain_type="stuff",    retriever=vectordb.as_retriever(),)# Ask a question!query = "Why do we need to zero out the gradient before backprop at each step?"qa_chain.run(query)    "We need to zero out the gradient before backprop at each step because the backward pass accumulates gradients in the grad attribute of each parameter. If we don't reset the grad to zero before each backward pass, the gradients will accumulate and add up, leading to incorrect updates and slower convergence. By resetting the grad to zero before each backward pass, we ensure that the gradients are calculated correctly and that the optimization process works as intended."query = "What is the difference between an encoder and decoder?"qa_chain.run(query)    'In the context of transformers, an encoder is a component that reads in a sequence of input tokens and generates a sequence of hidden representations. On the other hand, a decoder is a component that takes in a sequence of hidden representations and generates a sequence of output tokens. The main difference between the two is that the encoder is used to encode the input sequence into a fixed-length representation, while the decoder is used to decode the fixed-length representation into an output sequence. In machine translation, for example, the encoder reads in the source language sentence and generates a fixed-length representation, which is then used by the decoder to generate the target language sentence.'query = "For any token, what are x, k, v, and q?"qa_chain.run(query)    'For any token, x is the input vector that contains the private information of that token, k and q are the key and query vectors respectively, which are produced by forwarding linear modules on x, and v is the vector that is calculated by propagating the same linear module on x again. The key vector represents what the token contains, and the query vector represents what the token is looking for. The vector v is the information that the token will communicate to other tokens if it finds them interesting, and it gets aggregated for the purposes of the self-attention mechanism.'PreviousXorbits Pandas DataFrameNextYouTube transcriptsYouTube url to textBuilding a chat app from YouTube video IntegrationsDocument loadersLoading documents from a YouTube urlOn this pageLoading documents from a YouTube urlBuilding chat or QA applications on YouTube videos is a topic of high interest.Below we show how to easily go from a YouTube url to text to chat!We wil use the OpenAIWhisperParser, which will use the OpenAI Whisper API to transcribe audio to text, and the  OpenAIWhisperParserLocal for local support and running on private clouds or on premise.Note: You will need to have an OPENAI_API_KEY supplied.from langchain.document_loaders.generic import GenericLoaderfrom langchain.document_loaders.parsers import OpenAIWhisperParser, OpenAIWhisperParserLocalfrom langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoaderAPI Reference:GenericLoaderOpenAIWhisperParserYoutubeAudioLoaderWe will use yt_dlp to download audio for YouTube urls.We will use pydub to split downloaded audio files (such that we adhere to Whisper API's 25MB file size limit).pip install yt_dlp pip install pydub pip install librosaYouTube url to text‚ÄãUse YoutubeAudioLoader to fetch / download the audio files.Then, ues OpenAIWhisperParser() to transcribe them to text.Let's take the first lecture of Andrej Karpathy's YouTube course as an example! # set a flag to switch between local and remote parsing# change this to True if you want to use local parsinglocal = False# Two Karpathy lecture videosurls = ["https://youtu.be/kCc8FmEb1nY", "https://youtu.be/VMj-3S1tku0"]# Directory to save audio filessave_dir = "~/Downloads/YouTube"# Transcribe the videos to textif local:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParserLocal())else:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser())docs = loader.load()    [youtube] Extracting URL: https://youtu.be/kCc8FmEb1nY    [youtube] kCc8FmEb1nY: Downloading webpage    [youtube] kCc8FmEb1nY: Downloading android player API JSON    [info] kCc8FmEb1nY: Downloading 1 format(s): 140    [dashsegments] Total fragments: 11    [download] Destination: /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a    [download] 100% of  107.73MiB in 00:00:18 at 5.92MiB/s                       [FixupM4a] Correcting container of "/Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a"    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a; file is already in target format m4a    [youtube] Extracting URL: https://youtu.be/VMj-3S1tku0    [youtube] VMj-3S1tku0: Downloading webpage    [youtube] VMj-3S1tku0: Downloading android player API JSON    [info] VMj-3S1tku0: Downloading 1 format(s): 140    [download] /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a has already been downloaded    [download] 100% of  134.98MiB    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a; file is already in target format m4a# Returns a list of Documents, which can be easily viewed or parseddocs[0].page_content[0:500]    "Hello, my name is Andrej and I've been training deep neural networks for a bit more than a decade. And in this lecture I'd like to show you what neural network training looks like under the hood. So in particular we are going to start with a blank Jupyter notebook and by the end of this lecture we will define and train a neural net and you'll get to see everything that goes on under the hood and exactly sort of how that works on an intuitive level. Now specifically what I would like to do is I w"Building a chat app from YouTube video‚ÄãGiven Documents, we can easily enable chat / question+answering.from langchain.chains import RetrievalQAfrom langchain.vectorstores import FAISSfrom langchain.chat_models import ChatOpenAIfrom langchain.embeddings import OpenAIEmbeddingsfrom langchain.text_splitter import RecursiveCharacterTextSplitterAPI Reference:RetrievalQAFAISSChatOpenAIOpenAIEmbeddingsRecursiveCharacterTextSplitter# Combine doccombined_docs = [doc.page_content for doc in docs]text = " ".join(combined_docs)# Split themtext_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)splits = text_splitter.split_text(text)# Build an indexembeddings = OpenAIEmbeddings()vectordb = FAISS.from_texts(splits, embeddings)# Build a QA chainqa_chain = RetrievalQA.from_chain_type(    llm=ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0),    chain_type="stuff",    retriever=vectordb.as_retriever(),)# Ask a question!query = "Why do we need to zero out the gradient before backprop at each step?"qa_chain.run(query)    "We need to zero out the gradient before backprop at each step because the backward pass accumulates gradients in the grad attribute of each parameter. If we don't reset the grad to zero before each backward pass, the gradients will accumulate and add up, leading to incorrect updates and slower convergence. By resetting the grad to zero before each backward pass, we ensure that the gradients are calculated correctly and that the optimization process works as intended."query = "What is the difference between an encoder and decoder?"qa_chain.run(query)    'In the context of transformers, an encoder is a component that reads in a sequence of input tokens and generates a sequence of hidden representations. On the other hand, a decoder is a component that takes in a sequence of hidden representations and generates a sequence of output tokens. The main difference between the two is that the encoder is used to encode the input sequence into a fixed-length representation, while the decoder is used to decode the fixed-length representation into an output sequence. In machine translation, for example, the encoder reads in the source language sentence and generates a fixed-length representation, which is then used by the decoder to generate the target language sentence.'query = "For any token, what are x, k, v, and q?"qa_chain.run(query)    'For any token, x is the input vector that contains the private information of that token, k and q are the key and query vectors respectively, which are produced by forwarding linear modules on x, and v is the vector that is calculated by propagating the same linear module on x again. The key vector represents what the token contains, and the query vector represents what the token is looking for. The vector v is the information that the token will communicate to other tokens if it finds them interesting, and it gets aggregated for the purposes of the self-attention mechanism.'PreviousXorbits Pandas DataFrameNextYouTube transcripts IntegrationsDocument loadersLoading documents from a YouTube urlOn this pageLoading documents from a YouTube urlBuilding chat or QA applications on YouTube videos is a topic of high interest.Below we show how to easily go from a YouTube url to text to chat!We wil use the OpenAIWhisperParser, which will use the OpenAI Whisper API to transcribe audio to text, and the  OpenAIWhisperParserLocal for local support and running on private clouds or on premise.Note: You will need to have an OPENAI_API_KEY supplied.from langchain.document_loaders.generic import GenericLoaderfrom langchain.document_loaders.parsers import OpenAIWhisperParser, OpenAIWhisperParserLocalfrom langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoaderAPI Reference:GenericLoaderOpenAIWhisperParserYoutubeAudioLoaderWe will use yt_dlp to download audio for YouTube urls.We will use pydub to split downloaded audio files (such that we adhere to Whisper API's 25MB file size limit).pip install yt_dlp pip install pydub pip install librosaYouTube url to text‚ÄãUse YoutubeAudioLoader to fetch / download the audio files.Then, ues OpenAIWhisperParser() to transcribe them to text.Let's take the first lecture of Andrej Karpathy's YouTube course as an example! # set a flag to switch between local and remote parsing# change this to True if you want to use local parsinglocal = False# Two Karpathy lecture videosurls = ["https://youtu.be/kCc8FmEb1nY", "https://youtu.be/VMj-3S1tku0"]# Directory to save audio filessave_dir = "~/Downloads/YouTube"# Transcribe the videos to textif local:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParserLocal())else:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser())docs = loader.load()    [youtube] Extracting URL: https://youtu.be/kCc8FmEb1nY    [youtube] kCc8FmEb1nY: Downloading webpage    [youtube] kCc8FmEb1nY: Downloading android player API JSON    [info] kCc8FmEb1nY: Downloading 1 format(s): 140    [dashsegments] Total fragments: 11    [download] Destination: /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a    [download] 100% of  107.73MiB in 00:00:18 at 5.92MiB/s                       [FixupM4a] Correcting container of "/Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a"    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a; file is already in target format m4a    [youtube] Extracting URL: https://youtu.be/VMj-3S1tku0    [youtube] VMj-3S1tku0: Downloading webpage    [youtube] VMj-3S1tku0: Downloading android player API JSON    [info] VMj-3S1tku0: Downloading 1 format(s): 140    [download] /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a has already been downloaded    [download] 100% of  134.98MiB    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a; file is already in target format m4a# Returns a list of Documents, which can be easily viewed or parseddocs[0].page_content[0:500]    "Hello, my name is Andrej and I've been training deep neural networks for a bit more than a decade. And in this lecture I'd like to show you what neural network training looks like under the hood. So in particular we are going to start with a blank Jupyter notebook and by the end of this lecture we will define and train a neural net and you'll get to see everything that goes on under the hood and exactly sort of how that works on an intuitive level. Now specifically what I would like to do is I w"Building a chat app from YouTube video‚ÄãGiven Documents, we can easily enable chat / question+answering.from langchain.chains import RetrievalQAfrom langchain.vectorstores import FAISSfrom langchain.chat_models import ChatOpenAIfrom langchain.embeddings import OpenAIEmbeddingsfrom langchain.text_splitter import RecursiveCharacterTextSplitterAPI Reference:RetrievalQAFAISSChatOpenAIOpenAIEmbeddingsRecursiveCharacterTextSplitter# Combine doccombined_docs = [doc.page_content for doc in docs]text = " ".join(combined_docs)# Split themtext_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)splits = text_splitter.split_text(text)# Build an indexembeddings = OpenAIEmbeddings()vectordb = FAISS.from_texts(splits, embeddings)# Build a QA chainqa_chain = RetrievalQA.from_chain_type(    llm=ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0),    chain_type="stuff",    retriever=vectordb.as_retriever(),)# Ask a question!query = "Why do we need to zero out the gradient before backprop at each step?"qa_chain.run(query)    "We need to zero out the gradient before backprop at each step because the backward pass accumulates gradients in the grad attribute of each parameter. If we don't reset the grad to zero before each backward pass, the gradients will accumulate and add up, leading to incorrect updates and slower convergence. By resetting the grad to zero before each backward pass, we ensure that the gradients are calculated correctly and that the optimization process works as intended."query = "What is the difference between an encoder and decoder?"qa_chain.run(query)    'In the context of transformers, an encoder is a component that reads in a sequence of input tokens and generates a sequence of hidden representations. On the other hand, a decoder is a component that takes in a sequence of hidden representations and generates a sequence of output tokens. The main difference between the two is that the encoder is used to encode the input sequence into a fixed-length representation, while the decoder is used to decode the fixed-length representation into an output sequence. In machine translation, for example, the encoder reads in the source language sentence and generates a fixed-length representation, which is then used by the decoder to generate the target language sentence.'query = "For any token, what are x, k, v, and q?"qa_chain.run(query)    'For any token, x is the input vector that contains the private information of that token, k and q are the key and query vectors respectively, which are produced by forwarding linear modules on x, and v is the vector that is calculated by propagating the same linear module on x again. The key vector represents what the token contains, and the query vector represents what the token is looking for. The vector v is the information that the token will communicate to other tokens if it finds them interesting, and it gets aggregated for the purposes of the self-attention mechanism.'PreviousXorbits Pandas DataFrameNextYouTube transcripts On this page Loading documents from a YouTube urlBuilding chat or QA applications on YouTube videos is a topic of high interest.Below we show how to easily go from a YouTube url to text to chat!We wil use the OpenAIWhisperParser, which will use the OpenAI Whisper API to transcribe audio to text, and the  OpenAIWhisperParserLocal for local support and running on private clouds or on premise.Note: You will need to have an OPENAI_API_KEY supplied.from langchain.document_loaders.generic import GenericLoaderfrom langchain.document_loaders.parsers import OpenAIWhisperParser, OpenAIWhisperParserLocalfrom langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoaderAPI Reference:GenericLoaderOpenAIWhisperParserYoutubeAudioLoaderWe will use yt_dlp to download audio for YouTube urls.We will use pydub to split downloaded audio files (such that we adhere to Whisper API's 25MB file size limit).pip install yt_dlp pip install pydub pip install librosaYouTube url to text‚ÄãUse YoutubeAudioLoader to fetch / download the audio files.Then, ues OpenAIWhisperParser() to transcribe them to text.Let's take the first lecture of Andrej Karpathy's YouTube course as an example! # set a flag to switch between local and remote parsing# change this to True if you want to use local parsinglocal = False# Two Karpathy lecture videosurls = ["https://youtu.be/kCc8FmEb1nY", "https://youtu.be/VMj-3S1tku0"]# Directory to save audio filessave_dir = "~/Downloads/YouTube"# Transcribe the videos to textif local:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParserLocal())else:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser())docs = loader.load()    [youtube] Extracting URL: https://youtu.be/kCc8FmEb1nY    [youtube] kCc8FmEb1nY: Downloading webpage    [youtube] kCc8FmEb1nY: Downloading android player API JSON    [info] kCc8FmEb1nY: Downloading 1 format(s): 140    [dashsegments] Total fragments: 11    [download] Destination: /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a    [download] 100% of  107.73MiB in 00:00:18 at 5.92MiB/s                       [FixupM4a] Correcting container of "/Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a"    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a; file is already in target format m4a    [youtube] Extracting URL: https://youtu.be/VMj-3S1tku0    [youtube] VMj-3S1tku0: Downloading webpage    [youtube] VMj-3S1tku0: Downloading android player API JSON    [info] VMj-3S1tku0: Downloading 1 format(s): 140    [download] /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a has already been downloaded    [download] 100% of  134.98MiB    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a; file is already in target format m4a# Returns a list of Documents, which can be easily viewed or parseddocs[0].page_content[0:500]    "Hello, my name is Andrej and I've been training deep neural networks for a bit more than a decade. And in this lecture I'd like to show you what neural network training looks like under the hood. So in particular we are going to start with a blank Jupyter notebook and by the end of this lecture we will define and train a neural net and you'll get to see everything that goes on under the hood and exactly sort of how that works on an intuitive level. Now specifically what I would like to do is I w"Building a chat app from YouTube video‚ÄãGiven Documents, we can easily enable chat / question+answering.from langchain.chains import RetrievalQAfrom langchain.vectorstores import FAISSfrom langchain.chat_models import ChatOpenAIfrom langchain.embeddings import OpenAIEmbeddingsfrom langchain.text_splitter import RecursiveCharacterTextSplitterAPI Reference:RetrievalQAFAISSChatOpenAIOpenAIEmbeddingsRecursiveCharacterTextSplitter# Combine doccombined_docs = [doc.page_content for doc in docs]text = " ".join(combined_docs)# Split themtext_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)splits = text_splitter.split_text(text)# Build an indexembeddings = OpenAIEmbeddings()vectordb = FAISS.from_texts(splits, embeddings)# Build a QA chainqa_chain = RetrievalQA.from_chain_type(    llm=ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0),    chain_type="stuff",    retriever=vectordb.as_retriever(),)# Ask a question!query = "Why do we need to zero out the gradient before backprop at each step?"qa_chain.run(query)    "We need to zero out the gradient before backprop at each step because the backward pass accumulates gradients in the grad attribute of each parameter. If we don't reset the grad to zero before each backward pass, the gradients will accumulate and add up, leading to incorrect updates and slower convergence. By resetting the grad to zero before each backward pass, we ensure that the gradients are calculated correctly and that the optimization process works as intended."query = "What is the difference between an encoder and decoder?"qa_chain.run(query)    'In the context of transformers, an encoder is a component that reads in a sequence of input tokens and generates a sequence of hidden representations. On the other hand, a decoder is a component that takes in a sequence of hidden representations and generates a sequence of output tokens. The main difference between the two is that the encoder is used to encode the input sequence into a fixed-length representation, while the decoder is used to decode the fixed-length representation into an output sequence. In machine translation, for example, the encoder reads in the source language sentence and generates a fixed-length representation, which is then used by the decoder to generate the target language sentence.'query = "For any token, what are x, k, v, and q?"qa_chain.run(query)    'For any token, x is the input vector that contains the private information of that token, k and q are the key and query vectors respectively, which are produced by forwarding linear modules on x, and v is the vector that is calculated by propagating the same linear module on x again. The key vector represents what the token contains, and the query vector represents what the token is looking for. The vector v is the information that the token will communicate to other tokens if it finds them interesting, and it gets aggregated for the purposes of the self-attention mechanism.' from langchain.document_loaders.generic import GenericLoaderfrom langchain.document_loaders.parsers import OpenAIWhisperParser, OpenAIWhisperParserLocalfrom langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader from langchain.document_loaders.generic import GenericLoaderfrom langchain.document_loaders.parsers import OpenAIWhisperParser, OpenAIWhisperParserLocalfrom langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader  API Reference:GenericLoaderOpenAIWhisperParserYoutubeAudioLoader pip install yt_dlp pip install pydub pip install librosa pip install yt_dlp pip install pydub pip install librosa  # set a flag to switch between local and remote parsing# change this to True if you want to use local parsinglocal = False # set a flag to switch between local and remote parsing# change this to True if you want to use local parsinglocal = False  # Two Karpathy lecture videosurls = ["https://youtu.be/kCc8FmEb1nY", "https://youtu.be/VMj-3S1tku0"]# Directory to save audio filessave_dir = "~/Downloads/YouTube"# Transcribe the videos to textif local:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParserLocal())else:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser())docs = loader.load() # Two Karpathy lecture videosurls = ["https://youtu.be/kCc8FmEb1nY", "https://youtu.be/VMj-3S1tku0"]# Directory to save audio filessave_dir = "~/Downloads/YouTube"# Transcribe the videos to textif local:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParserLocal())else:    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser())docs = loader.load()      [youtube] Extracting URL: https://youtu.be/kCc8FmEb1nY    [youtube] kCc8FmEb1nY: Downloading webpage    [youtube] kCc8FmEb1nY: Downloading android player API JSON    [info] kCc8FmEb1nY: Downloading 1 format(s): 140    [dashsegments] Total fragments: 11    [download] Destination: /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a    [download] 100% of  107.73MiB in 00:00:18 at 5.92MiB/s                       [FixupM4a] Correcting container of "/Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a"    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a; file is already in target format m4a    [youtube] Extracting URL: https://youtu.be/VMj-3S1tku0    [youtube] VMj-3S1tku0: Downloading webpage    [youtube] VMj-3S1tku0: Downloading android player API JSON    [info] VMj-3S1tku0: Downloading 1 format(s): 140    [download] /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a has already been downloaded    [download] 100% of  134.98MiB    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a; file is already in target format m4a     [youtube] Extracting URL: https://youtu.be/kCc8FmEb1nY    [youtube] kCc8FmEb1nY: Downloading webpage    [youtube] kCc8FmEb1nY: Downloading android player API JSON    [info] kCc8FmEb1nY: Downloading 1 format(s): 140    [dashsegments] Total fragments: 11    [download] Destination: /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a    [download] 100% of  107.73MiB in 00:00:18 at 5.92MiB/s                       [FixupM4a] Correcting container of "/Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a"    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a; file is already in target format m4a    [youtube] Extracting URL: https://youtu.be/VMj-3S1tku0    [youtube] VMj-3S1tku0: Downloading webpage    [youtube] VMj-3S1tku0: Downloading android player API JSON    [info] VMj-3S1tku0: Downloading 1 format(s): 140    [download] /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a has already been downloaded    [download] 100% of  134.98MiB    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a; file is already in target format m4a     [youtube] Extracting URL: https://youtu.be/kCc8FmEb1nY    [youtube] kCc8FmEb1nY: Downloading webpage    [youtube] kCc8FmEb1nY: Downloading android player API JSON    [info] kCc8FmEb1nY: Downloading 1 format(s): 140    [dashsegments] Total fragments: 11    [download] Destination: /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a    [download] 100% of  107.73MiB in 00:00:18 at 5.92MiB/s                       [FixupM4a] Correcting container of "/Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a"    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/Let's build GPTÔºö from scratch, in code, spelled out..m4a; file is already in target format m4a    [youtube] Extracting URL: https://youtu.be/VMj-3S1tku0    [youtube] VMj-3S1tku0: Downloading webpage    [youtube] VMj-3S1tku0: Downloading android player API JSON    [info] VMj-3S1tku0: Downloading 1 format(s): 140    [download] /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a has already been downloaded    [download] 100% of  134.98MiB    [ExtractAudio] Not converting audio /Users/31treehaus/Desktop/AI/langchain-fork/docs/modules/indexes/document_loaders/examples/The spelled-out intro to neural networks and backpropagationÔºö building micrograd.m4a; file is already in target format m4a  # Returns a list of Documents, which can be easily viewed or parseddocs[0].page_content[0:500] # Returns a list of Documents, which can be easily viewed or parseddocs[0].page_content[0:500]      "Hello, my name is Andrej and I've been training deep neural networks for a bit more than a decade. And in this lecture I'd like to show you what neural network training looks like under the hood. So in particular we are going to start with a blank Jupyter notebook and by the end of this lecture we will define and train a neural net and you'll get to see everything that goes on under the hood and exactly sort of how that works on an intuitive level. Now specifically what I would like to do is I w"     "Hello, my name is Andrej and I've been training deep neural networks for a bit more than a decade. And in this lecture I'd like to show you what neural network training looks like under the hood. So in particular we are going to start with a blank Jupyter notebook and by the end of this lecture we will define and train a neural net and you'll get to see everything that goes on under the hood and exactly sort of how that works on an intuitive level. Now specifically what I would like to do is I w"     "Hello, my name is Andrej and I've been training deep neural networks for a bit more than a decade. And in this lecture I'd like to show you what neural network training looks like under the hood. So in particular we are going to start with a blank Jupyter notebook and by the end of this lecture we will define and train a neural net and you'll get to see everything that goes on under the hood and exactly sort of how that works on an intuitive level. Now specifically what I would like to do is I w"  from langchain.chains import RetrievalQAfrom langchain.vectorstores import FAISSfrom langchain.chat_models import ChatOpenAIfrom langchain.embeddings import OpenAIEmbeddingsfrom langchain.text_splitter import RecursiveCharacterTextSplitter from langchain.chains import RetrievalQAfrom langchain.vectorstores import FAISSfrom langchain.chat_models import ChatOpenAIfrom langchain.embeddings import OpenAIEmbeddingsfrom langchain.text_splitter import RecursiveCharacterTextSplitter  API Reference:RetrievalQAFAISSChatOpenAIOpenAIEmbeddingsRecursiveCharacterTextSplitter # Combine doccombined_docs = [doc.page_content for doc in docs]text = " ".join(combined_docs) # Combine doccombined_docs = [doc.page_content for doc in docs]text = " ".join(combined_docs)  # Split themtext_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)splits = text_splitter.split_text(text) # Split themtext_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)splits = text_splitter.split_text(text)  # Build an indexembeddings = OpenAIEmbeddings()vectordb = FAISS.from_texts(splits, embeddings) # Build an indexembeddings = OpenAIEmbeddings()vectordb = FAISS.from_texts(splits, embeddings)  # Build a QA chainqa_chain = RetrievalQA.from_chain_type(    llm=ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0),    chain_type="stuff",    retriever=vectordb.as_retriever(),) # Build a QA chainqa_chain = RetrievalQA.from_chain_type(    llm=ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0),    chain_type="stuff",    retriever=vectordb.as_retriever(),)  # Ask a question!query = "Why do we need to zero out the gradient before backprop at each step?"qa_chain.run(query) # Ask a question!query = "Why do we need to zero out the gradient before backprop at each step?"qa_chain.run(query)      "We need to zero out the gradient before backprop at each step because the backward pass accumulates gradients in the grad attribute of each parameter. If we don't reset the grad to zero before each backward pass, the gradients will accumulate and add up, leading to incorrect updates and slower convergence. By resetting the grad to zero before each backward pass, we ensure that the gradients are calculated correctly and that the optimization process works as intended."     "We need to zero out the gradient before backprop at each step because the backward pass accumulates gradients in the grad attribute of each parameter. If we don't reset the grad to zero before each backward pass, the gradients will accumulate and add up, leading to incorrect updates and slower convergence. By resetting the grad to zero before each backward pass, we ensure that the gradients are calculated correctly and that the optimization process works as intended."     "We need to zero out the gradient before backprop at each step because the backward pass accumulates gradients in the grad attribute of each parameter. If we don't reset the grad to zero before each backward pass, the gradients will accumulate and add up, leading to incorrect updates and slower convergence. By resetting the grad to zero before each backward pass, we ensure that the gradients are calculated correctly and that the optimization process works as intended."  query = "What is the difference between an encoder and decoder?"qa_chain.run(query) query = "What is the difference between an encoder and decoder?"qa_chain.run(query)      'In the context of transformers, an encoder is a component that reads in a sequence of input tokens and generates a sequence of hidden representations. On the other hand, a decoder is a component that takes in a sequence of hidden representations and generates a sequence of output tokens. The main difference between the two is that the encoder is used to encode the input sequence into a fixed-length representation, while the decoder is used to decode the fixed-length representation into an output sequence. In machine translation, for example, the encoder reads in the source language sentence and generates a fixed-length representation, which is then used by the decoder to generate the target language sentence.'     'In the context of transformers, an encoder is a component that reads in a sequence of input tokens and generates a sequence of hidden representations. On the other hand, a decoder is a component that takes in a sequence of hidden representations and generates a sequence of output tokens. The main difference between the two is that the encoder is used to encode the input sequence into a fixed-length representation, while the decoder is used to decode the fixed-length representation into an output sequence. In machine translation, for example, the encoder reads in the source language sentence and generates a fixed-length representation, which is then used by the decoder to generate the target language sentence.'     'In the context of transformers, an encoder is a component that reads in a sequence of input tokens and generates a sequence of hidden representations. On the other hand, a decoder is a component that takes in a sequence of hidden representations and generates a sequence of output tokens. The main difference between the two is that the encoder is used to encode the input sequence into a fixed-length representation, while the decoder is used to decode the fixed-length representation into an output sequence. In machine translation, for example, the encoder reads in the source language sentence and generates a fixed-length representation, which is then used by the decoder to generate the target language sentence.'  query = "For any token, what are x, k, v, and q?"qa_chain.run(query) query = "For any token, what are x, k, v, and q?"qa_chain.run(query)      'For any token, x is the input vector that contains the private information of that token, k and q are the key and query vectors respectively, which are produced by forwarding linear modules on x, and v is the vector that is calculated by propagating the same linear module on x again. The key vector represents what the token contains, and the query vector represents what the token is looking for. The vector v is the information that the token will communicate to other tokens if it finds them interesting, and it gets aggregated for the purposes of the self-attention mechanism.'     'For any token, x is the input vector that contains the private information of that token, k and q are the key and query vectors respectively, which are produced by forwarding linear modules on x, and v is the vector that is calculated by propagating the same linear module on x again. The key vector represents what the token contains, and the query vector represents what the token is looking for. The vector v is the information that the token will communicate to other tokens if it finds them interesting, and it gets aggregated for the purposes of the self-attention mechanism.'     'For any token, x is the input vector that contains the private information of that token, k and q are the key and query vectors respectively, which are produced by forwarding linear modules on x, and v is the vector that is calculated by propagating the same linear module on x again. The key vector represents what the token contains, and the query vector represents what the token is looking for. The vector v is the information that the token will communicate to other tokens if it finds them interesting, and it gets aggregated for the purposes of the self-attention mechanism.'  Previous Xorbits Pandas DataFrame Next YouTube transcripts YouTube url to textBuilding a chat app from YouTube video YouTube url to textBuilding a chat app from YouTube video CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Etherscan Loader (/docs/integrations/document_loaders/Etherscan) acreom (/docs/integrations/document_loaders/acreom) Airbyte CDK (/docs/integrations/document_loaders/airbyte_cdk) Airbyte Gong (/docs/integrations/document_loaders/airbyte_gong) Airbyte Hubspot (/docs/integrations/document_loaders/airbyte_hubspot) Airbyte JSON (/docs/integrations/document_loaders/airbyte_json) Airbyte Salesforce (/docs/integrations/document_loaders/airbyte_salesforce) Airbyte Shopify (/docs/integrations/document_loaders/airbyte_shopify) Airbyte Stripe (/docs/integrations/document_loaders/airbyte_stripe) Airbyte Typeform (/docs/integrations/document_loaders/airbyte_typeform) Airbyte Zendesk Support (/docs/integrations/document_loaders/airbyte_zendesk_support) Airtable (/docs/integrations/document_loaders/airtable) Alibaba Cloud MaxCompute (/docs/integrations/document_loaders/alibaba_cloud_maxcompute) Apify Dataset (/docs/integrations/document_loaders/apify_dataset) ArcGIS (/docs/integrations/document_loaders/arcgis) Arxiv (/docs/integrations/document_loaders/arxiv) AssemblyAI Audio Transcripts (/docs/integrations/document_loaders/assemblyai) Async Chromium (/docs/integrations/document_loaders/async_chromium) AsyncHtmlLoader (/docs/integrations/document_loaders/async_html) AWS S3 Directory (/docs/integrations/document_loaders/aws_s3_directory) AWS S3 File (/docs/integrations/document_loaders/aws_s3_file) AZLyrics (/docs/integrations/document_loaders/azlyrics) Azure Blob Storage Container (/docs/integrations/document_loaders/azure_blob_storage_container) Azure Blob Storage File (/docs/integrations/document_loaders/azure_blob_storage_file) Azure Document Intelligence (/docs/integrations/document_loaders/azure_document_intelligence) BibTeX (/docs/integrations/document_loaders/bibtex) BiliBili (/docs/integrations/document_loaders/bilibili) Blackboard (/docs/integrations/document_loaders/blackboard) Blockchain (/docs/integrations/document_loaders/blockchain) Brave Search (/docs/integrations/document_loaders/brave_search) Browserless (/docs/integrations/document_loaders/browserless) ChatGPT Data (/docs/integrations/document_loaders/chatgpt_loader) College Confidential (/docs/integrations/document_loaders/college_confidential) Concurrent Loader (/docs/integrations/document_loaders/concurrent) Confluence (/docs/integrations/document_loaders/confluence) CoNLL-U (/docs/integrations/document_loaders/conll-u) Copy Paste (/docs/integrations/document_loaders/copypaste) CSV (/docs/integrations/document_loaders/csv) Cube Semantic Layer (/docs/integrations/document_loaders/cube_semantic) Datadog Logs (/docs/integrations/document_loaders/datadog_logs) Diffbot (/docs/integrations/document_loaders/diffbot) Discord (/docs/integrations/document_loaders/discord) Docugami (/docs/integrations/document_loaders/docugami) Dropbox (/docs/integrations/document_loaders/dropbox) DuckDB (/docs/integrations/document_loaders/duckdb) Email (/docs/integrations/document_loaders/email) Embaas (/docs/integrations/document_loaders/embaas) EPub (/docs/integrations/document_loaders/epub) EverNote (/docs/integrations/document_loaders/evernote) example_data (/docs/integrations/document_loaders/example_data/notebook) Microsoft Excel (/docs/integrations/document_loaders/excel) Facebook Chat (/docs/integrations/document_loaders/facebook_chat) Fauna (/docs/integrations/document_loaders/fauna) Figma (/docs/integrations/document_loaders/figma) Geopandas (/docs/integrations/document_loaders/geopandas) Git (/docs/integrations/document_loaders/git) GitBook (/docs/integrations/document_loaders/gitbook) GitHub (/docs/integrations/document_loaders/github) Google BigQuery (/docs/integrations/document_loaders/google_bigquery) Google Cloud Storage Directory (/docs/integrations/document_loaders/google_cloud_storage_directory) Google Cloud Storage File (/docs/integrations/document_loaders/google_cloud_storage_file) Google Drive (/docs/integrations/document_loaders/google_drive) Grobid (/docs/integrations/document_loaders/grobid) Gutenberg (/docs/integrations/document_loaders/gutenberg) Hacker News (/docs/integrations/document_loaders/hacker_news) Huawei OBS Directory (/docs/integrations/document_loaders/huawei_obs_directory) Huawei OBS File (/docs/integrations/document_loaders/huawei_obs_file) HuggingFace dataset (/docs/integrations/document_loaders/hugging_face_dataset) iFixit (/docs/integrations/document_loaders/ifixit) Images (/docs/integrations/document_loaders/image) Image captions (/docs/integrations/document_loaders/image_captions) IMSDb (/docs/integrations/document_loaders/imsdb) Iugu (/docs/integrations/document_loaders/iugu) Joplin (/docs/integrations/document_loaders/joplin) Jupyter Notebook (/docs/integrations/document_loaders/jupyter_notebook) LarkSuite (FeiShu) (/docs/integrations/document_loaders/larksuite) Mastodon (/docs/integrations/document_loaders/mastodon) MediaWikiDump (/docs/integrations/document_loaders/mediawikidump) MergeDocLoader (/docs/integrations/document_loaders/merge_doc_loader) mhtml (/docs/integrations/document_loaders/mhtml) Microsoft OneDrive (/docs/integrations/document_loaders/microsoft_onedrive) Microsoft PowerPoint (/docs/integrations/document_loaders/microsoft_powerpoint) Microsoft SharePoint (/docs/integrations/document_loaders/microsoft_sharepoint) Microsoft Word (/docs/integrations/document_loaders/microsoft_word) Modern Treasury (/docs/integrations/document_loaders/modern_treasury) News URL (/docs/integrations/document_loaders/news) Notion DB 1/2 (/docs/integrations/document_loaders/notion) Notion DB 2/2 (/docs/integrations/document_loaders/notiondb) Nuclia Understanding API document loader (/docs/integrations/document_loaders/nuclia) Obsidian (/docs/integrations/document_loaders/obsidian) Open Document Format (ODT) (/docs/integrations/document_loaders/odt) Open City Data (/docs/integrations/document_loaders/open_city_data) Org-mode (/docs/integrations/document_loaders/org_mode) Pandas DataFrame (/docs/integrations/document_loaders/pandas_dataframe) Amazon Textract (/docs/integrations/document_loaders/pdf-amazonTextractPDFLoader) Polars DataFrame (/docs/integrations/document_loaders/polars_dataframe) Psychic (/docs/integrations/document_loaders/psychic) PubMed (/docs/integrations/document_loaders/pubmed) PySpark DataFrame Loader (/docs/integrations/document_loaders/pyspark_dataframe) ReadTheDocs Documentation (/docs/integrations/document_loaders/readthedocs_documentation) Recursive URL Loader (/docs/integrations/document_loaders/recursive_url_loader) Reddit (/docs/integrations/document_loaders/reddit) Roam (/docs/integrations/document_loaders/roam) Rockset (/docs/integrations/document_loaders/rockset) RSS Feeds (/docs/integrations/document_loaders/rss) RST (/docs/integrations/document_loaders/rst) Sitemap (/docs/integrations/document_loaders/sitemap) Slack (/docs/integrations/document_loaders/slack) Snowflake (/docs/integrations/document_loaders/snowflake) Source Code (/docs/integrations/document_loaders/source_code) Spreedly (/docs/integrations/document_loaders/spreedly) Stripe (/docs/integrations/document_loaders/stripe) Subtitle (/docs/integrations/document_loaders/subtitle) Telegram (/docs/integrations/document_loaders/telegram) Tencent COS Directory (/docs/integrations/document_loaders/tencent_cos_directory) Tencent COS File (/docs/integrations/document_loaders/tencent_cos_file) TensorFlow Datasets (/docs/integrations/document_loaders/tensorflow_datasets) 2Markdown (/docs/integrations/document_loaders/tomarkdown) TOML (/docs/integrations/document_loaders/toml) Trello (/docs/integrations/document_loaders/trello) TSV (/docs/integrations/document_loaders/tsv) Twitter (/docs/integrations/document_loaders/twitter) Unstructured File (/docs/integrations/document_loaders/unstructured_file) URL (/docs/integrations/document_loaders/url) Weather (/docs/integrations/document_loaders/weather) WebBaseLoader (/docs/integrations/document_loaders/web_base) WhatsApp Chat (/docs/integrations/document_loaders/whatsapp_chat) Wikipedia (/docs/integrations/document_loaders/wikipedia) XML (/docs/integrations/document_loaders/xml) Xorbits Pandas DataFrame (/docs/integrations/document_loaders/xorbits) Loading documents from a YouTube url (/docs/integrations/document_loaders/youtube_audio) YouTube transcripts (/docs/integrations/document_loaders/youtube_transcript) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Document loaders (/docs/integrations/document_loaders/) GenericLoader (https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.generic.GenericLoader.html) OpenAIWhisperParser (https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.parsers.audio.OpenAIWhisperParser.html) YoutubeAudioLoader (https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.blob_loaders.youtube_audio.YoutubeAudioLoader.html) ‚Äã (#youtube-url-to-text) ‚Äã (#building-a-chat-app-from-youtube-video) RetrievalQA (https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html) FAISS (https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.faiss.FAISS.html) ChatOpenAI (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html) OpenAIEmbeddings (https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html) RecursiveCharacterTextSplitter (https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html) PreviousXorbits Pandas DataFrame (/docs/integrations/document_loaders/xorbits) NextYouTube transcripts (/docs/integrations/document_loaders/youtube_transcript) YouTube url to text (#youtube-url-to-text) Building a chat app from YouTube video (#building-a-chat-app-from-youtube-video) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)