This notebook goes over how to store and use chat message history in a Streamlit app. StreamlitChatMessageHistory will store messages in Streamlit session state at the specified key=. The default key is "langchain_messages". You can see the full app example running here, and more examples in github.com/langchain-ai/streamlit-agent. You can integrate StreamlitChatMessageHistory into ConversationBufferMemory and chains or agents as usual. The history will be persisted across re-runs of the Streamlit app within a given user session. A given StreamlitChatMessageHistory will NOT be persisted or shared across user sessions. Conversational Streamlit apps will often re-draw each previous chat message on every re-run. This is easy to do by iterating through StreamlitChatMessageHistory.messages: View the final app. IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryCassandra Chat Message HistoryDynamodb Chat Message HistoryEntity Memory with SQLite storageMomento Chat Message HistoryMongodb Chat Message HistoryMot√∂rhead MemoryMot√∂rhead Memory (Managed)Postgres Chat Message HistoryRedis Chat Message HistoryRockset Chat Message HistorySQL Chat Message HistoryStreamlit Chat Message HistoryXata chat memoryZep MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Callbacks Chat models Chat loaders Document loaders Document transformers LLMs MemoryCassandra Chat Message HistoryDynamodb Chat Message HistoryEntity Memory with SQLite storageMomento Chat Message HistoryMongodb Chat Message HistoryMot√∂rhead MemoryMot√∂rhead Memory (Managed)Postgres Chat Message HistoryRedis Chat Message HistoryRockset Chat Message HistorySQL Chat Message HistoryStreamlit Chat Message HistoryXata chat memoryZep Memory Cassandra Chat Message History Dynamodb Chat Message History Entity Memory with SQLite storage Momento Chat Message History Mongodb Chat Message History Mot√∂rhead Memory Mot√∂rhead Memory (Managed) Postgres Chat Message History Redis Chat Message History Rockset Chat Message History SQL Chat Message History Streamlit Chat Message History Xata chat memory Zep Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations Memory Streamlit Chat Message History Note, StreamlitChatMessageHistory only works when run in a Streamlit app. You may also be interested in StreamlitCallbackHandler for LangChain. For more on Streamlit check out their getting started documentation. StreamlitChatMessageHistory ConversationBufferMemory StreamlitChatMessageHistory LLMChain OpenAI PromptTemplate Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryCassandra Chat Message HistoryDynamodb Chat Message HistoryEntity Memory with SQLite storageMomento Chat Message HistoryMongodb Chat Message HistoryMot√∂rhead MemoryMot√∂rhead Memory (Managed)Postgres Chat Message HistoryRedis Chat Message HistoryRockset Chat Message HistorySQL Chat Message HistoryStreamlit Chat Message HistoryXata chat memoryZep MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsMemoryStreamlit Chat Message HistoryStreamlit Chat Message HistoryThis notebook goes over how to store and use chat message history in a Streamlit app. StreamlitChatMessageHistory will store messages in at the specified key=. The default key is "langchain_messages".Note, StreamlitChatMessageHistory only works when run in a Streamlit app.You may also be interested in StreamlitCallbackHandler for LangChain.For more on Streamlit check out their getting started documentation.You can see the full app example running here, and more examples in github.com/langchain-ai/streamlit-agent.from langchain.memory import StreamlitChatMessageHistoryhistory = StreamlitChatMessageHistory(key="chat_messages")history.add_user_message("hi!")history.add_ai_message("whats up?")API Reference:StreamlitChatMessageHistoryhistory.messagesYou can integrate StreamlitChatMessageHistory into ConversationBufferMemory and chains or agents as usual. The history will be persisted across re-runs of the Streamlit app within a given user session. A given StreamlitChatMessageHistory will NOT be persisted or shared across user sessions.from langchain.memory import ConversationBufferMemoryfrom langchain.memory.chat_message_histories import StreamlitChatMessageHistory# Optionally, specify your own session_state key for storing messagesmsgs = StreamlitChatMessageHistory(key="special_app_key")memory = ConversationBufferMemory(memory_key="history", chat_memory=msgs)if len(msgs.messages) == 0:    msgs.add_ai_message("How can I help you?")API Reference:ConversationBufferMemoryStreamlitChatMessageHistoryfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatetemplate = """You are an AI chatbot having a conversation with a human.{history}Human: {human_input}AI: """prompt = PromptTemplate(input_variables=["history", "human_input"], template=template)# Add the memory to an LLMChain as usualllm_chain = LLMChain(llm=OpenAI(), prompt=prompt, memory=memory)API Reference:LLMChainOpenAIPromptTemplateConversational Streamlit apps will often re-draw each previous chat message on every re-run. This is easy to do by iterating through StreamlitChatMessageHistory.messages:import streamlit as stfor msg in msgs.messages:    st.chat_message(msg.type).write(msg.content)if prompt := st.chat_input():    st.chat_message("human").write(prompt)    # As usual, new messages are added to StreamlitChatMessageHistory when the Chain is called.    response = llm_chain.run(prompt)    st.chat_message("ai").write(response)View the final app.PreviousSQL Chat Message HistoryNextXata chat memoryCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryCassandra Chat Message HistoryDynamodb Chat Message HistoryEntity Memory with SQLite storageMomento Chat Message HistoryMongodb Chat Message HistoryMot√∂rhead MemoryMot√∂rhead Memory (Managed)Postgres Chat Message HistoryRedis Chat Message HistoryRockset Chat Message HistorySQL Chat Message HistoryStreamlit Chat Message HistoryXata chat memoryZep MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsMemoryStreamlit Chat Message HistoryStreamlit Chat Message HistoryThis notebook goes over how to store and use chat message history in a Streamlit app. StreamlitChatMessageHistory will store messages in github.com/langchain-ai/streamlit-agent.from langchain.memory import StreamlitChatMessageHistoryhistory = StreamlitChatMessageHistory(key="chat_messages")history.add_user_message("hi!")history.add_ai_message("whats up?")API Reference:StreamlitChatMessageHistoryhistory.messagesYou can integrate StreamlitChatMessageHistory into ConversationBufferMemory and chains or agents as usual. The history will be persisted across re-runs of the Streamlit app within a given user session. A given StreamlitChatMessageHistory will NOT be persisted or shared across user sessions.from langchain.memory import ConversationBufferMemoryfrom langchain.memory.chat_message_histories import StreamlitChatMessageHistory# Optionally, specify your own session_state key for storing messagesmsgs = StreamlitChatMessageHistory(key="special_app_key")memory = ConversationBufferMemory(memory_key="history", chat_memory=msgs)if len(msgs.messages) == 0:    msgs.add_ai_message("How can I help you?")API Reference:ConversationBufferMemoryStreamlitChatMessageHistoryfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatetemplate = """You are an AI chatbot having a conversation with a human.{history}Human: {human_input}AI: """prompt = PromptTemplate(input_variables=["history", "human_input"], template=template)# Add the memory to an LLMChain as usualllm_chain = LLMChain(llm=OpenAI(), prompt=prompt, memory=memory)API Reference:LLMChainOpenAIPromptTemplateConversational Streamlit apps will often re-draw each previous chat message on every re-run. This is easy to do by iterating through StreamlitChatMessageHistory.messages:import streamlit as stfor msg in msgs.messages:    st.chat_message(msg.type).write(msg.content)if prompt := st.chat_input():    st.chat_message("human").write(prompt)    # As usual, new messages are added to StreamlitChatMessageHistory when the Chain is called.    response = llm_chain.run(prompt)    st.chat_message("ai").write(response)View the final app.PreviousSQL Chat Message HistoryNextXata chat memory IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryCassandra Chat Message HistoryDynamodb Chat Message HistoryEntity Memory with SQLite storageMomento Chat Message HistoryMongodb Chat Message HistoryMot√∂rhead MemoryMot√∂rhead Memory (Managed)Postgres Chat Message HistoryRedis Chat Message HistoryRockset Chat Message HistorySQL Chat Message HistoryStreamlit Chat Message HistoryXata chat memoryZep MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsMemoryStreamlit Chat Message HistoryStreamlit Chat Message HistoryThis notebook goes over how to store and use chat message history in a Streamlit app. StreamlitChatMessageHistory will store messages in github.com/langchain-ai/streamlit-agent.from langchain.memory import StreamlitChatMessageHistoryhistory = StreamlitChatMessageHistory(key="chat_messages")history.add_user_message("hi!")history.add_ai_message("whats up?")API Reference:StreamlitChatMessageHistoryhistory.messagesYou can integrate StreamlitChatMessageHistory into ConversationBufferMemory and chains or agents as usual. The history will be persisted across re-runs of the Streamlit app within a given user session. A given StreamlitChatMessageHistory will NOT be persisted or shared across user sessions.from langchain.memory import ConversationBufferMemoryfrom langchain.memory.chat_message_histories import StreamlitChatMessageHistory# Optionally, specify your own session_state key for storing messagesmsgs = StreamlitChatMessageHistory(key="special_app_key")memory = ConversationBufferMemory(memory_key="history", chat_memory=msgs)if len(msgs.messages) == 0:    msgs.add_ai_message("How can I help you?")API Reference:ConversationBufferMemoryStreamlitChatMessageHistoryfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatetemplate = """You are an AI chatbot having a conversation with a human.{history}Human: {human_input}AI: """prompt = PromptTemplate(input_variables=["history", "human_input"], template=template)# Add the memory to an LLMChain as usualllm_chain = LLMChain(llm=OpenAI(), prompt=prompt, memory=memory)API Reference:LLMChainOpenAIPromptTemplateConversational Streamlit apps will often re-draw each previous chat message on every re-run. This is easy to do by iterating through StreamlitChatMessageHistory.messages:import streamlit as stfor msg in msgs.messages:    st.chat_message(msg.type).write(msg.content)if prompt := st.chat_input():    st.chat_message("human").write(prompt)    # As usual, new messages are added to StreamlitChatMessageHistory when the Chain is called.    response = llm_chain.run(prompt)    st.chat_message("ai").write(response)View the final app.PreviousSQL Chat Message HistoryNextXata chat memory IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryCassandra Chat Message HistoryDynamodb Chat Message HistoryEntity Memory with SQLite storageMomento Chat Message HistoryMongodb Chat Message HistoryMot√∂rhead MemoryMot√∂rhead Memory (Managed)Postgres Chat Message HistoryRedis Chat Message HistoryRockset Chat Message HistorySQL Chat Message HistoryStreamlit Chat Message HistoryXata chat memoryZep MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryCassandra Chat Message HistoryDynamodb Chat Message HistoryEntity Memory with SQLite storageMomento Chat Message HistoryMongodb Chat Message HistoryMot√∂rhead MemoryMot√∂rhead Memory (Managed)Postgres Chat Message HistoryRedis Chat Message HistoryRockset Chat Message HistorySQL Chat Message HistoryStreamlit Chat Message HistoryXata chat memoryZep MemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsMemoryStreamlit Chat Message HistoryStreamlit Chat Message HistoryThis notebook goes over how to store and use chat message history in a Streamlit app. StreamlitChatMessageHistory will store messages in github.com/langchain-ai/streamlit-agent.from langchain.memory import StreamlitChatMessageHistoryhistory = StreamlitChatMessageHistory(key="chat_messages")history.add_user_message("hi!")history.add_ai_message("whats up?")API Reference:StreamlitChatMessageHistoryhistory.messagesYou can integrate StreamlitChatMessageHistory into ConversationBufferMemory and chains or agents as usual. The history will be persisted across re-runs of the Streamlit app within a given user session. A given StreamlitChatMessageHistory will NOT be persisted or shared across user sessions.from langchain.memory import ConversationBufferMemoryfrom langchain.memory.chat_message_histories import StreamlitChatMessageHistory# Optionally, specify your own session_state key for storing messagesmsgs = StreamlitChatMessageHistory(key="special_app_key")memory = ConversationBufferMemory(memory_key="history", chat_memory=msgs)if len(msgs.messages) == 0:    msgs.add_ai_message("How can I help you?")API Reference:ConversationBufferMemoryStreamlitChatMessageHistoryfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatetemplate = """You are an AI chatbot having a conversation with a human.{history}Human: {human_input}AI: """prompt = PromptTemplate(input_variables=["history", "human_input"], template=template)# Add the memory to an LLMChain as usualllm_chain = LLMChain(llm=OpenAI(), prompt=prompt, memory=memory)API Reference:LLMChainOpenAIPromptTemplateConversational Streamlit apps will often re-draw each previous chat message on every re-run. This is easy to do by iterating through StreamlitChatMessageHistory.messages:import streamlit as stfor msg in msgs.messages:    st.chat_message(msg.type).write(msg.content)if prompt := st.chat_input():    st.chat_message("human").write(prompt)    # As usual, new messages are added to StreamlitChatMessageHistory when the Chain is called.    response = llm_chain.run(prompt)    st.chat_message("ai").write(response)View the final app.PreviousSQL Chat Message HistoryNextXata chat memory IntegrationsMemoryStreamlit Chat Message HistoryStreamlit Chat Message HistoryThis notebook goes over how to store and use chat message history in a Streamlit app. StreamlitChatMessageHistory will store messages in github.com/langchain-ai/streamlit-agent.from langchain.memory import StreamlitChatMessageHistoryhistory = StreamlitChatMessageHistory(key="chat_messages")history.add_user_message("hi!")history.add_ai_message("whats up?")API Reference:StreamlitChatMessageHistoryhistory.messagesYou can integrate StreamlitChatMessageHistory into ConversationBufferMemory and chains or agents as usual. The history will be persisted across re-runs of the Streamlit app within a given user session. A given StreamlitChatMessageHistory will NOT be persisted or shared across user sessions.from langchain.memory import ConversationBufferMemoryfrom langchain.memory.chat_message_histories import StreamlitChatMessageHistory# Optionally, specify your own session_state key for storing messagesmsgs = StreamlitChatMessageHistory(key="special_app_key")memory = ConversationBufferMemory(memory_key="history", chat_memory=msgs)if len(msgs.messages) == 0:    msgs.add_ai_message("How can I help you?")API Reference:ConversationBufferMemoryStreamlitChatMessageHistoryfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatetemplate = """You are an AI chatbot having a conversation with a human.{history}Human: {human_input}AI: """prompt = PromptTemplate(input_variables=["history", "human_input"], template=template)# Add the memory to an LLMChain as usualllm_chain = LLMChain(llm=OpenAI(), prompt=prompt, memory=memory)API Reference:LLMChainOpenAIPromptTemplateConversational Streamlit apps will often re-draw each previous chat message on every re-run. This is easy to do by iterating through StreamlitChatMessageHistory.messages:import streamlit as stfor msg in msgs.messages:    st.chat_message(msg.type).write(msg.content)if prompt := st.chat_input():    st.chat_message("human").write(prompt)    # As usual, new messages are added to StreamlitChatMessageHistory when the Chain is called.    response = llm_chain.run(prompt)    st.chat_message("ai").write(response)View the final app.PreviousSQL Chat Message HistoryNextXata chat memory Streamlit Chat Message HistoryThis notebook goes over how to store and use chat message history in a Streamlit app. StreamlitChatMessageHistory will store messages in github.com/langchain-ai/streamlit-agent.from langchain.memory import StreamlitChatMessageHistoryhistory = StreamlitChatMessageHistory(key="chat_messages")history.add_user_message("hi!")history.add_ai_message("whats up?")API Reference:StreamlitChatMessageHistoryhistory.messagesYou can integrate StreamlitChatMessageHistory into ConversationBufferMemory and chains or agents as usual. The history will be persisted across re-runs of the Streamlit app within a given user session. A given StreamlitChatMessageHistory will NOT be persisted or shared across user sessions.from langchain.memory import ConversationBufferMemoryfrom langchain.memory.chat_message_histories import StreamlitChatMessageHistory# Optionally, specify your own session_state key for storing messagesmsgs = StreamlitChatMessageHistory(key="special_app_key")memory = ConversationBufferMemory(memory_key="history", chat_memory=msgs)if len(msgs.messages) == 0:    msgs.add_ai_message("How can I help you?")API Reference:ConversationBufferMemoryStreamlitChatMessageHistoryfrom langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatetemplate = """You are an AI chatbot having a conversation with a human.{history}Human: {human_input}AI: """prompt = PromptTemplate(input_variables=["history", "human_input"], template=template)# Add the memory to an LLMChain as usualllm_chain = LLMChain(llm=OpenAI(), prompt=prompt, memory=memory)API Reference:LLMChainOpenAIPromptTemplateConversational Streamlit apps will often re-draw each previous chat message on every re-run. This is easy to do by iterating through StreamlitChatMessageHistory.messages:import streamlit as stfor msg in msgs.messages:    st.chat_message(msg.type).write(msg.content)if prompt := st.chat_input():    st.chat_message("human").write(prompt)    # As usual, new messages are added to StreamlitChatMessageHistory when the Chain is called.    response = llm_chain.run(prompt)    st.chat_message("ai").write(response)View the final app. from langchain.memory import StreamlitChatMessageHistoryhistory = StreamlitChatMessageHistory(key="chat_messages")history.add_user_message("hi!")history.add_ai_message("whats up?") from langchain.memory import StreamlitChatMessageHistoryhistory = StreamlitChatMessageHistory(key="chat_messages")history.add_user_message("hi!")history.add_ai_message("whats up?")  API Reference:StreamlitChatMessageHistory history.messages history.messages  from langchain.memory import ConversationBufferMemoryfrom langchain.memory.chat_message_histories import StreamlitChatMessageHistory# Optionally, specify your own session_state key for storing messagesmsgs = StreamlitChatMessageHistory(key="special_app_key")memory = ConversationBufferMemory(memory_key="history", chat_memory=msgs)if len(msgs.messages) == 0:    msgs.add_ai_message("How can I help you?") from langchain.memory import ConversationBufferMemoryfrom langchain.memory.chat_message_histories import StreamlitChatMessageHistory# Optionally, specify your own session_state key for storing messagesmsgs = StreamlitChatMessageHistory(key="special_app_key")memory = ConversationBufferMemory(memory_key="history", chat_memory=msgs)if len(msgs.messages) == 0:    msgs.add_ai_message("How can I help you?")  API Reference:ConversationBufferMemoryStreamlitChatMessageHistory from langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatetemplate = """You are an AI chatbot having a conversation with a human.{history}Human: {human_input}AI: """prompt = PromptTemplate(input_variables=["history", "human_input"], template=template)# Add the memory to an LLMChain as usualllm_chain = LLMChain(llm=OpenAI(), prompt=prompt, memory=memory) from langchain.chains import LLMChainfrom langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatetemplate = """You are an AI chatbot having a conversation with a human.{history}Human: {human_input}AI: """prompt = PromptTemplate(input_variables=["history", "human_input"], template=template)# Add the memory to an LLMChain as usualllm_chain = LLMChain(llm=OpenAI(), prompt=prompt, memory=memory)  API Reference:LLMChainOpenAIPromptTemplate import streamlit as stfor msg in msgs.messages:    st.chat_message(msg.type).write(msg.content)if prompt := st.chat_input():    st.chat_message("human").write(prompt)    # As usual, new messages are added to StreamlitChatMessageHistory when the Chain is called.    response = llm_chain.run(prompt)    st.chat_message("ai").write(response) import streamlit as stfor msg in msgs.messages:    st.chat_message(msg.type).write(msg.content)if prompt := st.chat_input():    st.chat_message("human").write(prompt)    # As usual, new messages are added to StreamlitChatMessageHistory when the Chain is called.    response = llm_chain.run(prompt)    st.chat_message("ai").write(response)  Previous SQL Chat Message History Next Xata chat memory CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Cassandra Chat Message History (/docs/integrations/memory/cassandra_chat_message_history) Dynamodb Chat Message History (/docs/integrations/memory/dynamodb_chat_message_history) Entity Memory with SQLite storage (/docs/integrations/memory/entity_memory_with_sqlite) Momento Chat Message History (/docs/integrations/memory/momento_chat_message_history) Mongodb Chat Message History (/docs/integrations/memory/mongodb_chat_message_history) Mot√∂rhead Memory (/docs/integrations/memory/motorhead_memory) Mot√∂rhead Memory (Managed) (/docs/integrations/memory/motorhead_memory_managed) Postgres Chat Message History (/docs/integrations/memory/postgres_chat_message_history) Redis Chat Message History (/docs/integrations/memory/redis_chat_message_history) Rockset Chat Message History (/docs/integrations/memory/rockset_chat_message_history) SQL Chat Message History (/docs/integrations/memory/sql_chat_message_history) Streamlit Chat Message History (/docs/integrations/memory/streamlit_chat_message_history) Xata chat memory (/docs/integrations/memory/xata_chat_message_history) Zep Memory (/docs/integrations/memory/zep_memory) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Memory (/docs/integrations/memory/) Streamlit session state (https://docs.streamlit.io/library/api-reference/session-state) StreamlitCallbackHandler (/docs/integrations/callbacks/streamlit) getting started documentation (https://docs.streamlit.io/library/get-started) full app example running here (https://langchain-st-memory.streamlit.app/) github.com/langchain-ai/streamlit-agent (https://github.com/langchain-ai/streamlit-agent) StreamlitChatMessageHistory (https://api.python.langchain.com/en/latest/memory/langchain.memory.chat_message_histories.streamlit.StreamlitChatMessageHistory.html) ConversationBufferMemory (https://api.python.langchain.com/en/latest/memory/langchain.memory.buffer.ConversationBufferMemory.html) StreamlitChatMessageHistory (https://api.python.langchain.com/en/latest/memory/langchain.memory.chat_message_histories.streamlit.StreamlitChatMessageHistory.html) LLMChain (https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html) OpenAI (https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html) PromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html) View the final app (https://langchain-st-memory.streamlit.app/) PreviousSQL Chat Message History (/docs/integrations/memory/sql_chat_message_history) NextXata chat memory (/docs/integrations/memory/xata_chat_message_history) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)