Qdrant (read: quadrant ) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural network or semantic-based matching, faceted search, and other applications. This notebook shows how to use functionality related to the Qdrant vector database.  There are various modes of how to run Qdrant, and depending on the chosen one, there will be some subtle differences. The options include: See the installation instructions. We want to use OpenAIEmbeddings so we have to get the OpenAI API Key. Python client allows you to run the same code in local mode without running the Qdrant server. That's great for testing things out and debugging or if you plan to store just a small amount of vectors. The embeddings might be fully kepy in memory or persisted on disk. For some testing scenarios and quick experiments, you may prefer to keep all the data in memory only, so it gets lost when the client is destroyed - usually at the end of your script/notebook. Local mode, without using the Qdrant server, may also store your vectors on disk so they're persisted between runs. No matter if you choose to launch Qdrant locally with a Docker container, or select a Kubernetes deployment with the official Helm chart, the way you're going to connect to such an instance will be identical. You'll need to provide a URL pointing to the service. If you prefer not to keep yourself busy with managing the infrastructure, you can choose to set up a fully-managed Qdrant cluster on Qdrant Cloud. There is a free forever 1GB cluster included for trying out. The main difference with using a managed version of Qdrant is that you'll need to provide an API key to secure your deployment from being accessed publicly. Both Qdrant.from_texts and Qdrant.from_documents methods are great to start using Qdrant with Langchain. In the previous versions the collection was recreated every time you called any of them. That behaviour has changed. Currently, the collection is going to be reused if it already exists. Setting force_recreate to True allows to remove the old collection and start from scratch. The simplest scenario for using Qdrant vector store is to perform a similarity search. Under the hood, our query will be encoded with the embedding_function and used to find similar documents in Qdrant collection. Sometimes we might want to perform the search, but also obtain a relevancy score to know how good is a particular result. The returned distance score is cosine distance. Therefore, a lower score is better. Qdrant has an extensive filtering system with rich type support. It is also possible to use the filters in Langchain, by passing an additional param to both the similarity_search_with_score and similarity_search methods. If you'd like to look up for some similar documents, but you'd also like to receive diverse results, MMR is method you should consider. Maximal marginal relevance optimizes for similarity to query AND diversity among selected documents. Qdrant, as all the other vector stores, is a LangChain Retriever, by using cosine similarity.  It might be also specified to use MMR as a search strategy, instead of similarity. There are some options to use an existing Qdrant collection within your Langchain application. In such cases you may need to define how to map Qdrant point into the Langchain Document. Qdrant supports multiple vectors per point by named vectors. Langchain requires just a single embedding per document and, by default, uses a single vector. However, if you work with a collection created externally or want to have the named vector used, you can configure it by providing its name. As a Langchain user, you won't see any difference whether you use named vectors or not. Qdrant integration will handle the conversion under the hood. Qdrant stores your vector embeddings along with the optional JSON-like payload. Payloads are optional, but since LangChain assumes the embeddings are generated from the documents, we keep the context data, so you can extract the original texts as well. By default, your document is going to be stored in the following payload structure: You can, however, decide to use different keys for the page content and metadata. That's useful if you already have a collection that you'd like to reuse. IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by provider Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZilliz Activeloop Deep Lake Alibaba Cloud OpenSearch AnalyticDB Annoy Atlas AwaDB Azure Cognitive Search BagelDB Cassandra Chroma ClickHouse DashVector Dingo DocArray HnswSearch DocArray InMemorySearch Elasticsearch Epsilla Faiss Hologres LanceDB Marqo Google Vertex AI MatchingEngine Meilisearch Milvus MongoDB Atlas MyScale Neo4j Vector Index NucliaDB OpenSearch Postgres Embedding PGVector Pinecone Qdrant Redis Rockset ScaNN SingleStoreDB scikit-learn sqlite-vss StarRocks Supabase (Postgres) Tair Tencent Cloud VectorDB Tigris Typesense USearch vearch Vectara Weaviate Xata Zep Zilliz Grouped by provider  Integrations Vector stores Qdrant Local mode, no server required On-premise server deployment Qdrant Cloud OpenAIEmbeddings CharacterTextSplitter Qdrant TextLoader Connecting to Qdrant from LangChainLocal modeOn-premise server deploymentQdrant Cloud Local mode On-premise server deployment Qdrant Cloud Recreating the collection Similarity search Similarity search with scoreMetadata filtering Metadata filtering Maximum marginal relevance search (MMR) Qdrant as a Retriever Customizing QdrantNamed vectorsMetadata Named vectors Metadata Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by providerIntegrationsVector storesQdrantOn this pageQdrantQdrant (read: quadrant ) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural network or semantic-based matching, faceted search, and other applications.This notebook shows how to use functionality related to the Qdrant vector database. There are various modes of how to run Qdrant, and depending on the chosen one, there will be some subtle differences. The options include:Local mode, no server requiredOn-premise server deploymentQdrant CloudSee the installation instructions.pip install qdrant-clientWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")    OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Qdrantfrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterQdrantTextLoaderloader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()Connecting to Qdrant from LangChain‚ÄãLocal mode‚ÄãPython client allows you to run the same code in local mode without running the Qdrant server. That's great for testing things out and debugging or if you plan to store just a small amount of vectors. The embeddings might be fully kepy in memory or persisted on disk.In-memory‚ÄãFor some testing scenarios and quick experiments, you may prefer to keep all the data in memory only, so it gets lost when the client is destroyed - usually at the end of your script/notebook.qdrant = Qdrant.from_documents(    docs,    embeddings,    location=":memory:",  # Local mode with in-memory storage only    collection_name="my_documents",)On-disk storage‚ÄãLocal mode, without using the Qdrant server, may also store your vectors on disk so they're persisted between runs.qdrant = Qdrant.from_documents(    docs,    embeddings,    path="/tmp/local_qdrant",    collection_name="my_documents",)On-premise server deployment‚ÄãNo matter if you choose to launch Qdrant locally with a Docker container, or select a Kubernetes deployment with the official Helm chart, the way you're going to connect to such an instance will be identical. You'll need to provide a URL pointing to the service.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",)Qdrant Cloud‚ÄãIf you prefer not to keep yourself busy with managing the infrastructure, you can choose to set up a fully-managed Qdrant cluster on Qdrant Cloud. There is a free forever 1GB cluster included for trying out. The main difference with using a managed version of Qdrant is that you'll need to provide an API key to secure your deployment from being accessed publicly.url = "<---qdrant cloud cluster url here --->"api_key = "<---api key here--->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    api_key=api_key,    collection_name="my_documents",)Recreating the collection‚ÄãBoth Qdrant.from_texts and Qdrant.from_documents methods are great to start using Qdrant with Langchain. In the previous versions the collection was recreated every time you called any of them. That behaviour has changed. Currently, the collection is going to be reused if it already exists. Setting force_recreate to True allows to remove the old collection and start from scratch.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",    force_recreate=True,)Similarity search‚ÄãThe simplest scenario for using Qdrant vector store is to perform a similarity search. Under the hood, our query will be encoded with the embedding_function and used to find similar documents in Qdrant collection.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search(query)print(found_docs[0].page_content)    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.Similarity search with score‚ÄãSometimes we might want to perform the search, but also obtain a relevancy score to know how good is a particular result. The returned distance score is cosine distance. Therefore, a lower score is better.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query)document, score = found_docs[0]print(document.page_content)print(f"\nScore: {score}")    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.        Score: 0.8153784913324512Metadata filtering‚ÄãQdrant has an extensive filtering system with rich type support. It is also possible to use the filters in Langchain, by passing an additional param to both the similarity_search_with_score and similarity_search methods.from qdrant_client.http import models as restquery = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query, filter=rest.Filter(...))Maximum marginal relevance search (MMR)‚ÄãIf you'd like to look up for some similar documents, but you'd also like to receive diverse results, MMR is method you should consider. Maximal marginal relevance optimizes for similarity to query AND diversity among selected documents.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.max_marginal_relevance_search(query, k=2, fetch_k=10)for i, doc in enumerate(found_docs):    print(f"{i + 1}.", doc.page_content, "\n")    1. Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.         2. We can‚Äôt change how divided we‚Äôve been. But we can change how we move forward‚Äîon COVID-19 and other issues we must face together.         I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera.         They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun.         Officer Mora was 27 years old.         Officer Rivera was 22.         Both Dominican Americans who‚Äôd grown up on the same streets they later chose to patrol as police officers.         I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.         I‚Äôve worked on these issues a long time.         I know what works: Investing in crime preventionand community police officers who‚Äôll walk the beat, who‚Äôll know the neighborhood, and who can restore trust and safety.     Qdrant as a Retriever‚ÄãQdrant, as all the other vector stores, is a LangChain Retriever, by using cosine similarity. retriever = qdrant.as_retriever()retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='similarity', search_kwargs={})It might be also specified to use MMR as a search strategy, instead of similarity.retriever = qdrant.as_retriever(search_type="mmr")retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='mmr', search_kwargs={})query = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]    Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.', metadata={'source': '../../../state_of_the_union.txt'})Customizing Qdrant‚ÄãThere are some options to use an existing Qdrant collection within your Langchain application. In such cases you may need to define how to map Qdrant point into the Langchain Document.Named vectors‚ÄãQdrant supports multiple vectors per point by named vectors. Langchain requires just a single embedding per document and, by default, uses a single vector. However, if you work with a collection created externally or want to have the named vector used, you can configure it by providing its name.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    vector_name="custom_vector",)As a Langchain user, you won't see any difference whether you use named vectors or not. Qdrant integration will handle the conversion under the hood.Metadata‚ÄãQdrant stores your vector embeddings along with the optional JSON-like payload. Payloads are optional, but since LangChain assumes the embeddings are generated from the documents, we keep the context data, so you can extract the original texts as well.By default, your document is going to be stored in the following payload structure:{    "page_content": "Lorem ipsum dolor sit amet",    "metadata": {        "foo": "bar"    }}You can, however, decide to use different keys for the page content and metadata. That's useful if you already have a collection that you'd like to reuse.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    content_payload_key="my_page_content_key",    metadata_payload_key="my_meta",)    <langchain.vectorstores.qdrant.Qdrant at 0x7fc4e2baa230>PreviousPineconeNextRedisConnecting to Qdrant from LangChainLocal modeOn-premise server deploymentQdrant CloudRecreating the collectionSimilarity searchSimilarity search with scoreMetadata filteringMaximum marginal relevance search (MMR)Qdrant as a RetrieverCustomizing QdrantNamed vectorsMetadataCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by providerIntegrationsVector storesQdrantOn this pageQdrantQdrant (read: quadrant ) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural network or semantic-based matching, faceted search, and other applications.This notebook shows how to use functionality related to the Qdrant vector database. There are various modes of how to run Qdrant, and depending on the chosen one, there will be some subtle differences. The options include:Local mode, no server requiredOn-premise server deploymentQdrant CloudSee the installation instructions.pip install qdrant-clientWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")    OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Qdrantfrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterQdrantTextLoaderloader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()Connecting to Qdrant from LangChain‚ÄãLocal mode‚ÄãPython client allows you to run the same code in local mode without running the Qdrant server. That's great for testing things out and debugging or if you plan to store just a small amount of vectors. The embeddings might be fully kepy in memory or persisted on disk.In-memory‚ÄãFor some testing scenarios and quick experiments, you may prefer to keep all the data in memory only, so it gets lost when the client is destroyed - usually at the end of your script/notebook.qdrant = Qdrant.from_documents(    docs,    embeddings,    location=":memory:",  # Local mode with in-memory storage only    collection_name="my_documents",)On-disk storage‚ÄãLocal mode, without using the Qdrant server, may also store your vectors on disk so they're persisted between runs.qdrant = Qdrant.from_documents(    docs,    embeddings,    path="/tmp/local_qdrant",    collection_name="my_documents",)On-premise server deployment‚ÄãNo matter if you choose to launch Qdrant locally with a Docker container, or select a Kubernetes deployment with the official Helm chart, the way you're going to connect to such an instance will be identical. You'll need to provide a URL pointing to the service.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",)Qdrant Cloud‚ÄãIf you prefer not to keep yourself busy with managing the infrastructure, you can choose to set up a fully-managed Qdrant cluster on Qdrant Cloud. There is a free forever 1GB cluster included for trying out. The main difference with using a managed version of Qdrant is that you'll need to provide an API key to secure your deployment from being accessed publicly.url = "<---qdrant cloud cluster url here --->"api_key = "<---api key here--->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    api_key=api_key,    collection_name="my_documents",)Recreating the collection‚ÄãBoth Qdrant.from_texts and Qdrant.from_documents methods are great to start using Qdrant with Langchain. In the previous versions the collection was recreated every time you called any of them. That behaviour has changed. Currently, the collection is going to be reused if it already exists. Setting force_recreate to True allows to remove the old collection and start from scratch.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",    force_recreate=True,)Similarity search‚ÄãThe simplest scenario for using Qdrant vector store is to perform a similarity search. Under the hood, our query will be encoded with the embedding_function and used to find similar documents in Qdrant collection.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search(query)print(found_docs[0].page_content)    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.Similarity search with score‚ÄãSometimes we might want to perform the search, but also obtain a relevancy score to know how good is a particular result. The returned distance score is cosine distance. Therefore, a lower score is better.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query)document, score = found_docs[0]print(document.page_content)print(f"\nScore: {score}")    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.        Score: 0.8153784913324512Metadata filtering‚ÄãQdrant has an extensive filtering system with rich type support. It is also possible to use the filters in Langchain, by passing an additional param to both the similarity_search_with_score and similarity_search methods.from qdrant_client.http import models as restquery = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query, filter=rest.Filter(...))Maximum marginal relevance search (MMR)‚ÄãIf you'd like to look up for some similar documents, but you'd also like to receive diverse results, MMR is method you should consider. Maximal marginal relevance optimizes for similarity to query AND diversity among selected documents.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.max_marginal_relevance_search(query, k=2, fetch_k=10)for i, doc in enumerate(found_docs):    print(f"{i + 1}.", doc.page_content, "\n")    1. Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.         2. We can‚Äôt change how divided we‚Äôve been. But we can change how we move forward‚Äîon COVID-19 and other issues we must face together.         I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera.         They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun.         Officer Mora was 27 years old.         Officer Rivera was 22.         Both Dominican Americans who‚Äôd grown up on the same streets they later chose to patrol as police officers.         I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.         I‚Äôve worked on these issues a long time.         I know what works: Investing in crime preventionand community police officers who‚Äôll walk the beat, who‚Äôll know the neighborhood, and who can restore trust and safety.     Qdrant as a Retriever‚ÄãQdrant, as all the other vector stores, is a LangChain Retriever, by using cosine similarity. retriever = qdrant.as_retriever()retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='similarity', search_kwargs={})It might be also specified to use MMR as a search strategy, instead of similarity.retriever = qdrant.as_retriever(search_type="mmr")retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='mmr', search_kwargs={})query = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]    Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.', metadata={'source': '../../../state_of_the_union.txt'})Customizing Qdrant‚ÄãThere are some options to use an existing Qdrant collection within your Langchain application. In such cases you may need to define how to map Qdrant point into the Langchain Document.Named vectors‚ÄãQdrant supports multiple vectors per point by named vectors. Langchain requires just a single embedding per document and, by default, uses a single vector. However, if you work with a collection created externally or want to have the named vector used, you can configure it by providing its name.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    vector_name="custom_vector",)As a Langchain user, you won't see any difference whether you use named vectors or not. Qdrant integration will handle the conversion under the hood.Metadata‚ÄãQdrant stores your vector embeddings along with the optional JSON-like payload. Payloads are optional, but since LangChain assumes the embeddings are generated from the documents, we keep the context data, so you can extract the original texts as well.By default, your document is going to be stored in the following payload structure:{    "page_content": "Lorem ipsum dolor sit amet",    "metadata": {        "foo": "bar"    }}You can, however, decide to use different keys for the page content and metadata. That's useful if you already have a collection that you'd like to reuse.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    content_payload_key="my_page_content_key",    metadata_payload_key="my_meta",)    <langchain.vectorstores.qdrant.Qdrant at 0x7fc4e2baa230>PreviousPineconeNextRedisConnecting to Qdrant from LangChainLocal modeOn-premise server deploymentQdrant CloudRecreating the collectionSimilarity searchSimilarity search with scoreMetadata filteringMaximum marginal relevance search (MMR)Qdrant as a RetrieverCustomizing QdrantNamed vectorsMetadata IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by providerIntegrationsVector storesQdrantOn this pageQdrantQdrant (read: quadrant ) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural network or semantic-based matching, faceted search, and other applications.This notebook shows how to use functionality related to the Qdrant vector database. There are various modes of how to run Qdrant, and depending on the chosen one, there will be some subtle differences. The options include:Local mode, no server requiredOn-premise server deploymentQdrant CloudSee the installation instructions.pip install qdrant-clientWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")    OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Qdrantfrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterQdrantTextLoaderloader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()Connecting to Qdrant from LangChain‚ÄãLocal mode‚ÄãPython client allows you to run the same code in local mode without running the Qdrant server. That's great for testing things out and debugging or if you plan to store just a small amount of vectors. The embeddings might be fully kepy in memory or persisted on disk.In-memory‚ÄãFor some testing scenarios and quick experiments, you may prefer to keep all the data in memory only, so it gets lost when the client is destroyed - usually at the end of your script/notebook.qdrant = Qdrant.from_documents(    docs,    embeddings,    location=":memory:",  # Local mode with in-memory storage only    collection_name="my_documents",)On-disk storage‚ÄãLocal mode, without using the Qdrant server, may also store your vectors on disk so they're persisted between runs.qdrant = Qdrant.from_documents(    docs,    embeddings,    path="/tmp/local_qdrant",    collection_name="my_documents",)On-premise server deployment‚ÄãNo matter if you choose to launch Qdrant locally with a Docker container, or select a Kubernetes deployment with the official Helm chart, the way you're going to connect to such an instance will be identical. You'll need to provide a URL pointing to the service.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",)Qdrant Cloud‚ÄãIf you prefer not to keep yourself busy with managing the infrastructure, you can choose to set up a fully-managed Qdrant cluster on Qdrant Cloud. There is a free forever 1GB cluster included for trying out. The main difference with using a managed version of Qdrant is that you'll need to provide an API key to secure your deployment from being accessed publicly.url = "<---qdrant cloud cluster url here --->"api_key = "<---api key here--->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    api_key=api_key,    collection_name="my_documents",)Recreating the collection‚ÄãBoth Qdrant.from_texts and Qdrant.from_documents methods are great to start using Qdrant with Langchain. In the previous versions the collection was recreated every time you called any of them. That behaviour has changed. Currently, the collection is going to be reused if it already exists. Setting force_recreate to True allows to remove the old collection and start from scratch.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",    force_recreate=True,)Similarity search‚ÄãThe simplest scenario for using Qdrant vector store is to perform a similarity search. Under the hood, our query will be encoded with the embedding_function and used to find similar documents in Qdrant collection.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search(query)print(found_docs[0].page_content)    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.Similarity search with score‚ÄãSometimes we might want to perform the search, but also obtain a relevancy score to know how good is a particular result. The returned distance score is cosine distance. Therefore, a lower score is better.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query)document, score = found_docs[0]print(document.page_content)print(f"\nScore: {score}")    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.        Score: 0.8153784913324512Metadata filtering‚ÄãQdrant has an extensive filtering system with rich type support. It is also possible to use the filters in Langchain, by passing an additional param to both the similarity_search_with_score and similarity_search methods.from qdrant_client.http import models as restquery = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query, filter=rest.Filter(...))Maximum marginal relevance search (MMR)‚ÄãIf you'd like to look up for some similar documents, but you'd also like to receive diverse results, MMR is method you should consider. Maximal marginal relevance optimizes for similarity to query AND diversity among selected documents.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.max_marginal_relevance_search(query, k=2, fetch_k=10)for i, doc in enumerate(found_docs):    print(f"{i + 1}.", doc.page_content, "\n")    1. Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.         2. We can‚Äôt change how divided we‚Äôve been. But we can change how we move forward‚Äîon COVID-19 and other issues we must face together.         I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera.         They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun.         Officer Mora was 27 years old.         Officer Rivera was 22.         Both Dominican Americans who‚Äôd grown up on the same streets they later chose to patrol as police officers.         I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.         I‚Äôve worked on these issues a long time.         I know what works: Investing in crime preventionand community police officers who‚Äôll walk the beat, who‚Äôll know the neighborhood, and who can restore trust and safety.     Qdrant as a Retriever‚ÄãQdrant, as all the other vector stores, is a LangChain Retriever, by using cosine similarity. retriever = qdrant.as_retriever()retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='similarity', search_kwargs={})It might be also specified to use MMR as a search strategy, instead of similarity.retriever = qdrant.as_retriever(search_type="mmr")retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='mmr', search_kwargs={})query = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]    Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.', metadata={'source': '../../../state_of_the_union.txt'})Customizing Qdrant‚ÄãThere are some options to use an existing Qdrant collection within your Langchain application. In such cases you may need to define how to map Qdrant point into the Langchain Document.Named vectors‚ÄãQdrant supports multiple vectors per point by named vectors. Langchain requires just a single embedding per document and, by default, uses a single vector. However, if you work with a collection created externally or want to have the named vector used, you can configure it by providing its name.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    vector_name="custom_vector",)As a Langchain user, you won't see any difference whether you use named vectors or not. Qdrant integration will handle the conversion under the hood.Metadata‚ÄãQdrant stores your vector embeddings along with the optional JSON-like payload. Payloads are optional, but since LangChain assumes the embeddings are generated from the documents, we keep the context data, so you can extract the original texts as well.By default, your document is going to be stored in the following payload structure:{    "page_content": "Lorem ipsum dolor sit amet",    "metadata": {        "foo": "bar"    }}You can, however, decide to use different keys for the page content and metadata. That's useful if you already have a collection that you'd like to reuse.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    content_payload_key="my_page_content_key",    metadata_payload_key="my_meta",)    <langchain.vectorstores.qdrant.Qdrant at 0x7fc4e2baa230>PreviousPineconeNextRedisConnecting to Qdrant from LangChainLocal modeOn-premise server deploymentQdrant CloudRecreating the collectionSimilarity searchSimilarity search with scoreMetadata filteringMaximum marginal relevance search (MMR)Qdrant as a RetrieverCustomizing QdrantNamed vectorsMetadata IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversText embedding modelsAgents & ToolkitsToolsVector storesActiveloop Deep LakeAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchBagelDBCassandraChromaClickHouseDashVectorDingoDocArray HnswSearchDocArray InMemorySearchElasticsearchEpsillaFaissHologresLanceDBMarqoGoogle Vertex AI MatchingEngineMeilisearchMilvusMongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOpenSearchPostgres EmbeddingPGVectorPineconeQdrantRedisRocksetScaNNSingleStoreDBscikit-learnsqlite-vssStarRocksSupabase (Postgres)TairTencent Cloud VectorDBTigrisTypesenseUSearchvearchVectaraWeaviateXataZepZillizGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsVector storesQdrantOn this pageQdrantQdrant (read: quadrant ) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural network or semantic-based matching, faceted search, and other applications.This notebook shows how to use functionality related to the Qdrant vector database. There are various modes of how to run Qdrant, and depending on the chosen one, there will be some subtle differences. The options include:Local mode, no server requiredOn-premise server deploymentQdrant CloudSee the installation instructions.pip install qdrant-clientWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")    OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Qdrantfrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterQdrantTextLoaderloader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()Connecting to Qdrant from LangChain‚ÄãLocal mode‚ÄãPython client allows you to run the same code in local mode without running the Qdrant server. That's great for testing things out and debugging or if you plan to store just a small amount of vectors. The embeddings might be fully kepy in memory or persisted on disk.In-memory‚ÄãFor some testing scenarios and quick experiments, you may prefer to keep all the data in memory only, so it gets lost when the client is destroyed - usually at the end of your script/notebook.qdrant = Qdrant.from_documents(    docs,    embeddings,    location=":memory:",  # Local mode with in-memory storage only    collection_name="my_documents",)On-disk storage‚ÄãLocal mode, without using the Qdrant server, may also store your vectors on disk so they're persisted between runs.qdrant = Qdrant.from_documents(    docs,    embeddings,    path="/tmp/local_qdrant",    collection_name="my_documents",)On-premise server deployment‚ÄãNo matter if you choose to launch Qdrant locally with a Docker container, or select a Kubernetes deployment with the official Helm chart, the way you're going to connect to such an instance will be identical. You'll need to provide a URL pointing to the service.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",)Qdrant Cloud‚ÄãIf you prefer not to keep yourself busy with managing the infrastructure, you can choose to set up a fully-managed Qdrant cluster on Qdrant Cloud. There is a free forever 1GB cluster included for trying out. The main difference with using a managed version of Qdrant is that you'll need to provide an API key to secure your deployment from being accessed publicly.url = "<---qdrant cloud cluster url here --->"api_key = "<---api key here--->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    api_key=api_key,    collection_name="my_documents",)Recreating the collection‚ÄãBoth Qdrant.from_texts and Qdrant.from_documents methods are great to start using Qdrant with Langchain. In the previous versions the collection was recreated every time you called any of them. That behaviour has changed. Currently, the collection is going to be reused if it already exists. Setting force_recreate to True allows to remove the old collection and start from scratch.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",    force_recreate=True,)Similarity search‚ÄãThe simplest scenario for using Qdrant vector store is to perform a similarity search. Under the hood, our query will be encoded with the embedding_function and used to find similar documents in Qdrant collection.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search(query)print(found_docs[0].page_content)    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.Similarity search with score‚ÄãSometimes we might want to perform the search, but also obtain a relevancy score to know how good is a particular result. The returned distance score is cosine distance. Therefore, a lower score is better.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query)document, score = found_docs[0]print(document.page_content)print(f"\nScore: {score}")    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.        Score: 0.8153784913324512Metadata filtering‚ÄãQdrant has an extensive filtering system with rich type support. It is also possible to use the filters in Langchain, by passing an additional param to both the similarity_search_with_score and similarity_search methods.from qdrant_client.http import models as restquery = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query, filter=rest.Filter(...))Maximum marginal relevance search (MMR)‚ÄãIf you'd like to look up for some similar documents, but you'd also like to receive diverse results, MMR is method you should consider. Maximal marginal relevance optimizes for similarity to query AND diversity among selected documents.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.max_marginal_relevance_search(query, k=2, fetch_k=10)for i, doc in enumerate(found_docs):    print(f"{i + 1}.", doc.page_content, "\n")    1. Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.         2. We can‚Äôt change how divided we‚Äôve been. But we can change how we move forward‚Äîon COVID-19 and other issues we must face together.         I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera.         They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun.         Officer Mora was 27 years old.         Officer Rivera was 22.         Both Dominican Americans who‚Äôd grown up on the same streets they later chose to patrol as police officers.         I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.         I‚Äôve worked on these issues a long time.         I know what works: Investing in crime preventionand community police officers who‚Äôll walk the beat, who‚Äôll know the neighborhood, and who can restore trust and safety.     Qdrant as a Retriever‚ÄãQdrant, as all the other vector stores, is a LangChain Retriever, by using cosine similarity. retriever = qdrant.as_retriever()retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='similarity', search_kwargs={})It might be also specified to use MMR as a search strategy, instead of similarity.retriever = qdrant.as_retriever(search_type="mmr")retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='mmr', search_kwargs={})query = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]    Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.', metadata={'source': '../../../state_of_the_union.txt'})Customizing Qdrant‚ÄãThere are some options to use an existing Qdrant collection within your Langchain application. In such cases you may need to define how to map Qdrant point into the Langchain Document.Named vectors‚ÄãQdrant supports multiple vectors per point by named vectors. Langchain requires just a single embedding per document and, by default, uses a single vector. However, if you work with a collection created externally or want to have the named vector used, you can configure it by providing its name.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    vector_name="custom_vector",)As a Langchain user, you won't see any difference whether you use named vectors or not. Qdrant integration will handle the conversion under the hood.Metadata‚ÄãQdrant stores your vector embeddings along with the optional JSON-like payload. Payloads are optional, but since LangChain assumes the embeddings are generated from the documents, we keep the context data, so you can extract the original texts as well.By default, your document is going to be stored in the following payload structure:{    "page_content": "Lorem ipsum dolor sit amet",    "metadata": {        "foo": "bar"    }}You can, however, decide to use different keys for the page content and metadata. That's useful if you already have a collection that you'd like to reuse.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    content_payload_key="my_page_content_key",    metadata_payload_key="my_meta",)    <langchain.vectorstores.qdrant.Qdrant at 0x7fc4e2baa230>PreviousPineconeNextRedisConnecting to Qdrant from LangChainLocal modeOn-premise server deploymentQdrant CloudRecreating the collectionSimilarity searchSimilarity search with scoreMetadata filteringMaximum marginal relevance search (MMR)Qdrant as a RetrieverCustomizing QdrantNamed vectorsMetadata IntegrationsVector storesQdrantOn this pageQdrantQdrant (read: quadrant ) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural network or semantic-based matching, faceted search, and other applications.This notebook shows how to use functionality related to the Qdrant vector database. There are various modes of how to run Qdrant, and depending on the chosen one, there will be some subtle differences. The options include:Local mode, no server requiredOn-premise server deploymentQdrant CloudSee the installation instructions.pip install qdrant-clientWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")    OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Qdrantfrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterQdrantTextLoaderloader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()Connecting to Qdrant from LangChain‚ÄãLocal mode‚ÄãPython client allows you to run the same code in local mode without running the Qdrant server. That's great for testing things out and debugging or if you plan to store just a small amount of vectors. The embeddings might be fully kepy in memory or persisted on disk.In-memory‚ÄãFor some testing scenarios and quick experiments, you may prefer to keep all the data in memory only, so it gets lost when the client is destroyed - usually at the end of your script/notebook.qdrant = Qdrant.from_documents(    docs,    embeddings,    location=":memory:",  # Local mode with in-memory storage only    collection_name="my_documents",)On-disk storage‚ÄãLocal mode, without using the Qdrant server, may also store your vectors on disk so they're persisted between runs.qdrant = Qdrant.from_documents(    docs,    embeddings,    path="/tmp/local_qdrant",    collection_name="my_documents",)On-premise server deployment‚ÄãNo matter if you choose to launch Qdrant locally with a Docker container, or select a Kubernetes deployment with the official Helm chart, the way you're going to connect to such an instance will be identical. You'll need to provide a URL pointing to the service.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",)Qdrant Cloud‚ÄãIf you prefer not to keep yourself busy with managing the infrastructure, you can choose to set up a fully-managed Qdrant cluster on Qdrant Cloud. There is a free forever 1GB cluster included for trying out. The main difference with using a managed version of Qdrant is that you'll need to provide an API key to secure your deployment from being accessed publicly.url = "<---qdrant cloud cluster url here --->"api_key = "<---api key here--->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    api_key=api_key,    collection_name="my_documents",)Recreating the collection‚ÄãBoth Qdrant.from_texts and Qdrant.from_documents methods are great to start using Qdrant with Langchain. In the previous versions the collection was recreated every time you called any of them. That behaviour has changed. Currently, the collection is going to be reused if it already exists. Setting force_recreate to True allows to remove the old collection and start from scratch.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",    force_recreate=True,)Similarity search‚ÄãThe simplest scenario for using Qdrant vector store is to perform a similarity search. Under the hood, our query will be encoded with the embedding_function and used to find similar documents in Qdrant collection.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search(query)print(found_docs[0].page_content)    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.Similarity search with score‚ÄãSometimes we might want to perform the search, but also obtain a relevancy score to know how good is a particular result. The returned distance score is cosine distance. Therefore, a lower score is better.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query)document, score = found_docs[0]print(document.page_content)print(f"\nScore: {score}")    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.        Score: 0.8153784913324512Metadata filtering‚ÄãQdrant has an extensive filtering system with rich type support. It is also possible to use the filters in Langchain, by passing an additional param to both the similarity_search_with_score and similarity_search methods.from qdrant_client.http import models as restquery = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query, filter=rest.Filter(...))Maximum marginal relevance search (MMR)‚ÄãIf you'd like to look up for some similar documents, but you'd also like to receive diverse results, MMR is method you should consider. Maximal marginal relevance optimizes for similarity to query AND diversity among selected documents.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.max_marginal_relevance_search(query, k=2, fetch_k=10)for i, doc in enumerate(found_docs):    print(f"{i + 1}.", doc.page_content, "\n")    1. Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.         2. We can‚Äôt change how divided we‚Äôve been. But we can change how we move forward‚Äîon COVID-19 and other issues we must face together.         I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera.         They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun.         Officer Mora was 27 years old.         Officer Rivera was 22.         Both Dominican Americans who‚Äôd grown up on the same streets they later chose to patrol as police officers.         I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.         I‚Äôve worked on these issues a long time.         I know what works: Investing in crime preventionand community police officers who‚Äôll walk the beat, who‚Äôll know the neighborhood, and who can restore trust and safety.     Qdrant as a Retriever‚ÄãQdrant, as all the other vector stores, is a LangChain Retriever, by using cosine similarity. retriever = qdrant.as_retriever()retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='similarity', search_kwargs={})It might be also specified to use MMR as a search strategy, instead of similarity.retriever = qdrant.as_retriever(search_type="mmr")retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='mmr', search_kwargs={})query = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]    Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.', metadata={'source': '../../../state_of_the_union.txt'})Customizing Qdrant‚ÄãThere are some options to use an existing Qdrant collection within your Langchain application. In such cases you may need to define how to map Qdrant point into the Langchain Document.Named vectors‚ÄãQdrant supports multiple vectors per point by named vectors. Langchain requires just a single embedding per document and, by default, uses a single vector. However, if you work with a collection created externally or want to have the named vector used, you can configure it by providing its name.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    vector_name="custom_vector",)As a Langchain user, you won't see any difference whether you use named vectors or not. Qdrant integration will handle the conversion under the hood.Metadata‚ÄãQdrant stores your vector embeddings along with the optional JSON-like payload. Payloads are optional, but since LangChain assumes the embeddings are generated from the documents, we keep the context data, so you can extract the original texts as well.By default, your document is going to be stored in the following payload structure:{    "page_content": "Lorem ipsum dolor sit amet",    "metadata": {        "foo": "bar"    }}You can, however, decide to use different keys for the page content and metadata. That's useful if you already have a collection that you'd like to reuse.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    content_payload_key="my_page_content_key",    metadata_payload_key="my_meta",)    <langchain.vectorstores.qdrant.Qdrant at 0x7fc4e2baa230>PreviousPineconeNextRedis IntegrationsVector storesQdrantOn this pageQdrantQdrant (read: quadrant ) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural network or semantic-based matching, faceted search, and other applications.This notebook shows how to use functionality related to the Qdrant vector database. There are various modes of how to run Qdrant, and depending on the chosen one, there will be some subtle differences. The options include:Local mode, no server requiredOn-premise server deploymentQdrant CloudSee the installation instructions.pip install qdrant-clientWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")    OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Qdrantfrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterQdrantTextLoaderloader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()Connecting to Qdrant from LangChain‚ÄãLocal mode‚ÄãPython client allows you to run the same code in local mode without running the Qdrant server. That's great for testing things out and debugging or if you plan to store just a small amount of vectors. The embeddings might be fully kepy in memory or persisted on disk.In-memory‚ÄãFor some testing scenarios and quick experiments, you may prefer to keep all the data in memory only, so it gets lost when the client is destroyed - usually at the end of your script/notebook.qdrant = Qdrant.from_documents(    docs,    embeddings,    location=":memory:",  # Local mode with in-memory storage only    collection_name="my_documents",)On-disk storage‚ÄãLocal mode, without using the Qdrant server, may also store your vectors on disk so they're persisted between runs.qdrant = Qdrant.from_documents(    docs,    embeddings,    path="/tmp/local_qdrant",    collection_name="my_documents",)On-premise server deployment‚ÄãNo matter if you choose to launch Qdrant locally with a Docker container, or select a Kubernetes deployment with the official Helm chart, the way you're going to connect to such an instance will be identical. You'll need to provide a URL pointing to the service.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",)Qdrant Cloud‚ÄãIf you prefer not to keep yourself busy with managing the infrastructure, you can choose to set up a fully-managed Qdrant cluster on Qdrant Cloud. There is a free forever 1GB cluster included for trying out. The main difference with using a managed version of Qdrant is that you'll need to provide an API key to secure your deployment from being accessed publicly.url = "<---qdrant cloud cluster url here --->"api_key = "<---api key here--->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    api_key=api_key,    collection_name="my_documents",)Recreating the collection‚ÄãBoth Qdrant.from_texts and Qdrant.from_documents methods are great to start using Qdrant with Langchain. In the previous versions the collection was recreated every time you called any of them. That behaviour has changed. Currently, the collection is going to be reused if it already exists. Setting force_recreate to True allows to remove the old collection and start from scratch.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",    force_recreate=True,)Similarity search‚ÄãThe simplest scenario for using Qdrant vector store is to perform a similarity search. Under the hood, our query will be encoded with the embedding_function and used to find similar documents in Qdrant collection.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search(query)print(found_docs[0].page_content)    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.Similarity search with score‚ÄãSometimes we might want to perform the search, but also obtain a relevancy score to know how good is a particular result. The returned distance score is cosine distance. Therefore, a lower score is better.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query)document, score = found_docs[0]print(document.page_content)print(f"\nScore: {score}")    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.        Score: 0.8153784913324512Metadata filtering‚ÄãQdrant has an extensive filtering system with rich type support. It is also possible to use the filters in Langchain, by passing an additional param to both the similarity_search_with_score and similarity_search methods.from qdrant_client.http import models as restquery = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query, filter=rest.Filter(...))Maximum marginal relevance search (MMR)‚ÄãIf you'd like to look up for some similar documents, but you'd also like to receive diverse results, MMR is method you should consider. Maximal marginal relevance optimizes for similarity to query AND diversity among selected documents.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.max_marginal_relevance_search(query, k=2, fetch_k=10)for i, doc in enumerate(found_docs):    print(f"{i + 1}.", doc.page_content, "\n")    1. Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.         2. We can‚Äôt change how divided we‚Äôve been. But we can change how we move forward‚Äîon COVID-19 and other issues we must face together.         I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera.         They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun.         Officer Mora was 27 years old.         Officer Rivera was 22.         Both Dominican Americans who‚Äôd grown up on the same streets they later chose to patrol as police officers.         I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.         I‚Äôve worked on these issues a long time.         I know what works: Investing in crime preventionand community police officers who‚Äôll walk the beat, who‚Äôll know the neighborhood, and who can restore trust and safety.     Qdrant as a Retriever‚ÄãQdrant, as all the other vector stores, is a LangChain Retriever, by using cosine similarity. retriever = qdrant.as_retriever()retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='similarity', search_kwargs={})It might be also specified to use MMR as a search strategy, instead of similarity.retriever = qdrant.as_retriever(search_type="mmr")retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='mmr', search_kwargs={})query = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]    Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.', metadata={'source': '../../../state_of_the_union.txt'})Customizing Qdrant‚ÄãThere are some options to use an existing Qdrant collection within your Langchain application. In such cases you may need to define how to map Qdrant point into the Langchain Document.Named vectors‚ÄãQdrant supports multiple vectors per point by named vectors. Langchain requires just a single embedding per document and, by default, uses a single vector. However, if you work with a collection created externally or want to have the named vector used, you can configure it by providing its name.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    vector_name="custom_vector",)As a Langchain user, you won't see any difference whether you use named vectors or not. Qdrant integration will handle the conversion under the hood.Metadata‚ÄãQdrant stores your vector embeddings along with the optional JSON-like payload. Payloads are optional, but since LangChain assumes the embeddings are generated from the documents, we keep the context data, so you can extract the original texts as well.By default, your document is going to be stored in the following payload structure:{    "page_content": "Lorem ipsum dolor sit amet",    "metadata": {        "foo": "bar"    }}You can, however, decide to use different keys for the page content and metadata. That's useful if you already have a collection that you'd like to reuse.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    content_payload_key="my_page_content_key",    metadata_payload_key="my_meta",)    <langchain.vectorstores.qdrant.Qdrant at 0x7fc4e2baa230>PreviousPineconeNextRedis On this page QdrantQdrant (read: quadrant ) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural network or semantic-based matching, faceted search, and other applications.This notebook shows how to use functionality related to the Qdrant vector database. There are various modes of how to run Qdrant, and depending on the chosen one, there will be some subtle differences. The options include:Local mode, no server requiredOn-premise server deploymentQdrant CloudSee the installation instructions.pip install qdrant-clientWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")    OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Qdrantfrom langchain.document_loaders import TextLoaderAPI Reference:OpenAIEmbeddingsCharacterTextSplitterQdrantTextLoaderloader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()Connecting to Qdrant from LangChain‚ÄãLocal mode‚ÄãPython client allows you to run the same code in local mode without running the Qdrant server. That's great for testing things out and debugging or if you plan to store just a small amount of vectors. The embeddings might be fully kepy in memory or persisted on disk.In-memory‚ÄãFor some testing scenarios and quick experiments, you may prefer to keep all the data in memory only, so it gets lost when the client is destroyed - usually at the end of your script/notebook.qdrant = Qdrant.from_documents(    docs,    embeddings,    location=":memory:",  # Local mode with in-memory storage only    collection_name="my_documents",)On-disk storage‚ÄãLocal mode, without using the Qdrant server, may also store your vectors on disk so they're persisted between runs.qdrant = Qdrant.from_documents(    docs,    embeddings,    path="/tmp/local_qdrant",    collection_name="my_documents",)On-premise server deployment‚ÄãNo matter if you choose to launch Qdrant locally with a Docker container, or select a Kubernetes deployment with the official Helm chart, the way you're going to connect to such an instance will be identical. You'll need to provide a URL pointing to the service.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",)Qdrant Cloud‚ÄãIf you prefer not to keep yourself busy with managing the infrastructure, you can choose to set up a fully-managed Qdrant cluster on Qdrant Cloud. There is a free forever 1GB cluster included for trying out. The main difference with using a managed version of Qdrant is that you'll need to provide an API key to secure your deployment from being accessed publicly.url = "<---qdrant cloud cluster url here --->"api_key = "<---api key here--->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    api_key=api_key,    collection_name="my_documents",)Recreating the collection‚ÄãBoth Qdrant.from_texts and Qdrant.from_documents methods are great to start using Qdrant with Langchain. In the previous versions the collection was recreated every time you called any of them. That behaviour has changed. Currently, the collection is going to be reused if it already exists. Setting force_recreate to True allows to remove the old collection and start from scratch.url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",    force_recreate=True,)Similarity search‚ÄãThe simplest scenario for using Qdrant vector store is to perform a similarity search. Under the hood, our query will be encoded with the embedding_function and used to find similar documents in Qdrant collection.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search(query)print(found_docs[0].page_content)    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.Similarity search with score‚ÄãSometimes we might want to perform the search, but also obtain a relevancy score to know how good is a particular result. The returned distance score is cosine distance. Therefore, a lower score is better.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query)document, score = found_docs[0]print(document.page_content)print(f"\nScore: {score}")    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.        Score: 0.8153784913324512Metadata filtering‚ÄãQdrant has an extensive filtering system with rich type support. It is also possible to use the filters in Langchain, by passing an additional param to both the similarity_search_with_score and similarity_search methods.from qdrant_client.http import models as restquery = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query, filter=rest.Filter(...))Maximum marginal relevance search (MMR)‚ÄãIf you'd like to look up for some similar documents, but you'd also like to receive diverse results, MMR is method you should consider. Maximal marginal relevance optimizes for similarity to query AND diversity among selected documents.query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.max_marginal_relevance_search(query, k=2, fetch_k=10)for i, doc in enumerate(found_docs):    print(f"{i + 1}.", doc.page_content, "\n")    1. Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.         2. We can‚Äôt change how divided we‚Äôve been. But we can change how we move forward‚Äîon COVID-19 and other issues we must face together.         I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera.         They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun.         Officer Mora was 27 years old.         Officer Rivera was 22.         Both Dominican Americans who‚Äôd grown up on the same streets they later chose to patrol as police officers.         I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.         I‚Äôve worked on these issues a long time.         I know what works: Investing in crime preventionand community police officers who‚Äôll walk the beat, who‚Äôll know the neighborhood, and who can restore trust and safety.     Qdrant as a Retriever‚ÄãQdrant, as all the other vector stores, is a LangChain Retriever, by using cosine similarity. retriever = qdrant.as_retriever()retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='similarity', search_kwargs={})It might be also specified to use MMR as a search strategy, instead of similarity.retriever = qdrant.as_retriever(search_type="mmr")retriever    VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='mmr', search_kwargs={})query = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]    Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.', metadata={'source': '../../../state_of_the_union.txt'})Customizing Qdrant‚ÄãThere are some options to use an existing Qdrant collection within your Langchain application. In such cases you may need to define how to map Qdrant point into the Langchain Document.Named vectors‚ÄãQdrant supports multiple vectors per point by named vectors. Langchain requires just a single embedding per document and, by default, uses a single vector. However, if you work with a collection created externally or want to have the named vector used, you can configure it by providing its name.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    vector_name="custom_vector",)As a Langchain user, you won't see any difference whether you use named vectors or not. Qdrant integration will handle the conversion under the hood.Metadata‚ÄãQdrant stores your vector embeddings along with the optional JSON-like payload. Payloads are optional, but since LangChain assumes the embeddings are generated from the documents, we keep the context data, so you can extract the original texts as well.By default, your document is going to be stored in the following payload structure:{    "page_content": "Lorem ipsum dolor sit amet",    "metadata": {        "foo": "bar"    }}You can, however, decide to use different keys for the page content and metadata. That's useful if you already have a collection that you'd like to reuse.Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    content_payload_key="my_page_content_key",    metadata_payload_key="my_meta",)    <langchain.vectorstores.qdrant.Qdrant at 0x7fc4e2baa230> pip install qdrant-client pip install qdrant-client  import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:") import osimport getpassos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")      OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑     OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑     OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑  from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Qdrantfrom langchain.document_loaders import TextLoader from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import Qdrantfrom langchain.document_loaders import TextLoader  API Reference:OpenAIEmbeddingsCharacterTextSplitterQdrantTextLoader loader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings() loader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()  qdrant = Qdrant.from_documents(    docs,    embeddings,    location=":memory:",  # Local mode with in-memory storage only    collection_name="my_documents",) qdrant = Qdrant.from_documents(    docs,    embeddings,    location=":memory:",  # Local mode with in-memory storage only    collection_name="my_documents",)  qdrant = Qdrant.from_documents(    docs,    embeddings,    path="/tmp/local_qdrant",    collection_name="my_documents",) qdrant = Qdrant.from_documents(    docs,    embeddings,    path="/tmp/local_qdrant",    collection_name="my_documents",)  url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",) url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",)  url = "<---qdrant cloud cluster url here --->"api_key = "<---api key here--->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    api_key=api_key,    collection_name="my_documents",) url = "<---qdrant cloud cluster url here --->"api_key = "<---api key here--->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    api_key=api_key,    collection_name="my_documents",)  url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",    force_recreate=True,) url = "<---qdrant url here --->"qdrant = Qdrant.from_documents(    docs,    embeddings,    url=url,    prefer_grpc=True,    collection_name="my_documents",    force_recreate=True,)  query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search(query) query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search(query)  print(found_docs[0].page_content) print(found_docs[0].page_content)      Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.     Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.     Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.  query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query) query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query)  document, score = found_docs[0]print(document.page_content)print(f"\nScore: {score}") document, score = found_docs[0]print(document.page_content)print(f"\nScore: {score}")      Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.        Score: 0.8153784913324512     Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.        Score: 0.8153784913324512     Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.        Score: 0.8153784913324512  from qdrant_client.http import models as restquery = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query, filter=rest.Filter(...)) from qdrant_client.http import models as restquery = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.similarity_search_with_score(query, filter=rest.Filter(...))  query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.max_marginal_relevance_search(query, k=2, fetch_k=10) query = "What did the president say about Ketanji Brown Jackson"found_docs = qdrant.max_marginal_relevance_search(query, k=2, fetch_k=10)  for i, doc in enumerate(found_docs):    print(f"{i + 1}.", doc.page_content, "\n") for i, doc in enumerate(found_docs):    print(f"{i + 1}.", doc.page_content, "\n")      1. Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.         2. We can‚Äôt change how divided we‚Äôve been. But we can change how we move forward‚Äîon COVID-19 and other issues we must face together.         I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera.         They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun.         Officer Mora was 27 years old.         Officer Rivera was 22.         Both Dominican Americans who‚Äôd grown up on the same streets they later chose to patrol as police officers.         I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.         I‚Äôve worked on these issues a long time.         I know what works: Investing in crime preventionand community police officers who‚Äôll walk the beat, who‚Äôll know the neighborhood, and who can restore trust and safety.          1. Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.         2. We can‚Äôt change how divided we‚Äôve been. But we can change how we move forward‚Äîon COVID-19 and other issues we must face together.         I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera.         They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun.         Officer Mora was 27 years old.         Officer Rivera was 22.         Both Dominican Americans who‚Äôd grown up on the same streets they later chose to patrol as police officers.         I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.         I‚Äôve worked on these issues a long time.         I know what works: Investing in crime preventionand community police officers who‚Äôll walk the beat, who‚Äôll know the neighborhood, and who can restore trust and safety.          1. Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.         2. We can‚Äôt change how divided we‚Äôve been. But we can change how we move forward‚Äîon COVID-19 and other issues we must face together.         I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera.         They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun.         Officer Mora was 27 years old.         Officer Rivera was 22.         Both Dominican Americans who‚Äôd grown up on the same streets they later chose to patrol as police officers.         I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.         I‚Äôve worked on these issues a long time.         I know what works: Investing in crime preventionand community police officers who‚Äôll walk the beat, who‚Äôll know the neighborhood, and who can restore trust and safety.       retriever = qdrant.as_retriever()retriever retriever = qdrant.as_retriever()retriever      VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='similarity', search_kwargs={})     VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='similarity', search_kwargs={})     VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='similarity', search_kwargs={})  retriever = qdrant.as_retriever(search_type="mmr")retriever retriever = qdrant.as_retriever(search_type="mmr")retriever      VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='mmr', search_kwargs={})     VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='mmr', search_kwargs={})     VectorStoreRetriever(vectorstore=<langchain.vectorstores.qdrant.Qdrant object at 0x7fc4e5720a00>, search_type='mmr', search_kwargs={})  query = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0] query = "What did the president say about Ketanji Brown Jackson"retriever.get_relevant_documents(query)[0]      Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.', metadata={'source': '../../../state_of_the_union.txt'})     Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.', metadata={'source': '../../../state_of_the_union.txt'})     Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections. \n\nTonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.', metadata={'source': '../../../state_of_the_union.txt'})  Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    vector_name="custom_vector",) Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    vector_name="custom_vector",)  {    "page_content": "Lorem ipsum dolor sit amet",    "metadata": {        "foo": "bar"    }} {    "page_content": "Lorem ipsum dolor sit amet",    "metadata": {        "foo": "bar"    }}  Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    content_payload_key="my_page_content_key",    metadata_payload_key="my_meta",) Qdrant.from_documents(    docs,    embeddings,    location=":memory:",    collection_name="my_documents_2",    content_payload_key="my_page_content_key",    metadata_payload_key="my_meta",)      <langchain.vectorstores.qdrant.Qdrant at 0x7fc4e2baa230>     <langchain.vectorstores.qdrant.Qdrant at 0x7fc4e2baa230>     <langchain.vectorstores.qdrant.Qdrant at 0x7fc4e2baa230>  Previous Pinecone Next Redis Connecting to Qdrant from LangChainLocal modeOn-premise server deploymentQdrant CloudRecreating the collectionSimilarity searchSimilarity search with scoreMetadata filteringMaximum marginal relevance search (MMR)Qdrant as a RetrieverCustomizing QdrantNamed vectorsMetadata Connecting to Qdrant from LangChainLocal modeOn-premise server deploymentQdrant CloudRecreating the collectionSimilarity searchSimilarity search with scoreMetadata filteringMaximum marginal relevance search (MMR)Qdrant as a RetrieverCustomizing QdrantNamed vectorsMetadata CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Activeloop Deep Lake (/docs/integrations/vectorstores/activeloop_deeplake) Alibaba Cloud OpenSearch (/docs/integrations/vectorstores/alibabacloud_opensearch) AnalyticDB (/docs/integrations/vectorstores/analyticdb) Annoy (/docs/integrations/vectorstores/annoy) Atlas (/docs/integrations/vectorstores/atlas) AwaDB (/docs/integrations/vectorstores/awadb) Azure Cognitive Search (/docs/integrations/vectorstores/azuresearch) BagelDB (/docs/integrations/vectorstores/bageldb) Cassandra (/docs/integrations/vectorstores/cassandra) Chroma (/docs/integrations/vectorstores/chroma) ClickHouse (/docs/integrations/vectorstores/clickhouse) DashVector (/docs/integrations/vectorstores/dashvector) Dingo (/docs/integrations/vectorstores/dingo) DocArray HnswSearch (/docs/integrations/vectorstores/docarray_hnsw) DocArray InMemorySearch (/docs/integrations/vectorstores/docarray_in_memory) Elasticsearch (/docs/integrations/vectorstores/elasticsearch) Epsilla (/docs/integrations/vectorstores/epsilla) Faiss (/docs/integrations/vectorstores/faiss) Hologres (/docs/integrations/vectorstores/hologres) LanceDB (/docs/integrations/vectorstores/lancedb) Marqo (/docs/integrations/vectorstores/marqo) Google Vertex AI MatchingEngine (/docs/integrations/vectorstores/matchingengine) Meilisearch (/docs/integrations/vectorstores/meilisearch) Milvus (/docs/integrations/vectorstores/milvus) MongoDB Atlas (/docs/integrations/vectorstores/mongodb_atlas) MyScale (/docs/integrations/vectorstores/myscale) Neo4j Vector Index (/docs/integrations/vectorstores/neo4jvector) NucliaDB (/docs/integrations/vectorstores/nucliadb) OpenSearch (/docs/integrations/vectorstores/opensearch) Postgres Embedding (/docs/integrations/vectorstores/pgembedding) PGVector (/docs/integrations/vectorstores/pgvector) Pinecone (/docs/integrations/vectorstores/pinecone) Qdrant (/docs/integrations/vectorstores/qdrant) Redis (/docs/integrations/vectorstores/redis) Rockset (/docs/integrations/vectorstores/rockset) ScaNN (/docs/integrations/vectorstores/scann) SingleStoreDB (/docs/integrations/vectorstores/singlestoredb) scikit-learn (/docs/integrations/vectorstores/sklearn) sqlite-vss (/docs/integrations/vectorstores/sqlitevss) StarRocks (/docs/integrations/vectorstores/starrocks) Supabase (Postgres) (/docs/integrations/vectorstores/supabase) Tair (/docs/integrations/vectorstores/tair) Tencent Cloud VectorDB (/docs/integrations/vectorstores/tencentvectordb) Tigris (/docs/integrations/vectorstores/tigris) Typesense (/docs/integrations/vectorstores/typesense) USearch (/docs/integrations/vectorstores/usearch) vearch (/docs/integrations/vectorstores/vearch) Vectara (/docs/integrations/vectorstores/vectara) Weaviate (/docs/integrations/vectorstores/weaviate) Xata (/docs/integrations/vectorstores/xata) Zep (/docs/integrations/vectorstores/zep) Zilliz (/docs/integrations/vectorstores/zilliz) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Vector stores (/docs/integrations/vectorstores/) Qdrant (https://qdrant.tech/documentation/) installation instructions (https://qdrant.tech/documentation/install/) OpenAIEmbeddings (https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html) CharacterTextSplitter (https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.CharacterTextSplitter.html) Qdrant (https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.qdrant.Qdrant.html) TextLoader (https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.text.TextLoader.html) ‚Äã (#connecting-to-qdrant-from-langchain) ‚Äã (#local-mode) ‚Äã (#in-memory) ‚Äã (#on-disk-storage) ‚Äã (#on-premise-server-deployment) a Docker container (https://qdrant.tech/documentation/install/) the official Helm chart (https://github.com/qdrant/qdrant-helm) ‚Äã (#qdrant-cloud) Qdrant Cloud (https://cloud.qdrant.io/) ‚Äã (#recreating-the-collection) ‚Äã (#similarity-search) ‚Äã (#similarity-search-with-score) ‚Äã (#metadata-filtering) extensive filtering system (https://qdrant.tech/documentation/concepts/filtering/) ‚Äã (#maximum-marginal-relevance-search-mmr) ‚Äã (#qdrant-as-a-retriever) ‚Äã (#customizing-qdrant) ‚Äã (#named-vectors) multiple vectors per point (https://qdrant.tech/documentation/concepts/collections/#collection-with-multiple-vectors) ‚Äã (#metadata) PreviousPinecone (/docs/integrations/vectorstores/pinecone) NextRedis (/docs/integrations/vectorstores/redis) Connecting to Qdrant from LangChain (#connecting-to-qdrant-from-langchain) Local mode (#local-mode) On-premise server deployment (#on-premise-server-deployment) Qdrant Cloud (#qdrant-cloud) Recreating the collection (#recreating-the-collection) Similarity search (#similarity-search) Similarity search with score (#similarity-search-with-score) Metadata filtering (#metadata-filtering) Maximum marginal relevance search (MMR) (#maximum-marginal-relevance-search-mmr) Qdrant as a Retriever (#qdrant-as-a-retriever) Customizing Qdrant (#customizing-qdrant) Named vectors (#named-vectors) Metadata (#metadata) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)