Simple retriever that applies an LLM between the user input and the query pass the to retriever. It can be used to pre-process the user input in any way. The default prompt used in the from_llm classmethod: Create a vectorstore. IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversAmazon KendraArxivAzure Cognitive SearchBM25ChaindeskChatGPT PluginCohere RerankerDocArray RetrieverElasticSearch BM25Google Cloud Enterprise SearchGoogle Drive RetrieverkNNLOTR (Merger Retriever)MetalPinecone Hybrid SearchPubMedRePhraseQueryRetrieverSVMTF-IDFVespaWeaviate Hybrid SearchWikipediaZepText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory RetrieversAmazon KendraArxivAzure Cognitive SearchBM25ChaindeskChatGPT PluginCohere RerankerDocArray RetrieverElasticSearch BM25Google Cloud Enterprise SearchGoogle Drive RetrieverkNNLOTR (Merger Retriever)MetalPinecone Hybrid SearchPubMedRePhraseQueryRetrieverSVMTF-IDFVespaWeaviate Hybrid SearchWikipediaZep Amazon Kendra Arxiv Azure Cognitive Search BM25 Chaindesk ChatGPT Plugin Cohere Reranker DocArray Retriever ElasticSearch BM25 Google Cloud Enterprise Search Google Drive Retriever kNN LOTR (Merger Retriever) Metal Pinecone Hybrid Search PubMed RePhraseQueryRetriever SVM TF-IDF Vespa Weaviate Hybrid Search Wikipedia Zep Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider  Integrations Retrievers RePhraseQueryRetriever WebBaseLoader RecursiveCharacterTextSplitter Chroma OpenAIEmbeddings ChatOpenAI RePhraseQueryRetriever PromptTemplate Using the default prompt Supply a prompt Discord Twitter Python JS/TS Homepage Blog Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKIntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversAmazon KendraArxivAzure Cognitive SearchBM25ChaindeskChatGPT PluginCohere RerankerDocArray RetrieverElasticSearch BM25Google Cloud Enterprise SearchGoogle Drive RetrieverkNNLOTR (Merger Retriever)MetalPinecone Hybrid SearchPubMedRePhraseQueryRetrieverSVMTF-IDFVespaWeaviate Hybrid SearchWikipediaZepText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsRetrieversRePhraseQueryRetrieverOn this pageRePhraseQueryRetrieverSimple retriever that applies an LLM between the user input and the query pass the to retriever.It can be used to pre-process the user input in any way.The default prompt used in the from_llm classmethod:DEFAULT_TEMPLATE = """You are an assistant tasked with taking a natural language \query from a user and converting it into a query for a vectorstore. \In this process, you strip out information that is not relevant for \the retrieval task. Here is the user query: {question}"""Create a vectorstore.from langchain.document_loaders import WebBaseLoaderloader = WebBaseLoader("https://lilianweng.github.io/posts/2023-06-23-agent/")data = loader.load()from langchain.text_splitter import RecursiveCharacterTextSplittertext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)all_splits = text_splitter.split_documents(data)from langchain.vectorstores import Chromafrom langchain.embeddings import OpenAIEmbeddingsvectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())API Reference:WebBaseLoaderRecursiveCharacterTextSplitterChromaOpenAIEmbeddingsimport logginglogging.basicConfig()logging.getLogger("langchain.retrievers.re_phraser").setLevel(logging.INFO)from langchain.chat_models import ChatOpenAIfrom langchain.retrievers import RePhraseQueryRetrieverAPI Reference:ChatOpenAIRePhraseQueryRetrieverUsing the default prompt‚Äãllm = ChatOpenAI(temperature=0)retriever_from_llm = RePhraseQueryRetriever.from_llm(    retriever=vectorstore.as_retriever(), llm=llm)docs = retriever_from_llm.get_relevant_documents(    "Hi I'm Lance. What are the approaches to Task Decomposition?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: The user query can be converted into a query for a vectorstore as follows:        "approaches to Task Decomposition"docs = retriever_from_llm.get_relevant_documents(    "I live in San Francisco. What are the Types of Memory?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Query for vectorstore: "Types of Memory"Supply a prompt‚Äãfrom langchain import LLMChainfrom langchain.prompts import PromptTemplateQUERY_PROMPT = PromptTemplate(    input_variables=["question"],    template="""You are an assistant tasked with taking a natural languge query from a user    and converting it into a query for a vectorstore. In the process, strip out all     information that is not relevant for the retrieval task and return a new, simplified    question for vectorstore retrieval. The new user query should be in pirate speech.    Here is the user query: {question} """,)llm = ChatOpenAI(temperature=0)llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT)API Reference:PromptTemplateretriever_from_llm_chain = RePhraseQueryRetriever(    retriever=vectorstore.as_retriever(), llm_chain=llm_chain)docs = retriever_from_llm_chain.get_relevant_documents(    "Hi I'm Lance. What is Maximum Inner Product Search?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Ahoy matey! What be Maximum Inner Product Search, ye scurvy dog?PreviousPubMedNextSVMUsing the default promptSupply a promptCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. Skip to main content ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLK ü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPI LangSmithJS/TS DocsCTRLK  CTRLK CTRLK  CTRLK   IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversAmazon KendraArxivAzure Cognitive SearchBM25ChaindeskChatGPT PluginCohere RerankerDocArray RetrieverElasticSearch BM25Google Cloud Enterprise SearchGoogle Drive RetrieverkNNLOTR (Merger Retriever)MetalPinecone Hybrid SearchPubMedRePhraseQueryRetrieverSVMTF-IDFVespaWeaviate Hybrid SearchWikipediaZepText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsRetrieversRePhraseQueryRetrieverOn this pageRePhraseQueryRetrieverSimple retriever that applies an LLM between the user input and the query pass the to retriever.It can be used to pre-process the user input in any way.The default prompt used in the from_llm classmethod:DEFAULT_TEMPLATE = """You are an assistant tasked with taking a natural language \query from a user and converting it into a query for a vectorstore. \In this process, you strip out information that is not relevant for \the retrieval task. Here is the user query: {question}"""Create a vectorstore.from langchain.document_loaders import WebBaseLoaderloader = WebBaseLoader("https://lilianweng.github.io/posts/2023-06-23-agent/")data = loader.load()from langchain.text_splitter import RecursiveCharacterTextSplittertext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)all_splits = text_splitter.split_documents(data)from langchain.vectorstores import Chromafrom langchain.embeddings import OpenAIEmbeddingsvectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())API Reference:WebBaseLoaderRecursiveCharacterTextSplitterChromaOpenAIEmbeddingsimport logginglogging.basicConfig()logging.getLogger("langchain.retrievers.re_phraser").setLevel(logging.INFO)from langchain.chat_models import ChatOpenAIfrom langchain.retrievers import RePhraseQueryRetrieverAPI Reference:ChatOpenAIRePhraseQueryRetrieverUsing the default prompt‚Äãllm = ChatOpenAI(temperature=0)retriever_from_llm = RePhraseQueryRetriever.from_llm(    retriever=vectorstore.as_retriever(), llm=llm)docs = retriever_from_llm.get_relevant_documents(    "Hi I'm Lance. What are the approaches to Task Decomposition?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: The user query can be converted into a query for a vectorstore as follows:        "approaches to Task Decomposition"docs = retriever_from_llm.get_relevant_documents(    "I live in San Francisco. What are the Types of Memory?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Query for vectorstore: "Types of Memory"Supply a prompt‚Äãfrom langchain import LLMChainfrom langchain.prompts import PromptTemplateQUERY_PROMPT = PromptTemplate(    input_variables=["question"],    template="""You are an assistant tasked with taking a natural languge query from a user    and converting it into a query for a vectorstore. In the process, strip out all     information that is not relevant for the retrieval task and return a new, simplified    question for vectorstore retrieval. The new user query should be in pirate speech.    Here is the user query: {question} """,)llm = ChatOpenAI(temperature=0)llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT)API Reference:PromptTemplateretriever_from_llm_chain = RePhraseQueryRetriever(    retriever=vectorstore.as_retriever(), llm_chain=llm_chain)docs = retriever_from_llm_chain.get_relevant_documents(    "Hi I'm Lance. What is Maximum Inner Product Search?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Ahoy matey! What be Maximum Inner Product Search, ye scurvy dog?PreviousPubMedNextSVMUsing the default promptSupply a prompt IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversAmazon KendraArxivAzure Cognitive SearchBM25ChaindeskChatGPT PluginCohere RerankerDocArray RetrieverElasticSearch BM25Google Cloud Enterprise SearchGoogle Drive RetrieverkNNLOTR (Merger Retriever)MetalPinecone Hybrid SearchPubMedRePhraseQueryRetrieverSVMTF-IDFVespaWeaviate Hybrid SearchWikipediaZepText embedding modelsAgents & ToolkitsToolsVector storesGrouped by providerIntegrationsRetrieversRePhraseQueryRetrieverOn this pageRePhraseQueryRetrieverSimple retriever that applies an LLM between the user input and the query pass the to retriever.It can be used to pre-process the user input in any way.The default prompt used in the from_llm classmethod:DEFAULT_TEMPLATE = """You are an assistant tasked with taking a natural language \query from a user and converting it into a query for a vectorstore. \In this process, you strip out information that is not relevant for \the retrieval task. Here is the user query: {question}"""Create a vectorstore.from langchain.document_loaders import WebBaseLoaderloader = WebBaseLoader("https://lilianweng.github.io/posts/2023-06-23-agent/")data = loader.load()from langchain.text_splitter import RecursiveCharacterTextSplittertext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)all_splits = text_splitter.split_documents(data)from langchain.vectorstores import Chromafrom langchain.embeddings import OpenAIEmbeddingsvectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())API Reference:WebBaseLoaderRecursiveCharacterTextSplitterChromaOpenAIEmbeddingsimport logginglogging.basicConfig()logging.getLogger("langchain.retrievers.re_phraser").setLevel(logging.INFO)from langchain.chat_models import ChatOpenAIfrom langchain.retrievers import RePhraseQueryRetrieverAPI Reference:ChatOpenAIRePhraseQueryRetrieverUsing the default prompt‚Äãllm = ChatOpenAI(temperature=0)retriever_from_llm = RePhraseQueryRetriever.from_llm(    retriever=vectorstore.as_retriever(), llm=llm)docs = retriever_from_llm.get_relevant_documents(    "Hi I'm Lance. What are the approaches to Task Decomposition?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: The user query can be converted into a query for a vectorstore as follows:        "approaches to Task Decomposition"docs = retriever_from_llm.get_relevant_documents(    "I live in San Francisco. What are the Types of Memory?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Query for vectorstore: "Types of Memory"Supply a prompt‚Äãfrom langchain import LLMChainfrom langchain.prompts import PromptTemplateQUERY_PROMPT = PromptTemplate(    input_variables=["question"],    template="""You are an assistant tasked with taking a natural languge query from a user    and converting it into a query for a vectorstore. In the process, strip out all     information that is not relevant for the retrieval task and return a new, simplified    question for vectorstore retrieval. The new user query should be in pirate speech.    Here is the user query: {question} """,)llm = ChatOpenAI(temperature=0)llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT)API Reference:PromptTemplateretriever_from_llm_chain = RePhraseQueryRetriever(    retriever=vectorstore.as_retriever(), llm_chain=llm_chain)docs = retriever_from_llm_chain.get_relevant_documents(    "Hi I'm Lance. What is Maximum Inner Product Search?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Ahoy matey! What be Maximum Inner Product Search, ye scurvy dog?PreviousPubMedNextSVMUsing the default promptSupply a prompt IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversAmazon KendraArxivAzure Cognitive SearchBM25ChaindeskChatGPT PluginCohere RerankerDocArray RetrieverElasticSearch BM25Google Cloud Enterprise SearchGoogle Drive RetrieverkNNLOTR (Merger Retriever)MetalPinecone Hybrid SearchPubMedRePhraseQueryRetrieverSVMTF-IDFVespaWeaviate Hybrid SearchWikipediaZepText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider IntegrationsCallbacksChat modelsChat loadersDocument loadersDocument transformersLLMsMemoryRetrieversAmazon KendraArxivAzure Cognitive SearchBM25ChaindeskChatGPT PluginCohere RerankerDocArray RetrieverElasticSearch BM25Google Cloud Enterprise SearchGoogle Drive RetrieverkNNLOTR (Merger Retriever)MetalPinecone Hybrid SearchPubMedRePhraseQueryRetrieverSVMTF-IDFVespaWeaviate Hybrid SearchWikipediaZepText embedding modelsAgents & ToolkitsToolsVector storesGrouped by provider Integrations Callbacks Chat models Chat loaders Document loaders Document transformers LLMs Memory Retrievers Text embedding models Agents & Toolkits Tools Vector stores Grouped by provider IntegrationsRetrieversRePhraseQueryRetrieverOn this pageRePhraseQueryRetrieverSimple retriever that applies an LLM between the user input and the query pass the to retriever.It can be used to pre-process the user input in any way.The default prompt used in the from_llm classmethod:DEFAULT_TEMPLATE = """You are an assistant tasked with taking a natural language \query from a user and converting it into a query for a vectorstore. \In this process, you strip out information that is not relevant for \the retrieval task. Here is the user query: {question}"""Create a vectorstore.from langchain.document_loaders import WebBaseLoaderloader = WebBaseLoader("https://lilianweng.github.io/posts/2023-06-23-agent/")data = loader.load()from langchain.text_splitter import RecursiveCharacterTextSplittertext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)all_splits = text_splitter.split_documents(data)from langchain.vectorstores import Chromafrom langchain.embeddings import OpenAIEmbeddingsvectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())API Reference:WebBaseLoaderRecursiveCharacterTextSplitterChromaOpenAIEmbeddingsimport logginglogging.basicConfig()logging.getLogger("langchain.retrievers.re_phraser").setLevel(logging.INFO)from langchain.chat_models import ChatOpenAIfrom langchain.retrievers import RePhraseQueryRetrieverAPI Reference:ChatOpenAIRePhraseQueryRetrieverUsing the default prompt‚Äãllm = ChatOpenAI(temperature=0)retriever_from_llm = RePhraseQueryRetriever.from_llm(    retriever=vectorstore.as_retriever(), llm=llm)docs = retriever_from_llm.get_relevant_documents(    "Hi I'm Lance. What are the approaches to Task Decomposition?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: The user query can be converted into a query for a vectorstore as follows:        "approaches to Task Decomposition"docs = retriever_from_llm.get_relevant_documents(    "I live in San Francisco. What are the Types of Memory?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Query for vectorstore: "Types of Memory"Supply a prompt‚Äãfrom langchain import LLMChainfrom langchain.prompts import PromptTemplateQUERY_PROMPT = PromptTemplate(    input_variables=["question"],    template="""You are an assistant tasked with taking a natural languge query from a user    and converting it into a query for a vectorstore. In the process, strip out all     information that is not relevant for the retrieval task and return a new, simplified    question for vectorstore retrieval. The new user query should be in pirate speech.    Here is the user query: {question} """,)llm = ChatOpenAI(temperature=0)llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT)API Reference:PromptTemplateretriever_from_llm_chain = RePhraseQueryRetriever(    retriever=vectorstore.as_retriever(), llm_chain=llm_chain)docs = retriever_from_llm_chain.get_relevant_documents(    "Hi I'm Lance. What is Maximum Inner Product Search?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Ahoy matey! What be Maximum Inner Product Search, ye scurvy dog?PreviousPubMedNextSVMUsing the default promptSupply a prompt IntegrationsRetrieversRePhraseQueryRetrieverOn this pageRePhraseQueryRetrieverSimple retriever that applies an LLM between the user input and the query pass the to retriever.It can be used to pre-process the user input in any way.The default prompt used in the from_llm classmethod:DEFAULT_TEMPLATE = """You are an assistant tasked with taking a natural language \query from a user and converting it into a query for a vectorstore. \In this process, you strip out information that is not relevant for \the retrieval task. Here is the user query: {question}"""Create a vectorstore.from langchain.document_loaders import WebBaseLoaderloader = WebBaseLoader("https://lilianweng.github.io/posts/2023-06-23-agent/")data = loader.load()from langchain.text_splitter import RecursiveCharacterTextSplittertext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)all_splits = text_splitter.split_documents(data)from langchain.vectorstores import Chromafrom langchain.embeddings import OpenAIEmbeddingsvectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())API Reference:WebBaseLoaderRecursiveCharacterTextSplitterChromaOpenAIEmbeddingsimport logginglogging.basicConfig()logging.getLogger("langchain.retrievers.re_phraser").setLevel(logging.INFO)from langchain.chat_models import ChatOpenAIfrom langchain.retrievers import RePhraseQueryRetrieverAPI Reference:ChatOpenAIRePhraseQueryRetrieverUsing the default prompt‚Äãllm = ChatOpenAI(temperature=0)retriever_from_llm = RePhraseQueryRetriever.from_llm(    retriever=vectorstore.as_retriever(), llm=llm)docs = retriever_from_llm.get_relevant_documents(    "Hi I'm Lance. What are the approaches to Task Decomposition?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: The user query can be converted into a query for a vectorstore as follows:        "approaches to Task Decomposition"docs = retriever_from_llm.get_relevant_documents(    "I live in San Francisco. What are the Types of Memory?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Query for vectorstore: "Types of Memory"Supply a prompt‚Äãfrom langchain import LLMChainfrom langchain.prompts import PromptTemplateQUERY_PROMPT = PromptTemplate(    input_variables=["question"],    template="""You are an assistant tasked with taking a natural languge query from a user    and converting it into a query for a vectorstore. In the process, strip out all     information that is not relevant for the retrieval task and return a new, simplified    question for vectorstore retrieval. The new user query should be in pirate speech.    Here is the user query: {question} """,)llm = ChatOpenAI(temperature=0)llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT)API Reference:PromptTemplateretriever_from_llm_chain = RePhraseQueryRetriever(    retriever=vectorstore.as_retriever(), llm_chain=llm_chain)docs = retriever_from_llm_chain.get_relevant_documents(    "Hi I'm Lance. What is Maximum Inner Product Search?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Ahoy matey! What be Maximum Inner Product Search, ye scurvy dog?PreviousPubMedNextSVMUsing the default promptSupply a prompt IntegrationsRetrieversRePhraseQueryRetrieverOn this pageRePhraseQueryRetrieverSimple retriever that applies an LLM between the user input and the query pass the to retriever.It can be used to pre-process the user input in any way.The default prompt used in the from_llm classmethod:DEFAULT_TEMPLATE = """You are an assistant tasked with taking a natural language \query from a user and converting it into a query for a vectorstore. \In this process, you strip out information that is not relevant for \the retrieval task. Here is the user query: {question}"""Create a vectorstore.from langchain.document_loaders import WebBaseLoaderloader = WebBaseLoader("https://lilianweng.github.io/posts/2023-06-23-agent/")data = loader.load()from langchain.text_splitter import RecursiveCharacterTextSplittertext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)all_splits = text_splitter.split_documents(data)from langchain.vectorstores import Chromafrom langchain.embeddings import OpenAIEmbeddingsvectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())API Reference:WebBaseLoaderRecursiveCharacterTextSplitterChromaOpenAIEmbeddingsimport logginglogging.basicConfig()logging.getLogger("langchain.retrievers.re_phraser").setLevel(logging.INFO)from langchain.chat_models import ChatOpenAIfrom langchain.retrievers import RePhraseQueryRetrieverAPI Reference:ChatOpenAIRePhraseQueryRetrieverUsing the default prompt‚Äãllm = ChatOpenAI(temperature=0)retriever_from_llm = RePhraseQueryRetriever.from_llm(    retriever=vectorstore.as_retriever(), llm=llm)docs = retriever_from_llm.get_relevant_documents(    "Hi I'm Lance. What are the approaches to Task Decomposition?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: The user query can be converted into a query for a vectorstore as follows:        "approaches to Task Decomposition"docs = retriever_from_llm.get_relevant_documents(    "I live in San Francisco. What are the Types of Memory?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Query for vectorstore: "Types of Memory"Supply a prompt‚Äãfrom langchain import LLMChainfrom langchain.prompts import PromptTemplateQUERY_PROMPT = PromptTemplate(    input_variables=["question"],    template="""You are an assistant tasked with taking a natural languge query from a user    and converting it into a query for a vectorstore. In the process, strip out all     information that is not relevant for the retrieval task and return a new, simplified    question for vectorstore retrieval. The new user query should be in pirate speech.    Here is the user query: {question} """,)llm = ChatOpenAI(temperature=0)llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT)API Reference:PromptTemplateretriever_from_llm_chain = RePhraseQueryRetriever(    retriever=vectorstore.as_retriever(), llm_chain=llm_chain)docs = retriever_from_llm_chain.get_relevant_documents(    "Hi I'm Lance. What is Maximum Inner Product Search?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Ahoy matey! What be Maximum Inner Product Search, ye scurvy dog?PreviousPubMedNextSVM IntegrationsRetrieversRePhraseQueryRetrieverOn this pageRePhraseQueryRetrieverSimple retriever that applies an LLM between the user input and the query pass the to retriever.It can be used to pre-process the user input in any way.The default prompt used in the from_llm classmethod:DEFAULT_TEMPLATE = """You are an assistant tasked with taking a natural language \query from a user and converting it into a query for a vectorstore. \In this process, you strip out information that is not relevant for \the retrieval task. Here is the user query: {question}"""Create a vectorstore.from langchain.document_loaders import WebBaseLoaderloader = WebBaseLoader("https://lilianweng.github.io/posts/2023-06-23-agent/")data = loader.load()from langchain.text_splitter import RecursiveCharacterTextSplittertext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)all_splits = text_splitter.split_documents(data)from langchain.vectorstores import Chromafrom langchain.embeddings import OpenAIEmbeddingsvectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())API Reference:WebBaseLoaderRecursiveCharacterTextSplitterChromaOpenAIEmbeddingsimport logginglogging.basicConfig()logging.getLogger("langchain.retrievers.re_phraser").setLevel(logging.INFO)from langchain.chat_models import ChatOpenAIfrom langchain.retrievers import RePhraseQueryRetrieverAPI Reference:ChatOpenAIRePhraseQueryRetrieverUsing the default prompt‚Äãllm = ChatOpenAI(temperature=0)retriever_from_llm = RePhraseQueryRetriever.from_llm(    retriever=vectorstore.as_retriever(), llm=llm)docs = retriever_from_llm.get_relevant_documents(    "Hi I'm Lance. What are the approaches to Task Decomposition?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: The user query can be converted into a query for a vectorstore as follows:        "approaches to Task Decomposition"docs = retriever_from_llm.get_relevant_documents(    "I live in San Francisco. What are the Types of Memory?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Query for vectorstore: "Types of Memory"Supply a prompt‚Äãfrom langchain import LLMChainfrom langchain.prompts import PromptTemplateQUERY_PROMPT = PromptTemplate(    input_variables=["question"],    template="""You are an assistant tasked with taking a natural languge query from a user    and converting it into a query for a vectorstore. In the process, strip out all     information that is not relevant for the retrieval task and return a new, simplified    question for vectorstore retrieval. The new user query should be in pirate speech.    Here is the user query: {question} """,)llm = ChatOpenAI(temperature=0)llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT)API Reference:PromptTemplateretriever_from_llm_chain = RePhraseQueryRetriever(    retriever=vectorstore.as_retriever(), llm_chain=llm_chain)docs = retriever_from_llm_chain.get_relevant_documents(    "Hi I'm Lance. What is Maximum Inner Product Search?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Ahoy matey! What be Maximum Inner Product Search, ye scurvy dog?PreviousPubMedNextSVM On this page RePhraseQueryRetrieverSimple retriever that applies an LLM between the user input and the query pass the to retriever.It can be used to pre-process the user input in any way.The default prompt used in the from_llm classmethod:DEFAULT_TEMPLATE = """You are an assistant tasked with taking a natural language \query from a user and converting it into a query for a vectorstore. \In this process, you strip out information that is not relevant for \the retrieval task. Here is the user query: {question}"""Create a vectorstore.from langchain.document_loaders import WebBaseLoaderloader = WebBaseLoader("https://lilianweng.github.io/posts/2023-06-23-agent/")data = loader.load()from langchain.text_splitter import RecursiveCharacterTextSplittertext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)all_splits = text_splitter.split_documents(data)from langchain.vectorstores import Chromafrom langchain.embeddings import OpenAIEmbeddingsvectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())API Reference:WebBaseLoaderRecursiveCharacterTextSplitterChromaOpenAIEmbeddingsimport logginglogging.basicConfig()logging.getLogger("langchain.retrievers.re_phraser").setLevel(logging.INFO)from langchain.chat_models import ChatOpenAIfrom langchain.retrievers import RePhraseQueryRetrieverAPI Reference:ChatOpenAIRePhraseQueryRetrieverUsing the default prompt‚Äãllm = ChatOpenAI(temperature=0)retriever_from_llm = RePhraseQueryRetriever.from_llm(    retriever=vectorstore.as_retriever(), llm=llm)docs = retriever_from_llm.get_relevant_documents(    "Hi I'm Lance. What are the approaches to Task Decomposition?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: The user query can be converted into a query for a vectorstore as follows:        "approaches to Task Decomposition"docs = retriever_from_llm.get_relevant_documents(    "I live in San Francisco. What are the Types of Memory?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Query for vectorstore: "Types of Memory"Supply a prompt‚Äãfrom langchain import LLMChainfrom langchain.prompts import PromptTemplateQUERY_PROMPT = PromptTemplate(    input_variables=["question"],    template="""You are an assistant tasked with taking a natural languge query from a user    and converting it into a query for a vectorstore. In the process, strip out all     information that is not relevant for the retrieval task and return a new, simplified    question for vectorstore retrieval. The new user query should be in pirate speech.    Here is the user query: {question} """,)llm = ChatOpenAI(temperature=0)llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT)API Reference:PromptTemplateretriever_from_llm_chain = RePhraseQueryRetriever(    retriever=vectorstore.as_retriever(), llm_chain=llm_chain)docs = retriever_from_llm_chain.get_relevant_documents(    "Hi I'm Lance. What is Maximum Inner Product Search?")    INFO:langchain.retrievers.re_phraser:Re-phrased question: Ahoy matey! What be Maximum Inner Product Search, ye scurvy dog? DEFAULT_TEMPLATE = """You are an assistant tasked with taking a natural language \query from a user and converting it into a query for a vectorstore. \In this process, you strip out information that is not relevant for \the retrieval task. Here is the user query: {question}""" DEFAULT_TEMPLATE = """You are an assistant tasked with taking a natural language \query from a user and converting it into a query for a vectorstore. \In this process, you strip out information that is not relevant for \the retrieval task. Here is the user query: {question}"""  from langchain.document_loaders import WebBaseLoaderloader = WebBaseLoader("https://lilianweng.github.io/posts/2023-06-23-agent/")data = loader.load()from langchain.text_splitter import RecursiveCharacterTextSplittertext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)all_splits = text_splitter.split_documents(data)from langchain.vectorstores import Chromafrom langchain.embeddings import OpenAIEmbeddingsvectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings()) from langchain.document_loaders import WebBaseLoaderloader = WebBaseLoader("https://lilianweng.github.io/posts/2023-06-23-agent/")data = loader.load()from langchain.text_splitter import RecursiveCharacterTextSplittertext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)all_splits = text_splitter.split_documents(data)from langchain.vectorstores import Chromafrom langchain.embeddings import OpenAIEmbeddingsvectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())  API Reference:WebBaseLoaderRecursiveCharacterTextSplitterChromaOpenAIEmbeddings import logginglogging.basicConfig()logging.getLogger("langchain.retrievers.re_phraser").setLevel(logging.INFO) import logginglogging.basicConfig()logging.getLogger("langchain.retrievers.re_phraser").setLevel(logging.INFO)  from langchain.chat_models import ChatOpenAIfrom langchain.retrievers import RePhraseQueryRetriever from langchain.chat_models import ChatOpenAIfrom langchain.retrievers import RePhraseQueryRetriever  API Reference:ChatOpenAIRePhraseQueryRetriever llm = ChatOpenAI(temperature=0)retriever_from_llm = RePhraseQueryRetriever.from_llm(    retriever=vectorstore.as_retriever(), llm=llm) llm = ChatOpenAI(temperature=0)retriever_from_llm = RePhraseQueryRetriever.from_llm(    retriever=vectorstore.as_retriever(), llm=llm)  docs = retriever_from_llm.get_relevant_documents(    "Hi I'm Lance. What are the approaches to Task Decomposition?") docs = retriever_from_llm.get_relevant_documents(    "Hi I'm Lance. What are the approaches to Task Decomposition?")      INFO:langchain.retrievers.re_phraser:Re-phrased question: The user query can be converted into a query for a vectorstore as follows:        "approaches to Task Decomposition"     INFO:langchain.retrievers.re_phraser:Re-phrased question: The user query can be converted into a query for a vectorstore as follows:        "approaches to Task Decomposition"     INFO:langchain.retrievers.re_phraser:Re-phrased question: The user query can be converted into a query for a vectorstore as follows:        "approaches to Task Decomposition"  docs = retriever_from_llm.get_relevant_documents(    "I live in San Francisco. What are the Types of Memory?") docs = retriever_from_llm.get_relevant_documents(    "I live in San Francisco. What are the Types of Memory?")      INFO:langchain.retrievers.re_phraser:Re-phrased question: Query for vectorstore: "Types of Memory"     INFO:langchain.retrievers.re_phraser:Re-phrased question: Query for vectorstore: "Types of Memory"     INFO:langchain.retrievers.re_phraser:Re-phrased question: Query for vectorstore: "Types of Memory"  from langchain import LLMChainfrom langchain.prompts import PromptTemplateQUERY_PROMPT = PromptTemplate(    input_variables=["question"],    template="""You are an assistant tasked with taking a natural languge query from a user    and converting it into a query for a vectorstore. In the process, strip out all     information that is not relevant for the retrieval task and return a new, simplified    question for vectorstore retrieval. The new user query should be in pirate speech.    Here is the user query: {question} """,)llm = ChatOpenAI(temperature=0)llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT) from langchain import LLMChainfrom langchain.prompts import PromptTemplateQUERY_PROMPT = PromptTemplate(    input_variables=["question"],    template="""You are an assistant tasked with taking a natural languge query from a user    and converting it into a query for a vectorstore. In the process, strip out all     information that is not relevant for the retrieval task and return a new, simplified    question for vectorstore retrieval. The new user query should be in pirate speech.    Here is the user query: {question} """,)llm = ChatOpenAI(temperature=0)llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT)  API Reference:PromptTemplate retriever_from_llm_chain = RePhraseQueryRetriever(    retriever=vectorstore.as_retriever(), llm_chain=llm_chain) retriever_from_llm_chain = RePhraseQueryRetriever(    retriever=vectorstore.as_retriever(), llm_chain=llm_chain)  docs = retriever_from_llm_chain.get_relevant_documents(    "Hi I'm Lance. What is Maximum Inner Product Search?") docs = retriever_from_llm_chain.get_relevant_documents(    "Hi I'm Lance. What is Maximum Inner Product Search?")      INFO:langchain.retrievers.re_phraser:Re-phrased question: Ahoy matey! What be Maximum Inner Product Search, ye scurvy dog?     INFO:langchain.retrievers.re_phraser:Re-phrased question: Ahoy matey! What be Maximum Inner Product Search, ye scurvy dog?     INFO:langchain.retrievers.re_phraser:Re-phrased question: Ahoy matey! What be Maximum Inner Product Search, ye scurvy dog?  Previous PubMed Next SVM Using the default promptSupply a prompt Using the default promptSupply a prompt CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc. CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlog CommunityDiscordTwitter Community GitHubPythonJS/TS GitHub MoreHomepageBlog More Copyright ¬© 2023 LangChain, Inc. Copyright ¬© 2023 LangChain, Inc. Skip to main content (#docusaurus_skipToContent_fallback) ü¶úÔ∏èüîó LangChain (/) Docs (/docs/get_started/introduction) Use cases (/docs/use_cases) Integrations (/docs/integrations) API (https://api.python.langchain.com) LangSmith (https://smith.langchain.com) JS/TS Docs (https://js.langchain.com/docs)  (https://github.com/hwchase17/langchain) Integrations (/docs/integrations) Callbacks (/docs/integrations/callbacks/) Chat models (/docs/integrations/chat/) Chat loaders (/docs/integrations/chat_loaders/) Document loaders (/docs/integrations/document_loaders/) Document transformers (/docs/integrations/document_transformers/) LLMs (/docs/integrations/llms/) Memory (/docs/integrations/memory/) Retrievers (/docs/integrations/retrievers/) Amazon Kendra (/docs/integrations/retrievers/amazon_kendra_retriever) Arxiv (/docs/integrations/retrievers/arxiv) Azure Cognitive Search (/docs/integrations/retrievers/azure_cognitive_search) BM25 (/docs/integrations/retrievers/bm25) Chaindesk (/docs/integrations/retrievers/chaindesk) ChatGPT Plugin (/docs/integrations/retrievers/chatgpt-plugin) Cohere Reranker (/docs/integrations/retrievers/cohere-reranker) DocArray Retriever (/docs/integrations/retrievers/docarray_retriever) ElasticSearch BM25 (/docs/integrations/retrievers/elastic_search_bm25) Google Cloud Enterprise Search (/docs/integrations/retrievers/google_cloud_enterprise_search) Google Drive Retriever (/docs/integrations/retrievers/google_drive) kNN (/docs/integrations/retrievers/knn) LOTR (Merger Retriever) (/docs/integrations/retrievers/merger_retriever) Metal (/docs/integrations/retrievers/metal) Pinecone Hybrid Search (/docs/integrations/retrievers/pinecone_hybrid_search) PubMed (/docs/integrations/retrievers/pubmed) RePhraseQueryRetriever (/docs/integrations/retrievers/re_phrase) SVM (/docs/integrations/retrievers/svm) TF-IDF (/docs/integrations/retrievers/tf_idf) Vespa (/docs/integrations/retrievers/vespa) Weaviate Hybrid Search (/docs/integrations/retrievers/weaviate-hybrid) Wikipedia (/docs/integrations/retrievers/wikipedia) Zep (/docs/integrations/retrievers/zep_memorystore) Text embedding models (/docs/integrations/text_embedding/) Agents & Toolkits (/docs/integrations/toolkits/) Tools (/docs/integrations/tools/) Vector stores (/docs/integrations/vectorstores/) Grouped by provider (/docs/integrations/providers/)  (/) Integrations (/docs/integrations) Retrievers (/docs/integrations/retrievers/) WebBaseLoader (https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.web_base.WebBaseLoader.html) RecursiveCharacterTextSplitter (https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html) Chroma (https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.chroma.Chroma.html) OpenAIEmbeddings (https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html) ChatOpenAI (https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html) RePhraseQueryRetriever (https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.re_phraser.RePhraseQueryRetriever.html) ‚Äã (#using-the-default-prompt) ‚Äã (#supply-a-prompt) PromptTemplate (https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html) PreviousPubMed (/docs/integrations/retrievers/pubmed) NextSVM (/docs/integrations/retrievers/svm) Using the default prompt (#using-the-default-prompt) Supply a prompt (#supply-a-prompt) Discord (https://discord.gg/cU2adEyC7w) Twitter (https://twitter.com/LangChainAI) Python (https://github.com/hwchase17/langchain) JS/TS (https://github.com/hwchase17/langchainjs) Homepage (https://langchain.com) Blog (https://blog.langchain.dev)